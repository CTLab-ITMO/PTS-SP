{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfec1f61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T16:49:59.521174Z",
     "iopub.status.busy": "2024-01-14T16:49:59.520624Z",
     "iopub.status.idle": "2024-01-14T16:51:19.609103Z",
     "shell.execute_reply": "2024-01-14T16:51:19.607625Z"
    },
    "id": "tKyXaYbpvLMm",
    "outputId": "421a4599-fff2-4e30-9da2-d15013fbe64d",
    "papermill": {
     "duration": 80.09738,
     "end_time": "2024-01-14T16:51:19.611524",
     "exception": false,
     "start_time": "2024-01-14T16:49:59.514144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab 4.0.10 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflowjs 4.15.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\r\n",
      "ydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\r\n",
      "Collecting ipywidgets\r\n",
      "  Obtaining dependency information for ipywidgets from https://files.pythonhosted.org/packages/4a/0e/57ed498fafbc60419a9332d872e929879ceba2d73cb11d284d7112472b3e/ipywidgets-8.1.1-py3-none-any.whl.metadata\r\n",
      "  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.1.4)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.14.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\r\n",
      "Collecting widgetsnbextension~=4.0.9 (from ipywidgets)\r\n",
      "  Obtaining dependency information for widgetsnbextension~=4.0.9 from https://files.pythonhosted.org/packages/29/03/107d96077c4befed191f7ad1a12c7b52a8f9d2778a5836d59f9855c105f6/widgetsnbextension-4.0.9-py3-none-any.whl.metadata\r\n",
      "  Downloading widgetsnbextension-4.0.9-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting jupyterlab-widgets~=3.0.9 (from ipywidgets)\r\n",
      "  Obtaining dependency information for jupyterlab-widgets~=3.0.9 from https://files.pythonhosted.org/packages/e8/05/0ebab152288693b5ec7b339aab857362947031143b282853b4c2dd4b5b40/jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata\r\n",
      "  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata (4.1 kB)\r\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\r\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\r\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\r\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\r\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\r\n",
      "Downloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.9/214.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\r\n",
      "  Attempting uninstall: widgetsnbextension\r\n",
      "    Found existing installation: widgetsnbextension 3.6.6\r\n",
      "    Uninstalling widgetsnbextension-3.6.6:\r\n",
      "      Successfully uninstalled widgetsnbextension-3.6.6\r\n",
      "  Attempting uninstall: jupyterlab-widgets\r\n",
      "    Found existing installation: jupyterlab-widgets 3.0.8\r\n",
      "    Uninstalling jupyterlab-widgets-3.0.8:\r\n",
      "      Successfully uninstalled jupyterlab-widgets-3.0.8\r\n",
      "  Attempting uninstall: ipywidgets\r\n",
      "    Found existing installation: ipywidgets 7.7.1\r\n",
      "    Uninstalling ipywidgets-7.7.1:\r\n",
      "      Successfully uninstalled ipywidgets-7.7.1\r\n",
      "Successfully installed ipywidgets-8.1.1 jupyterlab-widgets-3.0.9 widgetsnbextension-4.0.9\r\n",
      "--2024-01-14 16:51:02--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\r\n",
      "Resolving github.com (github.com)... 192.30.255.112\r\n",
      "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240114T165102Z&X-Amz-Expires=300&X-Amz-Signature=0e694d684adf2188eb9b256e5e69140d5397d6b6349300e8589eb33b003dcb52&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream [following]\r\n",
      "--2024-01-14 16:51:02--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240114T165102Z&X-Amz-Expires=300&X-Amz-Signature=0e694d684adf2188eb9b256e5e69140d5397d6b6349300e8589eb33b003dcb52&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream\r\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 54899779 (52M) [application/octet-stream]\r\n",
      "Saving to: 'yolov8m-seg.pt'\r\n",
      "\r\n",
      "yolov8m-seg.pt      100%[===================>]  52.36M   286MB/s    in 0.2s    \r\n",
      "\r\n",
      "2024-01-14 16:51:03 (286 MB/s) - 'yolov8m-seg.pt' saved [54899779/54899779]\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.200, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Berrybox_Quality_InstanceSeg-6 to yolov8:: 100%|██████████| 299105/299105 [00:09<00:00, 32783.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Berrybox_Quality_InstanceSeg-6 in yolov8:: 100%|██████████| 986/986 [00:00<00:00, 1614.63it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip -q install roboflow\n",
    "!pip -q install ultralytics==8.0.200\n",
    "!pip install -U ipywidgets\n",
    "! pip -q install ruamel.yaml\n",
    "! wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import sys\n",
    "import ruamel.yaml\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import psutil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import locale\n",
    "from IPython.display import clear_output\n",
    "import ctypes\n",
    "import ctypes.util\n",
    "import torch\n",
    "import random\n",
    "from ultralytics.utils import SETTINGS\n",
    "\n",
    "\n",
    "SETTINGS['wandb'] = False\n",
    "\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "# deterministic set\n",
    "torch.manual_seed(43)\n",
    "random.seed(43)\n",
    "np.random.seed(43)\n",
    "\n",
    "rf = Roboflow(api_key=\"tD9RSesaXxGqmwVD6eVZ\")\n",
    "project = rf.workspace(\"usdacranberrybreeding\").project(\"berrybox_quality_instanceseg\")\n",
    "dataset = project.version(6).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92fc2035",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T16:51:19.639903Z",
     "iopub.status.busy": "2024-01-14T16:51:19.639181Z",
     "iopub.status.idle": "2024-01-14T16:51:42.197051Z",
     "shell.execute_reply": "2024-01-14T16:51:42.196028Z"
    },
    "papermill": {
     "duration": 22.574505,
     "end_time": "2024-01-14T16:51:42.199470",
     "exception": false,
     "start_time": "2024-01-14T16:51:19.624965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\r\n",
      "Version: 2.0.0\r\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\r\n",
      "Home-page: https://pytorch.org/\r\n",
      "Author: PyTorch Team\r\n",
      "Author-email: packages@pytorch.org\r\n",
      "License: BSD-3\r\n",
      "Location: /opt/conda/lib/python3.10/site-packages\r\n",
      "Requires: filelock, jinja2, networkx, sympy, typing-extensions\r\n",
      "Required-by: accelerate, catalyst, easyocr, fastai, kornia, pytorch-ignite, pytorch-lightning, stable-baselines3, thop, timm, torchaudio, torchdata, torchmetrics, torchtext, torchvision, ultralytics\r\n",
      "Name: ultralytics\r\n",
      "Version: 8.0.200\r\n",
      "Summary: Ultralytics YOLOv8 for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.\r\n",
      "Home-page: https://github.com/ultralytics/ultralytics\r\n",
      "Author: Ultralytics\r\n",
      "Author-email: hello@ultralytics.com\r\n",
      "License: AGPL-3.0\r\n",
      "Location: /opt/conda/lib/python3.10/site-packages\r\n",
      "Requires: matplotlib, numpy, opencv-python, pandas, pillow, psutil, py-cpuinfo, pyyaml, requests, scipy, seaborn, thop, torch, torchvision, tqdm\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "! pip show torch\n",
    "! pip show ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fee179d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T16:51:42.227231Z",
     "iopub.status.busy": "2024-01-14T16:51:42.226887Z",
     "iopub.status.idle": "2024-01-14T16:51:42.251600Z",
     "shell.execute_reply": "2024-01-14T16:51:42.250570Z"
    },
    "papermill": {
     "duration": 0.040886,
     "end_time": "2024-01-14T16:51:42.253581",
     "exception": false,
     "start_time": "2024-01-14T16:51:42.212695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/Berrybox_Quality_InstanceSeg-6\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/Berrybox_Quality_InstanceSeg-6\n",
    "\n",
    "# trying to optimize RAM usage\n",
    "gc.enable()\n",
    "\n",
    "libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d572272b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T16:51:42.281681Z",
     "iopub.status.busy": "2024-01-14T16:51:42.281372Z",
     "iopub.status.idle": "2024-01-14T16:51:42.387919Z",
     "shell.execute_reply": "2024-01-14T16:51:42.387083Z"
    },
    "papermill": {
     "duration": 0.123275,
     "end_time": "2024-01-14T16:51:42.389808",
     "exception": false,
     "start_time": "2024-01-14T16:51:42.266533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YoloModel:\n",
    "    def __init__(self, path_to_model: str, path_to_yaml: str,\n",
    "                 train_perc: float, test_perc: float, val_perc: float,\n",
    "                 ttvs_flag = 0, tp_flag = 0):\n",
    "        \"\"\"Инициализация переменных\n",
    "\n",
    "        Args:\n",
    "            path_to_model (str): путь до весов yolov8.pt\n",
    "            path_to_yaml (str): путь до data.yaml файла датасета\n",
    "            train_perc (float): доля тренировочных данных \n",
    "            test_perc (float): доля тестовых данных\n",
    "            val_perc (float): доля валидационных данных\n",
    "        \"\"\"        \n",
    "        self.path_to_model = path_to_model\n",
    "        self.path_to_yaml = path_to_yaml\n",
    "        self.train_path = Path('train') if os.path.exists(Path('train')) else None\n",
    "        self.test_path = Path('test') if os.path.exists(Path('test')) else None\n",
    "        self.val_path = Path('valid') if os.path.exists(Path('valid')) else None\n",
    "        self.train_perc = train_perc\n",
    "        self.test_perc = test_perc\n",
    "        self.val_perc = val_perc\n",
    "        \n",
    "        self.ttvs_flag = ttvs_flag\n",
    "        self.tp_flag = tp_flag\n",
    "        \n",
    "        self.ram_usage = []\n",
    "        \n",
    "        assert self.train_path != None, 'Директория train отсутствует'\n",
    "        if (self.val_path == None):\n",
    "            os.mkdir(\"valid\", mode=0o777)\n",
    "            os.mkdir(\"valid/images\", mode=0o777)\n",
    "            os.mkdir(\"valid/labels\", mode=0o777)\n",
    "            self.val_path = Path(\"valid\")\n",
    "        if (self.test_path == None):\n",
    "            os.mkdir(\"test\", mode=0o777)\n",
    "            os.mkdir(\"test/images\", mode=0o777)\n",
    "            os.mkdir(\"test/labels\", mode=0o777)\n",
    "            self.test_path = Path(\"test\")\n",
    "    \n",
    "    def get_ram_usage(self,):\n",
    "        \"\"\"Gets the current RAM usage of the system.\n",
    "\n",
    "        Returns:\n",
    "            float: RAM usage in GB.\n",
    "        \"\"\"\n",
    "        return psutil.virtual_memory().used / 1e9\n",
    "\n",
    "    def train(self, folder_name: str, iters: int) -> YOLO: \n",
    "        \"\"\"Инициализация модели и обучение\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): название директории с частью данных\n",
    "            iters (int): кол-во интераций\n",
    "\n",
    "        Returns:\n",
    "            YOLO: экземпляр обученной модели\n",
    "        \"\"\"        \n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        # yaml.preserve_quotes = True\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = './'+folder_name+'/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(\n",
    "            # Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,\n",
    "            plots = False)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def retrain(self, folder_name: str, iters: int,) -> YOLO:\n",
    "        \"\"\"Обучение модели на всех предыдущих частях данных для профилакти просадки метрики\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): название директории с частью данных\n",
    "            iters (int): кол-во интераций\n",
    "\n",
    "        Returns:\n",
    "            YOLO: экземпляр обученной модели\n",
    "        \"\"\"        \n",
    "        os.mkdir(\"retrain\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/images\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/labels\", mode=0o777)\n",
    "\n",
    "        # собираем список всех кусков данных до нашего folder_name\n",
    "        folder_num = np.arange(1, int(folder_name.split('_')[-1]) + 1)\n",
    "        cls = folder_name.split(\"_\")[1]\n",
    "        source_pathes = [f\"temp_{cls}_{i}\" for i in folder_num]\n",
    "\n",
    "        # копируем все собранные куски данных в папку retrain\n",
    "        for path in source_pathes:\n",
    "            # собираем все файлы\n",
    "            all_images_train = os.listdir(path+\"/train/images\")\n",
    "            all_labels_train = os.listdir(path+\"/train/labels\")\n",
    "\n",
    "            for image in all_images_train:\n",
    "                shutil.copyfile(path+\"/train/images/\" + image,\n",
    "                                \"retrain/train/images/\" + image)\n",
    "            for label in all_labels_train:\n",
    "                shutil.copyfile(path+\"/train/labels/\" + label,\n",
    "                                \"retrain/train/labels/\" + label)\n",
    "\n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        \n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        # load a pretrained model (recommended for training)\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(# Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,\n",
    "            plots = False)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def test(self, folder_name: str, model: YOLO):\n",
    "        \"\"\"Тестирование модели\n",
    "\n",
    "        Args:\n",
    "            model (YOLO): экземпляр обученной модели\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"        \n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "            \n",
    "        metrics = model.val(data=self.path_to_yaml, split=\"test\")\n",
    "        return metrics\n",
    "    \n",
    "    def train_test_val_split(self, keep_perc: float):\n",
    "        \"\"\"Разделение изначального датасета на заданные доли train/test/val. Удаление 1-keep_perc доли данных \n",
    "\n",
    "        Args:\n",
    "            keep_perc (float): доля данных, которую нужно оставить\n",
    "        \"\"\"        \n",
    "        # создаем директории для объединения всех файлов\n",
    "        os.mkdir(\"temp\", mode=0o777)\n",
    "        os.mkdir(\"temp/images\", mode=0o777)\n",
    "        os.mkdir(\"temp/labels\", mode=0o777)\n",
    "            \n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels',\\\n",
    "                        self.test_path / 'images', self.test_path / 'labels',\\\n",
    "                        self.val_path / 'images', self.val_path / 'labels',)\n",
    "        destination = Path('temp')\n",
    "\n",
    "        for path in source_pathes:\n",
    "            # собираем все файлы\n",
    "            allfiles = os.listdir(path)\n",
    "            # итерируем по всем файлам, чтобы переместить их в папку назначения\n",
    "            sub_folder = path.name # images or labels\n",
    "            for f in allfiles:\n",
    "                src_path = os.path.join(path, f)\n",
    "                dst_path = os.path.join(destination / sub_folder, f)\n",
    "                os.rename(src_path, dst_path)\n",
    "        total_num = len(allfiles)\n",
    "        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"temp/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n",
    "                # а остальное - координаты сегментации\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"Пустой файл: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "        print(f\"Кол-во пустых файлов - {empty_count}\")\n",
    "        # Оставляем указанный процент данных\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(pathes)\n",
    "            num_to_del = num_files*(1-keep_perc)\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 >= num_to_del:\n",
    "                    break\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                try:\n",
    "                    Path(\"temp\",'images',\".\".join(f)).unlink()\n",
    "                    file_path.unlink()\n",
    "                except OSError as e:\n",
    "                    # Файл не найден (скорее всего имеет несколько классов и был уже перемещен)\n",
    "                    pass\n",
    "                classes[cls].remove(file_path)\n",
    "        for cls in classes.keys():\n",
    "#             shutil.copyfile(\"data.yaml\", f\"data_{cls}.yaml\")\n",
    "#              # Корректируем data.yaml файл\n",
    "#             yaml = ruamel.yaml.YAML()\n",
    "#             with open(f'data_{cls}.yaml', 'r+') as fp:\n",
    "#                 data = yaml.load(fp)\n",
    "#                 data['names'] = [data['names'][int(cls)]]\n",
    "#                 data['nc'] = 1\n",
    "#                 fp.truncate(0)\n",
    "#                 fp.seek(0)\n",
    "#                 yaml.dump(data, fp)\n",
    "            os.mkdir(f\"valid_{cls}\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}\", mode=0o777)\n",
    "\n",
    "\n",
    "            os.mkdir(f\"valid_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"valid_{cls}/images\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/images\", mode=0o777)\n",
    "        # Распределяем данные по директориям train, test, val с учетом указанных пропорций\n",
    "        class_copy = copy.deepcopy(classes)\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(class_copy[cls])\n",
    "            num_to_mv_train = int(num_files * self.train_perc)\n",
    "            num_to_mv_test = int(num_files * self.test_perc)\n",
    "            num_to_mv_val = int(num_files * self.val_perc)\n",
    "            # print(num_files, num_to_mv, len(pathes))\n",
    "            temp_dict_name = \"train\"\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 > num_to_mv_train and i+1 < num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"valid_{cls}\"\n",
    "                elif i+1 > num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"test_{cls}\"\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                shutil.copyfile(Path(\"temp\", \"images\", \".\".join(f)),\n",
    "                                Path(temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                shutil.copyfile(file_path,\n",
    "                                Path(temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                if temp_dict_name != \"train\":\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                classes[cls].remove(file_path)\n",
    "            dir_path = f\"valid_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "            dir_path = f\"test_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "        dir_path = f\"train/labels\"\n",
    "        print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        \n",
    "        shutil.rmtree(\"temp\")\n",
    "    \n",
    "    def __train_set_of(self,n):\n",
    "        x = []\n",
    "        temp = 2\n",
    "        while temp < n:\n",
    "            x.append(temp)\n",
    "            if temp < 10:\n",
    "                temp+=2\n",
    "            elif temp >= 10 and temp < 30:\n",
    "                temp += 3\n",
    "            elif temp >= 30 and temp < 100:\n",
    "                temp += 5\n",
    "            elif temp >= 100 and temp < 200:\n",
    "                temp += 10\n",
    "            elif temp >= 200 and temp < 300:\n",
    "                temp += 50\n",
    "            elif temp >= 300 and temp < 500:\n",
    "                temp +=100\n",
    "            elif temp >= 500:\n",
    "                temp += 500\n",
    "        if x[-1] != n:\n",
    "            x.append(n)\n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "    def take_piece(self, piece_perc: float = None, fib_flag:bool = False) -> (dict, dict):\n",
    "        \"\"\"Разделение исходного датасета на части равные доле piece_perc по директориям temp_{n}, n = {1..1/piece_perc}\n",
    "\n",
    "        Args:\n",
    "            piece_perc (float): доля части данных, на которые нужно поделить датасет\n",
    "        \"\"\"\n",
    "\n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels')\n",
    "        \n",
    "        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"train/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n",
    "                # а остальное - координаты сегментации\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"Пустой файл: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "                        \n",
    "        print(f\"Кол-во пустых файлов - {empty_count}\")\n",
    "        d_c = {key: len(value) for key, value in zip(classes.keys(), classes.values())}\n",
    "        print(*[f\"Класс {key} содержит {value} объекта(-ов)\\n\" for key, value in zip(d_c.keys(), d_c.values())])\n",
    "        \n",
    "        cls_tl_dict = defaultdict(list) # key - class, value - result of __train_set_of(n)\n",
    "        cls_fif_dict = defaultdict(int) # key - class, value - num folders\n",
    "        # Разделить сначала по классам, а потом внутри класса разделить по __train_set_of\n",
    "        for cls in classes.keys():\n",
    "            print(f\"Класс {cls}\")\n",
    "            total_num = len(classes[cls])\n",
    "            print(f\"\\tКол-во train класса {cls}: {total_num}\")\n",
    "            if fib_flag == True:\n",
    "                n = total_num\n",
    "                train_list = self.__train_set_of(n)\n",
    "                files_in_folder = []\n",
    "                for i in range(len(train_list)):\n",
    "                    if i == 0:\n",
    "                        files_in_folder.append(train_list[i])\n",
    "                        continue\n",
    "                    files_in_folder.append(train_list[i] - train_list[i-1])\n",
    "                print(f\"\\tКоличество данных (train) на каждой итерации класса {cls}: {train_list}\")\n",
    "                cls_tl_dict[cls] = train_list\n",
    "                cls_fif_dict[cls] = len(files_in_folder)\n",
    "\n",
    "            if fib_flag == True:\n",
    "                self.num_folders = len(files_in_folder)\n",
    "                print(f\"\\tКол-во директорий для класса {cls}: {self.num_folders} \")\n",
    "            else:\n",
    "                self.num_folders = 1 / piece_perc\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/labels\", mode=0o777)\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/images\", mode=0o777)\n",
    "            \n",
    "            # Распределяем данные по директориям  \n",
    "            class_copy = copy.deepcopy(classes)\n",
    "            for f_i, folder in enumerate(range(int(self.num_folders))):\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                num_to_mv_train = int(num_files * piece_perc) if fib_flag == False else files_in_folder[f_i]\n",
    "                print(f\"\\tnum_to_mv_train {num_to_mv_train}, folder {folder}, cls {cls}\")\n",
    "                # print(num_files, num_to_mv, len(pathes))\n",
    "                temp_dict_name = \"train\"\n",
    "                for i, file_path in enumerate(classes[cls].copy()):\n",
    "                    if i+1 > num_to_mv_train:\n",
    "                        break\n",
    "                    f = file_path.name.split('.')[:-1]\n",
    "                    f.append('jpg')\n",
    "                    shutil.copyfile(Path(\"train\", \"images\", \".\".join(f)),\n",
    "                                    Path(folder_name, temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                    shutil.copyfile(file_path,\n",
    "                                    Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                    classes[cls].remove(file_path)\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/labels\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/images\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        return cls_tl_dict, cls_fif_dict\n",
    "    \n",
    "    def plot_result(self, result_dict: dict, color_dict = \"green\", fib_list:list = None):\n",
    "        '''Функция для отрисовки графиков зависимости метрик от размера обучающей выборки\n",
    "\n",
    "        Args:\n",
    "            result_dict (dict): словарь с метриками {доля данных: массив метрик}\n",
    "            color_dict (dict): словарь с индикаторами повторного обучения\n",
    "        '''\n",
    "        metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "        colors = list(color_dict.values()) if color_dict != 'green' else color_dict\n",
    "        if fib_list == None:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(list(result_dict.keys()), [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(list(result_dict.keys()), [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(result_dict.keys())) \n",
    "                plt.show()\n",
    "        else:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(fib_list, [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(fib_list, [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(fib_list)) \n",
    "                plt.show()\n",
    "\n",
    "    def plot_ram_usage(self,):\n",
    "        '''Функция для отрисовки использования RAM в процессе обучения'''\n",
    "        plt.plot(self.ram_usage, marker='o', linestyle='-', color='b')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('RAM Usage (GB)')\n",
    "        plt.title('RAM Usage During Training')\n",
    "        plt.show()\n",
    "    \n",
    "    def __early_stopping(self, result_dict: dict, prev_num: int, threshold: float) -> bool:\n",
    "        keys_sorted = sorted(result_dict.keys())\n",
    "        prev_results = np.array([result_dict[i][0] for i in keys_sorted[-prev_num-1:-1]])\n",
    "        res = result_dict[keys_sorted[-1]][0] - prev_results\n",
    "        print(f\"Progress for {prev_num} last iterations with {threshold} threshold = {np.sum(res)}\")\n",
    "        if np.sum(res) < threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def increm_learning(self, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        # Инкрементальное обучение \n",
    "        for cls in cls_tl_dict.keys():\n",
    "#             self.path_to_yaml = \"/\".join(self.path_to_yaml.split('/')[0:-1]) + f\"/data_{cls}.yaml\"\n",
    "            print(self.path_to_yaml)\n",
    "            result_dict = defaultdict(list)\n",
    "            # словарь с индикаторами повторного обучения\n",
    "            color_dict = defaultdict(str)\n",
    "            # переменная для отслеживания максимального map в целях профилактики просадок метрики\n",
    "            max_map = 0\n",
    "            self.path_to_model = native_path_to_model\n",
    "            for folder in range(cls_fif_dict[cls]):\n",
    "                if (folder > prev_num):\n",
    "                    if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                        break\n",
    "                libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "                libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "                torch.set_num_threads(1)\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                # дообучаем модель\n",
    "                model = self.train(folder_name, iters)\n",
    "                # тестируем модель\n",
    "                metrics = self.test(folder_name, model)\n",
    "                # проверяем, что метрика улучшается\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                    # заносим метрики в словарь\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                else:\n",
    "                    self.path_to_model = native_path_to_model\n",
    "                    # дообучаем модель\n",
    "                    model = self.retrain(folder_name, iters)\n",
    "                    # тестируем модель\n",
    "                    metrics = self.test(folder_name, model)\n",
    "                    if metrics.seg.map > max_map:\n",
    "                        max_map = metrics.seg.map\n",
    "                    # заносим метрики в словарь\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                    shutil.rmtree(\"retrain\")\n",
    "                \n",
    "            print(f\"Итоговый результат (инкрементальное обучение) для класса {cls}: \\n {result_dict}\")\n",
    "            print(f\"Количество данных (train) для класса {cls}: {cls_tl_dict[cls]}\")\n",
    "            self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "            \n",
    "    def increm_learning_one_class(self,learn_cls: str, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        # Инкрементальное обучение \n",
    "        cls = learn_cls\n",
    "#         self.path_to_yaml = \"/\".join(self.path_to_yaml.split('/')[0:-1]) + f\"/data_{cls}.yaml\"\n",
    "        print(self.path_to_yaml)\n",
    "        print(cls_fif_dict, cls_tl_dict)\n",
    "        result_dict = defaultdict(list)\n",
    "        # словарь с индикаторами повторного обучения\n",
    "        color_dict = defaultdict(str)\n",
    "        # переменная для отслеживания максимального map в целях профилактики просадок метрики\n",
    "        max_map = 0\n",
    "        self.path_to_model = native_path_to_model\n",
    "        for folder in range(cls_fif_dict[cls]):\n",
    "            if (folder > prev_num):\n",
    "                if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                    print(\"EARLY STOPPING\")\n",
    "                    break\n",
    "            libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "            libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "            torch.set_num_threads(1)\n",
    "            folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "            # дообучаем модель\n",
    "            model = self.train(folder_name, iters)\n",
    "            # тестируем модель\n",
    "            metrics = self.test(folder_name, model)\n",
    "            # проверяем, что метрика улучшается\n",
    "            if metrics.seg.map > max_map:\n",
    "                max_map = metrics.seg.map\n",
    "                # заносим метрики в словарь\n",
    "                result_dict[folder].append(metrics.seg.map)\n",
    "                result_dict[folder].append(metrics.seg.map50)\n",
    "                result_dict[folder].append(metrics.seg.map75)\n",
    "                color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                del(model)\n",
    "                del(metrics)\n",
    "                gc.collect()\n",
    "                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "            else:\n",
    "                self.path_to_model = native_path_to_model\n",
    "                # дообучаем модель\n",
    "                model = self.retrain(folder_name, iters)\n",
    "                # тестируем модель\n",
    "                metrics = self.test(folder_name, model)\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                # заносим метрики в словарь\n",
    "                result_dict[folder].append(metrics.seg.map)\n",
    "                result_dict[folder].append(metrics.seg.map50)\n",
    "                result_dict[folder].append(metrics.seg.map75)\n",
    "                color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                del(model)\n",
    "                del(metrics)\n",
    "                gc.collect()\n",
    "                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                shutil.rmtree(\"retrain\")\n",
    "\n",
    "        print(f\"Итоговый результат (инкрементальное обучение) для класса {cls}: \\n {result_dict}\")\n",
    "        print(f\"Количество данных (train) для класса {cls}: {cls_tl_dict[cls]}\")\n",
    "        self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "            \n",
    "    def base_learning(self, keep_perc: float, piece_perc: float, iters: int):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            self.take_piece(piece_perc)\n",
    "            self.tp_flag = 1\n",
    "        else: \n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        result_dict = {k_p:[] for k_p in range(int(self.num_folders))}\n",
    "        \n",
    "        for folder in range(int(self.num_folders)):\n",
    "            folder_name = f\"temp_{folder+1}\"\n",
    "            # дообучаем модель\n",
    "            model = self.retrain(folder_name, iters)\n",
    "            # тестируем модель\n",
    "            metrics = self.test(model)\n",
    "            # заносим метрики в словарь\n",
    "            result_dict[folder].append(metrics.seg.map)\n",
    "            result_dict[folder].append(metrics.seg.map50)\n",
    "            result_dict[folder].append(metrics.seg.map75)\n",
    "            clear_output(wait=True)\n",
    "            del(model)\n",
    "            del(metrics)\n",
    "            gc.collect()\n",
    "            shutil.rmtree(\"retrain\")\n",
    "            \n",
    "        print(f\"Итоговый результат (базовое обучение): \\n {result_dict}\")\n",
    "        self.plot_result(result_dict)\n",
    "        \n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9ff9819",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-01-14T16:51:42.419375Z",
     "iopub.status.busy": "2024-01-14T16:51:42.418770Z",
     "iopub.status.idle": "2024-01-14T18:42:03.938349Z",
     "shell.execute_reply": "2024-01-14T18:42:03.937302Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 6621.537616,
     "end_time": "2024-01-14T18:42:03.940493",
     "exception": false,
     "start_time": "2024-01-14T16:51:42.402877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во пустых файлов - 0\n",
      "valid_0/images 34\n",
      "test_0/images 36\n",
      "valid_1/images 28\n",
      "test_1/images 29\n",
      "train/labels 398 \n",
      "\n",
      "Кол-во пустых файлов - 0\n",
      "Класс 0 содержит 277 объекта(-ов)\n",
      " Класс 1 содержит 234 объекта(-ов)\n",
      "\n",
      "Класс 0\n",
      "\tКол-во train класса 0: 277\n",
      "\tКоличество данных (train) на каждой итерации класса 0: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 277]\n",
      "\tКол-во директорий для класса 0: 38 \n",
      "\tnum_to_mv_train 2, folder 0, cls 0\n",
      "\tnum_to_mv_train 2, folder 1, cls 0\n",
      "\tnum_to_mv_train 2, folder 2, cls 0\n",
      "\tnum_to_mv_train 2, folder 3, cls 0\n",
      "\tnum_to_mv_train 2, folder 4, cls 0\n",
      "\tnum_to_mv_train 3, folder 5, cls 0\n",
      "\tnum_to_mv_train 3, folder 6, cls 0\n",
      "\tnum_to_mv_train 3, folder 7, cls 0\n",
      "\tnum_to_mv_train 3, folder 8, cls 0\n",
      "\tnum_to_mv_train 3, folder 9, cls 0\n",
      "\tnum_to_mv_train 3, folder 10, cls 0\n",
      "\tnum_to_mv_train 3, folder 11, cls 0\n",
      "\tnum_to_mv_train 5, folder 12, cls 0\n",
      "\tnum_to_mv_train 5, folder 13, cls 0\n",
      "\tnum_to_mv_train 5, folder 14, cls 0\n",
      "\tnum_to_mv_train 5, folder 15, cls 0\n",
      "\tnum_to_mv_train 5, folder 16, cls 0\n",
      "\tnum_to_mv_train 5, folder 17, cls 0\n",
      "\tnum_to_mv_train 5, folder 18, cls 0\n",
      "\tnum_to_mv_train 5, folder 19, cls 0\n",
      "\tnum_to_mv_train 5, folder 20, cls 0\n",
      "\tnum_to_mv_train 5, folder 21, cls 0\n",
      "\tnum_to_mv_train 5, folder 22, cls 0\n",
      "\tnum_to_mv_train 5, folder 23, cls 0\n",
      "\tnum_to_mv_train 5, folder 24, cls 0\n",
      "\tnum_to_mv_train 5, folder 25, cls 0\n",
      "\tnum_to_mv_train 10, folder 26, cls 0\n",
      "\tnum_to_mv_train 10, folder 27, cls 0\n",
      "\tnum_to_mv_train 10, folder 28, cls 0\n",
      "\tnum_to_mv_train 10, folder 29, cls 0\n",
      "\tnum_to_mv_train 10, folder 30, cls 0\n",
      "\tnum_to_mv_train 10, folder 31, cls 0\n",
      "\tnum_to_mv_train 10, folder 32, cls 0\n",
      "\tnum_to_mv_train 10, folder 33, cls 0\n",
      "\tnum_to_mv_train 10, folder 34, cls 0\n",
      "\tnum_to_mv_train 10, folder 35, cls 0\n",
      "\tnum_to_mv_train 50, folder 36, cls 0\n",
      "\tnum_to_mv_train 26, folder 37, cls 0\n",
      "temp_0_1/train/labels 2\n",
      "temp_0_1/train/images 2 \n",
      "\n",
      "temp_0_2/train/labels 2\n",
      "temp_0_2/train/images 2 \n",
      "\n",
      "temp_0_3/train/labels 2\n",
      "temp_0_3/train/images 2 \n",
      "\n",
      "temp_0_4/train/labels 2\n",
      "temp_0_4/train/images 2 \n",
      "\n",
      "temp_0_5/train/labels 2\n",
      "temp_0_5/train/images 2 \n",
      "\n",
      "temp_0_6/train/labels 3\n",
      "temp_0_6/train/images 3 \n",
      "\n",
      "temp_0_7/train/labels 3\n",
      "temp_0_7/train/images 3 \n",
      "\n",
      "temp_0_8/train/labels 3\n",
      "temp_0_8/train/images 3 \n",
      "\n",
      "temp_0_9/train/labels 3\n",
      "temp_0_9/train/images 3 \n",
      "\n",
      "temp_0_10/train/labels 3\n",
      "temp_0_10/train/images 3 \n",
      "\n",
      "temp_0_11/train/labels 3\n",
      "temp_0_11/train/images 3 \n",
      "\n",
      "temp_0_12/train/labels 3\n",
      "temp_0_12/train/images 3 \n",
      "\n",
      "temp_0_13/train/labels 5\n",
      "temp_0_13/train/images 5 \n",
      "\n",
      "temp_0_14/train/labels 5\n",
      "temp_0_14/train/images 5 \n",
      "\n",
      "temp_0_15/train/labels 5\n",
      "temp_0_15/train/images 5 \n",
      "\n",
      "temp_0_16/train/labels 5\n",
      "temp_0_16/train/images 5 \n",
      "\n",
      "temp_0_17/train/labels 5\n",
      "temp_0_17/train/images 5 \n",
      "\n",
      "temp_0_18/train/labels 5\n",
      "temp_0_18/train/images 5 \n",
      "\n",
      "temp_0_19/train/labels 5\n",
      "temp_0_19/train/images 5 \n",
      "\n",
      "temp_0_20/train/labels 5\n",
      "temp_0_20/train/images 5 \n",
      "\n",
      "temp_0_21/train/labels 5\n",
      "temp_0_21/train/images 5 \n",
      "\n",
      "temp_0_22/train/labels 5\n",
      "temp_0_22/train/images 5 \n",
      "\n",
      "temp_0_23/train/labels 5\n",
      "temp_0_23/train/images 5 \n",
      "\n",
      "temp_0_24/train/labels 5\n",
      "temp_0_24/train/images 5 \n",
      "\n",
      "temp_0_25/train/labels 5\n",
      "temp_0_25/train/images 5 \n",
      "\n",
      "temp_0_26/train/labels 5\n",
      "temp_0_26/train/images 5 \n",
      "\n",
      "temp_0_27/train/labels 10\n",
      "temp_0_27/train/images 10 \n",
      "\n",
      "temp_0_28/train/labels 10\n",
      "temp_0_28/train/images 10 \n",
      "\n",
      "temp_0_29/train/labels 10\n",
      "temp_0_29/train/images 10 \n",
      "\n",
      "temp_0_30/train/labels 10\n",
      "temp_0_30/train/images 10 \n",
      "\n",
      "temp_0_31/train/labels 10\n",
      "temp_0_31/train/images 10 \n",
      "\n",
      "temp_0_32/train/labels 10\n",
      "temp_0_32/train/images 10 \n",
      "\n",
      "temp_0_33/train/labels 10\n",
      "temp_0_33/train/images 10 \n",
      "\n",
      "temp_0_34/train/labels 10\n",
      "temp_0_34/train/images 10 \n",
      "\n",
      "temp_0_35/train/labels 10\n",
      "temp_0_35/train/images 10 \n",
      "\n",
      "temp_0_36/train/labels 10\n",
      "temp_0_36/train/images 10 \n",
      "\n",
      "temp_0_37/train/labels 50\n",
      "temp_0_37/train/images 50 \n",
      "\n",
      "temp_0_38/train/labels 26\n",
      "temp_0_38/train/images 26 \n",
      "\n",
      "Класс 1\n",
      "\tКол-во train класса 1: 234\n",
      "\tКоличество данных (train) на каждой итерации класса 1: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 234]\n",
      "\tКол-во директорий для класса 1: 37 \n",
      "\tnum_to_mv_train 2, folder 0, cls 1\n",
      "\tnum_to_mv_train 2, folder 1, cls 1\n",
      "\tnum_to_mv_train 2, folder 2, cls 1\n",
      "\tnum_to_mv_train 2, folder 3, cls 1\n",
      "\tnum_to_mv_train 2, folder 4, cls 1\n",
      "\tnum_to_mv_train 3, folder 5, cls 1\n",
      "\tnum_to_mv_train 3, folder 6, cls 1\n",
      "\tnum_to_mv_train 3, folder 7, cls 1\n",
      "\tnum_to_mv_train 3, folder 8, cls 1\n",
      "\tnum_to_mv_train 3, folder 9, cls 1\n",
      "\tnum_to_mv_train 3, folder 10, cls 1\n",
      "\tnum_to_mv_train 3, folder 11, cls 1\n",
      "\tnum_to_mv_train 5, folder 12, cls 1\n",
      "\tnum_to_mv_train 5, folder 13, cls 1\n",
      "\tnum_to_mv_train 5, folder 14, cls 1\n",
      "\tnum_to_mv_train 5, folder 15, cls 1\n",
      "\tnum_to_mv_train 5, folder 16, cls 1\n",
      "\tnum_to_mv_train 5, folder 17, cls 1\n",
      "\tnum_to_mv_train 5, folder 18, cls 1\n",
      "\tnum_to_mv_train 5, folder 19, cls 1\n",
      "\tnum_to_mv_train 5, folder 20, cls 1\n",
      "\tnum_to_mv_train 5, folder 21, cls 1\n",
      "\tnum_to_mv_train 5, folder 22, cls 1\n",
      "\tnum_to_mv_train 5, folder 23, cls 1\n",
      "\tnum_to_mv_train 5, folder 24, cls 1\n",
      "\tnum_to_mv_train 5, folder 25, cls 1\n",
      "\tnum_to_mv_train 10, folder 26, cls 1\n",
      "\tnum_to_mv_train 10, folder 27, cls 1\n",
      "\tnum_to_mv_train 10, folder 28, cls 1\n",
      "\tnum_to_mv_train 10, folder 29, cls 1\n",
      "\tnum_to_mv_train 10, folder 30, cls 1\n",
      "\tnum_to_mv_train 10, folder 31, cls 1\n",
      "\tnum_to_mv_train 10, folder 32, cls 1\n",
      "\tnum_to_mv_train 10, folder 33, cls 1\n",
      "\tnum_to_mv_train 10, folder 34, cls 1\n",
      "\tnum_to_mv_train 10, folder 35, cls 1\n",
      "\tnum_to_mv_train 33, folder 36, cls 1\n",
      "temp_1_1/train/labels 2\n",
      "temp_1_1/train/images 2 \n",
      "\n",
      "temp_1_2/train/labels 2\n",
      "temp_1_2/train/images 2 \n",
      "\n",
      "temp_1_3/train/labels 2\n",
      "temp_1_3/train/images 2 \n",
      "\n",
      "temp_1_4/train/labels 2\n",
      "temp_1_4/train/images 2 \n",
      "\n",
      "temp_1_5/train/labels 2\n",
      "temp_1_5/train/images 2 \n",
      "\n",
      "temp_1_6/train/labels 3\n",
      "temp_1_6/train/images 3 \n",
      "\n",
      "temp_1_7/train/labels 3\n",
      "temp_1_7/train/images 3 \n",
      "\n",
      "temp_1_8/train/labels 3\n",
      "temp_1_8/train/images 3 \n",
      "\n",
      "temp_1_9/train/labels 3\n",
      "temp_1_9/train/images 3 \n",
      "\n",
      "temp_1_10/train/labels 3\n",
      "temp_1_10/train/images 3 \n",
      "\n",
      "temp_1_11/train/labels 3\n",
      "temp_1_11/train/images 3 \n",
      "\n",
      "temp_1_12/train/labels 3\n",
      "temp_1_12/train/images 3 \n",
      "\n",
      "temp_1_13/train/labels 5\n",
      "temp_1_13/train/images 5 \n",
      "\n",
      "temp_1_14/train/labels 5\n",
      "temp_1_14/train/images 5 \n",
      "\n",
      "temp_1_15/train/labels 5\n",
      "temp_1_15/train/images 5 \n",
      "\n",
      "temp_1_16/train/labels 5\n",
      "temp_1_16/train/images 5 \n",
      "\n",
      "temp_1_17/train/labels 5\n",
      "temp_1_17/train/images 5 \n",
      "\n",
      "temp_1_18/train/labels 5\n",
      "temp_1_18/train/images 5 \n",
      "\n",
      "temp_1_19/train/labels 5\n",
      "temp_1_19/train/images 5 \n",
      "\n",
      "temp_1_20/train/labels 5\n",
      "temp_1_20/train/images 5 \n",
      "\n",
      "temp_1_21/train/labels 5\n",
      "temp_1_21/train/images 5 \n",
      "\n",
      "temp_1_22/train/labels 5\n",
      "temp_1_22/train/images 5 \n",
      "\n",
      "temp_1_23/train/labels 5\n",
      "temp_1_23/train/images 5 \n",
      "\n",
      "temp_1_24/train/labels 5\n",
      "temp_1_24/train/images 5 \n",
      "\n",
      "temp_1_25/train/labels 5\n",
      "temp_1_25/train/images 5 \n",
      "\n",
      "temp_1_26/train/labels 5\n",
      "temp_1_26/train/images 5 \n",
      "\n",
      "temp_1_27/train/labels 10\n",
      "temp_1_27/train/images 10 \n",
      "\n",
      "temp_1_28/train/labels 10\n",
      "temp_1_28/train/images 10 \n",
      "\n",
      "temp_1_29/train/labels 10\n",
      "temp_1_29/train/images 10 \n",
      "\n",
      "temp_1_30/train/labels 10\n",
      "temp_1_30/train/images 10 \n",
      "\n",
      "temp_1_31/train/labels 10\n",
      "temp_1_31/train/images 10 \n",
      "\n",
      "temp_1_32/train/labels 10\n",
      "temp_1_32/train/images 10 \n",
      "\n",
      "temp_1_33/train/labels 10\n",
      "temp_1_33/train/images 10 \n",
      "\n",
      "temp_1_34/train/labels 10\n",
      "temp_1_34/train/images 10 \n",
      "\n",
      "temp_1_35/train/labels 10\n",
      "temp_1_35/train/images 10 \n",
      "\n",
      "temp_1_36/train/labels 10\n",
      "temp_1_36/train/images 10 \n",
      "\n",
      "temp_1_37/train/labels 33\n",
      "temp_1_37/train/images 33 \n",
      "\n",
      "/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml\n",
      "defaultdict(<class 'int'>, {'0': 38, '1': 37}) defaultdict(<class 'list'>, {'0': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 277], '1': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 234]})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100%|██████████| 755k/755k [00:00<00:00, 25.7MB/s]\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100%|██████████| 6.23M/6.23M [00:00<00:00, 90.6MB/s]\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_1/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 35.45it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_1/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<00:00, 93.49it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      2.35G       1.24      1.989      3.876     0.9038        117        640: 100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         28        665   0.000188     0.0015   9.54e-05   5.73e-05   0.000188     0.0015   9.65e-05   5.79e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.63G      1.289      1.361       4.11     0.8594         82        640: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
      "                   all         28        665   0.000187     0.0015   9.69e-05   4.84e-05   0.000561    0.00451   0.000283   0.000152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.47G     0.9647       1.09      4.113     0.8573         34        640: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "                   all         28        665   0.000186     0.0015   9.74e-05   6.82e-05   0.000372    0.00301    0.00019   0.000124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.47G      1.237      1.323      3.992     0.9259         58        640: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "                   all         28        665   0.000186     0.0015   9.93e-05   7.95e-05   0.000186     0.0015   9.93e-05   4.97e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.63G      1.148      1.401      3.979     0.8953         79        640: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
      "                   all         28        665   0.000186     0.0015   9.92e-05   7.94e-05   0.000186     0.0015   9.92e-05   4.96e-05\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]\n",
      "                   all         28        665   0.000187     0.0015   9.67e-05   4.84e-05    0.00056    0.00451   0.000283   0.000133\n",
      "                rotten         28        665   0.000187     0.0015   9.67e-05   4.84e-05    0.00056    0.00451   0.000283   0.000133\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<00:00, 290.27it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.23it/s]\n",
      "                   all         29        547   0.000716    0.00731   0.000361   0.000261   0.000716    0.00731   0.000361   0.000207\n",
      "                rotten         29        547   0.000716    0.00731   0.000361   0.000261   0.000716    0.00731   0.000361   0.000207\n",
      "Speed: 0.1ms preprocess, 14.6ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_2/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 693.27it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_2/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.04G      1.022      1.641      3.806     0.8368         98        640: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "                   all         28        665   0.000394    0.00301   0.000198   0.000168   0.000394    0.00301   0.000198    8.9e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.46G      0.953      1.176      4.298     0.8917         44        640: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "                   all         28        665   0.000391    0.00301   0.000196   0.000177   0.000391    0.00301   0.000196   8.84e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.43G     0.8307      1.113      4.174     0.8215         35        640: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "                   all         28        665   0.000388    0.00301   0.000195   0.000175   0.000388    0.00301   0.000195   8.78e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.47G     0.9666      1.769      3.832      0.858         80        640: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
      "                   all         28        665    0.00039    0.00301   0.000196   0.000167    0.00039    0.00301   0.000196   0.000137\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.46G     0.9005      1.252       4.07     0.8679         41        640: 100%|██████████| 1/1 [00:00<00:00,  3.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "                   all         28        665   0.000773    0.00602   0.000389    0.00033   0.000773    0.00602   0.000389   0.000282\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n",
      "                   all         28        665   0.000772    0.00602   0.000389    0.00033   0.000772    0.00602   0.000389   0.000282\n",
      "                rotten         28        665   0.000772    0.00602   0.000389    0.00033   0.000772    0.00602   0.000389   0.000282\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n",
      "                   all         29        547    0.00223     0.0219    0.00114   0.000902    0.00204     0.0201    0.00104   0.000665\n",
      "                rotten         29        547    0.00223     0.0219    0.00114   0.000902    0.00204     0.0201    0.00104   0.000665\n",
      "Speed: 0.1ms preprocess, 10.5ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_3/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 567.95it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.05G      1.414      1.351      3.873     0.8442         94        640: 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "                   all         28        665          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.47G      1.277      1.133      4.286     0.8746         35        640: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "                   all         28        665   0.000395    0.00301   0.000198   0.000169   0.000593    0.00451   0.000298   0.000119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.43G      1.216      1.138      4.192     0.8759         36        640: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.04it/s]\n",
      "                   all         28        665   0.000395    0.00301   0.000198   0.000169   0.000395    0.00301   0.000198   0.000109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.46G      1.309      1.223      3.821      0.905         77        640: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "                   all         28        665   0.000593    0.00451   0.000298   0.000248   0.000593    0.00451   0.000298   0.000149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.42G     0.9563     0.8711      4.219     0.8755         31        640: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "                   all         28        665   0.000595    0.00451   0.000299   0.000249   0.000595    0.00451   0.000299   0.000149\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n",
      "                   all         28        665   0.000596    0.00451   0.000299   0.000249   0.000596    0.00451   0.000299   0.000149\n",
      "                rotten         28        665   0.000596    0.00451   0.000299   0.000249   0.000596    0.00451   0.000299   0.000149\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n",
      "                   all         29        547    0.00136     0.0128   0.000695   0.000546    0.00136     0.0128   0.000695   0.000425\n",
      "                rotten         29        547    0.00136     0.0128   0.000695   0.000546    0.00136     0.0128   0.000695   0.000425\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 6 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6/6 [00:00<00:00, 105.27it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.04G      1.216      1.308      3.985      0.896        255        640: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.04it/s]\n",
      "                   all         28        665   0.000188     0.0015   9.62e-05   5.74e-05   0.000188     0.0015   9.62e-05   5.77e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      5.29G      1.332      1.387       3.96     0.8911        227        640: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "                   all         28        665   0.000374    0.00301    0.00019   9.56e-05   0.000748    0.00602   0.000376   0.000189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      5.67G      1.237      1.393      4.026     0.8985        235        640: 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         28        665   0.000372    0.00301    0.00019   8.76e-05   0.000372    0.00301    0.00019    8.6e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      5.25G     0.8824      1.145      4.278      0.832        127        640: 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "                   all         28        665   0.000369    0.00301    0.00019   9.68e-05   0.000369    0.00301    0.00019   7.65e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      5.07G      1.231      1.564      3.845     0.8886        145        640: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n",
      "                   all         28        665    0.00037    0.00301    0.00019   0.000142    0.00037    0.00301    0.00019   9.48e-05\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n",
      "                   all         28        665   0.000373    0.00301   0.000189   8.62e-05   0.000746    0.00602   0.000376   0.000188\n",
      "                rotten         28        665   0.000373    0.00301   0.000189   8.62e-05   0.000746    0.00602   0.000376   0.000188\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.32it/s]\n",
      "                   all         29        547   0.000538    0.00548   0.000271   0.000198   0.000538    0.00548   0.000271   0.000153\n",
      "                rotten         29        547   0.000538    0.00548   0.000271   0.000198   0.000538    0.00548   0.000271   0.000153\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_4/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 112.12it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_4/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.27G      1.465      1.563      3.772     0.8291         77        640: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "                   all         28        665   0.000393    0.00301   0.000197   0.000167   0.000393    0.00301   0.000197   8.86e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.44G      1.188      1.373      3.984     0.8893         42        640: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "                   all         28        665   0.000197     0.0015   9.85e-05   8.87e-05   0.000197     0.0015   9.85e-05   3.94e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.36G      1.406      1.369      4.181     0.9643         25        640: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.05it/s]\n",
      "                   all         28        665   0.000198     0.0015   9.91e-05   8.92e-05   0.000198     0.0015   9.91e-05   3.97e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.27G      1.386      1.231      3.826     0.8625         45        640: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                   all         28        665   0.000199     0.0015   9.99e-05   8.99e-05   0.000199     0.0015   9.99e-05      4e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.44G      1.238      1.097      3.851     0.8977         38        640: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "                   all         28        665     0.0002     0.0015     0.0001   9.03e-05     0.0002     0.0015     0.0001   4.01e-05\n",
      "\n",
      "5 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n",
      "                   all         28        665   0.000393    0.00301   0.000197   0.000168   0.000393    0.00301   0.000197   8.88e-05\n",
      "                rotten         28        665   0.000393    0.00301   0.000197   0.000168   0.000393    0.00301   0.000197   8.88e-05\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.16it/s]\n",
      "                   all         29        547   0.000573    0.00548   0.000289   0.000241   0.000573    0.00548   0.000289   0.000203\n",
      "                rotten         29        547   0.000573    0.00548   0.000289   0.000241   0.000573    0.00548   0.000289   0.000203\n",
      "Speed: 0.1ms preprocess, 10.0ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 8 images, 0 backgrounds, 0 corrupt: 100%|██████████| 8/8 [00:00<00:00, 97.23it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.77G      1.284      1.432      3.933     0.8846        291        640: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.02it/s]\n",
      "                   all         28        665   0.000188     0.0015   9.62e-05   5.73e-05   0.000188     0.0015   9.62e-05   5.77e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      6.84G      1.448      1.572      3.882     0.8612        385        640: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        665   0.000187     0.0015   9.64e-05   5.78e-05   0.000747    0.00602   0.000376    0.00017\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      6.56G      1.205      1.203      4.184     0.8751        256        640: 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                   all         28        665   0.000372    0.00301   0.000189   0.000133   0.000558    0.00451   0.000282   0.000132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      6.88G      1.158      1.597      3.998      0.898        231        640: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        665   0.000372    0.00301    0.00019   8.72e-05   0.000372    0.00301    0.00019   6.72e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      6.55G      1.313      1.553       3.94      0.938        206        640: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "                   all         28        665   0.000186     0.0015   9.78e-05   7.82e-05   0.000186     0.0015   9.78e-05   4.89e-05\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n",
      "                   all         28        665   0.000372    0.00301   0.000189   0.000133   0.000558    0.00451   0.000282   0.000151\n",
      "                rotten         28        665   0.000372    0.00301   0.000189   0.000133   0.000558    0.00451   0.000282   0.000151\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n",
      "                   all         29        547   0.000893    0.00914   0.000451   0.000315   0.000893    0.00914   0.000451    0.00027\n",
      "                rotten         29        547   0.000893    0.00914   0.000451   0.000315   0.000893    0.00914   0.000451    0.00027\n",
      "Speed: 0.7ms preprocess, 10.4ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_5/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 192.19it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_5/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.39G      1.632      1.619      3.886      0.858        113        640: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "                   all         28        665   0.000196     0.0015   9.83e-05   7.86e-05   0.000196     0.0015   9.83e-05   4.91e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       2.5G      1.222     0.9771      4.209     0.9014         51        640: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "                   all         28        665   0.000195     0.0015   9.76e-05   8.79e-05   0.000195     0.0015   9.76e-05    3.9e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.46G      1.174     0.8609       4.24     0.8676         39        640: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n",
      "                   all         28        665   0.000194     0.0015   9.73e-05   8.76e-05   0.000194     0.0015   9.73e-05   3.89e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       2.4G      1.365      1.171       3.77     0.8692         87        640: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "                   all         28        665   0.000195     0.0015   9.79e-05   8.81e-05   0.000195     0.0015   9.79e-05   3.92e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.54G      1.149     0.9261      4.125     0.8844         36        640: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.15it/s]\n",
      "                   all         28        665   0.000193     0.0015   9.69e-05   8.72e-05   0.000193     0.0015   9.69e-05   3.88e-05\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]\n",
      "                   all         28        665   0.000193     0.0015   9.69e-05   8.72e-05   0.000193     0.0015   9.69e-05   3.88e-05\n",
      "                rotten         28        665   0.000193     0.0015   9.69e-05   8.72e-05   0.000193     0.0015   9.69e-05   3.88e-05\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n",
      "                   all         29        547    0.00224     0.0219    0.00114   0.000878    0.00205     0.0201    0.00105   0.000554\n",
      "                rotten         29        547    0.00224     0.0219    0.00114   0.000878    0.00205     0.0201    0.00105   0.000554\n",
      "Speed: 0.1ms preprocess, 10.0ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 106.54it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.81G      1.301      1.323      4.086     0.8828        352        640: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "                   all         28        665   0.000187     0.0015   9.57e-05    5.7e-05   0.000187     0.0015   9.57e-05   5.74e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       7.5G      1.232      1.269      4.053      0.852        286        640: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        665   0.000374    0.00301   0.000189   6.69e-05    0.00056    0.00451   0.000282    0.00016\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.59G      1.391      1.604      4.025     0.8917        416        640: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                   all         28        665   0.000372    0.00301   0.000189   8.64e-05   0.000372    0.00301   0.000189    8.6e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.48G      1.074      1.405      4.024      0.884        248        640: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                   all         28        665   0.000186     0.0015   9.68e-05   7.74e-05   0.000186     0.0015   9.68e-05   4.84e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.61G      1.236       1.44      3.942     0.8723        299        640: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                   all         28        665   0.000373    0.00301   0.000189   0.000151   0.000373    0.00301   0.000189   9.47e-05\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]\n",
      "                   all         28        665   0.000372    0.00301   0.000189   0.000151   0.000372    0.00301   0.000189   9.46e-05\n",
      "                rotten         28        665   0.000372    0.00301   0.000189   0.000151   0.000372    0.00301   0.000189   9.46e-05\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n",
      "                   all         29        547   0.000712    0.00731   0.000359   0.000269    0.00089    0.00914    0.00045   0.000234\n",
      "                rotten         29        547   0.000712    0.00731   0.000359   0.000269    0.00089    0.00914    0.00045   0.000234\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_6/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 731.01it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_6/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       3.4G      1.347      1.275      4.075     0.8691        101        640: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "                   all         28        665   0.000196     0.0015   9.83e-05   8.85e-05   0.000196     0.0015   9.83e-05   3.93e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.96G     0.8232     0.8422      4.571     0.8164         28        640: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "                   all         28        665   0.000197     0.0015   9.88e-05    8.9e-05   0.000197     0.0015   9.88e-05   3.95e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.12G      1.321     0.9971      4.205     0.8725         55        640: 100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "                   all         28        665   0.000196     0.0015   9.82e-05   8.84e-05   0.000196     0.0015   9.82e-05   3.93e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.02G       1.07     0.8936      4.349     0.8506         33        640: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "                   all         28        665   0.000197     0.0015   9.87e-05   8.88e-05   0.000197     0.0015   9.87e-05   3.95e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.99G      1.098      1.297      4.176     0.8767         83        640: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "                   all         28        665   0.000196     0.0015   9.83e-05   8.85e-05   0.000196     0.0015   9.83e-05   3.93e-05\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n",
      "                   all         28        665   0.000197     0.0015   9.88e-05   8.89e-05   0.000197     0.0015   9.88e-05   3.95e-05\n",
      "                rotten         28        665   0.000197     0.0015   9.88e-05   8.89e-05   0.000197     0.0015   9.88e-05   3.95e-05\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n",
      "                   all         29        547    0.00132     0.0128   0.000672   0.000528    0.00132     0.0128   0.000672     0.0003\n",
      "                rotten         29        547    0.00132     0.0128   0.000672   0.000528    0.00132     0.0128   0.000672     0.0003\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 13 images, 0 backgrounds, 0 corrupt: 100%|██████████| 13/13 [00:00<00:00, 134.30it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.26G      1.242      1.344       3.95     0.8827        364        640: 100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.04it/s]\n",
      "                   all         28        665   0.000188     0.0015    9.6e-05   5.73e-05   0.000188     0.0015    9.6e-05   5.76e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      8.95G      1.374      1.388      4.141     0.8966        368        640: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                   all         28        665   0.000374    0.00301   0.000189   6.69e-05   0.000561    0.00451   0.000282    0.00016\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.64G      1.461      1.527      3.886     0.9305        581        640: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                   all         28        665   0.000186     0.0015   9.62e-05   7.69e-05   0.000373    0.00301   0.000189   0.000104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.51G      1.295      1.515      3.879     0.9408        529        640: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                   all         28        665   0.000187     0.0015   9.64e-05   7.71e-05   0.000187     0.0015   9.64e-05   4.82e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      8.97G      1.234      1.281       4.22     0.9319        245        640: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                   all         28        665   0.000185     0.0015   9.58e-05   7.67e-05   0.000185     0.0015   9.58e-05   4.79e-05\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]\n",
      "                   all         28        665   0.000373    0.00301   0.000188   6.67e-05    0.00056    0.00451   0.000282    0.00016\n",
      "                rotten         28        665   0.000373    0.00301   0.000188   6.67e-05    0.00056    0.00451   0.000282    0.00016\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]\n",
      "                   all         29        547   0.000538    0.00548    0.00027   0.000198   0.000538    0.00548    0.00027   0.000153\n",
      "                rotten         29        547   0.000538    0.00548    0.00027   0.000198   0.000538    0.00548    0.00027   0.000153\n",
      "Speed: 0.1ms preprocess, 10.1ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_7/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 349.76it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_7/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.26G      1.398      1.696      3.801     0.9207        257        640: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.02it/s]\n",
      "                   all         28        665   0.000196     0.0015   9.81e-05   8.83e-05   0.000196     0.0015   9.81e-05   3.93e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.27G      1.311      1.236      3.925     0.8981        136        640: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "                   all         28        665   0.000196     0.0015    9.8e-05   8.82e-05   0.000196     0.0015    9.8e-05   3.92e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.38G      1.362      1.409      3.916     0.9022        152        640: 100%|██████████| 1/1 [00:00<00:00,  2.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "                   all         28        665   0.000195     0.0015   9.78e-05    8.8e-05   0.000195     0.0015   9.78e-05   3.91e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.42G      1.101      1.273      3.801     0.8863        108        640: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        665   0.000194     0.0015   9.74e-05   8.76e-05   0.000194     0.0015   9.74e-05   3.89e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.33G      1.402      1.668        3.8     0.8901        330        640: 100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "                   all         28        665   0.000581    0.00451   0.000292   0.000224   0.000581    0.00451   0.000292   0.000156\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "                   all         28        665   0.000581    0.00451   0.000292   0.000224   0.000581    0.00451   0.000292   0.000156\n",
      "                rotten         28        665   0.000581    0.00451   0.000292   0.000224   0.000581    0.00451   0.000292   0.000156\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "                   all         29        547    0.00188     0.0183   0.000958   0.000728    0.00169     0.0165   0.000861   0.000481\n",
      "                rotten         29        547    0.00188     0.0183   0.000958   0.000728    0.00169     0.0165   0.000861   0.000481\n",
      "Speed: 0.1ms preprocess, 10.3ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 16 images, 0 backgrounds, 0 corrupt: 100%|██████████| 16/16 [00:00<00:00, 150.24it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.8G      1.238      1.479      3.955     0.8756        636        640: 100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                   all         28        665   0.000188     0.0015   9.64e-05   5.75e-05   0.000188     0.0015   9.64e-05   5.78e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.73G      1.425      1.428      3.928     0.8775        786        640: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        665   0.000187     0.0015   9.63e-05   5.78e-05   0.000561    0.00451   0.000282    0.00016\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.86G      1.369      1.622      4.075     0.9045        726        640: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "                   all         28        665   0.000559    0.00451   0.000282   0.000142   0.000559    0.00451   0.000282   0.000151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.42G      1.241      1.276      4.146     0.9055        373        640: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                   all         28        665   0.000186     0.0015   9.65e-05   7.72e-05   0.000186     0.0015   9.65e-05   4.82e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.64G      1.236      1.322      4.031     0.8948        425        640: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                   all         28        665   0.000185     0.0015   9.58e-05   7.66e-05   0.000185     0.0015   9.58e-05   4.79e-05\n",
      "\n",
      "5 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]\n",
      "                   all         28        665   0.000559    0.00451   0.000282   0.000142   0.000559    0.00451   0.000282   0.000151\n",
      "                rotten         28        665   0.000559    0.00451   0.000282   0.000142   0.000559    0.00451   0.000282   0.000151\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]\n",
      "                   all         29        547   0.000712    0.00731   0.000359   0.000269    0.00089    0.00914   0.000449   0.000233\n",
      "                rotten         29        547   0.000712    0.00731   0.000359   0.000269    0.00089    0.00914   0.000449   0.000233\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_8/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 500.51it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_8/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.37G      1.175      1.979      3.975     0.9086        124        640: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "                   all         28        665   0.000194     0.0015   9.74e-05   8.77e-05   0.000194     0.0015   9.74e-05    3.9e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.36G     0.8713      1.197      4.053     0.8806        107        640: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "                   all         28        665   0.000195     0.0015   9.75e-05   8.77e-05   0.000195     0.0015   9.75e-05    3.9e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.26G      1.509      1.375      3.996     0.9555         93        640: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "                   all         28        665   0.000194     0.0015   9.71e-05   8.74e-05   0.000194     0.0015   9.71e-05   3.88e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5         3G     0.9706      1.096      4.185       0.87         40        640: 100%|██████████| 1/1 [00:00<00:00,  3.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "                   all         28        665   0.000193     0.0015   9.66e-05   8.69e-05   0.000193     0.0015   9.66e-05   3.86e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.27G      1.172      1.644      3.846     0.9076        175        640: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
      "                   all         28        665   0.000193     0.0015   9.66e-05   8.69e-05   0.000193     0.0015   9.66e-05   3.86e-05\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]\n",
      "                   all         28        665   0.000193     0.0015   9.67e-05    8.7e-05   0.000193     0.0015   9.67e-05   3.87e-05\n",
      "                rotten         28        665   0.000193     0.0015   9.67e-05    8.7e-05   0.000193     0.0015   9.67e-05   3.87e-05\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n",
      "                   all         29        547    0.00167     0.0165    0.00085   0.000652    0.00149     0.0146   0.000754   0.000426\n",
      "                rotten         29        547    0.00167     0.0165    0.00085   0.000652    0.00149     0.0146   0.000754   0.000426\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 19 images, 0 backgrounds, 0 corrupt: 100%|██████████| 19/19 [00:00<00:00, 168.25it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.75G      1.058      1.433      4.009     0.8808         60        640: 100%|██████████| 2/2 [00:01<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "                   all         28        665   0.000374    0.00301   0.000189   6.66e-05   0.000374    0.00301   0.000189   0.000142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5        10G      1.326       1.26      4.119     0.8728         63        640: 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        665   0.000371    0.00301   0.000188   9.53e-05   0.000371    0.00301   0.000188   7.57e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.47G      1.131      1.592      3.957     0.8841        194        640: 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        665   0.000553    0.00451   0.000279   0.000223   0.000553    0.00451   0.000279   0.000158\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       9.7G      1.199       1.35      3.966     0.8942         47        640: 100%|██████████| 2/2 [00:01<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         28        665    0.00291     0.0241    0.00149     0.0011    0.00327     0.0271    0.00168   0.000893\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      8.68G      1.249      1.665      3.592     0.8779        168        640: 100%|██████████| 2/2 [00:01<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                   all         28        665     0.0253      0.208     0.0153     0.0123     0.0253      0.208     0.0153    0.00918\n",
      "\n",
      "5 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                   all         28        665     0.0247      0.203      0.015      0.012     0.0247      0.203      0.015    0.00895\n",
      "                rotten         28        665     0.0247      0.203      0.015      0.012     0.0247      0.203      0.015    0.00895\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n",
      "                   all         29        547     0.0306      0.322     0.0214     0.0174     0.0302      0.318      0.021      0.013\n",
      "                rotten         29        547     0.0306      0.322     0.0214     0.0174     0.0302      0.318      0.021      0.013\n",
      "Speed: 0.2ms preprocess, 10.5ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_9/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 28.74it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_9/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.38G      1.505      1.582      3.291     0.8922        252        640: 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
      "                   all         28        665     0.0259      0.203     0.0157     0.0125     0.0254      0.198     0.0153    0.00923\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.49G      1.334      1.296      3.336     0.9347        129        640: 100%|██████████| 1/1 [00:00<00:00,  3.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                   all         28        665     0.0264      0.206     0.0159     0.0126     0.0258      0.202     0.0155    0.00935\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.32G      1.534      1.421       3.18     0.9196        165        640: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
      "                   all         28        665     0.0263      0.205     0.0159     0.0126     0.0257        0.2     0.0155    0.00893\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.14G      1.221      1.084      3.176     0.8983         88        640: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         28        665      0.027      0.209     0.0165      0.013     0.0264      0.205     0.0161    0.00918\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       3.4G      1.547      1.699      3.264     0.8937        283        640: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.01it/s]\n",
      "                   all         28        665     0.0305      0.235     0.0193     0.0153     0.0301      0.232      0.019     0.0108\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "                   all         28        665     0.0304      0.235     0.0193     0.0153       0.03      0.232      0.019     0.0108\n",
      "                rotten         28        665     0.0304      0.235     0.0193     0.0153       0.03      0.232      0.019     0.0108\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n",
      "                   all         29        547     0.0329      0.325     0.0242     0.0191      0.032      0.316     0.0235     0.0141\n",
      "                rotten         29        547     0.0329      0.325     0.0242     0.0191      0.032      0.316     0.0235     0.0141\n",
      "Speed: 0.1ms preprocess, 9.9ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_10/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 62.13it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_10/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.06G      1.295      1.712      3.369     0.8654        305        640: 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                   all         28        665       0.03      0.229     0.0185     0.0148     0.0298      0.227     0.0183      0.011\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.99G     0.9375     0.8961      3.873     0.8708         34        640: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n",
      "                   all         28        665     0.0308      0.235     0.0191     0.0152     0.0304      0.232     0.0189     0.0115\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.23G       1.02      1.231      3.336     0.8633        137        640: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "                   all         28        665       0.03      0.229     0.0189      0.015     0.0296      0.226     0.0186      0.011\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.28G     0.9433      1.002      3.389     0.8587         79        640: 100%|██████████| 1/1 [00:00<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "                   all         28        665      0.031      0.236     0.0197     0.0156     0.0306      0.233     0.0194     0.0115\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.99G      1.064      1.398      3.397     0.8465        102        640: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "                   all         28        665     0.0361      0.274     0.0245     0.0194     0.0359      0.272     0.0243     0.0142\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n",
      "                   all         28        665     0.0361      0.274     0.0245     0.0194     0.0359      0.272     0.0243     0.0142\n",
      "                rotten         28        665     0.0361      0.274     0.0245     0.0194     0.0359      0.272     0.0243     0.0142\n",
      "Speed: 0.1ms preprocess, 9.7ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n",
      "                   all         29        547     0.0339      0.325     0.0264     0.0209     0.0331      0.318     0.0257      0.015\n",
      "                rotten         29        547     0.0339      0.325     0.0264     0.0209     0.0331      0.318     0.0257      0.015\n",
      "Speed: 0.1ms preprocess, 10.1ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_11/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 69.38it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_11/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.06G      1.205      1.437      3.302     0.8534        301        640: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n",
      "                   all         28        665     0.0355       0.26     0.0225     0.0174     0.0359      0.263     0.0228     0.0138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.06G     0.8873      1.101      3.835     0.8924         48        640: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                   all         28        665     0.0375      0.277     0.0243     0.0189     0.0373      0.275     0.0242     0.0145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.47G      1.087      1.281      3.307     0.8768        158        640: 100%|██████████| 1/1 [00:00<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "                   all         28        665     0.0394      0.292     0.0264     0.0206     0.0394      0.292     0.0264     0.0156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.26G     0.9101     0.8522      3.609     0.8411         74        640: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "                   all         28        665     0.0417      0.308     0.0282     0.0219     0.0411      0.304     0.0278     0.0163\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.11G      1.133      1.263      3.275     0.8777        143        640: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "                   all         28        665     0.0429      0.316     0.0295     0.0228     0.0422      0.311     0.0291     0.0176\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                   all         28        665     0.0433      0.319     0.0297      0.023     0.0427      0.314     0.0293     0.0178\n",
      "                rotten         28        665     0.0433      0.319     0.0297      0.023     0.0427      0.314     0.0293     0.0178\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n",
      "                   all         29        547     0.0357      0.331     0.0292     0.0226     0.0354      0.327     0.0286     0.0163\n",
      "                rotten         29        547     0.0357      0.331     0.0292     0.0226     0.0354      0.327     0.0286     0.0163\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_12/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 61.20it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_12/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      2.94G      1.418      1.158      3.226     0.8894        124        640: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                   all         28        665     0.0417       0.29     0.0269     0.0198     0.0408      0.284     0.0262     0.0157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.12G      1.339      1.131      3.376     0.8889         89        640: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n",
      "                   all         28        665      0.041      0.287     0.0266     0.0196     0.0402      0.281     0.0259      0.016\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.12G      1.272      1.046      3.326     0.8854         80        640: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "                   all         28        665     0.0403       0.28     0.0262     0.0195     0.0396      0.275     0.0257     0.0159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.08G      1.235     0.8418      3.409     0.8525         58        640: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "                   all         28        665      0.042      0.293     0.0276     0.0205     0.0414      0.289     0.0272     0.0163\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.11G      1.469      1.327      3.192     0.8816        211        640: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "                   all         28        665     0.0429      0.301     0.0285     0.0211     0.0421      0.295     0.0279     0.0167\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "                   all         28        665     0.0428      0.299     0.0283      0.021     0.0419      0.293     0.0277     0.0166\n",
      "                rotten         28        665     0.0428      0.299     0.0283      0.021     0.0419      0.293     0.0277     0.0166\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n",
      "                   all         29        547     0.0378      0.331     0.0301      0.023     0.0376      0.329     0.0296     0.0168\n",
      "                rotten         29        547     0.0378      0.331     0.0301      0.023     0.0376      0.329     0.0296     0.0168\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_13/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 388.07it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_13/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.66G      0.791      1.068      3.383     0.8255        168        640: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                   all         28        665     0.0394      0.251     0.0249     0.0182     0.0387      0.247     0.0243     0.0156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.16G     0.8153     0.9814       3.42     0.8474        135        640: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         28        665     0.0392      0.253      0.025     0.0185     0.0387       0.25     0.0247     0.0153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.45G     0.9786      1.156      3.527     0.8535        201        640: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                   all         28        665     0.0422      0.278     0.0273     0.0198      0.041      0.271     0.0264     0.0162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.31G     0.8579      1.117      3.555     0.8708        151        640: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         28        665     0.0434      0.292      0.028     0.0205     0.0425      0.286     0.0273     0.0167\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.11G     0.9665       1.08      3.438     0.8355        170        640: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "                   all         28        665     0.0443      0.301     0.0289     0.0211     0.0434      0.295     0.0282     0.0172\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                   all         28        665     0.0442      0.299     0.0287      0.021     0.0433      0.293      0.028     0.0171\n",
      "                rotten         28        665     0.0442      0.299     0.0287      0.021     0.0433      0.293      0.028     0.0171\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.19it/s]\n",
      "                   all         29        547      0.036      0.302     0.0269       0.02     0.0353      0.296     0.0263     0.0153\n",
      "                rotten         29        547      0.036      0.302     0.0269       0.02     0.0353      0.296     0.0263     0.0153\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<00:00, 94.44it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.52G      1.384      1.255      4.018     0.8957        142        640: 100%|██████████| 3/3 [00:02<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         28        665   0.000562    0.00451   0.000284   0.000143   0.000562    0.00451   0.000284   0.000114\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.77G      1.244      1.456      3.973     0.8843        179        640: 100%|██████████| 3/3 [00:02<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "                   all         28        665    0.00187      0.015   0.000954   0.000743    0.00206     0.0165    0.00105    0.00059\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.86G      1.288      1.485      3.677     0.8939         99        640: 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "                   all         28        665     0.0744       0.58     0.0875     0.0688      0.074      0.577     0.0866     0.0498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.95G      1.066      1.241      2.677     0.8619        193        640: 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "                   all         28        665       0.54      0.827      0.695      0.534      0.537      0.823      0.687      0.355\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.1G     0.8349     0.9482      1.331     0.8318        157        640: 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "                   all         28        665      0.591      0.938      0.772        0.6       0.59      0.937      0.769      0.402\n",
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                   all         28        665      0.591      0.938      0.772      0.599       0.59      0.937      0.769      0.403\n",
      "                rotten         28        665      0.591      0.938      0.772      0.599       0.59      0.937      0.769      0.403\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.27it/s]\n",
      "                   all         29        547      0.516      0.943      0.698      0.539      0.513      0.938      0.691      0.351\n",
      "                rotten         29        547      0.516      0.943      0.698      0.539      0.513      0.938      0.691      0.351\n",
      "Speed: 0.1ms preprocess, 10.4ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_14/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 76.02it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_14/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       3.4G     0.6507     0.8318      1.333     0.7966        157        640: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "                   all         28        665      0.611      0.912      0.798      0.623      0.605      0.911      0.781      0.429\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.33G     0.7811     0.7701      1.213     0.8286        188        640: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                   all         28        665      0.609      0.919      0.801      0.625      0.603      0.916      0.791       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.59G     0.6557     0.8326     0.8755     0.8191        266        640: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "                   all         28        665       0.61       0.91      0.805      0.627      0.605      0.903       0.79      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.61G     0.6537     0.7958      1.033     0.8361        213        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         28        665      0.613      0.911      0.808      0.634      0.608      0.904      0.793      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.28G     0.8115     0.8293      1.197     0.7988        227        640: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         28        665      0.609      0.911       0.81      0.634      0.605      0.905      0.799      0.435\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "                   all         28        665       0.61       0.91      0.809      0.634      0.606      0.904        0.8      0.434\n",
      "                rotten         28        665       0.61       0.91      0.809      0.634      0.606      0.904        0.8      0.434\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n",
      "                   all         29        547      0.517      0.925      0.695       0.54      0.512      0.912      0.686      0.353\n",
      "                rotten         29        547      0.517      0.925      0.695       0.54      0.512      0.912      0.686      0.353\n",
      "Speed: 0.1ms preprocess, 10.2ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_15/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 570.10it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_15/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.77G     0.6816     0.7663      1.909     0.7976        120        640: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "                   all         28        665      0.621      0.896      0.777      0.607      0.617      0.887       0.77      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.18G     0.7252      0.831      1.541     0.8138        129        640: 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                   all         28        665      0.621      0.889       0.78      0.609      0.615       0.88      0.771      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.26G     0.6423     0.8487      1.175     0.8087        112        640: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "                   all         28        665      0.621      0.884      0.786      0.614      0.614      0.875      0.778      0.435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.23G     0.7346     0.8585      1.155     0.8219        137        640: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "                   all         28        665      0.622      0.878      0.789      0.618      0.616      0.869       0.78      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.14G     0.6506     0.9077      1.679     0.7962        119        640: 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "                   all         28        665      0.624       0.88      0.791      0.619      0.616      0.872      0.778      0.436\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                   all         28        665      0.624       0.88      0.793       0.62      0.616      0.869      0.779      0.438\n",
      "                rotten         28        665      0.624       0.88      0.793       0.62      0.616      0.869      0.779      0.438\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n",
      "                   all         29        547      0.519      0.914      0.665      0.513      0.514      0.905      0.653      0.342\n",
      "                rotten         29        547      0.519      0.914      0.665      0.513      0.514      0.905      0.653      0.342\n",
      "Speed: 0.1ms preprocess, 10.2ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 46 images, 0 backgrounds, 0 corrupt: 100%|██████████| 46/46 [00:00<00:00, 103.10it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.47G      1.244       1.37      4.091     0.8843        426        640: 100%|██████████| 3/3 [00:03<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "                   all         28        665   0.000186     0.0015    9.6e-05   7.68e-05   0.000371    0.00301   0.000188   0.000104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.73G      1.226      1.497      3.965     0.9014        889        640: 100%|██████████| 3/3 [00:03<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "                   all         28        665   0.000368    0.00301   0.000186   0.000149   0.000368    0.00301   0.000186   9.31e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.64G      1.261      1.464      3.738     0.8784        459        640: 100%|██████████| 3/3 [00:03<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "                   all         28        665      0.107      0.893      0.231      0.182      0.106      0.889      0.228      0.124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.91G     0.9038      1.128      2.333     0.8432        678        640: 100%|██████████| 3/3 [00:03<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n",
      "                   all         28        665      0.639      0.924      0.725      0.557      0.635      0.918      0.719      0.374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.68G     0.8116     0.9903      1.073      0.822        738        640: 100%|██████████| 3/3 [00:03<00:00,  1.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "                   all         28        665      0.613      0.954      0.767      0.578      0.606      0.944      0.745      0.382\n",
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n",
      "                   all         28        665      0.612      0.955      0.766      0.578      0.606      0.944      0.745       0.38\n",
      "                rotten         28        665      0.612      0.955      0.766      0.578      0.606      0.944      0.745       0.38\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n",
      "                   all         29        547       0.53      0.949      0.691      0.516      0.525       0.94       0.68      0.331\n",
      "                rotten         29        547       0.53      0.949      0.691      0.516      0.525       0.94       0.68      0.331\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_16/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 194.73it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_16/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       3.4G     0.7194     0.7919      2.471     0.8009        106        640: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "                   all         28        665      0.628       0.95      0.781      0.589      0.621      0.943      0.766      0.393\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.19G     0.8021     0.7951      1.597     0.8073        134        640: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "                   all         28        665      0.621      0.943      0.783      0.591      0.615      0.934      0.767      0.396\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.39G      0.872     0.9385      1.003     0.8209        153        640: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         28        665      0.625      0.935      0.786      0.595      0.619      0.926       0.77        0.4\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.32G     0.8696     0.9128      1.061     0.8184        156        640: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                   all         28        665      0.625      0.927      0.789      0.596       0.62       0.92      0.773      0.402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.08G     0.8819     0.9061       1.77     0.7857        132        640: 100%|██████████| 1/1 [00:00<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         28        665      0.612      0.935      0.791      0.598      0.608      0.928      0.775      0.404\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n",
      "                   all         28        665      0.614      0.935      0.791      0.598       0.61      0.927      0.775      0.402\n",
      "                rotten         28        665      0.614      0.935      0.791      0.598       0.61      0.927      0.775      0.402\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n",
      "                   all         29        547      0.517      0.936      0.678      0.506      0.511      0.929      0.668      0.325\n",
      "                rotten         29        547      0.517      0.936      0.678      0.506      0.511      0.929      0.668      0.325\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 51 images, 0 backgrounds, 0 corrupt: 100%|██████████| 51/51 [00:00<00:00, 105.34it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      10.1G      1.354      1.501      3.974     0.9117        225        640: 100%|██████████| 4/4 [00:04<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "                   all         28        665    0.00037    0.00301   0.000189    8.7e-05    0.00037    0.00301   0.000189    6.7e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.74G      1.279      1.553       3.91     0.9102         92        640: 100%|██████████| 4/4 [00:03<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
      "                   all         28        665     0.0335      0.274     0.0216     0.0173     0.0332      0.271     0.0213     0.0126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.88G     0.9514      1.143      2.339     0.8559        107        640: 100%|██████████| 4/4 [00:03<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "                   all         28        665      0.638      0.937      0.699       0.54      0.624      0.937      0.693      0.358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.82G      0.729      0.848     0.9359     0.8134        173        640: 100%|██████████| 4/4 [00:03<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "                   all         28        665      0.643      0.892      0.841      0.666      0.642       0.89      0.837      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.91G     0.7286     0.7228     0.9039       0.81        276        640: 100%|██████████| 4/4 [00:03<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "                   all         28        665       0.76      0.752      0.855      0.668       0.75      0.747       0.84      0.423\n",
      "\n",
      "5 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                   all         28        665      0.643      0.889       0.84      0.666      0.641      0.888      0.837      0.451\n",
      "                rotten         28        665      0.643      0.889       0.84      0.666      0.641      0.888      0.837      0.451\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n",
      "                   all         29        547      0.567      0.865      0.767      0.611      0.564      0.859      0.753       0.39\n",
      "                rotten         29        547      0.567      0.865      0.767      0.611      0.564      0.859      0.753       0.39\n",
      "Speed: 0.1ms preprocess, 10.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_17/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 96.47it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_17/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.68G     0.5976      0.654      1.246     0.8103        112        640: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "                   all         28        665      0.684      0.809      0.831      0.651      0.676      0.802      0.815      0.426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.23G     0.6746     0.6636     0.8564      0.813        181        640: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "                   all         28        665      0.691      0.776      0.833      0.653      0.683       0.77      0.817      0.427\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.69G      0.707     0.6913      1.028     0.8158        278        640: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         28        665      0.712       0.77      0.836      0.657      0.693      0.768      0.821      0.429\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.64G     0.7329     0.7015       1.05     0.8126        255        640: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         28        665      0.715      0.762      0.838      0.659      0.708      0.755      0.823       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       4.2G     0.6795     0.6318     0.8221     0.7823        207        640: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "                   all         28        665      0.713      0.765      0.841      0.664      0.707      0.756      0.826      0.431\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                   all         28        665      0.716      0.765      0.841      0.664      0.707      0.754      0.826      0.431\n",
      "                rotten         28        665      0.716      0.765      0.841      0.664      0.707      0.754      0.826      0.431\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.32it/s]\n",
      "                   all         29        547      0.631      0.786      0.803      0.625      0.623      0.777      0.784      0.376\n",
      "                rotten         29        547      0.631      0.786      0.803      0.625      0.623      0.777      0.784      0.376\n",
      "Speed: 0.1ms preprocess, 9.9ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 56 images, 0 backgrounds, 0 corrupt: 100%|██████████| 56/56 [00:00<00:00, 105.76it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.99G      1.136      1.429          4     0.8788        295        640: 100%|██████████| 4/4 [00:04<00:00,  1.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "                   all         28        665   0.000372    0.00301   0.000189   9.59e-05   0.000372    0.00301   0.000189   7.61e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5        10G      1.276      1.563       3.95     0.8906        406        640: 100%|██████████| 4/4 [00:04<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "                   all         28        665     0.0429      0.341     0.0289     0.0229     0.0427       0.34     0.0287      0.017\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.1G     0.9568      1.151      2.409      0.848        317        640: 100%|██████████| 4/4 [00:04<00:00,  1.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "                   all         28        665      0.605      0.937      0.738      0.545      0.599      0.928      0.724      0.368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       9.7G     0.7751     0.8357     0.9837     0.8161        362        640: 100%|██████████| 4/4 [00:03<00:00,  1.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "                   all         28        665      0.683      0.882      0.868      0.642       0.68      0.877       0.86      0.453\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.98G     0.7606     0.7574      0.826     0.7985        322        640: 100%|██████████| 4/4 [00:03<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "                   all         28        665      0.757      0.814      0.891      0.687      0.752      0.808      0.882      0.453\n",
      "\n",
      "5 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                   all         28        665      0.758      0.814      0.891      0.687       0.75      0.808      0.882      0.453\n",
      "                rotten         28        665      0.758      0.814      0.891      0.687       0.75      0.808      0.882      0.453\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]\n",
      "                   all         29        547        0.7      0.777      0.839      0.646      0.694       0.77      0.826       0.39\n",
      "                rotten         29        547        0.7      0.777      0.839      0.646      0.694       0.77      0.826       0.39\n",
      "Speed: 0.4ms preprocess, 9.9ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_18/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 575.41it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_18/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.94G     0.6322     0.7161     0.8488     0.7946        136        640: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n",
      "                   all         28        665      0.773      0.797      0.883      0.679      0.764      0.788      0.866      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.25G     0.6517     0.6774      1.198     0.8116        134        640: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        665      0.765        0.8      0.884      0.682      0.756      0.792      0.867      0.454\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.29G     0.5539     0.5817      1.054     0.8081        132        640: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "                   all         28        665      0.762      0.809      0.885      0.684      0.754      0.801      0.868      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.28G     0.5606     0.6192      1.086      0.809        111        640: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n",
      "                   all         28        665      0.762      0.803      0.883      0.684      0.752      0.795      0.867      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.42G     0.8008      0.859     0.8248     0.8003        200        640: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                   all         28        665       0.77      0.797      0.884      0.685      0.758      0.788      0.868      0.457\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                   all         28        665      0.772      0.796      0.884      0.685      0.758      0.788      0.868      0.457\n",
      "                rotten         28        665      0.772      0.796      0.884      0.685      0.758      0.788      0.868      0.457\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n",
      "                   all         29        547      0.715      0.755      0.831       0.64      0.704      0.748      0.815      0.398\n",
      "                rotten         29        547      0.715      0.755      0.831       0.64      0.704      0.748      0.815      0.398\n",
      "Speed: 0.1ms preprocess, 9.9ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_19/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 145.67it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_19/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.83G     0.6498     0.6996     0.7312     0.7996        229        640: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "                   all         28        665      0.725        0.8      0.863      0.662       0.72      0.794      0.854      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.45G     0.6593     0.7997     0.6907     0.8129        181        640: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "                   all         28        665      0.753      0.792      0.866      0.664      0.746      0.785      0.852      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.35G     0.7179     0.6391     0.8642     0.8043        147        640: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        665      0.754      0.794      0.869      0.668      0.746      0.786      0.852      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.27G     0.6684      0.626     0.9673     0.7987         93        640: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        665      0.763      0.782       0.87       0.67      0.753      0.773      0.853      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.31G     0.7373      0.676     0.8501     0.8077        154        640: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "                   all         28        665      0.772      0.777      0.871      0.675      0.759      0.769      0.852      0.455\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "                   all         28        665       0.77       0.78      0.871      0.675      0.759       0.77      0.852      0.455\n",
      "                rotten         28        665       0.77       0.78      0.871      0.675      0.759       0.77      0.852      0.455\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n",
      "                   all         29        547       0.74      0.702      0.815      0.626      0.724      0.698      0.802      0.401\n",
      "                rotten         29        547       0.74      0.702      0.815      0.626      0.724      0.698      0.802      0.401\n",
      "Speed: 0.1ms preprocess, 9.9ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_20/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 351.49it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_20/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.77G     0.6075     0.5207      1.538     0.7852         68        640: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "                   all         28        665      0.675      0.798       0.83      0.629      0.666      0.792      0.814      0.446\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.06G     0.6319     0.7028      1.849     0.7771         79        640: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "                   all         28        665      0.709      0.764      0.833      0.635        0.7      0.755      0.818      0.447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       4.1G     0.6269     0.5909      1.485     0.7761         77        640: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "                   all         28        665      0.714      0.767      0.838      0.641      0.705      0.758      0.822      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.06G     0.6435     0.7311      1.603     0.8261         91        640: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "                   all         28        665       0.71      0.774      0.839      0.643        0.7      0.767      0.824      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.05G     0.6645     0.5504      1.943     0.8071         75        640: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "                   all         28        665      0.722       0.77      0.843      0.648      0.711      0.762      0.825      0.454\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                   all         28        665      0.718      0.774      0.842      0.648      0.707      0.764      0.825      0.453\n",
      "                rotten         28        665      0.718      0.774      0.842      0.648      0.707      0.764      0.825      0.453\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n",
      "                   all         29        547      0.565      0.878      0.784      0.588      0.557      0.874       0.77      0.377\n",
      "                rotten         29        547      0.565      0.878      0.784      0.588      0.557      0.874       0.77      0.377\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 71 images, 0 backgrounds, 0 corrupt: 100%|██████████| 71/71 [00:00<00:00, 119.27it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5        10G      1.229      1.368      4.035     0.8896        198        640: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "                   all         28        665   0.000184     0.0015    9.6e-05   7.68e-05   0.000184     0.0015    9.6e-05    4.8e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.98G      1.175       1.52       3.71     0.8863        219        640: 100%|██████████| 5/5 [00:04<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "                   all         28        665      0.546      0.383      0.536      0.421       0.55      0.366      0.531      0.282\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.76G     0.8535     0.9959      1.609     0.8248        289        640: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "                   all         28        665      0.581      0.858      0.797      0.593      0.577      0.852      0.784      0.389\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5        10G     0.7192     0.7567     0.8882     0.8056        319        640: 100%|██████████| 5/5 [00:04<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "                   all         28        665      0.815      0.761      0.883      0.694       0.81      0.761      0.878      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.69G     0.7169     0.7067     0.8163     0.8045        535        640: 100%|██████████| 5/5 [00:05<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
      "                   all         28        665      0.881      0.808      0.929      0.745      0.874      0.802      0.919      0.486\n",
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.04it/s]\n",
      "                   all         28        665      0.917      0.783      0.929      0.746      0.875      0.803      0.919      0.485\n",
      "                rotten         28        665      0.917      0.783      0.929      0.746      0.875      0.803      0.919      0.485\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.16it/s]\n",
      "                   all         29        547      0.783      0.793      0.887      0.717      0.776      0.785      0.872      0.431\n",
      "                rotten         29        547      0.783      0.793      0.887      0.717      0.776      0.785      0.872      0.431\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_21/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 71.98it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_21/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.37G      1.151     0.9812     0.6575     0.8113        361        640: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n",
      "                   all         28        665       0.84       0.82      0.913      0.724      0.829      0.814      0.903      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.27G      1.003     0.9077     0.6918     0.8314        211        640: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                   all         28        665      0.846      0.818      0.913      0.725      0.839      0.812      0.903      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.29G     0.9163     0.9857     0.6753     0.8242        161        640: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "                   all         28        665      0.863      0.805      0.913      0.725      0.857        0.8      0.904      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.57G     0.9135     0.8536     0.6483     0.8224        205        640: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        665      0.857      0.808      0.915      0.727      0.842      0.809      0.905       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.24G     0.9431      1.233     0.6593     0.8203        232        640: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         28        665      0.856      0.812      0.916      0.732      0.849      0.806      0.906      0.481\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "                   all         28        665      0.856      0.812      0.916      0.732      0.849      0.806      0.906      0.481\n",
      "                rotten         28        665      0.856      0.812      0.916      0.732      0.849      0.806      0.906      0.481\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n",
      "                   all         29        547      0.783      0.753      0.871      0.705      0.748       0.77      0.855      0.436\n",
      "                rotten         29        547      0.783      0.753      0.871      0.705      0.748       0.77      0.855      0.436\n",
      "Speed: 0.3ms preprocess, 9.8ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_22/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 54.78it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_22/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.81G     0.6696     0.6302     0.6273     0.8102        203        640: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "                   all         28        665      0.785      0.835      0.892      0.702      0.778      0.827       0.88      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.48G     0.7149     0.7001     0.7407     0.8238        218        640: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        665      0.803      0.817      0.895      0.704      0.797      0.811      0.885      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.61G     0.6868     0.7094     0.6675      0.803        275        640: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all         28        665      0.818      0.814      0.901       0.71      0.812      0.808      0.891      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.64G     0.6816     0.7098     0.7765     0.8184        204        640: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        665      0.825      0.814      0.908      0.721      0.818      0.816      0.897      0.488\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.75G     0.7179     0.7162     0.6367     0.7828        353        640: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         28        665      0.835      0.824      0.912      0.726      0.829      0.818      0.902      0.492\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "                   all         28        665      0.837      0.825      0.912      0.726       0.83       0.82      0.902      0.491\n",
      "                rotten         28        665      0.837      0.825      0.912      0.726       0.83       0.82      0.902      0.491\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n",
      "                   all         29        547       0.76      0.773      0.864        0.7      0.747      0.773      0.848      0.439\n",
      "                rotten         29        547       0.76      0.773      0.864        0.7      0.747      0.773      0.848      0.439\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_23/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 119.77it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_23/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.75G     0.5111     0.5572      1.322     0.7846        100        640: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n",
      "                   all         28        665      0.827      0.782      0.896      0.695      0.815      0.775      0.883      0.496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.24G     0.6756      0.546     0.9649     0.8103        136        640: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "                   all         28        665      0.828      0.782      0.896      0.697      0.819      0.777      0.886      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.25G     0.6864     0.6308     0.7084     0.8195        122        640: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "                   all         28        665      0.824      0.775      0.896      0.701      0.818      0.769      0.886      0.493\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.37G     0.7233     0.6275     0.7593     0.8146        159        640: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "                   all         28        665      0.832      0.782      0.898      0.703      0.818      0.782      0.888      0.492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.23G     0.6759     0.5941     0.8693     0.8282        137        640: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "                   all         28        665      0.834      0.783      0.898      0.703      0.825      0.777      0.889      0.496\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                   all         28        665      0.834      0.783      0.898      0.703      0.825      0.777      0.888      0.497\n",
      "                rotten         28        665      0.834      0.783      0.898      0.703      0.825      0.777      0.888      0.497\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.27it/s]\n",
      "                   all         29        547      0.756      0.742      0.846      0.672      0.748       0.74       0.83      0.431\n",
      "                rotten         29        547      0.756      0.742      0.846      0.672      0.748       0.74       0.83      0.431\n",
      "Speed: 0.2ms preprocess, 9.9ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 86 images, 0 backgrounds, 0 corrupt: 100%|██████████| 86/86 [00:00<00:00, 108.19it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.57G      1.269       1.45      4.061     0.8896        357        640: 100%|██████████| 6/6 [00:06<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "                   all         28        665    0.00147      0.012   0.000746   0.000578    0.00147      0.012   0.000746   0.000447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.8G      1.073      1.377      3.164     0.8679        174        640: 100%|██████████| 6/6 [00:06<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "                   all         28        665       0.62      0.944      0.727      0.552      0.613      0.934      0.715      0.364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.98G     0.7239     0.8029      1.003     0.8094        146        640: 100%|██████████| 6/6 [00:06<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "                   all         28        665      0.845       0.82       0.92      0.737      0.844      0.819      0.917      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.82G     0.7316     0.6942     0.7904     0.8054        253        640: 100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "                   all         28        665      0.835      0.853      0.911      0.686      0.832       0.85      0.905      0.492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.75G     0.6662     0.6273     0.7513     0.7958        163        640: 100%|██████████| 6/6 [00:06<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "                   all         28        665      0.885      0.871      0.941      0.759      0.882      0.868      0.937      0.506\n",
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                   all         28        665      0.885      0.871      0.941      0.758      0.882      0.868      0.937      0.506\n",
      "                rotten         28        665      0.885      0.871      0.941      0.758      0.882      0.868      0.937      0.506\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n",
      "                   all         29        547      0.808      0.865      0.908      0.749      0.801      0.859      0.899      0.454\n",
      "                rotten         29        547      0.808      0.865      0.908      0.749      0.801      0.859      0.899      0.454\n",
      "Speed: 0.1ms preprocess, 10.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_24/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 505.91it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_24/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.08G     0.6214     0.6182     0.7684     0.7851        195        640: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "                   all         28        665      0.858      0.865      0.918      0.734      0.852      0.859      0.908      0.499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.21G     0.6662     0.7229     0.8908     0.8085        164        640: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "                   all         28        665      0.859      0.862      0.919      0.735      0.855      0.858      0.913      0.502\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.53G     0.6494     0.8083     0.6799     0.8004        209        640: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "                   all         28        665       0.86      0.863       0.92      0.737      0.857       0.86      0.916      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.51G     0.6131      0.763     0.6602     0.7958        177        640: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                   all         28        665      0.877      0.865       0.93      0.748      0.874      0.862      0.926      0.512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.44G     0.6849     0.6097     0.7085     0.8238        209        640: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         28        665      0.882      0.861      0.931      0.749      0.877      0.859      0.927      0.514\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                   all         28        665       0.88      0.862       0.93      0.749      0.877       0.86      0.927      0.513\n",
      "                rotten         28        665       0.88      0.862       0.93      0.749      0.877       0.86      0.927      0.513\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "                   all         29        547      0.805      0.822      0.895      0.735      0.798      0.817      0.885      0.458\n",
      "                rotten         29        547      0.805      0.822      0.895      0.735      0.798      0.817      0.885      0.458\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_25/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 58.72it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_25/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      3.77G     0.7592     0.5908     0.5622     0.8221        187        640: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n",
      "                   all         28        665      0.852      0.832      0.903      0.716      0.846      0.826      0.892        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       4.2G     0.7491     0.6495     0.6352     0.7838        170        640: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                   all         28        665      0.854      0.836      0.905      0.719      0.849      0.831      0.897      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.65G     0.7232     0.6593     0.6865     0.8045        264        640: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                   all         28        665      0.841      0.857      0.908      0.723      0.836      0.853        0.9      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.58G     0.7749     0.7537     0.6399     0.8106        176        640: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                   all         28        665      0.847      0.857       0.91      0.725       0.84      0.851        0.9      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.15G     0.8599     0.8918     0.7302     0.8043        206        640: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         28        665      0.853      0.858      0.912       0.73      0.847      0.852      0.902      0.507\n",
      "\n",
      "5 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                   all         28        665      0.852      0.856      0.912      0.729      0.846       0.85      0.902      0.507\n",
      "                rotten         28        665      0.852      0.856      0.912      0.729      0.846       0.85      0.902      0.507\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n",
      "                   all         29        547      0.778      0.812      0.878      0.712      0.771      0.808      0.865      0.457\n",
      "                rotten         29        547      0.778      0.812      0.878      0.712      0.771      0.808      0.865      0.457\n",
      "Speed: 0.1ms preprocess, 10.3ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 96 images, 0 backgrounds, 0 corrupt: 100%|██████████| 96/96 [00:00<00:00, 107.71it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5        10G      1.299      1.489      3.991     0.8913        691        640: 100%|██████████| 6/6 [00:06<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "                   all         28        665    0.00037    0.00301   0.000188    0.00016    0.00037    0.00301   0.000188   9.41e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5        10G       1.14      1.316      3.068     0.8723        570        640: 100%|██████████| 6/6 [00:06<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "                   all         28        665      0.626      0.971      0.738      0.572      0.621      0.962      0.729      0.371\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.74G     0.7559     0.8067     0.9599     0.8096        838        640: 100%|██████████| 6/6 [00:06<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "                   all         28        665      0.797      0.812      0.892      0.701      0.793      0.808      0.882      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.3G     0.7336     0.7166     0.7062      0.798        680        640: 100%|██████████| 6/6 [00:06<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "                   all         28        665      0.856      0.861      0.931      0.712      0.848      0.854      0.913       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       9.4G      0.673     0.6078     0.7222     0.7921        585        640: 100%|██████████| 6/6 [00:06<00:00,  1.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "                   all         28        665      0.866      0.883       0.94      0.752      0.862      0.878      0.934      0.513\n",
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                   all         28        665      0.864      0.883      0.939      0.752      0.859      0.878      0.934      0.513\n",
      "                rotten         28        665      0.864      0.883      0.939      0.752      0.859      0.878      0.934      0.513\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "                   all         29        547      0.807      0.828      0.889       0.73      0.802      0.823      0.882      0.457\n",
      "                rotten         29        547      0.807      0.828      0.889       0.73      0.802      0.823      0.882      0.457\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_26/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 139.15it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_26/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.48G     0.6709     0.5194     0.6942     0.8056        256        640: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n",
      "                   all         28        665      0.847       0.88      0.926      0.735      0.839      0.874      0.915      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       4.3G     0.6215     0.5867     0.7629      0.781        190        640: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                   all         28        665      0.848      0.886      0.929      0.737      0.841      0.878      0.917      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.61G     0.5682     0.4943     0.5102     0.7812        208        640: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        665      0.852      0.886      0.929      0.739      0.847       0.88      0.921      0.511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.69G     0.5257     0.6045     0.5496      0.787        203        640: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                   all         28        665      0.848      0.886      0.933      0.741       0.84      0.879      0.922      0.513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.06G     0.7268      1.001      1.127     0.7491        150        640: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "                   all         28        665       0.85       0.89      0.933      0.741      0.844      0.884      0.926      0.515\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "                   all         28        665       0.85      0.889      0.933      0.741      0.844      0.883      0.926      0.514\n",
      "                rotten         28        665       0.85      0.889      0.933      0.741      0.844      0.883      0.926      0.514\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]\n",
      "                   all         29        547      0.767      0.846      0.882      0.715      0.762      0.841      0.874      0.462\n",
      "                rotten         29        547      0.767      0.846      0.882      0.715      0.762      0.841      0.874      0.462\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_27/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 53.42it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_27/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.62G     0.8148     0.6001        0.6     0.7988        675        640: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "                   all         28        665      0.847      0.859      0.917      0.724      0.841      0.853      0.908      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       7.3G     0.7708     0.6079     0.6674     0.7952        438        640: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        665      0.855       0.85      0.919      0.725      0.849      0.844      0.909      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.41G     0.7361     0.6688     0.6283     0.8042        670        640: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                   all         28        665      0.853      0.849      0.923      0.729      0.847      0.843      0.914      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.62G     0.5689      0.616     0.5195     0.7888        388        640: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        665      0.861       0.85      0.924      0.731      0.852      0.845      0.914      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.78G     0.5604     0.5829     0.5703     0.8062        495        640: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        665      0.866      0.851      0.929      0.733      0.856      0.844      0.917       0.51\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                   all         28        665      0.865      0.851      0.929      0.734      0.854      0.844      0.917       0.51\n",
      "                rotten         28        665      0.865      0.851      0.929      0.734      0.854      0.844      0.917       0.51\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n",
      "                   all         29        547      0.763      0.828      0.883      0.711      0.756      0.821      0.869      0.467\n",
      "                rotten         29        547      0.763      0.828      0.883      0.711      0.756      0.821      0.869      0.467\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_28/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 91.89it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_28/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.45G     0.6207     0.6075     0.6356     0.8061        378        640: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "                   all         28        665      0.818      0.864      0.916      0.708      0.812      0.858      0.905      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.26G     0.7766      0.667     0.7694     0.8024        534        640: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "                   all         28        665      0.833      0.865      0.919      0.714      0.829       0.86      0.911      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.38G     0.7363     0.6392     0.7048     0.7933        466        640: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                   all         28        665      0.855       0.86      0.921      0.719      0.847      0.857      0.911      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       7.1G     0.6107     0.5103      1.013     0.7983        248        640: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "                   all         28        665       0.85      0.869      0.923      0.723      0.845      0.863      0.914       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.18G     0.6306     0.6236     0.8155     0.8126        270        640: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "                   all         28        665       0.86      0.869      0.924      0.726      0.855      0.865      0.918      0.514\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                   all         28        665      0.859      0.869      0.924      0.727      0.854      0.865      0.918      0.513\n",
      "                rotten         28        665      0.859      0.869      0.924      0.727      0.854      0.865      0.918      0.513\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n",
      "                   all         29        547      0.785      0.817       0.88      0.705      0.777       0.81      0.867      0.466\n",
      "                rotten         29        547      0.785      0.817       0.88      0.705      0.777       0.81      0.867      0.466\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 121 images, 0 backgrounds, 0 corrupt: 100%|██████████| 121/121 [00:01<00:00, 100.65it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.04G      1.287      1.528      3.977     0.8898        310        640: 100%|██████████| 8/8 [00:09<00:00,  1.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "                   all         28        665     0.0804      0.666     0.0862     0.0686     0.0799      0.662      0.085     0.0485\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.76G     0.8001     0.9094      1.469     0.8291        359        640: 100%|██████████| 8/8 [00:09<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "                   all         28        665      0.824      0.842      0.918      0.658      0.819      0.836      0.909      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.85G     0.7506     0.6228     0.7737     0.7976        268        640: 100%|██████████| 8/8 [00:08<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "                   all         28        665      0.845      0.844      0.916       0.71      0.842      0.841      0.912      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.78G     0.6795     0.6097      0.656     0.7964        318        640: 100%|██████████| 8/8 [00:08<00:00,  1.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "                   all         28        665       0.89      0.898      0.957      0.757      0.879      0.887       0.94      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5        10G     0.6979     0.6079     0.6817      0.795        430        640: 100%|██████████| 8/8 [00:08<00:00,  1.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "                   all         28        665      0.877      0.915       0.96        0.7      0.875      0.912      0.956      0.525\n",
      "\n",
      "5 epochs completed in 0.025 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                   all         28        665       0.89      0.898      0.957      0.757      0.879      0.887       0.94      0.506\n",
      "                rotten         28        665       0.89      0.898      0.957      0.757      0.879      0.887       0.94      0.506\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n",
      "                   all         29        547      0.863      0.868      0.938      0.746      0.855      0.861      0.924      0.451\n",
      "                rotten         29        547      0.863      0.868      0.938      0.746      0.855      0.861      0.924      0.451\n",
      "Speed: 0.1ms preprocess, 10.1ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_29/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 124.00it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_29/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.14G     0.6257     0.5967     0.8037     0.7975        246        640: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                   all         28        665      0.855      0.893      0.934      0.672      0.847      0.892      0.929      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.22G     0.7667     0.6245     0.5793     0.7969        451        640: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                   all         28        665      0.855      0.896      0.936      0.677      0.852      0.893      0.932      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.54G     0.7037     0.5758     0.5609     0.7945        452        640: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                   all         28        665      0.856      0.899      0.938      0.681      0.853      0.896      0.934      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.01G     0.6833     0.6459     0.7599     0.7851        228        640: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         28        665      0.866      0.891      0.939      0.681      0.861      0.889      0.934      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.01G     0.6595     0.5948     0.6812     0.7896        227        640: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                   all         28        665      0.869       0.89      0.941      0.689      0.867      0.887      0.936      0.528\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                   all         28        665      0.869      0.891      0.941      0.689      0.867      0.888      0.936      0.527\n",
      "                rotten         28        665      0.869      0.891      0.941      0.689      0.867      0.888      0.936      0.527\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.02it/s]\n",
      "                   all         29        547      0.862      0.876      0.942      0.712      0.856       0.87      0.935      0.491\n",
      "                rotten         29        547      0.862      0.876      0.942      0.712      0.856       0.87      0.935      0.491\n",
      "Speed: 0.1ms preprocess, 10.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_30/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 91.19it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_30/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.51G      0.578     0.5169     0.5834     0.7871        470        640: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                   all         28        665      0.818      0.898      0.913      0.655      0.815      0.895      0.908      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.26G     0.6782     0.6007     0.6487     0.7898        439        640: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                   all         28        665      0.826      0.899      0.918      0.661      0.823      0.896      0.912      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.66G     0.6336     0.5491     0.6046     0.8004        514        640: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         28        665      0.827      0.901      0.923      0.665      0.825      0.898      0.918      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.44G     0.5446     0.4737      0.665     0.8053        349        640: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                   all         28        665      0.831      0.899      0.927      0.669      0.828      0.896      0.921      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.73G     0.5806     0.4718     0.6183     0.8174        463        640: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                   all         28        665      0.845      0.895      0.936      0.677      0.842      0.892       0.93      0.522\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                   all         28        665      0.848      0.895      0.936      0.677      0.845      0.892       0.93      0.523\n",
      "                rotten         28        665      0.848      0.895      0.936      0.677      0.845      0.892       0.93      0.523\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.27it/s]\n",
      "                   all         29        547      0.842      0.888      0.939        0.7      0.835      0.881      0.925      0.487\n",
      "                rotten         29        547      0.842      0.888      0.939        0.7      0.835      0.881      0.925      0.487\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 141 images, 0 backgrounds, 0 corrupt: 100%|██████████| 141/141 [00:01<00:00, 101.09it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      10.1G      1.266      1.403      3.914     0.8813        571        640: 100%|██████████| 9/9 [00:10<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "                   all         28        665      0.589      0.766      0.596      0.465      0.586      0.762       0.59      0.308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.1G     0.8027     0.8936      1.257     0.8176        475        640: 100%|██████████| 9/9 [00:09<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "                   all         28        665      0.805      0.844      0.912      0.684        0.8      0.838      0.899       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.68G     0.7426     0.6489     0.7973     0.8031        472        640: 100%|██████████| 9/9 [00:09<00:00,  1.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "                   all         28        665      0.846      0.881      0.928        0.7       0.83      0.874      0.898      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.3G     0.7332     0.6298     0.6431     0.8015       1041        640: 100%|██████████| 9/9 [00:09<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "                   all         28        665      0.889       0.91       0.96      0.664      0.883      0.907      0.953      0.499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.96G     0.7032     0.5986      0.624     0.7921        839        640: 100%|██████████| 9/9 [00:10<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "                   all         28        665      0.936      0.899      0.973      0.755      0.926      0.891      0.958      0.497\n",
      "\n",
      "5 epochs completed in 0.027 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                   all         28        665      0.935      0.899      0.972      0.754      0.922      0.895      0.962      0.498\n",
      "                rotten         28        665      0.935      0.899      0.972      0.754      0.922      0.895      0.962      0.498\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n",
      "                   all         29        547      0.914      0.899      0.956      0.759      0.904      0.892      0.943      0.464\n",
      "                rotten         29        547      0.914      0.899      0.956      0.759      0.904      0.892      0.943      0.464\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_31/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 233.61it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_31/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.44G     0.7478     0.7073     0.5686     0.7684        560        640: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        665      0.907      0.913       0.96      0.744      0.898      0.904      0.944       0.49\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       7.3G     0.7352      0.758     0.5777     0.8121        396        640: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\n",
      "                   all         28        665      0.909       0.91      0.961      0.744      0.899      0.901      0.946      0.492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.12G     0.7263     0.6168       0.62     0.7987        381        640: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                   all         28        665      0.909      0.911      0.963      0.745        0.9      0.902      0.947      0.492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.01G     0.6524     0.5828     0.7549     0.8133        171        640: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                   all         28        665      0.911       0.91      0.963      0.746        0.9      0.902      0.947      0.491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.01G     0.7085     0.6363      0.627     0.7837        273        640: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                   all         28        665      0.911      0.909      0.964      0.745      0.902        0.9      0.948      0.492\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                   all         28        665      0.911      0.908      0.964      0.745      0.902      0.899      0.948      0.492\n",
      "                rotten         28        665      0.911      0.908      0.964      0.745      0.902      0.899      0.948      0.492\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.27it/s]\n",
      "                   all         29        547      0.896      0.888      0.951      0.753      0.889      0.881      0.936      0.452\n",
      "                rotten         29        547      0.896      0.888      0.951      0.753      0.889      0.881      0.936      0.452\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|██████████| 151/151 [00:01<00:00, 105.76it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.9G      1.196       1.47      3.753     0.8871        416        640: 100%|██████████| 10/10 [00:11<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "                   all         28        665      0.634      0.952      0.658      0.499      0.627      0.942       0.65      0.326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.1G     0.7673     0.7881     0.9401     0.8126        171        640: 100%|██████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "                   all         28        665      0.777      0.835      0.858      0.649      0.756       0.82      0.826      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.82G     0.7331     0.6055     0.6801     0.7924        332        640: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "                   all         28        665      0.884      0.901       0.95      0.733       0.88      0.896      0.944      0.554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.65G     0.7781     0.6467     0.6967     0.7949        416        640: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "                   all         28        665      0.895      0.907       0.96      0.766      0.893      0.906      0.958      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.85G     0.6784     0.6316     0.6097     0.7911        258        640: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "                   all         28        665      0.955      0.901      0.974      0.749      0.952      0.898      0.969      0.568\n",
      "\n",
      "5 epochs completed in 0.029 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                   all         28        665      0.955      0.899      0.974      0.748      0.952      0.898      0.969      0.568\n",
      "                rotten         28        665      0.955      0.899      0.974      0.748      0.952      0.898      0.969      0.568\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "                   all         29        547      0.903      0.896      0.955      0.767      0.899      0.892      0.948      0.528\n",
      "                rotten         29        547      0.903      0.896      0.955      0.767      0.899      0.892      0.948      0.528\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_32/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 86.44it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_32/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.16G     0.6181     0.5811     0.6122     0.7886        262        640: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                   all         28        665      0.926      0.907       0.97      0.746      0.923      0.904      0.965      0.565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.28G     0.8079     0.5168     0.5966     0.8002        476        640: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                   all         28        665      0.933      0.908      0.971      0.747       0.93      0.905      0.965      0.565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.73G     0.6585     0.5055     0.4788     0.7986        584        640: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "                   all         28        665      0.935      0.908      0.971      0.747      0.932      0.905      0.966      0.567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.42G     0.5416       0.48     0.4995     0.7812        369        640: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                   all         28        665      0.935       0.91      0.971      0.748      0.932      0.907      0.967      0.567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.68G      0.578     0.5317     0.4882     0.7954        424        640: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                   all         28        665      0.941       0.91      0.972      0.744      0.938      0.907      0.967      0.568\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                   all         28        665      0.935       0.91      0.971      0.746      0.932      0.907      0.967      0.566\n",
      "                rotten         28        665      0.935       0.91      0.971      0.746      0.932      0.907      0.967      0.566\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "                   all         29        547      0.901      0.909      0.955      0.763      0.897      0.905      0.948      0.527\n",
      "                rotten         29        547      0.901      0.909      0.955      0.763      0.897      0.905      0.948      0.527\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 161 images, 0 backgrounds, 0 corrupt: 100%|██████████| 161/161 [00:01<00:00, 107.26it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5        10G      1.191      1.397      3.657     0.8805         26        640: 100%|██████████| 11/11 [00:11<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "                   all         28        665      0.631      0.931      0.639       0.46      0.623      0.919      0.629      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.7G     0.7903     0.7905     0.9576     0.8128         53        640: 100%|██████████| 11/11 [00:11<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n",
      "                   all         28        665      0.798      0.818      0.873      0.656      0.783      0.803      0.842      0.395\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.1G     0.7534      0.604     0.7208     0.7998         15        640: 100%|██████████| 11/11 [00:11<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "                   all         28        665      0.912       0.91      0.969      0.711      0.903      0.901      0.952      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.79G     0.7649     0.6624     0.6258     0.7986         39        640: 100%|██████████| 11/11 [00:11<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "                   all         28        665      0.953      0.904      0.977      0.715       0.95      0.901      0.973      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.5G      0.719      0.584     0.5882     0.7914         72        640: 100%|██████████| 11/11 [00:11<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "                   all         28        665      0.919      0.913      0.972      0.753      0.913      0.907       0.96      0.524\n",
      "\n",
      "5 epochs completed in 0.030 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                   all         28        665      0.919      0.913      0.972      0.754      0.911      0.905      0.958      0.523\n",
      "                rotten         28        665      0.919      0.913      0.972      0.754      0.911      0.905      0.958      0.523\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.27it/s]\n",
      "                   all         29        547      0.849      0.912      0.955      0.768       0.84      0.903      0.933      0.477\n",
      "                rotten         29        547      0.849      0.912      0.955      0.768       0.84      0.903      0.933      0.477\n",
      "Speed: 0.1ms preprocess, 9.9ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_33/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 262.13it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_33/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.11G     0.6338     0.5509     0.8334     0.7694        315        640: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         28        665      0.906      0.902       0.97      0.756      0.897      0.899      0.958      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.11G     0.7726     0.7007     0.8384     0.8002        381        640: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        665      0.907      0.904      0.971      0.757      0.899      0.899      0.959      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.55G     0.5795     0.4987     0.5999     0.7935        464        640: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                   all         28        665      0.909      0.907      0.972      0.757      0.899      0.899      0.957      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.14G      0.555     0.4394      0.911     0.7991        247        640: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                   all         28        665      0.908       0.91      0.973      0.757      0.899      0.902      0.957      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.16G     0.5996     0.5446     0.6469     0.7958        269        640: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         28        665      0.911      0.902      0.972      0.759      0.902      0.893      0.957      0.525\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                   all         28        665      0.911      0.902      0.972      0.761      0.901      0.893      0.957      0.525\n",
      "                rotten         28        665      0.911      0.902      0.972      0.761      0.901      0.893      0.957      0.525\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.23it/s]\n",
      "                   all         29        547      0.863      0.888      0.954      0.769      0.856      0.881      0.938      0.477\n",
      "                rotten         29        547      0.863      0.888      0.954      0.769      0.856      0.881      0.938      0.477\n",
      "Speed: 0.1ms preprocess, 10.1ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 171 images, 0 backgrounds, 0 corrupt: 100%|██████████| 171/171 [00:01<00:00, 111.75it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.59G      1.212      1.389      3.533     0.8825        476        640: 100%|██████████| 11/11 [00:13<00:00,  1.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "                   all         28        665      0.611      0.988      0.734      0.542      0.603      0.976      0.722      0.365\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.3G     0.7709     0.7343     0.8647     0.8026        533        640: 100%|██████████| 11/11 [00:12<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "                   all         28        665      0.823      0.849      0.918      0.694       0.81      0.835      0.892      0.423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.1G     0.7455     0.6116     0.7246     0.7946        509        640: 100%|██████████| 11/11 [00:11<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "                   all         28        665      0.928      0.907       0.97      0.754      0.909      0.889      0.934       0.47\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.1G      0.729       0.59      0.672     0.7969        499        640: 100%|██████████| 11/11 [00:11<00:00,  1.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "                   all         28        665      0.926       0.88      0.966      0.715      0.923      0.877      0.961      0.541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.4G     0.7081     0.5787     0.6029     0.7947        602        640: 100%|██████████| 11/11 [00:11<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "                   all         28        665      0.774      0.935      0.921      0.737      0.771      0.932      0.916      0.497\n",
      "\n",
      "5 epochs completed in 0.031 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                   all         28        665      0.924      0.882      0.965      0.715      0.921      0.879      0.961      0.541\n",
      "                rotten         28        665      0.924      0.882      0.965      0.715      0.921      0.879      0.961      0.541\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n",
      "                   all         29        547      0.909      0.875      0.954      0.732      0.903      0.874      0.944       0.51\n",
      "                rotten         29        547      0.909      0.875      0.954      0.732      0.903      0.874      0.944       0.51\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_34/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 159.99it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_34/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.17G     0.6336     0.5336     0.7469     0.7936        235        640: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         28        665      0.799      0.936      0.935      0.749      0.796      0.933      0.931      0.502\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.26G     0.6502     0.5475     0.5871     0.7955        484        640: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\n",
      "                   all         28        665      0.805      0.928      0.938      0.752      0.802      0.925      0.934      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.37G     0.6247      0.495     0.5372     0.7678        361        640: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         28        665      0.812      0.925      0.939      0.754      0.809      0.922      0.935      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.06G     0.6211      0.577     0.6089     0.7931        260        640: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "                   all         28        665      0.819      0.914      0.941      0.755      0.815      0.911      0.937       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.09G     0.7496     0.7915     0.5592     0.8041        227        640: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                   all         28        665      0.822      0.917      0.942      0.759      0.819      0.914      0.938      0.515\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "                   all         28        665      0.821      0.913      0.942      0.759      0.819       0.91      0.938      0.516\n",
      "                rotten         28        665      0.821      0.913      0.942      0.759      0.819       0.91      0.938      0.516\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.29it/s]\n",
      "                   all         29        547      0.786      0.905      0.929      0.766       0.78      0.899      0.919      0.481\n",
      "                rotten         29        547      0.786      0.905      0.929      0.766       0.78      0.899      0.919      0.481\n",
      "Speed: 0.1ms preprocess, 10.3ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 181 images, 0 backgrounds, 0 corrupt: 100%|██████████| 181/181 [00:01<00:00, 112.66it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5        10G      1.182      1.376      3.488     0.8787        200        640: 100%|██████████| 12/12 [00:13<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "                   all         28        665      0.639      0.989      0.701      0.517      0.635      0.983      0.697       0.36\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.3G     0.7527     0.7129     0.9258     0.8034        163        640: 100%|██████████| 12/12 [00:12<00:00,  1.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "                   all         28        665      0.838      0.884      0.908      0.718      0.836      0.883      0.906      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.91G     0.7396     0.6082     0.7173     0.7964        161        640: 100%|██████████| 12/12 [00:12<00:00,  1.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "                   all         28        665      0.933       0.92      0.975      0.702      0.931      0.919      0.972      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.97G     0.7835     0.5875     0.6592     0.7958        251        640: 100%|██████████| 12/12 [00:12<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "                   all         28        665      0.837      0.932      0.953      0.695      0.837      0.932      0.953      0.574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.59G     0.7005     0.5748     0.5721     0.7956        158        640: 100%|██████████| 12/12 [00:12<00:00,  1.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "                   all         28        665      0.899      0.919      0.967      0.778      0.896      0.916      0.962      0.545\n",
      "\n",
      "5 epochs completed in 0.033 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                   all         28        665      0.899      0.919      0.967      0.778      0.896      0.916      0.962      0.545\n",
      "                rotten         28        665      0.899      0.919      0.967      0.778      0.896      0.916      0.962      0.545\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n",
      "                   all         29        547      0.924      0.888      0.968      0.798      0.918      0.883      0.957      0.525\n",
      "                rotten         29        547      0.924      0.888      0.968      0.798      0.918      0.883      0.957      0.525\n",
      "Speed: 0.1ms preprocess, 10.1ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_35/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 89.12it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_35/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.16G     0.8748     0.8082     0.6404     0.7926        277        640: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "                   all         28        665      0.846      0.932      0.958      0.768      0.843      0.929      0.952      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.16G     0.9366      0.684     0.6258     0.7941        528        640: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                   all         28        665      0.847      0.934      0.959      0.771      0.844      0.931      0.953      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.22G     0.8016     0.5968     0.5373     0.8033        381        640: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "                   all         28        665      0.846      0.933      0.961       0.77      0.843       0.93      0.954      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.02G     0.7524     0.5754     0.6679     0.8224        205        640: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                   all         28        665      0.855      0.925      0.961      0.771      0.853      0.922      0.955      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.16G     0.8092     0.8393     0.5421      0.821        239        640: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                   all         28        665      0.856      0.923      0.961      0.771      0.853       0.92      0.956      0.546\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "                   all         28        665      0.856      0.923      0.961      0.771      0.852       0.92      0.956      0.546\n",
      "                rotten         28        665      0.856      0.923      0.961      0.771      0.852       0.92      0.956      0.546\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.29it/s]\n",
      "                   all         29        547      0.885      0.889      0.958      0.784      0.878      0.882      0.941      0.527\n",
      "                rotten         29        547      0.885      0.889      0.958      0.784      0.878      0.882      0.941      0.527\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 191 images, 0 backgrounds, 0 corrupt: 100%|██████████| 191/191 [00:01<00:00, 111.42it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5        10G      1.172      1.319      3.304     0.8761        585        640: 100%|██████████| 12/12 [00:14<00:00,  1.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "                   all         28        665      0.628       0.98      0.799       0.63      0.624      0.974      0.793      0.424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5        10G     0.7513     0.6872     0.8491     0.7985        474        640: 100%|██████████| 12/12 [00:13<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "                   all         28        665      0.838      0.875        0.9       0.69      0.829      0.869      0.877      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.7G     0.8058     0.6711     0.7119     0.7956        931        640: 100%|██████████| 12/12 [00:13<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "                   all         28        665      0.919      0.901      0.963      0.683      0.913      0.895      0.954      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.91G     0.7798     0.6092     0.6701     0.7951        734        640: 100%|██████████| 12/12 [00:13<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "                   all         28        665      0.879      0.862      0.947      0.651      0.877       0.86      0.945      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.98G     0.7359     0.5629     0.6039     0.7955        826        640: 100%|██████████| 12/12 [00:13<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "                   all         28        665      0.925      0.885      0.966      0.771      0.923      0.884      0.964       0.54\n",
      "\n",
      "5 epochs completed in 0.033 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                   all         28        665      0.924      0.884      0.965      0.771      0.922      0.883      0.964       0.54\n",
      "                rotten         28        665      0.924      0.884      0.965      0.771      0.922      0.883      0.964       0.54\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n",
      "                   all         29        547      0.901      0.874      0.956      0.788      0.897       0.87       0.95      0.517\n",
      "                rotten         29        547      0.901      0.874      0.956      0.788      0.897       0.87       0.95      0.517\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_36/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 199.35it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_36/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.18G     0.7353     0.6378     0.5661     0.7838        278        640: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "                   all         28        665      0.901      0.874      0.958      0.759      0.896      0.869      0.952       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.57G     0.7239     0.6686     0.5168     0.7985        707        640: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                   all         28        665      0.901      0.879      0.959       0.76      0.899      0.879      0.955      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       7.5G     0.6961     0.5934     0.4739     0.7939        523        640: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                   all         28        665      0.902      0.886       0.96      0.761      0.897      0.881      0.953      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.85G     0.6676     0.6624      0.577     0.8167        581        640: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                   all         28        665      0.902      0.885      0.961      0.762      0.899      0.882      0.957      0.534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.67G     0.6961     0.6408     0.5163      0.801        432        640: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                   all         28        665      0.902      0.889      0.963      0.763      0.899      0.886      0.959      0.542\n",
      "\n",
      "5 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "                   all         28        665      0.902       0.89      0.963      0.764      0.899      0.887      0.958      0.542\n",
      "                rotten         28        665      0.902       0.89      0.963      0.764      0.899      0.887      0.958      0.542\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n",
      "                   all         29        547      0.894      0.881      0.954      0.775      0.891      0.878      0.948       0.52\n",
      "                rotten         29        547      0.894      0.881      0.954      0.775      0.891      0.878      0.948       0.52\n",
      "Speed: 0.1ms preprocess, 9.8ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 201 images, 0 backgrounds, 0 corrupt: 100%|██████████| 201/201 [00:01<00:00, 112.94it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      10.2G      1.097      1.259      3.091     0.8648        357        640: 100%|██████████| 13/13 [00:14<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "                   all         28        665      0.726      0.823      0.877      0.702      0.721      0.817      0.865      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.92G     0.7863     0.7056     0.8172     0.7979        262        640: 100%|██████████| 13/13 [00:14<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "                   all         28        665      0.901      0.874      0.957      0.715      0.885      0.859      0.932      0.454\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.2G      0.781     0.6535     0.7004     0.7988        328        640: 100%|██████████| 13/13 [00:14<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "                   all         28        665      0.911      0.921       0.97      0.761      0.905      0.915      0.966      0.541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.95G     0.7811      0.585     0.6987     0.7946        271        640: 100%|██████████| 13/13 [00:13<00:00,  1.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "                   all         28        665      0.911      0.886      0.964      0.692      0.908      0.883       0.96      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.98G     0.7395       0.57     0.6077     0.7929        352        640: 100%|██████████| 13/13 [00:13<00:00,  1.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "                   all         28        665      0.898      0.899      0.965       0.74      0.897      0.898      0.963      0.553\n",
      "\n",
      "5 epochs completed in 0.034 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                   all         28        665      0.912      0.917       0.97      0.761      0.905      0.915      0.966      0.542\n",
      "                rotten         28        665      0.912      0.917       0.97      0.761      0.905      0.915      0.966      0.542\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.23it/s]\n",
      "                   all         29        547      0.901      0.879       0.95      0.762      0.901       0.87      0.938      0.495\n",
      "                rotten         29        547      0.901      0.879       0.95      0.762      0.901       0.87      0.938      0.495\n",
      "Speed: 0.1ms preprocess, 10.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_37/train/labels... 33 images, 0 backgrounds, 0 corrupt: 100%|██████████| 33/33 [00:00<00:00, 103.16it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/temp_1_37/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.7G     0.6331     0.4752      0.596     0.7894         19        640: 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                   all         28        665      0.889      0.887      0.957      0.741      0.884      0.884       0.95      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.42G     0.6866     0.5453     0.7444     0.8074         25        640: 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "                   all         28        665      0.893      0.871      0.956      0.761      0.889      0.868      0.949      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.9G     0.5785     0.4115     0.5932     0.7925         36        640: 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "                   all         28        665      0.928      0.872      0.969      0.742      0.915      0.877      0.961      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.23G     0.7046     0.5481     0.5836     0.7979         57        640: 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                   all         28        665      0.941      0.899      0.975      0.768      0.938      0.896      0.971      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.1G     0.6779     0.4552      1.431     0.8137          7        640: 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all         28        665      0.955      0.866      0.971       0.76      0.953      0.865      0.969      0.553\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                   all         28        665      0.954      0.866      0.971      0.759      0.953      0.865      0.969      0.554\n",
      "                rotten         28        665      0.954      0.866      0.971      0.759      0.953      0.865      0.969      0.554\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n",
      "                   all         29        547      0.901      0.874      0.957      0.766      0.897       0.87      0.952      0.517\n",
      "                rotten         29        547      0.901      0.874      0.957      0.766      0.897       0.87      0.952      0.517\n",
      "Speed: 0.2ms preprocess, 10.4ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.1.1 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels... 234 images, 0 backgrounds, 0 corrupt: 100%|██████████| 234/234 [00:02<00:00, 114.20it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/Berrybox_Quality_InstanceSeg-6/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/valid_1/labels.cache... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.51G      1.118      1.206      2.852     0.8588        535        640: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "                   all         28        665      0.788      0.811      0.885      0.668      0.783      0.812      0.868      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.2G     0.7953     0.6419      0.789      0.802        435        640: 100%|██████████| 15/15 [00:16<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "                   all         28        665      0.882      0.908      0.949      0.723      0.873      0.901      0.931      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.3G      0.848     0.6348     0.6564     0.8017        613        640: 100%|██████████| 15/15 [00:16<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "                   all         28        665      0.823      0.887      0.914      0.662      0.814       0.88      0.902      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.1G     0.7878     0.5514     0.6107     0.7996        534        640: 100%|██████████| 15/15 [00:16<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "                   all         28        665      0.932      0.902      0.973      0.776      0.921      0.891       0.96        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.82G     0.6855     0.5524     0.5636     0.7942        498        640: 100%|██████████| 15/15 [00:16<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "                   all         28        665      0.945      0.917      0.977      0.746      0.945      0.917      0.977        0.6\n",
      "\n",
      "5 epochs completed in 0.039 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                   all         28        665      0.945      0.917      0.977      0.747      0.944      0.916      0.977        0.6\n",
      "                rotten         28        665      0.945      0.917      0.977      0.747      0.944      0.916      0.977        0.6\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Berrybox_Quality_InstanceSeg-6/test_1/labels.cache... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n",
      "                   all         29        547      0.919      0.911      0.968      0.771      0.919      0.911      0.968      0.563\n",
      "                rotten         29        547      0.919      0.911      0.968      0.771      0.919      0.911      0.968      0.563\n",
      "Speed: 0.1ms preprocess, 10.6ms inference, 0.0ms loss, 2.5ms postprocess per image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговый результат (инкрементальное обучение) для класса 1: \n",
      " defaultdict(<class 'list'>, {0: [0.00020721092496759136, 0.0003607266074337864, 0.00027005284958320615], 1: [0.0006648566465348611, 0.0010445458639145515, 0.0007585742044491664], 2: [0.0001533349030211108, 0.00027072691455373927, 0.0001801570395266332], 3: [0.00027021438620086237, 0.000450841655312457, 0.0003600160555773973], 4: [0.0002335054331843018, 0.0004495928178598895, 0.00026877440420527895], 5: [0.00015316922600649364, 0.00027036402311594144, 0.00017996160541670458], 6: [0.00023324697011095895, 0.00044933771787726307, 0.00026862151894620727], 7: [0.012960079264115909, 0.02104875828510579, 0.013572577613718769], 8: [0.014121682070892514, 0.023477109739826987, 0.014651547565511031], 9: [0.014958358041101924, 0.025665096211008466, 0.01569378092272453], 10: [0.016327033037585002, 0.028596198578925248, 0.016570861682855133], 11: [0.01675549833683372, 0.02958491226602173, 0.016764683960282772], 12: [0.35091312258126944, 0.6905226730350382, 0.29622236592883555], 13: [0.3525808341034157, 0.6857229385328576, 0.30501096660393145], 14: [0.330803546560301, 0.6802207228938194, 0.24937270688974333], 15: [0.38985400164938483, 0.7525985236719652, 0.3396329205901808], 16: [0.38962229839486495, 0.8256977993431736, 0.28509147415252994], 17: [0.3983079217702564, 0.8152377580190577, 0.3121227174503037], 18: [0.4007808855791066, 0.8018840249172612, 0.3369305908406248], 19: [0.4305037642405013, 0.8722943930879609, 0.3583880935697834], 20: [0.43612085571525955, 0.8549373555795025, 0.392563273124143], 21: [0.438761161689101, 0.8482919994461766, 0.40869652667906664], 22: [0.4539041961029685, 0.8989274526104106, 0.397224238367864], 23: [0.4583704508251333, 0.8846934637126755, 0.4102658526093848], 24: [0.4568196161978707, 0.8821434426494518, 0.4019173161709252], 25: [0.46235447763896387, 0.8739986865134758, 0.4206104679873258], 26: [0.4665424086444724, 0.8691084987013799, 0.43437658667785106], 27: [0.4513467281660987, 0.9244976224472686, 0.3664948719821409], 28: [0.49149550354571475, 0.9347401100895778, 0.4341245412651403], 29: [0.4637383295990608, 0.9429513242063092, 0.3876416367060902], 30: [0.5281536670141751, 0.9476485667279009, 0.5217564007459367], 31: [0.47720838776597524, 0.9328565470874729, 0.4206494814240386], 32: [0.5101288404471862, 0.9441994761561041, 0.47244178262055614], 33: [0.5246384377824964, 0.9570022244808197, 0.5101266480647234], 34: [0.5168351235928226, 0.9496816472131422, 0.5022574994630407], 35: [0.49471561555621213, 0.9377367420489983, 0.4679790412078065], 36: [0.5632960670777474, 0.9679374789816764, 0.5808369654119652]})\n",
      "Количество данных (train) для класса 1: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 234]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/Berrybox_Quality_InstanceSeg-6/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "FIB_FLAG = True\n",
    "PREV_NUM = 50\n",
    "THRESHOLD = 0.001\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "\n",
    "# exp_inc.train_test_val_split(KEEP_PERC)\n",
    "# cls_tl_dict, cls_fif_dict = exp_inc.take_piece(PIECE_PERC, FIB_FLAG)\n",
    "\n",
    "# exp_inc.increm_learning(KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "# exp_inc.plot_ram_usage()\n",
    "\n",
    "exp_inc.increm_learning_one_class('1', KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "exp_inc.plot_ram_usage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379cdc34",
   "metadata": {
    "papermill": {
     "duration": 0.730954,
     "end_time": "2024-01-14T18:42:05.348310",
     "exception": false,
     "start_time": "2024-01-14T18:42:04.617356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Сравнение базового и инкрементального обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0193fd59",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.850572Z",
     "iopub.status.idle": "2023-11-08T18:23:06.850969Z",
     "shell.execute_reply": "2023-11-08T18:23:06.850802Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.850768Z"
    },
    "papermill": {
     "duration": 0.665457,
     "end_time": "2024-01-14T18:42:06.678998",
     "exception": false,
     "start_time": "2024-01-14T18:42:06.013541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/feet-14/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_base = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "result_dict_base = exp_base.base_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_base.plot_ram_usage()\n",
    "del(exp_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fff615",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.852484Z",
     "iopub.status.idle": "2023-11-08T18:23:06.852881Z",
     "shell.execute_reply": "2023-11-08T18:23:06.852713Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.852691Z"
    },
    "papermill": {
     "duration": 0.664111,
     "end_time": "2024-01-14T18:42:08.061625",
     "exception": false,
     "start_time": "2024-01-14T18:42:07.397514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC, 1, 1)\n",
    "result_dict_inc, color_dict_inc = exp_inc.increm_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_inc.plot_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badbccf0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.854063Z",
     "iopub.status.idle": "2023-11-08T18:23:06.854396Z",
     "shell.execute_reply": "2023-11-08T18:23:06.854260Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.854245Z"
    },
    "papermill": {
     "duration": 0.661661,
     "end_time": "2024-01-14T18:42:09.383652",
     "exception": false,
     "start_time": "2024-01-14T18:42:08.721991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import math \n",
    "\n",
    "map_base_list = [j[0] for j in result_dict_base.values()]\n",
    "map_inc_list = [j[0] for j in result_dict_inc.values()]\n",
    "mse = 0\n",
    "for map_base, map_inc in zip(map_base_list, map_inc_list):\n",
    "    dev = (map_base - map_inc)\n",
    "    mse += dev**2\n",
    "print(f\"MSE = {mse}\\nRMSE = {math.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb05db",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.856319Z",
     "iopub.status.idle": "2023-11-08T18:23:06.856674Z",
     "shell.execute_reply": "2023-11-08T18:23:06.856526Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.856509Z"
    },
    "papermill": {
     "duration": 0.662743,
     "end_time": "2024-01-14T18:42:10.769138",
     "exception": false,
     "start_time": "2024-01-14T18:42:10.106395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "for i, metric in enumerate(metrics_names):\n",
    "    plt.plot(list(result_dict_base.keys()),\n",
    "             [j[i] for j in result_dict_base.values()],\n",
    "             marker='o',\n",
    "             color=\"green\",\n",
    "             linestyle='-',\n",
    "             zorder=0,\n",
    "             label = \"Базовое обучение\")\n",
    "    \n",
    "    plt.scatter(list(result_dict_inc.keys()),\n",
    "                [j[i] for j in result_dict_inc.values()],\n",
    "                color=list(color_dict_inc.values()),\n",
    "                zorder=1)\n",
    "    plt.plot(list(result_dict_inc.keys()),\n",
    "             [j[i] for j in result_dict_inc.values()],\n",
    "             linestyle='-',\n",
    "             label = \"Инкрементальное обучение\")\n",
    "    \n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"Keep percent (%)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fc1db7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.858132Z",
     "iopub.status.idle": "2023-11-08T18:23:06.858483Z",
     "shell.execute_reply": "2023-11-08T18:23:06.858342Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.858326Z"
    },
    "papermill": {
     "duration": 0.720184,
     "end_time": "2024-01-14T18:42:12.146395",
     "exception": false,
     "start_time": "2024-01-14T18:42:11.426211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "num_folders = 1 / PIECE_PERC\n",
    "for folder in range(int(num_folders)):\n",
    "    dir_path = f\"temp_{folder+1}/train/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/train/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), '\\n')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6743.564397,
   "end_time": "2024-01-14T18:42:19.629642",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-14T16:49:56.065245",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
