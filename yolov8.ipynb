{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7992d000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T21:25:16.420186Z",
     "iopub.status.busy": "2024-05-13T21:25:16.419542Z",
     "iopub.status.idle": "2024-05-13T21:26:23.182895Z",
     "shell.execute_reply": "2024-05-13T21:26:23.182074Z"
    },
    "id": "tKyXaYbpvLMm",
    "outputId": "421a4599-fff2-4e30-9da2-d15013fbe64d",
    "papermill": {
     "duration": 66.7733,
     "end_time": "2024-05-13T21:26:23.185266",
     "exception": false,
     "start_time": "2024-05-13T21:25:16.411966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "jupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\r\n",
      "Collecting ipywidgets\r\n",
      "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.20.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\r\n",
      "Collecting widgetsnbextension~=4.0.10 (from ipywidgets)\r\n",
      "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting jupyterlab-widgets~=3.0.10 (from ipywidgets)\r\n",
      "  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\r\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\r\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.42)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\r\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\r\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\r\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\r\n",
      "Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.0/215.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\r\n",
      "  Attempting uninstall: widgetsnbextension\r\n",
      "    Found existing installation: widgetsnbextension 3.6.6\r\n",
      "    Uninstalling widgetsnbextension-3.6.6:\r\n",
      "      Successfully uninstalled widgetsnbextension-3.6.6\r\n",
      "  Attempting uninstall: jupyterlab-widgets\r\n",
      "    Found existing installation: jupyterlab-widgets 3.0.9\r\n",
      "    Uninstalling jupyterlab-widgets-3.0.9:\r\n",
      "      Successfully uninstalled jupyterlab-widgets-3.0.9\r\n",
      "  Attempting uninstall: ipywidgets\r\n",
      "    Found existing installation: ipywidgets 7.7.1\r\n",
      "    Uninstalling ipywidgets-7.7.1:\r\n",
      "      Successfully uninstalled ipywidgets-7.7.1\r\n",
      "Successfully installed ipywidgets-8.1.2 jupyterlab-widgets-3.0.10 widgetsnbextension-4.0.10\r\n",
      "--2024-05-13 21:26:14--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\r\n",
      "Resolving github.com (github.com)... 20.27.177.113\r\n",
      "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240513%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240513T212614Z&X-Amz-Expires=300&X-Amz-Signature=4bc7391ff9759448c9f6a6a954a499cdd846375ff19afedc86c2420717529860&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream [following]\r\n",
      "--2024-05-13 21:26:14--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240513%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240513T212614Z&X-Amz-Expires=300&X-Amz-Signature=4bc7391ff9759448c9f6a6a954a499cdd846375ff19afedc86c2420717529860&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream\r\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\r\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 54899779 (52M) [application/octet-stream]\r\n",
      "Saving to: 'yolov8m-seg.pt'\r\n",
      "\r\n",
      "yolov8m-seg.pt      100%[===================>]  52.36M  67.7MB/s    in 0.8s    \r\n",
      "\r\n",
      "2024-05-13 21:26:16 (67.7 MB/s) - 'yolov8m-seg.pt' saved [54899779/54899779]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install roboflow\n",
    "!pip -q install ultralytics==8.0.200\n",
    "!pip install -U ipywidgets\n",
    "! pip -q install ruamel.yaml\n",
    "! wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import sys\n",
    "import ruamel.yaml\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import psutil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import locale\n",
    "from IPython.display import clear_output\n",
    "import ctypes\n",
    "import ctypes.util\n",
    "import torch\n",
    "import random\n",
    "from ultralytics.utils import SETTINGS\n",
    "\n",
    "\n",
    "\n",
    "SETTINGS['wandb'] = False\n",
    "\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "# deterministic set\n",
    "torch.manual_seed(43)\n",
    "random.seed(43)\n",
    "np.random.seed(43)\n",
    "\n",
    "# rf = Roboflow(api_key=\"tD9RSesaXxGqmwVD6eVZ\")\n",
    "# project = rf.workspace(\"kafrelsheikh-university\").project(\"strawberry_diseases\")\n",
    "# dataset = project.version(2).download(\"yolov8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364d8848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-11T22:40:46.477540Z",
     "iopub.status.busy": "2024-05-11T22:40:46.476591Z",
     "iopub.status.idle": "2024-05-11T22:40:50.787038Z",
     "shell.execute_reply": "2024-05-11T22:40:50.785701Z",
     "shell.execute_reply.started": "2024-05-11T22:40:46.477505Z"
    },
    "papermill": {
     "duration": 0.007993,
     "end_time": "2024-05-13T21:26:23.202034",
     "exception": false,
     "start_time": "2024-05-13T21:26:23.194041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "! rm -rf /kaggle/working/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fd5b021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T21:26:23.219763Z",
     "iopub.status.busy": "2024-05-13T21:26:23.219020Z",
     "iopub.status.idle": "2024-05-13T21:28:50.299227Z",
     "shell.execute_reply": "2024-05-13T21:28:50.298165Z"
    },
    "papermill": {
     "duration": 147.099228,
     "end_time": "2024-05-13T21:28:50.309270",
     "exception": false,
     "start_time": "2024-05-13T21:26:23.210042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/dataset'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.copytree(\"/kaggle/input/isaid-class-7\",\"/kaggle/working/dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50df3522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T16:37:42.950780Z",
     "iopub.status.busy": "2024-05-12T16:37:42.950402Z",
     "iopub.status.idle": "2024-05-12T16:37:44.070466Z",
     "shell.execute_reply": "2024-05-12T16:37:44.069165Z",
     "shell.execute_reply.started": "2024-05-12T16:37:42.950747Z"
    },
    "papermill": {
     "duration": 0.008032,
     "end_time": "2024-05-13T21:28:50.325631",
     "exception": false,
     "start_time": "2024-05-13T21:28:50.317599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "! rm -rf /kaggle/working/dataset/isaid_class_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4d2cb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-11T22:42:43.683356Z",
     "iopub.status.busy": "2024-05-11T22:42:43.682974Z",
     "iopub.status.idle": "2024-05-11T22:42:44.654950Z",
     "shell.execute_reply": "2024-05-11T22:42:44.653727Z",
     "shell.execute_reply.started": "2024-05-11T22:42:43.683322Z"
    },
    "papermill": {
     "duration": 0.007971,
     "end_time": "2024-05-13T21:28:50.341719",
     "exception": false,
     "start_time": "2024-05-13T21:28:50.333748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "! mv /kaggle/working/dataset/isaid_class_0/train/data.yaml /kaggle/working/dataset/isaid_class_0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "403f3658",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T21:28:50.359934Z",
     "iopub.status.busy": "2024-05-13T21:28:50.359211Z",
     "iopub.status.idle": "2024-05-13T21:29:13.716971Z",
     "shell.execute_reply": "2024-05-13T21:29:13.715829Z"
    },
    "papermill": {
     "duration": 23.369478,
     "end_time": "2024-05-13T21:29:13.719435",
     "exception": false,
     "start_time": "2024-05-13T21:28:50.349957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\r\n",
      "Version: 2.1.2\r\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\r\n",
      "Home-page: https://pytorch.org/\r\n",
      "Author: PyTorch Team\r\n",
      "Author-email: packages@pytorch.org\r\n",
      "License: BSD-3\r\n",
      "Location: /opt/conda/lib/python3.10/site-packages\r\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\r\n",
      "Required-by: accelerate, catalyst, easyocr, fastai, kornia, pytorch-ignite, pytorch-lightning, stable-baselines3, thop, timm, torchaudio, torchdata, torchmetrics, torchtext, torchvision, ultralytics\r\n",
      "Name: ultralytics\r\n",
      "Version: 8.0.200\r\n",
      "Summary: Ultralytics YOLOv8 for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.\r\n",
      "Home-page: https://github.com/ultralytics/ultralytics\r\n",
      "Author: Ultralytics\r\n",
      "Author-email: hello@ultralytics.com\r\n",
      "License: AGPL-3.0\r\n",
      "Location: /opt/conda/lib/python3.10/site-packages\r\n",
      "Requires: matplotlib, numpy, opencv-python, pandas, pillow, psutil, py-cpuinfo, pyyaml, requests, scipy, seaborn, thop, torch, torchvision, tqdm\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "! pip show torch\n",
    "! pip show ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f02559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T21:29:13.738590Z",
     "iopub.status.busy": "2024-05-13T21:29:13.738162Z",
     "iopub.status.idle": "2024-05-13T21:29:13.767878Z",
     "shell.execute_reply": "2024-05-13T21:29:13.766971Z"
    },
    "papermill": {
     "duration": 0.041614,
     "end_time": "2024-05-13T21:29:13.769913",
     "exception": false,
     "start_time": "2024-05-13T21:29:13.728299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/dataset/isaid_class_7\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/dataset/isaid_class_7\n",
    "\n",
    "# trying to optimize RAM usage\n",
    "gc.enable()\n",
    "\n",
    "libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "442660b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T21:29:13.790229Z",
     "iopub.status.busy": "2024-05-13T21:29:13.789947Z",
     "iopub.status.idle": "2024-05-13T21:29:13.927036Z",
     "shell.execute_reply": "2024-05-13T21:29:13.926222Z"
    },
    "papermill": {
     "duration": 0.150458,
     "end_time": "2024-05-13T21:29:13.928997",
     "exception": false,
     "start_time": "2024-05-13T21:29:13.778539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YoloModel:\n",
    "    def __init__(self, path_to_model: str, path_to_yaml: str,\n",
    "                 train_perc: float, test_perc: float, val_perc: float,\n",
    "                 ttvs_flag = 0, tp_flag = 0):\n",
    "        \"\"\"Инициализация переменных\n",
    "\n",
    "        Args:\n",
    "            path_to_model (str): путь до весов yolov8.pt\n",
    "            path_to_yaml (str): путь до data.yaml файла датасета\n",
    "            train_perc (float): доля тренировочных данных \n",
    "            test_perc (float): доля тестовых данных\n",
    "            val_perc (float): доля валидационных данных\n",
    "        \"\"\"        \n",
    "        self.path_to_model = path_to_model\n",
    "        self.path_to_yaml = path_to_yaml\n",
    "        self.train_path = Path('train') if os.path.exists(Path('train')) else None\n",
    "        self.test_path = Path('test') if os.path.exists(Path('test')) else None\n",
    "        self.val_path = Path('valid') if os.path.exists(Path('valid')) else None\n",
    "        self.train_perc = train_perc\n",
    "        self.test_perc = test_perc\n",
    "        self.val_perc = val_perc\n",
    "        \n",
    "        self.ttvs_flag = ttvs_flag\n",
    "        self.tp_flag = tp_flag\n",
    "        \n",
    "        self.ram_usage = []\n",
    "        \n",
    "        assert self.train_path != None, 'Директория train отсутствует'\n",
    "        if (self.val_path == None):\n",
    "            os.mkdir(\"valid\", mode=0o777)\n",
    "            os.mkdir(\"valid/images\", mode=0o777)\n",
    "            os.mkdir(\"valid/labels\", mode=0o777)\n",
    "            self.val_path = Path(\"valid\")\n",
    "        if (self.test_path == None):\n",
    "            os.mkdir(\"test\", mode=0o777)\n",
    "            os.mkdir(\"test/images\", mode=0o777)\n",
    "            os.mkdir(\"test/labels\", mode=0o777)\n",
    "            self.test_path = Path(\"test\")\n",
    "    \n",
    "    def get_ram_usage(self,):\n",
    "        \"\"\"Gets the current RAM usage of the system.\n",
    "\n",
    "        Returns:\n",
    "            float: RAM usage in GB.\n",
    "        \"\"\"\n",
    "        return psutil.virtual_memory().used / 1e9\n",
    "\n",
    "    def train(self, folder_name: str, iters: int) -> YOLO: \n",
    "        \"\"\"Инициализация модели и обучение\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): название директории с частью данных\n",
    "            iters (int): кол-во интераций\n",
    "\n",
    "        Returns:\n",
    "            YOLO: экземпляр обученной модели\n",
    "        \"\"\"        \n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        # yaml.preserve_quotes = True\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = './'+folder_name+'/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(\n",
    "            # Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,\n",
    "            plots = False)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def retrain(self, folder_name: str, iters: int,) -> YOLO:\n",
    "        \"\"\"Обучение модели на всех предыдущих частях данных для профилакти просадки метрики\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): название директории с частью данных\n",
    "            iters (int): кол-во интераций\n",
    "\n",
    "        Returns:\n",
    "            YOLO: экземпляр обученной модели\n",
    "        \"\"\"        \n",
    "        os.mkdir(\"retrain\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/images\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/labels\", mode=0o777)\n",
    "\n",
    "        # собираем список всех кусков данных до нашего folder_name\n",
    "        folder_num = np.arange(1, int(folder_name.split('_')[-1]) + 1)\n",
    "        cls = folder_name.split(\"_\")[1]\n",
    "        source_pathes = [f\"temp_{cls}_{i}\" for i in folder_num]\n",
    "\n",
    "        # копируем все собранные куски данных в папку retrain\n",
    "        for path in source_pathes:\n",
    "            # собираем все файлы\n",
    "            all_images_train = os.listdir(path+\"/train/images\")\n",
    "            all_labels_train = os.listdir(path+\"/train/labels\")\n",
    "\n",
    "            for image in all_images_train:\n",
    "                shutil.copyfile(path+\"/train/images/\" + image,\n",
    "                                \"retrain/train/images/\" + image)\n",
    "            for label in all_labels_train:\n",
    "                shutil.copyfile(path+\"/train/labels/\" + label,\n",
    "                                \"retrain/train/labels/\" + label)\n",
    "\n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        \n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        # load a pretrained model (recommended for training)\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(# Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,\n",
    "            plots = False)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def test(self, folder_name: str, model: YOLO):\n",
    "        \"\"\"Тестирование модели\n",
    "\n",
    "        Args:\n",
    "            model (YOLO): экземпляр обученной модели\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"        \n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open(\"data.yaml\", 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "            \n",
    "        metrics = model.val(data=self.path_to_yaml, split=\"test\")\n",
    "        return metrics\n",
    "    \n",
    "    def train_test_val_split(self, keep_perc: float, learn_cls: str = None):\n",
    "        \"\"\"Разделение изначального датасета на заданные доли train/test/val. Удаление 1-keep_perc доли данных \n",
    "\n",
    "        Args:\n",
    "            keep_perc (float): доля данных, которую нужно оставить\n",
    "        \"\"\"        \n",
    "        # создаем директории для объединения всех файлов\n",
    "        os.mkdir(\"temp\", mode=0o777)\n",
    "        os.mkdir(\"temp/images\", mode=0o777)\n",
    "        os.mkdir(\"temp/labels\", mode=0o777)\n",
    "            \n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels',\\\n",
    "                        self.test_path / 'images', self.test_path / 'labels',\\\n",
    "                        self.val_path / 'images', self.val_path / 'labels',)\n",
    "        destination = Path('temp')\n",
    "\n",
    "        for path in source_pathes:\n",
    "            # собираем все файлы\n",
    "            allfiles = os.listdir(path)\n",
    "            # итерируем по всем файлам, чтобы переместить их в папку назначения\n",
    "            sub_folder = path.name # images or labels\n",
    "            for f in allfiles:\n",
    "                src_path = os.path.join(path, f)\n",
    "                dst_path = os.path.join(destination / sub_folder, f)\n",
    "                os.rename(src_path, dst_path)\n",
    "        total_num = len(allfiles)\n",
    "        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"temp/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read().strip()\n",
    "                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n",
    "                # а остальное - координаты сегментации\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"Пустой файл: {txt_path}\")\n",
    "                        print(text)\n",
    "                        empty_count += 1\n",
    "        print(f\"Кол-во пустых файлов - {empty_count}\")\n",
    "        # Оставляем указанный процент данных\n",
    "        if learn_cls == None:\n",
    "            for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "                num_files = len(pathes)\n",
    "                num_to_del = num_files*(1-keep_perc)\n",
    "                for i, file_path in enumerate(pathes.copy()):\n",
    "                    if i+1 >= num_to_del:\n",
    "                        break\n",
    "                    f = file_path.name.split('.')[:-1]\n",
    "                    f.append('png')\n",
    "                    try:\n",
    "                        Path(\"temp\",'images',\".\".join(f)).unlink()\n",
    "                        file_path.unlink()\n",
    "                    except OSError as e:\n",
    "                        # Файл не найден (скорее всего имеет несколько классов и был уже перемещен)\n",
    "                        pass\n",
    "                    classes[cls].remove(file_path)\n",
    "        else:\n",
    "            cls = learn_cls\n",
    "            pathes = classes[cls]\n",
    "            num_files = len(pathes)\n",
    "            num_to_del = num_files*(1-keep_perc)\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 >= num_to_del:\n",
    "                    break\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('png')\n",
    "                try:\n",
    "                    Path(\"temp\",'images',\".\".join(f)).unlink()\n",
    "                    file_path.unlink()\n",
    "                except OSError as e:\n",
    "                    # Файл не найден (скорее всего имеет несколько классов и был уже перемещен)\n",
    "                    pass\n",
    "                classes[cls].remove(file_path)\n",
    "        if learn_cls == None:\n",
    "            for cls in classes.keys():\n",
    "    #             shutil.copyfile(\"data.yaml\", f\"data_{cls}.yaml\")\n",
    "    #              # Корректируем data.yaml файл\n",
    "    #             yaml = ruamel.yaml.YAML()\n",
    "    #             with open(f'data_{cls}.yaml', 'r+') as fp:\n",
    "    #                 data = yaml.load(fp)\n",
    "    #                 data['names'] = [data['names'][int(cls)]]\n",
    "    #                 data['nc'] = 1\n",
    "    #                 fp.truncate(0)\n",
    "    #                 fp.seek(0)\n",
    "    #                 yaml.dump(data, fp)\n",
    "                os.mkdir(f\"valid_{cls}\", mode=0o777)\n",
    "                os.mkdir(f\"test_{cls}\", mode=0o777)\n",
    "\n",
    "\n",
    "                os.mkdir(f\"valid_{cls}/labels\", mode=0o777)\n",
    "                os.mkdir(f\"valid_{cls}/images\", mode=0o777)\n",
    "                os.mkdir(f\"test_{cls}/labels\", mode=0o777)\n",
    "                os.mkdir(f\"test_{cls}/images\", mode=0o777)\n",
    "        else:\n",
    "            cls = learn_cls\n",
    "            os.mkdir(f\"valid_{cls}\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}\", mode=0o777)\n",
    "            os.mkdir(f\"valid_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"valid_{cls}/images\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/images\", mode=0o777)\n",
    "        # Распределяем данные по директориям train, test, val с учетом указанных пропорций\n",
    "        class_copy = copy.deepcopy(classes)\n",
    "        if learn_cls == None:\n",
    "            for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "                num_files = len(class_copy[cls])\n",
    "                num_to_mv_train = int(num_files * self.train_perc)\n",
    "                num_to_mv_test = int(num_files * self.test_perc)\n",
    "                num_to_mv_val = int(num_files * self.val_perc)\n",
    "                # print(num_files, num_to_mv, len(pathes))\n",
    "                temp_dict_name = \"train\"\n",
    "                for i, file_path in enumerate(pathes.copy()):\n",
    "                    if i+1 > num_to_mv_train and i+1 < num_to_mv_val + num_to_mv_train:\n",
    "                        temp_dict_name = f\"valid_{cls}\"\n",
    "                    elif i+1 > num_to_mv_val + num_to_mv_train:\n",
    "                        temp_dict_name = f\"test_{cls}\"\n",
    "                    f = file_path.name.split('.')[:-1]\n",
    "                    f.append('png')\n",
    "                    shutil.copyfile(Path(\"temp\", \"images\", \".\".join(f)),\n",
    "                                    Path(temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                    shutil.copyfile(file_path,\n",
    "                                    Path(temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                    if temp_dict_name != \"train\":\n",
    "                        # remove another classes in label file\n",
    "                        orig_lines = [line.strip() for line in open(Path(temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                        new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                        with open(Path(temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                            print(*new_lines, sep='\\n', file=fp)\n",
    "                    classes[cls].remove(file_path)\n",
    "                dir_path = f\"valid_{cls}/images\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "                dir_path = f\"test_{cls}/images\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "        else:\n",
    "            cls = learn_cls\n",
    "            num_files = len(class_copy[cls])\n",
    "            num_to_mv_train = int(num_files * self.train_perc)\n",
    "            num_to_mv_test = int(num_files * self.test_perc)\n",
    "            num_to_mv_val = int(num_files * self.val_perc)\n",
    "            # print(num_files, num_to_mv, len(pathes))\n",
    "            temp_dict_name = \"train\"\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 > num_to_mv_train and i+1 < num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"valid_{cls}\"\n",
    "                elif i+1 > num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"test_{cls}\"\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('png')\n",
    "                shutil.copyfile(Path(\"temp\", \"images\", \".\".join(f)),\n",
    "                                Path(temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                shutil.copyfile(file_path,\n",
    "                                Path(temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                if temp_dict_name != \"train\":\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                classes[cls].remove(file_path)\n",
    "            dir_path = f\"valid_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "            dir_path = f\"test_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "        dir_path = f\"train/labels\"\n",
    "        print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        \n",
    "        shutil.rmtree(\"temp\")\n",
    "    \n",
    "    def __train_set_of(self,n):\n",
    "        x = []\n",
    "        temp = 2\n",
    "        while temp < n:\n",
    "            x.append(temp)\n",
    "            if temp < 10:\n",
    "                temp+=2\n",
    "            elif temp >= 10 and temp < 30:\n",
    "                temp += 3\n",
    "            elif temp >= 30 and temp < 100:\n",
    "                temp += 5\n",
    "            elif temp >= 100 and temp < 200:\n",
    "                temp += 10\n",
    "            elif temp >= 200 and temp < 300:\n",
    "                temp += 50\n",
    "            elif temp >= 300 and temp < 500:\n",
    "                temp +=100\n",
    "            elif temp >= 500:\n",
    "                temp += 500\n",
    "        if x[-1] != n:\n",
    "            x.append(n)\n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "    def take_piece(self, piece_perc: float = None, fib_flag:bool = False, learn_cls: str = None) -> (dict, dict):\n",
    "        \"\"\"Разделение исходного датасета на части равные доле piece_perc по директориям temp_{n}, n = {1..1/piece_perc}\n",
    "\n",
    "        Args:\n",
    "            piece_perc (float): доля части данных, на которые нужно поделить датасет\n",
    "        \"\"\"\n",
    "\n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels')\n",
    "        \n",
    "        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"train/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read().strip()\n",
    "                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n",
    "                # а остальное - координаты сегментации\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"Пустой файл: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "                        \n",
    "        print(f\"Кол-во пустых файлов - {empty_count}\")\n",
    "        d_c = {key: len(value) for key, value in zip(classes.keys(), classes.values())}\n",
    "        print(*[f\"Класс {key} содержит {value} объекта(-ов)\\n\" for key, value in zip(d_c.keys(), d_c.values())])\n",
    "        \n",
    "        cls_tl_dict = defaultdict(list) # key - class, value - result of __train_set_of(n)\n",
    "        cls_fif_dict = defaultdict(int) # key - class, value - num folders\n",
    "        # Разделить сначала по классам, а потом внутри класса разделить по __train_set_of\n",
    "        if learn_cls == None:\n",
    "            for cls in classes.keys():\n",
    "                print(f\"Класс {cls}\")\n",
    "                total_num = len(classes[cls])\n",
    "                print(f\"\\tКол-во train класса {cls}: {total_num}\")\n",
    "                if fib_flag == True:\n",
    "                    n = total_num\n",
    "                    train_list = self.__train_set_of(n)\n",
    "                    files_in_folder = []\n",
    "                    for i in range(len(train_list)):\n",
    "                        if i == 0:\n",
    "                            files_in_folder.append(train_list[i])\n",
    "                            continue\n",
    "                        files_in_folder.append(train_list[i] - train_list[i-1])\n",
    "                    print(f\"\\tКоличество данных (train) на каждой итерации класса {cls}: {train_list}\")\n",
    "                    cls_tl_dict[cls] = train_list\n",
    "                    cls_fif_dict[cls] = len(files_in_folder)\n",
    "\n",
    "                if fib_flag == True:\n",
    "                    self.num_folders = len(files_in_folder)\n",
    "                    print(f\"\\tКол-во директорий для класса {cls}: {self.num_folders} \")\n",
    "                else:\n",
    "                    self.num_folders = 1 / piece_perc\n",
    "                for folder in range(int(self.num_folders)):\n",
    "                    os.mkdir(f\"temp_{cls}_{folder+1}\", mode=0o777)\n",
    "\n",
    "                    os.mkdir(f\"temp_{cls}_{folder+1}/train\", mode=0o777)\n",
    "\n",
    "                    os.mkdir(f\"temp_{cls}_{folder+1}/train/labels\", mode=0o777)\n",
    "                    os.mkdir(f\"temp_{cls}_{folder+1}/train/images\", mode=0o777)\n",
    "\n",
    "                # Распределяем данные по директориям  \n",
    "                class_copy = copy.deepcopy(classes)\n",
    "                for f_i, folder in enumerate(range(int(self.num_folders))):\n",
    "                    folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                    num_to_mv_train = int(num_files * piece_perc) if fib_flag == False else files_in_folder[f_i]\n",
    "                    print(f\"\\tnum_to_mv_train {num_to_mv_train}, folder {folder}, cls {cls}\")\n",
    "                    # print(num_files, num_to_mv, len(pathes))\n",
    "                    temp_dict_name = \"train\"\n",
    "                    for i, file_path in enumerate(classes[cls].copy()):\n",
    "                        if i+1 > num_to_mv_train:\n",
    "                            break\n",
    "                        f = file_path.name.split('.')[:-1]\n",
    "                        f.append('png')\n",
    "                        shutil.copyfile(Path(\"train\", \"images\", \".\".join(f)),\n",
    "                                        Path(folder_name, temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                        shutil.copyfile(file_path,\n",
    "                                        Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                        # remove another classes in label file\n",
    "                        orig_lines = [line.strip() for line in open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                        new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                        with open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                            print(*new_lines, sep='\\n', file=fp)\n",
    "                        classes[cls].remove(file_path)\n",
    "                for folder in range(int(self.num_folders)):\n",
    "                    dir_path = f\"temp_{cls}_{folder+1}/train/labels\"\n",
    "                    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "                    dir_path = f\"temp_{cls}_{folder+1}/train/images\"\n",
    "                    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        else:\n",
    "            cls = learn_cls\n",
    "            print(f\"Класс {cls}\")\n",
    "            total_num = len(classes[cls])\n",
    "            print(f\"\\tКол-во train класса {cls}: {total_num}\")\n",
    "            if fib_flag == True:\n",
    "                n = total_num\n",
    "                train_list = self.__train_set_of(n)\n",
    "                files_in_folder = []\n",
    "                for i in range(len(train_list)):\n",
    "                    if i == 0:\n",
    "                        files_in_folder.append(train_list[i])\n",
    "                        continue\n",
    "                    files_in_folder.append(train_list[i] - train_list[i-1])\n",
    "                print(f\"\\tКоличество данных (train) на каждой итерации класса {cls}: {train_list}\")\n",
    "                cls_tl_dict[cls] = train_list\n",
    "                cls_fif_dict[cls] = len(files_in_folder)\n",
    "\n",
    "            if fib_flag == True:\n",
    "                self.num_folders = len(files_in_folder)\n",
    "                print(f\"\\tКол-во директорий для класса {cls}: {self.num_folders} \")\n",
    "            else:\n",
    "                self.num_folders = 1 / piece_perc\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/labels\", mode=0o777)\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/images\", mode=0o777)\n",
    "\n",
    "            # Распределяем данные по директориям  \n",
    "            class_copy = copy.deepcopy(classes)\n",
    "            for f_i, folder in enumerate(range(int(self.num_folders))):\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                num_to_mv_train = int(num_files * piece_perc) if fib_flag == False else files_in_folder[f_i]\n",
    "                print(f\"\\tnum_to_mv_train {num_to_mv_train}, folder {folder}, cls {cls}\")\n",
    "                # print(num_files, num_to_mv, len(pathes))\n",
    "                temp_dict_name = \"train\"\n",
    "                for i, file_path in enumerate(classes[cls].copy()):\n",
    "                    if i+1 > num_to_mv_train:\n",
    "                        break\n",
    "                    f = file_path.name.split('.')[:-1]\n",
    "                    f.append('png')\n",
    "                    shutil.copyfile(Path(\"train\", \"images\", \".\".join(f)),\n",
    "                                    Path(folder_name, temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                    shutil.copyfile(file_path,\n",
    "                                    Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                    classes[cls].remove(file_path)\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/labels\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/images\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        shutil.rmtree(\"train\")\n",
    "        return cls_tl_dict, cls_fif_dict\n",
    "    \n",
    "    def plot_result(self, result_dict: dict, color_dict = \"green\", fib_list:list = None):\n",
    "        '''Функция для отрисовки графиков зависимости метрик от размера обучающей выборки\n",
    "\n",
    "        Args:\n",
    "            result_dict (dict): словарь с метриками {доля данных: массив метрик}\n",
    "            color_dict (dict): словарь с индикаторами повторного обучения\n",
    "        '''\n",
    "        metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "        colors = list(color_dict.values()) if color_dict != 'green' else color_dict\n",
    "        if fib_list == None:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(list(result_dict.keys()), [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(list(result_dict.keys()), [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(result_dict.keys())) \n",
    "                plt.show()\n",
    "        else:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(fib_list, [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(fib_list, [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(fib_list)) \n",
    "                plt.show()\n",
    "\n",
    "    def plot_ram_usage(self,):\n",
    "        '''Функция для отрисовки использования RAM в процессе обучения'''\n",
    "        plt.plot(self.ram_usage, marker='o', linestyle='-', color='b')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('RAM Usage (GB)')\n",
    "        plt.title('RAM Usage During Training')\n",
    "        plt.show()\n",
    "    \n",
    "    def __early_stopping(self, result_dict: dict, prev_num: int, threshold: float) -> bool:\n",
    "        keys_sorted = sorted(result_dict.keys())\n",
    "        prev_results = np.array([result_dict[i][0] for i in keys_sorted[-prev_num-1:-1]])\n",
    "        res = result_dict[keys_sorted[-1]][0] - prev_results\n",
    "        print(f\"Progress for {prev_num} last iterations with {threshold} threshold = {np.sum(res)}\")\n",
    "        if np.sum(res) < threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def increm_learning(self, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        # Инкрементальное обучение \n",
    "        for cls in cls_tl_dict.keys():\n",
    "#             self.path_to_yaml = \"/\".join(self.path_to_yaml.split('/')[0:-1]) + f\"/data_{cls}.yaml\"\n",
    "            print(self.path_to_yaml)\n",
    "            result_dict = defaultdict(list)\n",
    "            # словарь с индикаторами повторного обучения\n",
    "            color_dict = defaultdict(str)\n",
    "            # переменная для отслеживания максимального map в целях профилактики просадок метрики\n",
    "            max_map = 0\n",
    "            self.path_to_model = native_path_to_model\n",
    "            for folder in range(cls_fif_dict[cls]):\n",
    "                if (folder > prev_num):\n",
    "                    if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                        break\n",
    "                libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "                libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "                torch.set_num_threads(1)\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                # дообучаем модель\n",
    "                model = self.train(folder_name, iters)\n",
    "                # тестируем модель\n",
    "                metrics = self.test(folder_name, model)\n",
    "                # проверяем, что метрика улучшается\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                    # заносим метрики в словарь\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                else:\n",
    "                    self.path_to_model = native_path_to_model\n",
    "                    # дообучаем модель\n",
    "                    model = self.retrain(folder_name, iters)\n",
    "                    # тестируем модель\n",
    "                    metrics = self.test(folder_name, model)\n",
    "                    if metrics.seg.map > max_map:\n",
    "                        max_map = metrics.seg.map\n",
    "                    # заносим метрики в словарь\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                    shutil.rmtree(\"retrain\")\n",
    "                \n",
    "            print(f\"Итоговый результат (инкрементальное обучение) для класса {cls}: \\n {result_dict}\")\n",
    "            print(f\"Количество данных (train) для класса {cls}: {cls_tl_dict[cls]}\")\n",
    "            self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "            \n",
    "    def increm_learning_one_class(self,learn_cls: str, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc,learn_cls)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag, learn_cls)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        # Инкрементальное обучение \n",
    "        cls = learn_cls\n",
    "#         self.path_to_yaml = \"/\".join(self.path_to_yaml.split('/')[0:-1]) + f\"/data_{cls}.yaml\"\n",
    "        print(self.path_to_yaml)\n",
    "        print(cls_fif_dict, cls_tl_dict)\n",
    "        result_dict = defaultdict(list)\n",
    "        # словарь с индикаторами повторного обучения\n",
    "        color_dict = defaultdict(str)\n",
    "        # переменная для отслеживания максимального map в целях профилактики просадок метрики\n",
    "        max_map = 0\n",
    "        self.path_to_model = native_path_to_model\n",
    "        for folder in range(cls_fif_dict[cls]):\n",
    "            if (folder > prev_num):\n",
    "                if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                    print(\"EARLY STOPPING\")\n",
    "                    break\n",
    "            libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "            libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "            torch.set_num_threads(1)\n",
    "            folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "            # дообучаем модель\n",
    "            model = self.train(folder_name, iters)\n",
    "            # тестируем модель\n",
    "            metrics = self.test(folder_name, model)\n",
    "            # проверяем, что метрика улучшается\n",
    "            if metrics.seg.map > max_map:\n",
    "                max_map = metrics.seg.map\n",
    "                # заносим метрики в словарь\n",
    "                result_dict[folder].append(metrics.seg.map)\n",
    "                result_dict[folder].append(metrics.seg.map50)\n",
    "                result_dict[folder].append(metrics.seg.map75)\n",
    "                color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                del(model)\n",
    "                del(metrics)\n",
    "                gc.collect()\n",
    "                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "            else:\n",
    "                self.path_to_model = native_path_to_model\n",
    "                # дообучаем модель\n",
    "                model = self.retrain(folder_name, iters)\n",
    "                # тестируем модель\n",
    "                metrics = self.test(folder_name, model)\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                # заносим метрики в словарь\n",
    "                result_dict[folder].append(metrics.seg.map)\n",
    "                result_dict[folder].append(metrics.seg.map50)\n",
    "                result_dict[folder].append(metrics.seg.map75)\n",
    "                color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                del(model)\n",
    "                del(metrics)\n",
    "                gc.collect()\n",
    "                self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                shutil.rmtree(\"retrain\")\n",
    "\n",
    "        print(f\"Итоговый результат (инкрементальное обучение) для класса {cls}: \\n {result_dict}\")\n",
    "        print(f\"Количество данных (train) для класса {cls}: {cls_tl_dict[cls]}\")\n",
    "        self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "            \n",
    "    def base_learning(self, keep_perc: float, piece_perc: float, iters: int):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            self.take_piece(piece_perc)\n",
    "            self.tp_flag = 1\n",
    "        else: \n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        result_dict = {k_p:[] for k_p in range(int(self.num_folders))}\n",
    "        \n",
    "        for folder in range(int(self.num_folders)):\n",
    "            folder_name = f\"temp_{folder+1}\"\n",
    "            # дообучаем модель\n",
    "            model = self.retrain(folder_name, iters)\n",
    "            # тестируем модель\n",
    "            metrics = self.test(model)\n",
    "            # заносим метрики в словарь\n",
    "            result_dict[folder].append(metrics.seg.map)\n",
    "            result_dict[folder].append(metrics.seg.map50)\n",
    "            result_dict[folder].append(metrics.seg.map75)\n",
    "            clear_output(wait=True)\n",
    "            del(model)\n",
    "            del(metrics)\n",
    "            gc.collect()\n",
    "            shutil.rmtree(\"retrain\")\n",
    "            \n",
    "        print(f\"Итоговый результат (базовое обучение): \\n {result_dict}\")\n",
    "        self.plot_result(result_dict)\n",
    "        \n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99e093a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T21:29:13.947141Z",
     "iopub.status.busy": "2024-05-13T21:29:13.946872Z",
     "iopub.status.idle": "2024-05-14T05:38:18.857335Z",
     "shell.execute_reply": "2024-05-14T05:38:18.856382Z"
    },
    "papermill": {
     "duration": 29347.662814,
     "end_time": "2024-05-14T05:38:21.600286",
     "exception": false,
     "start_time": "2024-05-13T21:29:13.937472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во пустых файлов - 0\n",
      "valid_7/images 852\n",
      "test_7/images 852\n",
      "train/labels 6816 \n",
      "\n",
      "Кол-во пустых файлов - 0\n",
      "Класс 7 содержит 6816 объекта(-ов)\n",
      " Класс 8 содержит 6058 объекта(-ов)\n",
      " Класс 3 содержит 238 объекта(-ов)\n",
      " Класс 4 содержит 117 объекта(-ов)\n",
      " Класс 12 содержит 280 объекта(-ов)\n",
      " Класс 0 содержит 696 объекта(-ов)\n",
      " Класс 13 содержит 1384 объекта(-ов)\n",
      " Класс 2 содержит 84 объекта(-ов)\n",
      " Класс 5 содержит 222 объекта(-ов)\n",
      " Класс 1 содержит 599 объекта(-ов)\n",
      " Класс 10 содержит 294 объекта(-ов)\n",
      " Класс 14 содержит 401 объекта(-ов)\n",
      " Класс 6 содержит 257 объекта(-ов)\n",
      " Класс 11 содержит 271 объекта(-ов)\n",
      " Класс 9 содержит 56 объекта(-ов)\n",
      "\n",
      "Класс 7\n",
      "\tКол-во train класса 7: 6816\n",
      "\tКоличество данных (train) на каждой итерации класса 7: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 4001, 4501, 5001, 5501, 6001, 6501, 6816]\n",
      "\tКол-во директорий для класса 7: 53 \n",
      "\tnum_to_mv_train 2, folder 0, cls 7\n",
      "\tnum_to_mv_train 2, folder 1, cls 7\n",
      "\tnum_to_mv_train 2, folder 2, cls 7\n",
      "\tnum_to_mv_train 2, folder 3, cls 7\n",
      "\tnum_to_mv_train 2, folder 4, cls 7\n",
      "\tnum_to_mv_train 3, folder 5, cls 7\n",
      "\tnum_to_mv_train 3, folder 6, cls 7\n",
      "\tnum_to_mv_train 3, folder 7, cls 7\n",
      "\tnum_to_mv_train 3, folder 8, cls 7\n",
      "\tnum_to_mv_train 3, folder 9, cls 7\n",
      "\tnum_to_mv_train 3, folder 10, cls 7\n",
      "\tnum_to_mv_train 3, folder 11, cls 7\n",
      "\tnum_to_mv_train 5, folder 12, cls 7\n",
      "\tnum_to_mv_train 5, folder 13, cls 7\n",
      "\tnum_to_mv_train 5, folder 14, cls 7\n",
      "\tnum_to_mv_train 5, folder 15, cls 7\n",
      "\tnum_to_mv_train 5, folder 16, cls 7\n",
      "\tnum_to_mv_train 5, folder 17, cls 7\n",
      "\tnum_to_mv_train 5, folder 18, cls 7\n",
      "\tnum_to_mv_train 5, folder 19, cls 7\n",
      "\tnum_to_mv_train 5, folder 20, cls 7\n",
      "\tnum_to_mv_train 5, folder 21, cls 7\n",
      "\tnum_to_mv_train 5, folder 22, cls 7\n",
      "\tnum_to_mv_train 5, folder 23, cls 7\n",
      "\tnum_to_mv_train 5, folder 24, cls 7\n",
      "\tnum_to_mv_train 5, folder 25, cls 7\n",
      "\tnum_to_mv_train 10, folder 26, cls 7\n",
      "\tnum_to_mv_train 10, folder 27, cls 7\n",
      "\tnum_to_mv_train 10, folder 28, cls 7\n",
      "\tnum_to_mv_train 10, folder 29, cls 7\n",
      "\tnum_to_mv_train 10, folder 30, cls 7\n",
      "\tnum_to_mv_train 10, folder 31, cls 7\n",
      "\tnum_to_mv_train 10, folder 32, cls 7\n",
      "\tnum_to_mv_train 10, folder 33, cls 7\n",
      "\tnum_to_mv_train 10, folder 34, cls 7\n",
      "\tnum_to_mv_train 10, folder 35, cls 7\n",
      "\tnum_to_mv_train 50, folder 36, cls 7\n",
      "\tnum_to_mv_train 50, folder 37, cls 7\n",
      "\tnum_to_mv_train 100, folder 38, cls 7\n",
      "\tnum_to_mv_train 100, folder 39, cls 7\n",
      "\tnum_to_mv_train 500, folder 40, cls 7\n",
      "\tnum_to_mv_train 500, folder 41, cls 7\n",
      "\tnum_to_mv_train 500, folder 42, cls 7\n",
      "\tnum_to_mv_train 500, folder 43, cls 7\n",
      "\tnum_to_mv_train 500, folder 44, cls 7\n",
      "\tnum_to_mv_train 500, folder 45, cls 7\n",
      "\tnum_to_mv_train 500, folder 46, cls 7\n",
      "\tnum_to_mv_train 500, folder 47, cls 7\n",
      "\tnum_to_mv_train 500, folder 48, cls 7\n",
      "\tnum_to_mv_train 500, folder 49, cls 7\n",
      "\tnum_to_mv_train 500, folder 50, cls 7\n",
      "\tnum_to_mv_train 500, folder 51, cls 7\n",
      "\tnum_to_mv_train 315, folder 52, cls 7\n",
      "temp_7_1/train/labels 2\n",
      "temp_7_1/train/images 2 \n",
      "\n",
      "temp_7_2/train/labels 2\n",
      "temp_7_2/train/images 2 \n",
      "\n",
      "temp_7_3/train/labels 2\n",
      "temp_7_3/train/images 2 \n",
      "\n",
      "temp_7_4/train/labels 2\n",
      "temp_7_4/train/images 2 \n",
      "\n",
      "temp_7_5/train/labels 2\n",
      "temp_7_5/train/images 2 \n",
      "\n",
      "temp_7_6/train/labels 3\n",
      "temp_7_6/train/images 3 \n",
      "\n",
      "temp_7_7/train/labels 3\n",
      "temp_7_7/train/images 3 \n",
      "\n",
      "temp_7_8/train/labels 3\n",
      "temp_7_8/train/images 3 \n",
      "\n",
      "temp_7_9/train/labels 3\n",
      "temp_7_9/train/images 3 \n",
      "\n",
      "temp_7_10/train/labels 3\n",
      "temp_7_10/train/images 3 \n",
      "\n",
      "temp_7_11/train/labels 3\n",
      "temp_7_11/train/images 3 \n",
      "\n",
      "temp_7_12/train/labels 3\n",
      "temp_7_12/train/images 3 \n",
      "\n",
      "temp_7_13/train/labels 5\n",
      "temp_7_13/train/images 5 \n",
      "\n",
      "temp_7_14/train/labels 5\n",
      "temp_7_14/train/images 5 \n",
      "\n",
      "temp_7_15/train/labels 5\n",
      "temp_7_15/train/images 5 \n",
      "\n",
      "temp_7_16/train/labels 5\n",
      "temp_7_16/train/images 5 \n",
      "\n",
      "temp_7_17/train/labels 5\n",
      "temp_7_17/train/images 5 \n",
      "\n",
      "temp_7_18/train/labels 5\n",
      "temp_7_18/train/images 5 \n",
      "\n",
      "temp_7_19/train/labels 5\n",
      "temp_7_19/train/images 5 \n",
      "\n",
      "temp_7_20/train/labels 5\n",
      "temp_7_20/train/images 5 \n",
      "\n",
      "temp_7_21/train/labels 5\n",
      "temp_7_21/train/images 5 \n",
      "\n",
      "temp_7_22/train/labels 5\n",
      "temp_7_22/train/images 5 \n",
      "\n",
      "temp_7_23/train/labels 5\n",
      "temp_7_23/train/images 5 \n",
      "\n",
      "temp_7_24/train/labels 5\n",
      "temp_7_24/train/images 5 \n",
      "\n",
      "temp_7_25/train/labels 5\n",
      "temp_7_25/train/images 5 \n",
      "\n",
      "temp_7_26/train/labels 5\n",
      "temp_7_26/train/images 5 \n",
      "\n",
      "temp_7_27/train/labels 10\n",
      "temp_7_27/train/images 10 \n",
      "\n",
      "temp_7_28/train/labels 10\n",
      "temp_7_28/train/images 10 \n",
      "\n",
      "temp_7_29/train/labels 10\n",
      "temp_7_29/train/images 10 \n",
      "\n",
      "temp_7_30/train/labels 10\n",
      "temp_7_30/train/images 10 \n",
      "\n",
      "temp_7_31/train/labels 10\n",
      "temp_7_31/train/images 10 \n",
      "\n",
      "temp_7_32/train/labels 10\n",
      "temp_7_32/train/images 10 \n",
      "\n",
      "temp_7_33/train/labels 10\n",
      "temp_7_33/train/images 10 \n",
      "\n",
      "temp_7_34/train/labels 10\n",
      "temp_7_34/train/images 10 \n",
      "\n",
      "temp_7_35/train/labels 10\n",
      "temp_7_35/train/images 10 \n",
      "\n",
      "temp_7_36/train/labels 10\n",
      "temp_7_36/train/images 10 \n",
      "\n",
      "temp_7_37/train/labels 50\n",
      "temp_7_37/train/images 50 \n",
      "\n",
      "temp_7_38/train/labels 50\n",
      "temp_7_38/train/images 50 \n",
      "\n",
      "temp_7_39/train/labels 100\n",
      "temp_7_39/train/images 100 \n",
      "\n",
      "temp_7_40/train/labels 100\n",
      "temp_7_40/train/images 100 \n",
      "\n",
      "temp_7_41/train/labels 500\n",
      "temp_7_41/train/images 500 \n",
      "\n",
      "temp_7_42/train/labels 500\n",
      "temp_7_42/train/images 500 \n",
      "\n",
      "temp_7_43/train/labels 500\n",
      "temp_7_43/train/images 500 \n",
      "\n",
      "temp_7_44/train/labels 500\n",
      "temp_7_44/train/images 500 \n",
      "\n",
      "temp_7_45/train/labels 500\n",
      "temp_7_45/train/images 500 \n",
      "\n",
      "temp_7_46/train/labels 500\n",
      "temp_7_46/train/images 500 \n",
      "\n",
      "temp_7_47/train/labels 500\n",
      "temp_7_47/train/images 500 \n",
      "\n",
      "temp_7_48/train/labels 500\n",
      "temp_7_48/train/images 500 \n",
      "\n",
      "temp_7_49/train/labels 500\n",
      "temp_7_49/train/images 500 \n",
      "\n",
      "temp_7_50/train/labels 500\n",
      "temp_7_50/train/images 500 \n",
      "\n",
      "temp_7_51/train/labels 500\n",
      "temp_7_51/train/images 500 \n",
      "\n",
      "temp_7_52/train/labels 500\n",
      "temp_7_52/train/images 500 \n",
      "\n",
      "temp_7_53/train/labels 315\n",
      "temp_7_53/train/images 315 \n",
      "\n",
      "/kaggle/working/dataset/isaid_class_7/data.yaml\n",
      "defaultdict(<class 'int'>, {'7': 53}) defaultdict(<class 'list'>, {'7': [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 4001, 4501, 5001, 5501, 6001, 6501, 6816]})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100%|██████████| 755k/755k [00:00<00:00, 3.75MB/s]\n",
      "2024-05-13 21:31:17.624494: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-13 21:31:17.624630: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-13 21:31:17.765561: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100%|██████████| 6.23M/6.23M [00:00<00:00, 22.7MB/s]\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_1/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 91.00it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_1/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:06<00:00, 130.05it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      2.28G      3.916      5.582      23.96      1.447         18        640: 100%|██████████| 1/1 [00:02<00:00,  2.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397    0.00247   0.000962    0.00126   0.000785    0.00173   0.000673   0.000887   0.000254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.35G      3.299      8.156      18.79      0.886          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397    0.00319    0.00125    0.00165   0.000919    0.00197   0.000769    0.00101   0.000264\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.35G      3.758      4.971       10.4      1.724          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397    0.00286    0.00115    0.00149   0.000802    0.00191   0.000769   0.000984   0.000258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.37G      4.488      5.144       16.7       1.85          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397    0.00326    0.00135    0.00168   0.000934    0.00186   0.000769   0.000949   0.000285\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.37G      5.175      5.359      15.56       3.11          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397    0.00344    0.00144    0.00175   0.000871    0.00161   0.000673   0.000811   0.000234\n",
      "\n",
      "5 epochs completed in 0.035 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.46it/s]\n",
      "                   all        852      10397    0.00327    0.00135    0.00168   0.000935    0.00187   0.000769    0.00095   0.000285\n",
      "         Large_Vehicle        852      10397    0.00327    0.00135    0.00168   0.000935    0.00187   0.000769    0.00095   0.000285\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:08<00:00, 100.45it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/test_7/labels.cache\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:20<00:00,  2.60it/s]\n",
      "                   all        852       9278    0.00258    0.00119    0.00131    0.00045    0.00141   0.000647   0.000706   0.000259\n",
      "         Large_Vehicle        852       9278    0.00258    0.00119    0.00131    0.00045    0.00141   0.000647   0.000706   0.000259\n",
      "Speed: 0.2ms preprocess, 14.5ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_2/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 209.27it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_2/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       4.1G      2.786      4.348      8.601      1.022         32        640: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397    0.00363    0.00135    0.00187   0.000966    0.00207   0.000769     0.0011   0.000393\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.33G      3.669      4.308      11.98      1.517          8        640: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:26<00:00,  1.02it/s]\n",
      "                   all        852      10397    0.00277    0.00106    0.00144   0.000815    0.00176   0.000673   0.000944    0.00037\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.35G      4.535      3.843       20.4      1.422          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.13it/s]\n",
      "                   all        852      10397    0.00298    0.00115    0.00157     0.0009    0.00199   0.000769    0.00108   0.000406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.34G      4.361      4.424      19.59      1.442          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:26<00:00,  1.02it/s]\n",
      "                   all        852      10397    0.00273    0.00106    0.00145   0.000782    0.00199   0.000769    0.00108   0.000359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.34G      3.398      3.337      9.381      1.171         20        640: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397    0.00305    0.00125    0.00161   0.000912    0.00211   0.000866    0.00115   0.000386\n",
      "\n",
      "5 epochs completed in 0.039 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397    0.00364    0.00135    0.00187   0.000987    0.00208   0.000769     0.0011   0.000394\n",
      "         Large_Vehicle        852      10397    0.00364    0.00135    0.00187   0.000987    0.00208   0.000769     0.0011   0.000394\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.46it/s]\n",
      "                   all        852       9278    0.00386    0.00162      0.002    0.00125    0.00257    0.00108    0.00136   0.000488\n",
      "         Large_Vehicle        852       9278    0.00386    0.00162      0.002    0.00125    0.00257    0.00108    0.00136   0.000488\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_3/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 176.49it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       4.1G      1.876       4.56      6.446       1.48         26        640: 100%|██████████| 1/1 [00:00<00:00,  2.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397    0.00262   0.000962    0.00135   0.000627    0.00157   0.000577   0.000823   0.000192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.36G      1.637      5.823      6.998       1.39          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397    0.00263   0.000962    0.00134   0.000687    0.00211   0.000769    0.00108   0.000296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.26G      3.317      4.347      12.69      1.919          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397     0.0024   0.000866    0.00122    0.00059     0.0024   0.000866    0.00122   0.000343\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.25G      2.817      4.411        8.7      1.551         12        640: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397    0.00367    0.00135    0.00185   0.000729    0.00236   0.000866    0.00119   0.000309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.35G      2.296      5.716      9.285        1.8          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397    0.00353    0.00135    0.00178   0.000762    0.00227   0.000866    0.00114   0.000284\n",
      "\n",
      "5 epochs completed in 0.035 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.39it/s]\n",
      "                   all        852      10397    0.00367    0.00135    0.00185   0.000729    0.00236   0.000866    0.00119   0.000309\n",
      "         Large_Vehicle        852      10397    0.00367    0.00135    0.00185   0.000729    0.00236   0.000866    0.00119   0.000309\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.48it/s]\n",
      "                   all        852       9278    0.00502    0.00216    0.00261    0.00129    0.00427    0.00183    0.00218   0.000812\n",
      "         Large_Vehicle        852       9278    0.00502    0.00216    0.00261    0.00129    0.00427    0.00183    0.00218   0.000812\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_4/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 157.17it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_4/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.08G      4.129      5.735      9.798      1.508        105        640: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397    0.00221   0.000769    0.00122   0.000565    0.00276   0.000962    0.00149   0.000467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.34G      3.422      5.419      7.219      1.345         56        640: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397    0.00218   0.000769    0.00117   0.000572    0.00246   0.000866     0.0013   0.000467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.34G      3.452       5.55      7.003      1.342         62        640: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397    0.00239   0.000866    0.00124   0.000571    0.00239   0.000866    0.00124   0.000477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.42G      3.695      6.161      7.588      1.373         69        640: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397    0.00266   0.000962    0.00136   0.000602     0.0024   0.000866    0.00124    0.00045\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.38G      4.987      6.112      8.923      1.611         90        640: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397    0.00261   0.000962    0.00133   0.000638    0.00235   0.000866    0.00121   0.000452\n",
      "\n",
      "5 epochs completed in 0.036 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397     0.0026   0.000962    0.00132   0.000634    0.00234   0.000866     0.0012    0.00045\n",
      "         Large_Vehicle        852      10397     0.0026   0.000962    0.00132   0.000634    0.00234   0.000866     0.0012    0.00045\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.44it/s]\n",
      "                   all        852       9278     0.0068    0.00269    0.00344    0.00164    0.00599    0.00237    0.00306    0.00138\n",
      "         Large_Vehicle        852       9278     0.0068    0.00269    0.00344    0.00164    0.00599    0.00237    0.00306    0.00138\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_5/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 217.82it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_5/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.11G      4.526      5.119      18.28      1.393         28        640: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.19it/s]\n",
      "                   all        852      10397    0.00522    0.00164    0.00268    0.00148    0.00522    0.00164    0.00268    0.00108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.34G      2.567       4.46      16.78      1.151          5        640: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397     0.0049    0.00154    0.00259    0.00161     0.0052    0.00164    0.00274    0.00121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.27G      3.317      4.155      13.59      1.057          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397    0.00507    0.00164    0.00264     0.0016    0.00507    0.00164    0.00264    0.00119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.33G      3.875      4.375      23.21      1.241         29        640: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397    0.00422    0.00135    0.00219    0.00122    0.00422    0.00135    0.00222   0.000901\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.33G      4.557       6.27      33.61      1.434         16        640: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.19it/s]\n",
      "                   all        852      10397    0.00471    0.00154    0.00244    0.00132    0.00442    0.00144    0.00229   0.000985\n",
      "\n",
      "5 epochs completed in 0.036 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.32it/s]\n",
      "                   all        852      10397    0.00489    0.00154    0.00258     0.0016    0.00519    0.00164    0.00273    0.00121\n",
      "         Large_Vehicle        852      10397    0.00489    0.00154    0.00258     0.0016    0.00519    0.00164    0.00273    0.00121\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:23<00:00,  2.29it/s]\n",
      "                   all        852       9278    0.00923    0.00323    0.00474     0.0022    0.00954    0.00334    0.00491    0.00204\n",
      "         Large_Vehicle        852       9278    0.00923    0.00323    0.00474     0.0022    0.00954    0.00334    0.00491    0.00204\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 6.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_6/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 61.19it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_6/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.09G      2.906      3.477      10.66      1.374         14        640: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.17it/s]\n",
      "                   all        852      10397    0.00647    0.00192    0.00333     0.0019     0.0068    0.00202    0.00349    0.00144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.88G       2.94      2.515      12.89      1.162          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397    0.00713    0.00221    0.00366    0.00206    0.00744    0.00231    0.00381     0.0017\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.89G      3.509      3.479      13.19      1.206         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.19it/s]\n",
      "                   all        852      10397    0.00609    0.00192    0.00315    0.00172    0.00579    0.00183      0.003    0.00143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.91G      4.203      4.606      12.34       1.49         14        640: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.19it/s]\n",
      "                   all        852      10397    0.00562    0.00183    0.00291    0.00152    0.00503    0.00164    0.00262    0.00102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       2.9G      2.505      2.892      9.273       1.22         14        640: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.19it/s]\n",
      "                   all        852      10397    0.00477    0.00164    0.00249    0.00138    0.00421    0.00144    0.00221   0.000916\n",
      "\n",
      "5 epochs completed in 0.036 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397    0.00713    0.00221    0.00365    0.00206    0.00744    0.00231    0.00381     0.0017\n",
      "         Large_Vehicle        852      10397    0.00713    0.00221    0.00365    0.00206    0.00744    0.00231    0.00381     0.0017\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 5.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.36it/s]\n",
      "                   all        852       9278    0.00483    0.00172    0.00246   0.000908    0.00603    0.00216    0.00309    0.00102\n",
      "         Large_Vehicle        852       9278    0.00483    0.00172    0.00246   0.000908    0.00603    0.00216    0.00309    0.00102\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 6.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 13 images, 0 backgrounds, 0 corrupt: 100%|██████████| 13/13 [00:00<00:00, 140.19it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.02G       2.75      3.566      9.749      1.227         93        640: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:26<00:00,  1.04it/s]\n",
      "                   all        852      10397    0.00262    0.00106    0.00133   0.000704    0.00143   0.000577   0.000731    0.00022\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      8.86G      3.451      5.126      11.62      1.455        103        640: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:26<00:00,  1.01it/s]\n",
      "                   all        852      10397    0.00282    0.00115    0.00143   0.000793    0.00165   0.000673   0.000845   0.000266\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      8.84G      3.775       4.73      11.72      1.336         80        640: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397    0.00297    0.00125     0.0015   0.000861    0.00183   0.000769   0.000934   0.000269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.12G       2.55      3.668      9.517      1.276         39        640: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:25<00:00,  1.07it/s]\n",
      "                   all        852      10397    0.00289    0.00125    0.00147   0.000829    0.00178   0.000769    0.00091   0.000239\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.13G      3.324      4.957      8.248      1.705         90        640: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:26<00:00,  1.03it/s]\n",
      "                   all        852      10397    0.00331    0.00144    0.00168   0.000853    0.00154   0.000673   0.000784   0.000225\n",
      "\n",
      "5 epochs completed in 0.043 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.47it/s]\n",
      "                   all        852      10397    0.00297    0.00125     0.0015   0.000873    0.00183   0.000769   0.000935   0.000269\n",
      "         Large_Vehicle        852      10397    0.00297    0.00125     0.0015   0.000873    0.00183   0.000769   0.000935   0.000269\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.38it/s]\n",
      "                   all        852       9278    0.00188   0.000862   0.000947   0.000353   0.000938   0.000431    0.00047   0.000235\n",
      "         Large_Vehicle        852       9278    0.00188   0.000862   0.000947   0.000353   0.000938   0.000431    0.00047   0.000235\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_7/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 191.92it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_7/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.54G      2.863       5.67      6.621      1.344         21        640: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397    0.00272    0.00106    0.00142    0.00076    0.00148   0.000577   0.000808   0.000275\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.81G      1.999      5.707      7.192       1.19          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397    0.00265    0.00106    0.00142   0.000771    0.00169   0.000673   0.000939   0.000275\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       2.9G      2.888      4.709       7.83       1.37         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397    0.00331    0.00135    0.00176   0.000989    0.00189   0.000769    0.00105   0.000334\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.93G      2.481      4.894      8.189      1.229          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397    0.00326    0.00135    0.00174   0.000997    0.00209   0.000866    0.00116   0.000332\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.91G      2.592       4.68      10.33      1.044         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397    0.00339    0.00144    0.00183     0.0011    0.00226   0.000962    0.00127   0.000386\n",
      "\n",
      "5 epochs completed in 0.035 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.44it/s]\n",
      "                   all        852      10397    0.00338    0.00144    0.00184    0.00111    0.00225   0.000962    0.00128   0.000389\n",
      "         Large_Vehicle        852      10397    0.00338    0.00144    0.00184    0.00111    0.00225   0.000962    0.00128   0.000389\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.56it/s]\n",
      "                   all        852       9278    0.00253    0.00119    0.00133   0.000528    0.00184   0.000862   0.000921   0.000357\n",
      "         Large_Vehicle        852       9278    0.00253    0.00119    0.00133   0.000528    0.00184   0.000862   0.000921   0.000357\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 16 images, 0 backgrounds, 0 corrupt: 100%|██████████| 16/16 [00:00<00:00, 137.76it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.28G      2.571      4.385      9.275      1.249        124        640: 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:27<00:00,  1.03s/it]\n",
      "                   all        852      10397    0.00243   0.000962    0.00123   0.000692    0.00146   0.000577   0.000743   0.000212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.35G      2.375      4.238      8.159        1.3        122        640: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:27<00:00,  1.01s/it]\n",
      "                   all        852      10397    0.00282    0.00115    0.00143   0.000793    0.00165   0.000673   0.000845   0.000241\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.35G      3.687      4.746      12.82      1.259        108        640: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:27<00:00,  1.00s/it]\n",
      "                   all        852      10397    0.00299    0.00125    0.00152   0.000882    0.00161   0.000673   0.000817   0.000258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.35G      2.994      4.758      11.22      1.336         67        640: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:26<00:00,  1.04it/s]\n",
      "                   all        852      10397    0.00344    0.00144    0.00175    0.00096     0.0016   0.000673   0.000819   0.000234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.34G      2.945      5.663      9.395      1.413        110        640: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:24<00:00,  1.11it/s]\n",
      "                   all        852      10397    0.00314    0.00135     0.0016   0.000859    0.00157   0.000673   0.000799   0.000241\n",
      "\n",
      "5 epochs completed in 0.045 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397    0.00322    0.00135    0.00165    0.00085    0.00161   0.000673   0.000823   0.000235\n",
      "         Large_Vehicle        852      10397    0.00322    0.00135    0.00165    0.00085    0.00161   0.000673   0.000823   0.000235\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.39it/s]\n",
      "                   all        852       9278     0.0021    0.00097    0.00106   0.000363    0.00116   0.000539   0.000584   0.000245\n",
      "         Large_Vehicle        852       9278     0.0021    0.00097    0.00106   0.000363    0.00116   0.000539   0.000584   0.000245\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_8/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 89.12it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_8/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.55G      1.835      3.914      5.309      1.662        200        640: 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397    0.00296    0.00115    0.00154    0.00072    0.00148   0.000577   0.000803   0.000213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.96G      1.556      3.187      5.303      1.521         31        640: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397    0.00237   0.000962    0.00127   0.000685    0.00142   0.000577   0.000796   0.000211\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.34G      1.612      3.857      5.081      1.688         96        640: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397    0.00319    0.00135    0.00167    0.00094    0.00228   0.000962    0.00122   0.000499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.46G      1.684       3.97      5.284      1.697        127        640: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397    0.00307    0.00135     0.0016   0.000942    0.00197   0.000866    0.00106   0.000446\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.14G      1.602      3.229      5.699      1.516         42        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397    0.00273    0.00125    0.00146   0.000849    0.00189   0.000866    0.00105   0.000353\n",
      "\n",
      "5 epochs completed in 0.034 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.43it/s]\n",
      "                   all        852      10397    0.00318    0.00135    0.00167    0.00095    0.00205   0.000866    0.00111   0.000465\n",
      "         Large_Vehicle        852      10397    0.00318    0.00135    0.00167    0.00095    0.00205   0.000866    0.00111   0.000465\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.55it/s]\n",
      "                   all        852       9278    0.00386    0.00183    0.00204     0.0011    0.00273    0.00129    0.00137   0.000424\n",
      "         Large_Vehicle        852       9278    0.00386    0.00183    0.00204     0.0011    0.00273    0.00129    0.00137   0.000424\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 19 images, 0 backgrounds, 0 corrupt: 100%|██████████| 19/19 [00:00<00:00, 127.36it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.68G      3.011      4.527      9.983      1.519         20        640: 100%|██████████| 2/2 [00:01<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397    0.00264    0.00106    0.00134   0.000782    0.00168   0.000673   0.000858   0.000271\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.48G       2.39      4.338      9.713      1.322         14        640: 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397    0.00272    0.00115    0.00138    0.00073    0.00159   0.000673   0.000814   0.000267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.48G      2.949      5.196       9.59      1.657         29        640: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397    0.00306    0.00135    0.00155   0.000845    0.00175   0.000769   0.000888   0.000234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.59G       2.72      4.349      7.339      1.555         23        640: 100%|██████████| 2/2 [00:01<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397    0.00357    0.00164     0.0018   0.000876    0.00105   0.000481   0.000534   0.000182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.59G      2.285       3.98      11.21      1.382          3        640: 100%|██████████| 2/2 [00:01<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.32it/s]\n",
      "                   all        852      10397    0.00263    0.00125    0.00134   0.000734    0.00122   0.000577   0.000613   0.000175\n",
      "\n",
      "5 epochs completed in 0.036 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.46it/s]\n",
      "                   all        852      10397    0.00305    0.00135    0.00155   0.000844    0.00174   0.000769   0.000886   0.000234\n",
      "         Large_Vehicle        852      10397    0.00305    0.00135    0.00155   0.000844    0.00174   0.000769   0.000886   0.000234\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:56<00:00,  1.05s/it]\n",
      "                   all        852       9278   0.000867   0.000431    0.00046   9.24e-05   0.000217   0.000108   0.000109   3.27e-05\n",
      "         Large_Vehicle        852       9278   0.000867   0.000431    0.00046   9.24e-05   0.000217   0.000108   0.000109   3.27e-05\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_9/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 102.30it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_9/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.72G      2.205      3.404      6.133      1.226         81        640: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397    0.00211   0.000962    0.00112   0.000617    0.00126   0.000577   0.000698   0.000272\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.97G      1.715      3.246      6.472       1.16         25        640: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397    0.00163   0.000769   0.000899   0.000587    0.00122   0.000577   0.000698   0.000268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.96G      1.556      2.837      6.019      1.233         44        640: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397    0.00157   0.000769   0.000881   0.000578    0.00118   0.000577   0.000687   0.000262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.19G      1.989      2.995      6.262      1.282         69        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397    0.00187   0.000962    0.00103    0.00059    0.00112   0.000577   0.000655   0.000249\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.96G      2.538      3.864      7.288      1.159         40        640: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397    0.00234    0.00125    0.00124    0.00071    0.00144   0.000769   0.000798   0.000332\n",
      "\n",
      "5 epochs completed in 0.034 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.44it/s]\n",
      "                   all        852      10397    0.00234    0.00125    0.00125   0.000701    0.00144   0.000769   0.000799   0.000332\n",
      "         Large_Vehicle        852      10397    0.00234    0.00125    0.00125   0.000701    0.00144   0.000769   0.000799   0.000332\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:20<00:00,  2.57it/s]\n",
      "                   all        852       9278    0.00484    0.00291    0.00246    0.00128    0.00287    0.00172    0.00144   0.000499\n",
      "         Large_Vehicle        852       9278    0.00484    0.00291    0.00246    0.00128    0.00287    0.00172    0.00144   0.000499\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 22 images, 0 backgrounds, 0 corrupt: 100%|██████████| 22/22 [00:00<00:00, 127.02it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.65G       2.46      4.449       13.7      1.508         14        640: 100%|██████████| 2/2 [00:02<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397    0.00292    0.00115    0.00148   0.000809    0.00146   0.000577   0.000745   0.000212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.37G      2.256      4.114       6.73      1.613         42        640: 100%|██████████| 2/2 [00:01<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:25<00:00,  1.06it/s]\n",
      "                   all        852      10397    0.00337    0.00144    0.00172    0.00094    0.00225   0.000962    0.00114   0.000298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.35G      2.339      4.334      7.604      1.551         83        640: 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397    0.00346    0.00154    0.00176    0.00094    0.00216   0.000962    0.00111   0.000331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.46G      1.819      3.527       6.86      1.344         24        640: 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397    0.00368    0.00173    0.00187    0.00104    0.00225    0.00106    0.00115   0.000424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.47G      1.988      3.533      7.106      1.355         22        640: 100%|██████████| 2/2 [00:01<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397    0.00435    0.00212    0.00222    0.00117    0.00296    0.00144    0.00151    0.00059\n",
      "\n",
      "5 epochs completed in 0.040 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.47it/s]\n",
      "                   all        852      10397    0.00435    0.00212    0.00222    0.00117    0.00296    0.00144    0.00151    0.00059\n",
      "         Large_Vehicle        852      10397    0.00435    0.00212    0.00222    0.00117    0.00296    0.00144    0.00151    0.00059\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:23<00:00,  2.26it/s]\n",
      "                   all        852       9278    0.00372    0.00205    0.00188   0.000743    0.00117   0.000647   0.000598   0.000207\n",
      "         Large_Vehicle        852       9278    0.00372    0.00205    0.00188   0.000743    0.00117   0.000647   0.000598   0.000207\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_10/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 51.07it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_10/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.65G      2.397      6.057      6.011      1.791         20        640: 100%|██████████| 1/1 [00:00<00:00,  2.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397    0.00317    0.00135    0.00163   0.000901    0.00159   0.000673   0.000848   0.000382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.84G      2.052      4.656      5.767      1.517         18        640: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397    0.00315    0.00135    0.00163     0.0011    0.00202   0.000866    0.00106   0.000422\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      2.95G      1.811      4.666      6.503      1.367         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397    0.00374    0.00164    0.00196    0.00135    0.00242    0.00106    0.00126   0.000513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      2.97G      1.944      4.234      5.466      1.451         11        640: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397    0.00383    0.00173    0.00202    0.00132    0.00255    0.00115    0.00132   0.000411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.05G      2.167      4.484      5.577      1.532         45        640: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397    0.00484    0.00221    0.00248    0.00167    0.00337    0.00154    0.00173   0.000603\n",
      "\n",
      "5 epochs completed in 0.035 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.44it/s]\n",
      "                   all        852      10397    0.00484    0.00221    0.00248    0.00165    0.00337    0.00154    0.00173   0.000603\n",
      "         Large_Vehicle        852      10397    0.00484    0.00221    0.00248    0.00165    0.00337    0.00154    0.00173   0.000603\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.55it/s]\n",
      "                   all        852       9278    0.00723    0.00377    0.00371    0.00205    0.00516    0.00269    0.00264    0.00109\n",
      "         Large_Vehicle        852       9278    0.00723    0.00377    0.00371    0.00205    0.00516    0.00269    0.00264    0.00109\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 25 images, 0 backgrounds, 0 corrupt: 100%|██████████| 25/25 [00:00<00:00, 125.81it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.34G      2.165      3.786      6.763      1.603        181        640: 100%|██████████| 2/2 [00:01<00:00,  1.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397    0.00312    0.00125    0.00158   0.000902    0.00192   0.000769   0.000979   0.000306\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.35G      1.854      3.827      5.509      1.472        223        640: 100%|██████████| 2/2 [00:01<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397    0.00321    0.00135    0.00165   0.000874    0.00184   0.000769   0.000937   0.000258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.36G      2.032      3.645      6.241       1.46        170        640: 100%|██████████| 2/2 [00:01<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397    0.00282    0.00125    0.00143   0.000786     0.0013   0.000577   0.000664     0.0002\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.36G      2.131      3.789      6.149      1.461        108        640: 100%|██████████| 2/2 [00:01<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397    0.00249    0.00115    0.00127   0.000734    0.00104   0.000481   0.000536   0.000171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.47G      2.072      3.872      6.302       1.47        187        640: 100%|██████████| 2/2 [00:01<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397      0.003    0.00144    0.00153   0.000861     0.0018   0.000866   0.000921   0.000346\n",
      "\n",
      "5 epochs completed in 0.036 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.42it/s]\n",
      "                   all        852      10397    0.00287    0.00115    0.00146   0.000806    0.00168   0.000673   0.000859   0.000258\n",
      "         Large_Vehicle        852      10397    0.00287    0.00115    0.00146   0.000806    0.00168   0.000673   0.000859   0.000258\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:24<00:00,  2.18it/s]\n",
      "                   all        852       9278     0.0022    0.00097    0.00111   0.000406   0.000735   0.000323   0.000368   0.000209\n",
      "         Large_Vehicle        852       9278     0.0022    0.00097    0.00111   0.000406   0.000735   0.000323   0.000368   0.000209\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_11/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 95.47it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_11/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.61G       1.68       2.99      5.715       1.25         52        640: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397    0.00239    0.00106    0.00124   0.000692    0.00152   0.000673   0.000794   0.000304\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.08G      1.574      2.131       5.48      1.386         35        640: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397    0.00215   0.000962    0.00113   0.000671    0.00151   0.000673     0.0008   0.000307\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.07G      1.648      2.484      5.259      1.411         33        640: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397    0.00232    0.00106    0.00124   0.000689    0.00148   0.000673     0.0008   0.000306\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.01G      1.745      2.719      5.537      1.453         25        640: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397    0.00244    0.00115    0.00129   0.000731    0.00163   0.000769   0.000864   0.000363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.25G       1.76      2.432      5.722      1.336         61        640: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397    0.00258    0.00125    0.00135   0.000744    0.00159   0.000769    0.00085   0.000355\n",
      "\n",
      "5 epochs completed in 0.035 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.43it/s]\n",
      "                   all        852      10397    0.00238    0.00115    0.00125   0.000732    0.00159   0.000769   0.000848   0.000354\n",
      "         Large_Vehicle        852      10397    0.00238    0.00115    0.00125   0.000732    0.00159   0.000769   0.000848   0.000354\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:20<00:00,  2.59it/s]\n",
      "                   all        852       9278    0.00532    0.00291    0.00273    0.00144    0.00394    0.00216      0.002      0.001\n",
      "         Large_Vehicle        852       9278    0.00532    0.00291    0.00273    0.00144    0.00394    0.00216      0.002      0.001\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<00:00, 111.71it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.42G      2.208      4.056      7.592      1.441         78        640: 100%|██████████| 2/2 [00:01<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397    0.00288    0.00115    0.00146   0.000797    0.00168   0.000673   0.000862   0.000259\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.46G      1.985      3.884      6.128      1.626         59        640: 100%|██████████| 2/2 [00:01<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397    0.00297    0.00125    0.00152   0.000822    0.00206   0.000866    0.00105    0.00028\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.47G      2.065      4.154      5.948      1.643         88        640: 100%|██████████| 2/2 [00:01<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397    0.00304    0.00135    0.00154   0.000812    0.00152   0.000673   0.000775   0.000233\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.58G      1.936      3.403       5.95      1.449        100        640: 100%|██████████| 2/2 [00:01<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397    0.00511     0.0024    0.00263    0.00122    0.00347    0.00164    0.00178   0.000648\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.58G       1.79      3.944      5.824       1.52         76        640: 100%|██████████| 2/2 [00:01<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397     0.0053     0.0026    0.00273    0.00142    0.00412    0.00202    0.00213   0.000932\n",
      "\n",
      "5 epochs completed in 0.037 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.48it/s]\n",
      "                   all        852      10397    0.00531     0.0026    0.00274    0.00141    0.00413    0.00202    0.00214   0.000934\n",
      "         Large_Vehicle        852      10397    0.00531     0.0026    0.00274    0.00141    0.00413    0.00202    0.00214   0.000934\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:24<00:00,  2.21it/s]\n",
      "                   all        852       9278    0.00374    0.00205    0.00189   0.000727    0.00118   0.000647     0.0006   0.000238\n",
      "         Large_Vehicle        852       9278    0.00374    0.00205    0.00189   0.000727    0.00118   0.000647     0.0006   0.000238\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_12/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 92.26it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_12/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.73G      2.981      3.195      5.769       1.55         55        640: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397    0.00327    0.00144    0.00167    0.00114    0.00262    0.00115    0.00134   0.000741\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      2.91G      2.675      3.196       7.22      1.716          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397    0.00333    0.00144    0.00171    0.00108    0.00266    0.00115    0.00137   0.000659\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.04G      2.463      2.969      5.681      1.563         27        640: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397    0.00476    0.00212    0.00243    0.00149    0.00389    0.00173    0.00199   0.000894\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.06G      2.685      3.209      6.079      1.515         29        640: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397    0.00525     0.0024    0.00268    0.00164    0.00378    0.00173    0.00193   0.000823\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      2.97G      2.577      2.424      6.553      1.292         20        640: 100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397    0.00514     0.0024    0.00264    0.00168     0.0037    0.00173    0.00189   0.000766\n",
      "\n",
      "5 epochs completed in 0.034 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.42it/s]\n",
      "                   all        852      10397    0.00484    0.00221    0.00247    0.00148    0.00379    0.00173    0.00193   0.000761\n",
      "         Large_Vehicle        852      10397    0.00484    0.00221    0.00247    0.00148    0.00379    0.00173    0.00193   0.000761\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.55it/s]\n",
      "                   all        852       9278    0.00805     0.0042    0.00414    0.00234    0.00578    0.00302    0.00296    0.00124\n",
      "         Large_Vehicle        852       9278    0.00805     0.0042    0.00414    0.00234    0.00578    0.00302    0.00296    0.00124\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 31 images, 0 backgrounds, 0 corrupt: 100%|██████████| 31/31 [00:00<00:00, 120.59it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.54G      2.113      3.902      6.767      1.433        107        640: 100%|██████████| 2/2 [00:02<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397    0.00286    0.00115    0.00145   0.000793    0.00167   0.000673   0.000858    0.00027\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.38G      2.038      3.958      6.189      1.457        374        640: 100%|██████████| 2/2 [00:01<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397    0.00316    0.00135    0.00161   0.000936    0.00203   0.000866    0.00103   0.000299\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.37G      1.935      3.802       5.88      1.415        266        640: 100%|██████████| 2/2 [00:01<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397    0.00259    0.00115    0.00132   0.000786     0.0013   0.000577   0.000663    0.00021\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.37G      1.929      3.411      5.897      1.383        264        640: 100%|██████████| 2/2 [00:01<00:00,  1.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397     0.0053     0.0025    0.00273    0.00134    0.00347    0.00164    0.00178   0.000665\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.46G      2.074      3.656      6.346      1.568        130        640: 100%|██████████| 2/2 [00:01<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.17it/s]\n",
      "                   all        852      10397    0.00715    0.00356    0.00369     0.0019    0.00502     0.0025    0.00258    0.00122\n",
      "\n",
      "5 epochs completed in 0.038 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397    0.00713    0.00356    0.00369    0.00189    0.00501     0.0025    0.00257    0.00121\n",
      "         Large_Vehicle        852      10397    0.00713    0.00356    0.00369    0.00189    0.00501     0.0025    0.00257    0.00121\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:24<00:00,  2.23it/s]\n",
      "                   all        852       9278    0.00567    0.00313    0.00288    0.00119    0.00235    0.00129    0.00121   0.000475\n",
      "         Large_Vehicle        852       9278    0.00567    0.00313    0.00288    0.00119    0.00235    0.00129    0.00121   0.000475\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_13/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 110.82it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_13/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.51G       2.05       3.88      6.251      1.413         73        640: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397    0.00366    0.00164    0.00191    0.00118    0.00302    0.00135    0.00157   0.000764\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.81G      2.004      4.067      6.234      1.571         47        640: 100%|██████████| 1/1 [00:00<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397    0.00436    0.00192    0.00226    0.00141    0.00327    0.00144    0.00169   0.000841\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       4.3G      1.922      3.866      5.337      1.454         83        640: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397    0.00529    0.00231    0.00273    0.00174    0.00375    0.00164    0.00194   0.000912\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.14G      1.915      3.774      5.565      1.569         43        640: 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397    0.00683    0.00298    0.00354    0.00216    0.00485    0.00212    0.00252    0.00114\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.14G      2.088        3.6      6.219      1.445         47        640: 100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397    0.00741    0.00327    0.00384    0.00236    0.00523    0.00231    0.00271    0.00132\n",
      "\n",
      "5 epochs completed in 0.035 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.43it/s]\n",
      "                   all        852      10397    0.00762    0.00337    0.00395    0.00239    0.00522    0.00231    0.00271    0.00132\n",
      "         Large_Vehicle        852      10397    0.00762    0.00337    0.00395    0.00239    0.00522    0.00231    0.00271    0.00132\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.56it/s]\n",
      "                   all        852       9278    0.00861    0.00431    0.00448    0.00232    0.00624    0.00313    0.00322    0.00133\n",
      "         Large_Vehicle        852       9278    0.00861    0.00431    0.00448    0.00232    0.00624    0.00313    0.00322    0.00133\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<00:00, 128.68it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.43G      1.921      3.281      6.188      1.396         66        640: 100%|██████████| 3/3 [00:02<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397    0.00301    0.00125    0.00153   0.000874    0.00185   0.000769   0.000949   0.000284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.37G      1.828      3.415      5.975      1.441         46        640: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.32it/s]\n",
      "                   all        852      10397    0.00328    0.00144    0.00168   0.000966    0.00219   0.000962    0.00111    0.00029\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.48G      2.152      3.684       5.78      1.616         78        640: 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397    0.00715    0.00337    0.00365    0.00212    0.00531     0.0025    0.00272    0.00128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.49G      1.847       3.43      5.566      1.439         60        640: 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397      0.017    0.00914    0.00888    0.00551     0.0131    0.00702    0.00672    0.00353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.48G       1.74      3.201      5.246      1.298         50        640: 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397     0.0439     0.0294     0.0272     0.0177     0.0357     0.0239      0.022     0.0113\n",
      "\n",
      "5 epochs completed in 0.038 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.47it/s]\n",
      "                   all        852      10397     0.0442     0.0297     0.0274     0.0178     0.0357      0.024      0.022     0.0113\n",
      "         Large_Vehicle        852      10397     0.0442     0.0297     0.0274     0.0178     0.0357      0.024      0.022     0.0113\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.51it/s]\n",
      "                   all        852       9278     0.0453     0.0341     0.0271     0.0165     0.0363     0.0273     0.0209     0.0113\n",
      "         Large_Vehicle        852       9278     0.0453     0.0341     0.0271     0.0165     0.0363     0.0273     0.0209     0.0113\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_14/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 87.69it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_14/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.66G      2.468       4.65      5.677      1.994        213        640: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397     0.0348     0.0224     0.0198     0.0136     0.0281     0.0181     0.0152    0.00854\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.33G      2.512      4.297      6.223      2.166         75        640: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397     0.0372     0.0239     0.0213     0.0144     0.0297      0.019     0.0161    0.00889\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       4.4G      1.797      3.905      5.459      2.028        125        640: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397     0.0371     0.0239      0.021     0.0142     0.0299     0.0192     0.0162    0.00869\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.39G      2.062      4.512       5.76      2.392        104        640: 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397     0.0389     0.0253     0.0222      0.015     0.0309     0.0201     0.0168    0.00896\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.41G      2.703      4.515      6.055      2.495         95        640: 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397      0.038      0.025     0.0217     0.0148     0.0303     0.0199     0.0163    0.00868\n",
      "\n",
      "5 epochs completed in 0.035 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.42it/s]\n",
      "                   all        852      10397     0.0386     0.0252      0.022     0.0148     0.0305     0.0199     0.0165    0.00886\n",
      "         Large_Vehicle        852      10397     0.0386     0.0252      0.022     0.0148     0.0305     0.0199     0.0165    0.00886\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.54it/s]\n",
      "                   all        852       9278     0.0378     0.0269     0.0213     0.0136     0.0328     0.0234     0.0183    0.00988\n",
      "         Large_Vehicle        852       9278     0.0378     0.0269     0.0213     0.0136     0.0328     0.0234     0.0183    0.00988\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 41 images, 0 backgrounds, 0 corrupt: 100%|██████████| 41/41 [00:00<00:00, 135.09it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.57G      2.097      3.792      6.133      1.566        271        640: 100%|██████████| 3/3 [00:02<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397    0.00304    0.00125    0.00154   0.000882    0.00187   0.000769   0.000958   0.000263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.38G      2.056      3.684      6.166      1.617        143        640: 100%|██████████| 3/3 [00:02<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397     0.0028    0.00125    0.00142    0.00078    0.00151   0.000673   0.000767   0.000199\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.35G      2.094      3.649      6.091      1.633        110        640: 100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397     0.0028    0.00135    0.00144   0.000854     0.0022    0.00106    0.00113   0.000346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.59G      2.164      3.867      5.936      1.682         64        640: 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397    0.00714    0.00385    0.00361    0.00208    0.00536    0.00289     0.0027    0.00137\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.47G      1.937      3.361      5.618       1.42         84        640: 100%|██████████| 3/3 [00:02<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397     0.0221     0.0139     0.0116    0.00786     0.0182     0.0114     0.0096    0.00526\n",
      "\n",
      "5 epochs completed in 0.038 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.46it/s]\n",
      "                   all        852      10397     0.0219     0.0138     0.0115    0.00779     0.0179     0.0113    0.00943    0.00517\n",
      "         Large_Vehicle        852      10397     0.0219     0.0138     0.0115    0.00779     0.0179     0.0113    0.00943    0.00517\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:20<00:00,  2.58it/s]\n",
      "                   all        852       9278      0.028     0.0198     0.0154     0.0092     0.0218     0.0154     0.0118    0.00614\n",
      "         Large_Vehicle        852       9278      0.028     0.0198     0.0154     0.0092     0.0218     0.0154     0.0118    0.00614\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_15/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 116.62it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_15/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       4.8G      2.501      3.832      10.76      1.386         13        640: 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397     0.0197     0.0115     0.0103    0.00704     0.0172     0.0101    0.00885    0.00483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.09G      2.071      3.691      10.02       1.64          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397     0.0214     0.0126     0.0113    0.00777      0.019     0.0112    0.00982     0.0053\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.98G      2.549      3.563      8.672      1.501         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397     0.0228     0.0138     0.0122    0.00833     0.0193     0.0116     0.0104     0.0055\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.99G      1.923      3.184      7.532      1.565          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397     0.0233     0.0143     0.0124    0.00846     0.0195      0.012     0.0104    0.00551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.99G      2.294      2.815      10.19      1.332         12        640: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397     0.0234     0.0146     0.0122    0.00824     0.0192      0.012       0.01    0.00527\n",
      "\n",
      "5 epochs completed in 0.035 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.42it/s]\n",
      "                   all        852      10397     0.0232     0.0142     0.0124    0.00842     0.0198     0.0121     0.0105    0.00555\n",
      "         Large_Vehicle        852      10397     0.0232     0.0142     0.0124    0.00842     0.0198     0.0121     0.0105    0.00555\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.55it/s]\n",
      "                   all        852       9278     0.0295     0.0205      0.016     0.0101     0.0253     0.0176     0.0137    0.00738\n",
      "         Large_Vehicle        852       9278     0.0295     0.0205      0.016     0.0101     0.0253     0.0176     0.0137    0.00738\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 46 images, 0 backgrounds, 0 corrupt: 100%|██████████| 46/46 [00:00<00:00, 130.62it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.56G      2.343      4.363       6.48      1.759        110        640: 100%|██████████| 3/3 [00:03<00:00,  1.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397    0.00301    0.00125    0.00154   0.000865    0.00185   0.000769    0.00095   0.000261\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.38G      2.201      3.696      6.128      1.723        147        640: 100%|██████████| 3/3 [00:02<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397    0.00276    0.00125    0.00141    0.00076    0.00127   0.000577    0.00065   0.000185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.37G      2.164      3.948      6.292      1.788        189        640: 100%|██████████| 3/3 [00:02<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397    0.00254    0.00125    0.00129   0.000773    0.00215    0.00106    0.00109   0.000435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.77G      1.993      3.436      6.046      1.521         96        640: 100%|██████████| 3/3 [00:02<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397    0.00895    0.00481    0.00454    0.00274     0.0077    0.00414    0.00389    0.00197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.47G       2.05      3.501      5.986       1.59        184        640: 100%|██████████| 3/3 [00:02<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397     0.0309     0.0186      0.017     0.0111     0.0263     0.0158     0.0144     0.0076\n",
      "\n",
      "5 epochs completed in 0.039 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.46it/s]\n",
      "                   all        852      10397      0.031     0.0186      0.017     0.0111     0.0263     0.0158     0.0144    0.00764\n",
      "         Large_Vehicle        852      10397      0.031     0.0186      0.017     0.0111     0.0263     0.0158     0.0144    0.00764\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:20<00:00,  2.59it/s]\n",
      "                   all        852       9278     0.0311     0.0212     0.0171     0.0101     0.0246     0.0168     0.0136    0.00733\n",
      "         Large_Vehicle        852       9278     0.0311     0.0212     0.0171     0.0101     0.0246     0.0168     0.0136    0.00733\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_16/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 59.97it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_16/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.48G      1.487      3.625       5.22      1.628         39        640: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397     0.0252     0.0139     0.0133    0.00903     0.0215     0.0119     0.0113    0.00623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5         4G      2.276      4.356      7.634      2.076         27        640: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397     0.0241     0.0135     0.0127    0.00845     0.0205     0.0114     0.0108    0.00588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.01G      2.341      4.486      8.599      2.089         35        640: 100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397     0.0246     0.0138      0.013    0.00861     0.0203     0.0113     0.0107    0.00601\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.98G       1.97      4.631      8.105       1.66         46        640: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397     0.0254     0.0143     0.0134    0.00875     0.0213      0.012     0.0112    0.00624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.26G      1.947      4.213      5.406      1.856         81        640: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397     0.0258     0.0147     0.0137    0.00905     0.0213     0.0121     0.0112    0.00617\n",
      "\n",
      "5 epochs completed in 0.034 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.40it/s]\n",
      "                   all        852      10397     0.0255     0.0141     0.0135    0.00904     0.0218     0.0121     0.0115    0.00629\n",
      "         Large_Vehicle        852      10397     0.0255     0.0141     0.0135    0.00904     0.0218     0.0121     0.0115    0.00629\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.48it/s]\n",
      "                   all        852       9278     0.0257      0.016     0.0138     0.0086     0.0219     0.0136     0.0118    0.00668\n",
      "         Large_Vehicle        852       9278     0.0257      0.016     0.0138     0.0086     0.0219     0.0136     0.0118    0.00668\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 51 images, 0 backgrounds, 0 corrupt: 100%|██████████| 51/51 [00:00<00:00, 118.93it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.56G      2.138      3.679        7.4      1.587          5        640: 100%|██████████| 4/4 [00:03<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397    0.00321    0.00135    0.00164   0.000844    0.00206   0.000866    0.00105   0.000258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.65G      2.125      3.924      6.449      1.524         14        640: 100%|██████████| 4/4 [00:03<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397    0.00434    0.00212    0.00221    0.00129    0.00315    0.00154     0.0016   0.000622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.49G      1.882      3.622      6.135      1.552         12        640: 100%|██████████| 4/4 [00:03<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397     0.0242     0.0136     0.0132    0.00882     0.0207     0.0116     0.0112    0.00582\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.47G      1.976      3.282      5.492      1.337         14        640: 100%|██████████| 4/4 [00:03<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397      0.132      0.165      0.148      0.091      0.114      0.142      0.123     0.0606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.75G      1.685       2.83       7.35      1.482          1        640: 100%|██████████| 4/4 [00:03<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397      0.434      0.142      0.179       0.11      0.377      0.124      0.149     0.0745\n",
      "\n",
      "5 epochs completed in 0.040 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.44it/s]\n",
      "                   all        852      10397      0.435      0.143       0.18       0.11      0.392      0.122       0.15     0.0745\n",
      "         Large_Vehicle        852      10397      0.435      0.143       0.18       0.11      0.392      0.122       0.15     0.0745\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.54it/s]\n",
      "                   all        852       9278      0.521      0.126      0.177      0.112      0.438      0.117      0.143     0.0734\n",
      "         Large_Vehicle        852       9278      0.521      0.126      0.177      0.112      0.438      0.117      0.143     0.0734\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_17/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 98.01it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_17/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.87G      2.494      3.211      6.426      1.201         26        640: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.488      0.119      0.159     0.0955      0.414      0.103      0.128     0.0609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      3.98G      3.011      3.885      9.713      1.069         25        640: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397      0.487      0.122      0.161     0.0973      0.415      0.106      0.129     0.0616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.99G      2.617      3.318      7.299      1.076         28        640: 100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397      0.491      0.123      0.163     0.0989      0.417      0.107      0.131     0.0627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.99G      2.905      4.732      14.42      1.326         14        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397      0.492      0.125      0.165        0.1      0.426      0.108      0.134     0.0638\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.03G      2.332      3.136      5.473     0.9662         73        640: 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397      0.489      0.127      0.166      0.101      0.422       0.11      0.134     0.0646\n",
      "\n",
      "5 epochs completed in 0.036 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.39it/s]\n",
      "                   all        852      10397      0.489      0.127      0.166      0.101      0.422       0.11      0.134     0.0646\n",
      "         Large_Vehicle        852      10397      0.489      0.127      0.166      0.101      0.422       0.11      0.134     0.0646\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.50it/s]\n",
      "                   all        852       9278      0.417      0.125      0.151      0.098      0.369      0.111      0.122     0.0623\n",
      "         Large_Vehicle        852       9278      0.417      0.125      0.151      0.098      0.369      0.111      0.122     0.0623\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 56 images, 0 backgrounds, 0 corrupt: 100%|██████████| 56/56 [00:00<00:00, 112.76it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.33G      2.086      3.521      6.783      1.514         43        640: 100%|██████████| 4/4 [00:03<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397    0.00316    0.00135     0.0016   0.000965    0.00203   0.000866    0.00104   0.000299\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.35G      2.182      3.887      6.343       1.69        135        640: 100%|██████████| 4/4 [00:03<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397    0.00369    0.00173    0.00187   0.000895    0.00205   0.000962    0.00104   0.000354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.48G      2.018      3.773      5.989      1.555         89        640: 100%|██████████| 4/4 [00:03<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397     0.0213     0.0122     0.0112    0.00737     0.0176     0.0101     0.0093    0.00504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.48G      1.876      3.442      5.568      1.456         71        640: 100%|██████████| 4/4 [00:03<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.13it/s]\n",
      "                   all        852      10397      0.102     0.0961     0.0864     0.0555     0.0865     0.0817     0.0707     0.0374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.53G      1.495      2.756      4.681      1.228         93        640: 100%|██████████| 4/4 [00:03<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:27<00:00,  1.01s/it]\n",
      "                   all        852      10397      0.131      0.182       0.15      0.095      0.114      0.158       0.12     0.0611\n",
      "\n",
      "5 epochs completed in 0.044 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397      0.131      0.182       0.15     0.0949      0.114      0.158       0.12     0.0611\n",
      "         Large_Vehicle        852      10397      0.131      0.182       0.15     0.0949      0.114      0.158       0.12     0.0611\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.41it/s]\n",
      "                   all        852       9278      0.126       0.19      0.147     0.0954      0.112      0.169      0.118     0.0623\n",
      "         Large_Vehicle        852       9278      0.126       0.19      0.147     0.0954      0.112      0.169      0.118     0.0623\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_18/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 86.94it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_18/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.57G      1.498      2.545      4.384      1.086        119        640: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397      0.101      0.147      0.111     0.0715      0.085      0.123     0.0864     0.0441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.33G      1.433      2.879      4.833      1.097         70        640: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.103      0.148      0.114     0.0732      0.087      0.125     0.0885      0.045\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.89G      1.397      2.658       4.25      1.163         67        640: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397      0.105      0.148      0.116     0.0739     0.0886      0.126     0.0899     0.0459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.23G      1.262      2.347      4.546      1.163         57        640: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397      0.105      0.147      0.116      0.074     0.0894      0.126     0.0908     0.0461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.24G       1.78      2.994      4.939      1.112         95        640: 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397      0.108      0.151      0.119     0.0761     0.0924      0.129     0.0937     0.0477\n",
      "\n",
      "5 epochs completed in 0.036 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.39it/s]\n",
      "                   all        852      10397      0.108      0.151      0.119     0.0763     0.0922      0.129     0.0935     0.0477\n",
      "         Large_Vehicle        852      10397      0.108      0.151      0.119     0.0763     0.0922      0.129     0.0935     0.0477\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.48it/s]\n",
      "                   all        852       9278      0.103      0.155      0.112      0.076     0.0914      0.137     0.0919      0.049\n",
      "         Large_Vehicle        852       9278      0.103      0.155      0.112      0.076     0.0914      0.137     0.0919      0.049\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 61 images, 0 backgrounds, 0 corrupt: 100%|██████████| 61/61 [00:00<00:00, 126.24it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.55G      1.994       3.79      6.162      1.635        270        640: 100%|██████████| 4/4 [00:03<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397    0.00338    0.00144    0.00172   0.000943    0.00203   0.000866    0.00103   0.000287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.37G       2.08      3.865      6.179      1.633        107        640: 100%|██████████| 4/4 [00:03<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397    0.00413    0.00192    0.00211    0.00112    0.00289    0.00135    0.00148    0.00061\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.47G      1.916      3.534      5.761      1.487        306        640: 100%|██████████| 4/4 [00:03<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397     0.0366     0.0214     0.0216     0.0148      0.028     0.0164     0.0165    0.00867\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.47G      1.835      3.231      5.496      1.344        203        640: 100%|██████████| 4/4 [00:03<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397      0.144      0.167       0.16      0.102      0.124      0.143      0.124     0.0629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.48G       1.69      3.067      4.656      1.273        112        640: 100%|██████████| 4/4 [00:03<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.29it/s]\n",
      "                   all        852      10397      0.142      0.217      0.185      0.116      0.124       0.19      0.145     0.0726\n",
      "\n",
      "5 epochs completed in 0.041 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.43it/s]\n",
      "                   all        852      10397      0.142      0.217      0.185      0.116      0.124       0.19      0.145     0.0728\n",
      "         Large_Vehicle        852      10397      0.142      0.217      0.185      0.116      0.124       0.19      0.145     0.0728\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.57it/s]\n",
      "                   all        852       9278      0.388      0.184      0.193      0.123      0.232      0.192      0.152     0.0783\n",
      "         Large_Vehicle        852       9278      0.388      0.184      0.193      0.123      0.232      0.192      0.152     0.0783\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_19/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 81.98it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_19/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.86G      1.391      2.898      4.027      1.317        150        640: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.191      0.186      0.162        0.1      0.106       0.17      0.124     0.0602\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.58G      1.622      3.201      4.204      1.479        160        640: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397      0.133      0.199      0.166      0.103      0.109      0.173      0.127     0.0617\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.27G      1.702      3.609      4.665       1.79         67        640: 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397      0.135      0.203      0.168      0.105      0.111      0.177       0.13     0.0629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.58G      1.927      3.492       4.32      1.624        163        640: 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397       0.13      0.206       0.17      0.106      0.114       0.18      0.132     0.0643\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.75G      1.634      3.464      4.508      1.466        204        640: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397      0.131      0.207      0.171      0.107      0.114      0.181      0.134     0.0655\n",
      "\n",
      "5 epochs completed in 0.036 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397      0.131      0.207      0.171      0.107      0.114      0.181      0.134     0.0656\n",
      "         Large_Vehicle        852      10397      0.131      0.207      0.171      0.107      0.114      0.181      0.134     0.0656\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.48it/s]\n",
      "                   all        852       9278       0.34       0.16      0.168      0.109      0.288      0.144      0.134     0.0683\n",
      "         Large_Vehicle        852       9278       0.34       0.16      0.168      0.109      0.288      0.144      0.134     0.0683\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 66 images, 0 backgrounds, 0 corrupt: 100%|██████████| 66/66 [00:00<00:00, 129.54it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.91G      1.983      3.668      6.488      1.687          2        640: 100%|██████████| 5/5 [00:04<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397    0.00304    0.00135    0.00155   0.000876    0.00196   0.000866   0.000991   0.000266\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.39G      2.045      3.716      6.215      1.656         38        640: 100%|██████████| 5/5 [00:04<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397     0.0091    0.00423    0.00459    0.00283    0.00724    0.00337    0.00366    0.00204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.49G      1.906      3.519      5.874      1.417         13        640: 100%|██████████| 5/5 [00:04<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397      0.062     0.0428     0.0389     0.0268      0.055      0.038     0.0341     0.0188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.9G      1.542      2.545       6.35      1.168          2        640: 100%|██████████| 5/5 [00:04<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397      0.441      0.178      0.197      0.125      0.391      0.159      0.163     0.0813\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.53G      1.466       2.86      3.156      1.204        122        640: 100%|██████████| 5/5 [00:04<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397      0.393       0.23      0.226      0.141      0.346      0.203      0.184     0.0901\n",
      "\n",
      "5 epochs completed in 0.042 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.39it/s]\n",
      "                   all        852      10397      0.393       0.23      0.226      0.141      0.346      0.203      0.184     0.0905\n",
      "         Large_Vehicle        852      10397      0.393       0.23      0.226      0.141      0.346      0.203      0.184     0.0905\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.48it/s]\n",
      "                   all        852       9278      0.389      0.264      0.235       0.15      0.355      0.243      0.204      0.101\n",
      "         Large_Vehicle        852       9278      0.389      0.264      0.235       0.15      0.355      0.243      0.204      0.101\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_20/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 109.42it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_20/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.42G      1.621      1.968       3.24      1.268         52        640: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397       0.28      0.217      0.172      0.106      0.249      0.187      0.137     0.0667\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.04G      1.232      1.889       3.12      1.185         23        640: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397      0.272      0.227      0.175      0.109      0.235      0.201       0.14     0.0678\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.05G      1.072      1.584      2.831     0.9853         31        640: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397       0.28      0.228      0.178      0.111      0.239      0.202      0.142      0.068\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.98G      1.043      1.941      3.814      1.052         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397      0.286      0.228      0.182      0.113      0.248      0.199      0.143     0.0694\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5         4G      1.079       1.66      3.139     0.9342         25        640: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397      0.285      0.234      0.186      0.115      0.243      0.205      0.146     0.0714\n",
      "\n",
      "5 epochs completed in 0.037 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.35it/s]\n",
      "                   all        852      10397      0.286      0.234      0.186      0.116      0.243      0.205      0.146     0.0716\n",
      "         Large_Vehicle        852      10397      0.286      0.234      0.186      0.116      0.243      0.205      0.146     0.0716\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.43it/s]\n",
      "                   all        852       9278      0.325      0.237      0.193      0.121      0.295      0.213      0.164     0.0795\n",
      "         Large_Vehicle        852       9278      0.325      0.237      0.193      0.121      0.295      0.213      0.164     0.0795\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 71 images, 0 backgrounds, 0 corrupt: 100%|██████████| 71/71 [00:00<00:00, 129.92it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.56G      2.264      4.264       6.18      1.876        135        640: 100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397    0.00277    0.00115    0.00141   0.000804    0.00185   0.000769   0.000939   0.000236\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.37G       1.95      3.729      5.877      1.557        214        640: 100%|██████████| 5/5 [00:04<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397     0.0158    0.00693    0.00813     0.0054     0.0149    0.00654    0.00768    0.00389\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.82G       1.57      3.063      5.208      1.213         66        640: 100%|██████████| 5/5 [00:04<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397      0.148      0.181      0.163      0.106      0.131      0.161      0.134     0.0704\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.47G      1.468      2.541      3.608      1.176         81        640: 100%|██████████| 5/5 [00:04<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397      0.383      0.254      0.243      0.151      0.339      0.232      0.201     0.0976\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       9.5G      1.479      2.521      3.127      1.242        103        640: 100%|██████████| 5/5 [00:04<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397      0.415      0.279      0.265      0.167      0.377      0.265      0.233      0.113\n",
      "\n",
      "5 epochs completed in 0.042 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.40it/s]\n",
      "                   all        852      10397      0.415      0.279      0.265      0.167      0.376      0.265      0.232      0.113\n",
      "         Large_Vehicle        852      10397      0.415      0.279      0.265      0.167      0.376      0.265      0.232      0.113\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.54it/s]\n",
      "                   all        852       9278      0.428      0.302      0.278      0.183      0.407      0.284      0.247      0.123\n",
      "         Large_Vehicle        852       9278      0.428      0.302      0.278      0.183      0.407      0.284      0.247      0.123\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_21/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 75.76it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_21/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.65G      1.846      3.338      3.301      1.478        329        640: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397      0.376      0.256      0.234      0.146      0.339      0.238      0.198     0.0951\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.82G      2.082      3.476      3.719      1.606        218        640: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397      0.376      0.261      0.237      0.148      0.333      0.248      0.203     0.0971\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.82G      1.459      2.923      2.875      1.111         58        640: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397      0.374      0.264      0.239      0.149      0.346      0.244      0.204     0.0982\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.06G      1.619      3.129      3.101      1.197         91        640: 100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397       0.38      0.265       0.24       0.15      0.353      0.244      0.205     0.0993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.96G       1.65       3.09      2.949      1.474        199        640: 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.399      0.262      0.244      0.152      0.369      0.242      0.211      0.101\n",
      "\n",
      "5 epochs completed in 0.037 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.36it/s]\n",
      "                   all        852      10397      0.397      0.262      0.244      0.152      0.366      0.242       0.21        0.1\n",
      "         Large_Vehicle        852      10397      0.397      0.262      0.244      0.152      0.366      0.242       0.21        0.1\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.43it/s]\n",
      "                   all        852       9278      0.372      0.304       0.25      0.161      0.349      0.286      0.221      0.107\n",
      "         Large_Vehicle        852       9278      0.372      0.304       0.25      0.161      0.349      0.286      0.221      0.107\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 76 images, 0 backgrounds, 0 corrupt: 100%|██████████| 76/76 [00:00<00:00, 123.12it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.48G      2.038      3.892      5.833      1.712        183        640: 100%|██████████| 5/5 [00:05<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397    0.00295    0.00125    0.00151   0.000898    0.00204   0.000866    0.00104   0.000301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.47G      2.142      3.943      5.986        1.6        144        640: 100%|██████████| 5/5 [00:04<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397     0.0234     0.0116     0.0123    0.00828     0.0203     0.0101     0.0106     0.0054\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.73G      1.666      3.157      5.036      1.373        160        640: 100%|██████████| 5/5 [00:04<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397      0.128      0.171      0.137     0.0906      0.114      0.151      0.113     0.0597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.81G      1.552      2.923      3.627      1.229        230        640: 100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397      0.381      0.245      0.242      0.151      0.338      0.219      0.198     0.0962\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.62G      1.669      2.778      2.867      1.251         94        640: 100%|██████████| 5/5 [00:04<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.394      0.275      0.261      0.163      0.347      0.258       0.22      0.107\n",
      "\n",
      "5 epochs completed in 0.043 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.38it/s]\n",
      "                   all        852      10397      0.395      0.274      0.262      0.163      0.348      0.258      0.221      0.107\n",
      "         Large_Vehicle        852      10397      0.395      0.274      0.262      0.163      0.348      0.258      0.221      0.107\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.48it/s]\n",
      "                   all        852       9278      0.394      0.298      0.269      0.171      0.379      0.274      0.236      0.115\n",
      "         Large_Vehicle        852       9278      0.394      0.298      0.269      0.171      0.379      0.274      0.236      0.115\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_22/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 122.27it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_22/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.75G      2.493      4.885      9.983     0.9873         60        640: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397      0.327       0.26      0.217      0.133      0.295      0.238      0.178      0.083\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.08G      3.258      4.302      9.465      1.247         19        640: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397      0.332       0.26      0.218      0.134      0.301      0.239       0.18      0.086\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.98G      3.039      4.048      12.19      1.154         19        640: 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397      0.336      0.262       0.22      0.135      0.305      0.239      0.181     0.0857\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.03G      3.074      4.357      10.32       1.56         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397      0.336      0.262      0.221      0.135      0.306       0.24      0.183     0.0872\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.07G      2.173      3.565      5.012      1.107         68        640: 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.19it/s]\n",
      "                   all        852      10397      0.344      0.262      0.223      0.137      0.304      0.244      0.185     0.0863\n",
      "\n",
      "5 epochs completed in 0.038 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.32it/s]\n",
      "                   all        852      10397      0.344      0.262      0.223      0.137      0.304      0.244      0.185     0.0868\n",
      "         Large_Vehicle        852      10397      0.344      0.262      0.223      0.137      0.304      0.244      0.185     0.0868\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.39it/s]\n",
      "                   all        852       9278      0.357      0.273       0.23      0.144      0.331      0.253      0.197     0.0925\n",
      "         Large_Vehicle        852       9278      0.357      0.273       0.23      0.144      0.331      0.253      0.197     0.0925\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 81 images, 0 backgrounds, 0 corrupt: 100%|██████████| 81/81 [00:00<00:00, 127.67it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.74G      2.342      4.293      6.335      1.565         25        640: 100%|██████████| 6/6 [00:05<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397    0.00288    0.00125    0.00147   0.000794    0.00111   0.000481   0.000568   0.000182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.52G      2.216       3.91      6.826      1.641          1        640: 100%|██████████| 6/6 [00:05<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397     0.0234     0.0121     0.0122    0.00802     0.0187    0.00971    0.00968    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.87G      2.141      3.485      6.355      1.315          1        640: 100%|██████████| 6/6 [00:05<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.187      0.179      0.103     0.0611       0.15       0.17     0.0771     0.0357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.4G      1.579      2.858       2.69      1.379         33        640: 100%|██████████| 6/6 [00:05<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397      0.214      0.279      0.142     0.0852       0.19      0.258      0.113     0.0501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.53G      1.435      2.628      2.142      1.181         40        640: 100%|██████████| 6/6 [00:05<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397      0.303      0.298       0.21      0.131      0.288      0.278      0.187     0.0893\n",
      "\n",
      "5 epochs completed in 0.044 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.34it/s]\n",
      "                   all        852      10397      0.303      0.298      0.211      0.131      0.288      0.279      0.187     0.0892\n",
      "         Large_Vehicle        852      10397      0.303      0.298      0.211      0.131      0.288      0.279      0.187     0.0892\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:23<00:00,  2.27it/s]\n",
      "                   all        852       9278      0.313      0.321      0.224      0.144      0.295      0.304      0.197     0.0961\n",
      "         Large_Vehicle        852       9278      0.313      0.321      0.224      0.144      0.295      0.304      0.197     0.0961\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_23/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 39.01it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_23/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      4.67G      1.924      3.677       2.17      1.232        534        640: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.16it/s]\n",
      "                   all        852      10397      0.252      0.296      0.176      0.106       0.24      0.275      0.154     0.0709\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.33G      1.346      2.436      2.162      1.148         75        640: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397      0.256      0.298      0.181      0.109      0.241       0.28      0.158     0.0732\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      5.17G      1.986      3.488      3.133      1.648        409        640: 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.19it/s]\n",
      "                   all        852      10397      0.262      0.299      0.186      0.113      0.247      0.281      0.163     0.0753\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.81G      1.537       2.95      2.446      1.454        173        640: 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.19it/s]\n",
      "                   all        852      10397      0.264      0.303      0.192      0.116      0.251      0.281      0.168      0.078\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      5.11G      1.649      3.141      2.235      1.282        333        640: 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.19it/s]\n",
      "                   all        852      10397      0.272      0.301      0.196      0.119      0.255      0.283      0.171     0.0813\n",
      "\n",
      "5 epochs completed in 0.038 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.33it/s]\n",
      "                   all        852      10397       0.27      0.303      0.196      0.119      0.255      0.283      0.171     0.0813\n",
      "         Large_Vehicle        852      10397       0.27      0.303      0.196      0.119      0.255      0.283      0.171     0.0813\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.39it/s]\n",
      "                   all        852       9278      0.303      0.309      0.214      0.136      0.285      0.291      0.187     0.0886\n",
      "         Large_Vehicle        852       9278      0.303      0.309      0.214      0.136      0.285      0.291      0.187     0.0886\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 86 images, 0 backgrounds, 0 corrupt: 100%|██████████| 86/86 [00:00<00:00, 113.71it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.67G      2.282      3.898      6.191        1.7         66        640: 100%|██████████| 6/6 [00:05<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397    0.00313    0.00135    0.00159    0.00087    0.00156   0.000673   0.000798   0.000228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.2G      1.986      3.764      5.642      1.527         80        640: 100%|██████████| 6/6 [00:05<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397     0.0488     0.0359     0.0278     0.0179     0.0407     0.0299     0.0229     0.0113\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.89G      1.577      2.914      3.979      1.213         65        640: 100%|██████████| 6/6 [00:05<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397      0.198      0.241      0.128     0.0734      0.174      0.217     0.0997     0.0421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.3G       1.47      2.639      2.212       1.22         54        640: 100%|██████████| 6/6 [00:05<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397      0.234       0.29      0.147     0.0842      0.216      0.265      0.128     0.0567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.1G      1.305      2.353      1.897      1.128         83        640: 100%|██████████| 6/6 [00:05<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397        0.3      0.315      0.212       0.13      0.294      0.297      0.195     0.0934\n",
      "\n",
      "5 epochs completed in 0.045 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397        0.3      0.316      0.212      0.131      0.293      0.299      0.195     0.0933\n",
      "         Large_Vehicle        852      10397        0.3      0.316      0.212      0.131      0.293      0.299      0.195     0.0933\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.39it/s]\n",
      "                   all        852       9278       0.32      0.347      0.236      0.151      0.314      0.328      0.221      0.107\n",
      "         Large_Vehicle        852       9278       0.32      0.347      0.236      0.151      0.314      0.328      0.221      0.107\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_24/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 124.05it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_24/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.41G      2.202      4.983      14.43      1.107         69        640: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:24<00:00,  1.11it/s]\n",
      "                   all        852      10397      0.267      0.297      0.185      0.112      0.255       0.28      0.165     0.0781\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.09G       1.87      3.091      9.618      0.997         21        640: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.14it/s]\n",
      "                   all        852      10397      0.266      0.298      0.187      0.113      0.259      0.278      0.167     0.0788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.98G      3.257      5.684       22.8      1.262         59        640: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.16it/s]\n",
      "                   all        852      10397      0.265      0.303      0.188      0.114      0.257      0.281      0.169     0.0793\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.99G      2.773      3.563      9.899      1.377         21        640: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.16it/s]\n",
      "                   all        852      10397      0.264      0.305       0.19      0.116      0.259      0.281      0.171     0.0805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.09G      3.355      3.293      19.66      1.602         28        640: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.15it/s]\n",
      "                   all        852      10397      0.266      0.307      0.192      0.117      0.254       0.29      0.173     0.0815\n",
      "\n",
      "5 epochs completed in 0.039 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397      0.266      0.307      0.192      0.117      0.255      0.289      0.173     0.0815\n",
      "         Large_Vehicle        852      10397      0.266      0.307      0.192      0.117      0.255      0.289      0.173     0.0815\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 6.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:24<00:00,  2.21it/s]\n",
      "                   all        852       9278      0.296      0.332      0.214      0.134      0.286      0.314      0.196      0.093\n",
      "         Large_Vehicle        852       9278      0.296      0.332      0.214      0.134      0.286      0.314      0.196      0.093\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 7.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 91 images, 0 backgrounds, 0 corrupt: 100%|██████████| 91/91 [00:00<00:00, 105.16it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.57G      2.105       3.55      6.365       1.56        107        640: 100%|██████████| 6/6 [00:05<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397    0.00358    0.00154    0.00182   0.000949    0.00179   0.000769    0.00091   0.000262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.52G      2.058      3.853      5.754       1.55        157        640: 100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.092     0.0665     0.0687     0.0436     0.0769     0.0555      0.056     0.0294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.47G      1.574      2.993      4.128      1.259        134        640: 100%|██████████| 6/6 [00:05<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397      0.351      0.242      0.228      0.141      0.311       0.22      0.186     0.0887\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.4G      1.494      2.835      2.639      1.195        221        640: 100%|██████████| 6/6 [00:05<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397      0.387      0.284       0.26      0.161      0.351      0.261      0.215      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.2G      1.269      2.386      2.312      1.133        104        640: 100%|██████████| 6/6 [00:05<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397      0.391      0.291      0.266      0.164      0.369      0.279      0.237      0.116\n",
      "\n",
      "5 epochs completed in 0.046 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397       0.39      0.291      0.266      0.165      0.368      0.279      0.238      0.117\n",
      "         Large_Vehicle        852      10397       0.39      0.291      0.266      0.165      0.368      0.279      0.238      0.117\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.41it/s]\n",
      "                   all        852       9278      0.376      0.332      0.277       0.18      0.353      0.314      0.243      0.123\n",
      "         Large_Vehicle        852       9278      0.376      0.332      0.277       0.18      0.353      0.314      0.243      0.123\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_25/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 51.92it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_25/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.15G      1.267      2.177      1.396      1.091         73        640: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.14it/s]\n",
      "                   all        852      10397      0.305      0.299      0.224      0.137      0.282      0.282      0.193      0.093\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.24G        1.1      1.731      1.718      1.093         75        640: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.17it/s]\n",
      "                   all        852      10397      0.315      0.293      0.226      0.139       0.29      0.276      0.195     0.0952\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      4.24G     0.9595      1.722      1.712      1.001         50        640: 100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.16it/s]\n",
      "                   all        852      10397      0.321      0.292      0.227       0.14      0.296      0.273      0.197     0.0963\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      4.21G      1.084      1.846       1.79      1.014         65        640: 100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397      0.327      0.289      0.229      0.141      0.303       0.27      0.197     0.0962\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      4.07G      1.238      1.484      1.762       1.08         44        640: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397       0.34      0.285      0.231      0.142      0.314      0.269      0.202     0.0988\n",
      "\n",
      "5 epochs completed in 0.038 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397       0.34      0.285      0.231      0.142      0.314      0.269      0.202        0.1\n",
      "         Large_Vehicle        852      10397       0.34      0.285      0.231      0.142      0.314      0.269      0.202        0.1\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.35it/s]\n",
      "                   all        852       9278      0.328       0.33      0.246      0.158      0.307      0.311      0.214      0.106\n",
      "         Large_Vehicle        852       9278      0.328       0.33      0.246      0.158      0.307      0.311      0.214      0.106\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 96 images, 0 backgrounds, 0 corrupt: 100%|██████████| 96/96 [00:00<00:00, 107.80it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.53G      2.213       3.93      6.258      1.566        225        640: 100%|██████████| 6/6 [00:06<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397    0.00294    0.00125    0.00149   0.000821    0.00158   0.000673   0.000805    0.00022\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.9G      1.892       3.72      5.652      1.562        507        640: 100%|██████████| 6/6 [00:06<00:00,  1.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.14it/s]\n",
      "                   all        852      10397     0.0439     0.0268     0.0261     0.0189     0.0385     0.0236     0.0229     0.0123\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      11.1G      1.487      2.783      3.534      1.267        200        640: 100%|██████████| 6/6 [00:06<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:31<00:00,  1.15s/it]\n",
      "                   all        852      10397      0.193      0.241      0.122      0.074      0.162      0.223     0.0937     0.0433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.64G      1.541      2.668      3.218      1.227        193        640: 100%|██████████| 6/6 [00:06<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:24<00:00,  1.09it/s]\n",
      "                   all        852      10397      0.279      0.265      0.188      0.117      0.254      0.245      0.157     0.0734\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       9.1G      1.474      2.497       1.87      1.235        534        640: 100%|██████████| 6/6 [00:06<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:25<00:00,  1.07it/s]\n",
      "                   all        852      10397      0.346      0.283      0.239      0.152      0.332      0.269      0.218      0.106\n",
      "\n",
      "5 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.36it/s]\n",
      "                   all        852      10397      0.345      0.283      0.239      0.151      0.332       0.27      0.217      0.105\n",
      "         Large_Vehicle        852      10397      0.345      0.283      0.239      0.151      0.332       0.27      0.217      0.105\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:25<00:00,  2.13it/s]\n",
      "                   all        852       9278      0.338      0.311       0.25      0.165      0.325      0.298      0.228      0.112\n",
      "         Large_Vehicle        852       9278      0.338      0.311       0.25      0.165      0.325      0.298      0.228      0.112\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 6.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_26/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 123.38it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_26/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       6.7G       2.75      3.591       17.8      1.416         30        640: 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.14it/s]\n",
      "                   all        852      10397      0.312      0.267      0.213      0.134      0.296      0.253      0.187     0.0896\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      4.04G      3.376      7.792      40.33      1.196         13        640: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.14it/s]\n",
      "                   all        852      10397      0.313      0.269      0.214      0.135      0.295      0.254      0.187     0.0911\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      3.98G      2.935      3.782      12.57      1.312         39        640: 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.15it/s]\n",
      "                   all        852      10397      0.312      0.272      0.215      0.136      0.295      0.258      0.189     0.0921\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      3.99G      2.346      3.762      17.83      1.464         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.15it/s]\n",
      "                   all        852      10397      0.318       0.27      0.216      0.136        0.3      0.258      0.191     0.0927\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      3.98G      2.576      4.094      8.012      1.259         33        640: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.15it/s]\n",
      "                   all        852      10397       0.32       0.27      0.217      0.137      0.299      0.259      0.191     0.0926\n",
      "\n",
      "5 epochs completed in 0.039 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397       0.32       0.27      0.217      0.136      0.302      0.257      0.191     0.0924\n",
      "         Large_Vehicle        852      10397       0.32       0.27      0.217      0.136      0.302      0.257      0.191     0.0924\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:23<00:00,  2.28it/s]\n",
      "                   all        852       9278      0.316      0.297      0.229      0.148      0.301      0.284      0.206     0.0983\n",
      "         Large_Vehicle        852       9278      0.316      0.297      0.229      0.148      0.301      0.284      0.206     0.0983\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 6.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 101 images, 0 backgrounds, 0 corrupt: 100%|██████████| 101/101 [00:00<00:00, 111.09it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.56G      2.148      3.741      6.672      1.551          9        640: 100%|██████████| 7/7 [00:06<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397    0.00308    0.00135    0.00156   0.000896    0.00198   0.000866      0.001   0.000268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       9.5G      2.029      3.754      5.572      1.529        127        640: 100%|██████████| 7/7 [00:06<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.23it/s]\n",
      "                   all        852      10397     0.0852      0.111     0.0624     0.0406      0.077     0.0999     0.0548      0.029\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.9G      1.555      2.829      3.453      1.203        206        640: 100%|██████████| 7/7 [00:06<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397      0.299      0.276        0.2      0.123      0.282      0.259      0.176     0.0859\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.9G      1.355      2.492      1.826      1.146         99        640: 100%|██████████| 7/7 [00:06<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397       0.32      0.325       0.26      0.159      0.307      0.312      0.241      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.51G      1.295      2.209      1.844       1.13         96        640: 100%|██████████| 7/7 [00:06<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397      0.433      0.318        0.3      0.189      0.419      0.308      0.284      0.149\n",
      "\n",
      "5 epochs completed in 0.047 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.39it/s]\n",
      "                   all        852      10397      0.432      0.318        0.3      0.189      0.418      0.308      0.283      0.149\n",
      "         Large_Vehicle        852      10397      0.432      0.318        0.3      0.189      0.418      0.308      0.283      0.149\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.43it/s]\n",
      "                   all        852       9278      0.453      0.349      0.328      0.214      0.442      0.342      0.311      0.164\n",
      "         Large_Vehicle        852       9278      0.453      0.349      0.328      0.214      0.442      0.342      0.311      0.164\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_27/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 41.57it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_27/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.43G      1.525      3.184      2.351      1.036        236        640: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397      0.359        0.3      0.254      0.157      0.353      0.286      0.238      0.124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.07G       1.63      2.787      2.133      1.057        131        640: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.17it/s]\n",
      "                   all        852      10397      0.359      0.302      0.256      0.158      0.353      0.288      0.239      0.126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.97G      1.839       3.74      2.181       1.17       1373        640: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.19it/s]\n",
      "                   all        852      10397      0.366      0.304       0.26      0.161      0.363      0.289      0.244      0.128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.32G       1.35      2.619       1.79      1.044        198        640: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.19it/s]\n",
      "                   all        852      10397      0.365      0.306      0.261      0.162      0.369      0.289      0.245      0.129\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.07G      1.313      2.677      3.199      1.049         53        640: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397      0.364      0.306      0.261      0.163      0.362      0.294      0.246      0.129\n",
      "\n",
      "5 epochs completed in 0.039 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.32it/s]\n",
      "                   all        852      10397      0.362      0.307      0.261      0.163       0.36      0.295      0.245      0.129\n",
      "         Large_Vehicle        852      10397      0.362      0.307      0.261      0.163       0.36      0.295      0.245      0.129\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.39it/s]\n",
      "                   all        852       9278      0.384       0.34      0.291      0.188      0.374      0.329      0.274      0.141\n",
      "         Large_Vehicle        852       9278      0.384       0.34      0.291      0.188      0.374      0.329      0.274      0.141\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 111 images, 0 backgrounds, 0 corrupt: 100%|██████████| 111/111 [00:00<00:00, 118.41it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.54G        2.1      4.083      6.123      1.701        170        640: 100%|██████████| 7/7 [00:06<00:00,  1.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397    0.00475    0.00202    0.00241    0.00144    0.00294    0.00125    0.00148   0.000638\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.98G      1.942      3.805      5.798      1.412        373        640: 100%|██████████| 7/7 [00:06<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397     0.0602     0.0656     0.0346     0.0229     0.0538     0.0586     0.0305     0.0165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.2G      1.479      2.891      3.134      1.256        144        640: 100%|██████████| 7/7 [00:07<00:00,  1.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397      0.191      0.274      0.129     0.0777      0.176      0.257      0.111      0.052\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.1G      1.475      2.697      1.673      1.176        229        640: 100%|██████████| 7/7 [00:07<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:33<00:00,  1.22s/it]\n",
      "                   all        852      10397      0.253      0.314      0.192      0.119      0.241      0.296       0.17     0.0816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.69G      1.408      2.444      1.949      1.109        152        640: 100%|██████████| 7/7 [00:07<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:30<00:00,  1.13s/it]\n",
      "                   all        852      10397      0.405      0.306      0.279      0.177      0.385      0.295      0.258       0.13\n",
      "\n",
      "5 epochs completed in 0.053 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397      0.405      0.306      0.279      0.177      0.386      0.294      0.258       0.13\n",
      "         Large_Vehicle        852      10397      0.405      0.306      0.279      0.177      0.386      0.294      0.258       0.13\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.35it/s]\n",
      "                   all        852       9278      0.405      0.321      0.284      0.187      0.389      0.309      0.263      0.132\n",
      "         Large_Vehicle        852       9278      0.405      0.321      0.284      0.187      0.389      0.309      0.263      0.132\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_28/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 96.66it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_28/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.38G      1.766      2.664      1.821      1.104        907        640: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.16it/s]\n",
      "                   all        852      10397      0.338       0.27      0.228      0.143      0.324       0.26      0.209      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.78G       1.42      2.287      1.481      1.158        279        640: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397       0.34      0.274      0.231      0.145      0.312      0.275      0.213      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      8.26G      1.845      2.973      1.907        1.2        623        640: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.19it/s]\n",
      "                   all        852      10397      0.335      0.283      0.236      0.147      0.322      0.272      0.217      0.106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.77G      1.843      2.654      2.047       1.15        311        640: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397      0.342      0.286      0.238      0.149      0.322       0.28      0.218      0.106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.26G      1.824      2.596          2      1.107        223        640: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397      0.342      0.285       0.24       0.15      0.326      0.278       0.22      0.108\n",
      "\n",
      "5 epochs completed in 0.039 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397      0.342      0.286       0.24       0.15      0.326      0.278       0.22      0.108\n",
      "         Large_Vehicle        852      10397      0.342      0.286       0.24       0.15      0.326      0.278       0.22      0.108\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.38it/s]\n",
      "                   all        852       9278      0.347      0.314      0.249       0.16      0.335        0.3       0.23      0.113\n",
      "         Large_Vehicle        852       9278      0.347      0.314      0.249       0.16      0.335        0.3       0.23      0.113\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 121 images, 0 backgrounds, 0 corrupt: 100%|██████████| 121/121 [00:01<00:00, 110.53it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.94G      2.283      4.209      6.314      1.588         89        640: 100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397    0.00446    0.00192    0.00228    0.00122    0.00267    0.00115    0.00136   0.000542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      11.1G      1.801      3.429      5.091      1.383        125        640: 100%|██████████| 8/8 [00:07<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397      0.329      0.234      0.213      0.132      0.272      0.198      0.161     0.0759\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.52G      1.666      2.852      3.116      1.163        121        640: 100%|██████████| 8/8 [00:07<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397      0.356      0.281      0.236      0.143      0.329       0.27      0.213      0.105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5        11G      1.432      2.545      2.164      1.093         94        640: 100%|██████████| 8/8 [00:07<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397      0.305      0.317       0.21      0.126      0.287      0.299      0.189     0.0912\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      12.2G      1.382      2.415        1.9      1.082        134        640: 100%|██████████| 8/8 [00:07<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397      0.455      0.329      0.311      0.191      0.439      0.312      0.289      0.146\n",
      "\n",
      "5 epochs completed in 0.048 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.36it/s]\n",
      "                   all        852      10397      0.455      0.329      0.311      0.191      0.437      0.312      0.289      0.146\n",
      "         Large_Vehicle        852      10397      0.455      0.329      0.311      0.191      0.437      0.312      0.289      0.146\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:24<00:00,  2.22it/s]\n",
      "                   all        852       9278      0.497      0.331      0.337      0.213      0.473      0.322      0.317      0.161\n",
      "         Large_Vehicle        852       9278      0.497      0.331      0.337      0.213      0.473      0.322      0.317      0.161\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_29/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 124.94it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_29/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.61G     0.9175       1.88       1.28     0.9625        222        640: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.17it/s]\n",
      "                   all        852      10397      0.399      0.295      0.267      0.161      0.391      0.278      0.247      0.124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5       7.1G     0.8195      1.945       1.58     0.9907        141        640: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397      0.402      0.297       0.27      0.163      0.393       0.28      0.251      0.126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.06G      1.334      2.222      2.048     0.9732        106        640: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397        0.4      0.301      0.271      0.164      0.401      0.279      0.252      0.127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.07G      2.159       3.12      4.444      1.183         77        640: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397      0.399      0.303      0.272      0.165      0.394      0.284      0.253      0.127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.05G      1.597      2.919      2.174      1.165        143        640: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.19it/s]\n",
      "                   all        852      10397      0.402      0.304      0.274      0.166      0.396      0.285      0.255      0.128\n",
      "\n",
      "5 epochs completed in 0.039 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397      0.402      0.304      0.274      0.166      0.396      0.285      0.255      0.128\n",
      "         Large_Vehicle        852      10397      0.402      0.304      0.274      0.166      0.396      0.285      0.255      0.128\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.38it/s]\n",
      "                   all        852       9278      0.441      0.319      0.303      0.187      0.418      0.308      0.283       0.14\n",
      "         Large_Vehicle        852       9278      0.441      0.319      0.303      0.187      0.418      0.308      0.283       0.14\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 131 images, 0 backgrounds, 0 corrupt: 100%|██████████| 131/131 [00:01<00:00, 111.71it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      10.1G      2.382      4.326      6.472      1.623         61        640: 100%|██████████| 9/9 [00:08<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397     0.0063    0.00279     0.0032    0.00196    0.00521    0.00231    0.00264    0.00135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.6G      1.837       3.51      4.908      1.355         10        640: 100%|██████████| 9/9 [00:08<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397       0.16      0.241      0.109     0.0646      0.129      0.216      0.074     0.0323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.2G      1.544      2.726      2.249      1.224         13        640: 100%|██████████| 9/9 [00:08<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.14it/s]\n",
      "                   all        852      10397      0.308      0.312       0.23      0.138      0.295        0.3      0.212      0.105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5        11G      1.356      2.325       2.09      1.067         33        640: 100%|██████████| 9/9 [00:08<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397       0.43      0.329      0.307      0.191      0.422      0.312      0.283      0.143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.62G      1.355      2.438      1.799      1.093         32        640: 100%|██████████| 9/9 [00:08<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397      0.472      0.353      0.333      0.219      0.466      0.335      0.314      0.166\n",
      "\n",
      "5 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.38it/s]\n",
      "                   all        852      10397      0.471      0.353      0.333      0.218      0.466      0.335      0.314      0.165\n",
      "         Large_Vehicle        852      10397      0.471      0.353      0.333      0.218      0.466      0.335      0.314      0.165\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.36it/s]\n",
      "                   all        852       9278      0.509      0.354      0.365      0.249      0.518      0.342       0.35      0.189\n",
      "         Large_Vehicle        852       9278      0.509      0.354      0.365      0.249      0.518      0.342       0.35      0.189\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_30/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 41.46it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_30/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       7.3G      1.781      2.578      2.313      0.967        131        640: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397       0.46      0.319       0.31      0.199      0.457      0.304       0.29       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.11G      1.364      2.187      1.336     0.9369        187        640: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.18it/s]\n",
      "                   all        852      10397      0.467      0.317      0.312      0.199       0.46      0.305      0.291       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.07G      1.711      2.331      1.706      1.075        161        640: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.19it/s]\n",
      "                   all        852      10397      0.459      0.323      0.313      0.201      0.462      0.306      0.292      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.07G       1.58      2.013      3.147      1.089         84        640: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.19it/s]\n",
      "                   all        852      10397      0.457      0.326      0.314      0.201      0.454       0.31      0.293      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.06G       1.41      2.093      1.381      1.028        170        640: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397      0.454       0.33      0.315      0.202       0.45      0.312      0.293      0.152\n",
      "\n",
      "5 epochs completed in 0.038 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.32it/s]\n",
      "                   all        852      10397      0.454      0.328      0.315      0.202       0.45      0.312      0.293      0.152\n",
      "         Large_Vehicle        852      10397      0.454      0.328      0.315      0.202       0.45      0.312      0.293      0.152\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.37it/s]\n",
      "                   all        852       9278      0.494      0.345       0.35      0.233      0.495      0.331      0.331      0.174\n",
      "         Large_Vehicle        852       9278      0.494      0.345       0.35      0.233      0.495      0.331      0.331      0.174\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 141 images, 0 backgrounds, 0 corrupt: 100%|██████████| 141/141 [00:01<00:00, 114.00it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      11.6G      2.157      4.214      6.118      1.599        244        640: 100%|██████████| 9/9 [00:09<00:00,  1.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397    0.00684    0.00317    0.00348    0.00217     0.0056     0.0026    0.00284    0.00146\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5        10G       1.78      3.343      4.574      1.293         89        640: 100%|██████████| 9/9 [00:09<00:00,  1.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.16it/s]\n",
      "                   all        852      10397      0.152      0.237     0.0939     0.0554      0.123      0.233     0.0703     0.0299\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.61G      1.441      2.507      2.355      1.151        175        640: 100%|██████████| 9/9 [00:08<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.17it/s]\n",
      "                   all        852      10397      0.417       0.29      0.284      0.173      0.389      0.276      0.251      0.123\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5        11G      1.358      2.405      1.853      1.055        465        640: 100%|██████████| 9/9 [00:09<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397      0.392      0.346      0.287       0.18      0.388      0.328      0.268      0.134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       9.6G       1.23       2.18      1.696      1.084        222        640: 100%|██████████| 9/9 [00:08<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397      0.519      0.333      0.344      0.223      0.498      0.322      0.315      0.165\n",
      "\n",
      "5 epochs completed in 0.051 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.39it/s]\n",
      "                   all        852      10397       0.52      0.333      0.345      0.223        0.5      0.321      0.315      0.165\n",
      "         Large_Vehicle        852      10397       0.52      0.333      0.345      0.223        0.5      0.321      0.315      0.165\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.47it/s]\n",
      "                   all        852       9278       0.56      0.353      0.376      0.252       0.54       0.34      0.349      0.191\n",
      "         Large_Vehicle        852       9278       0.56      0.353      0.376      0.252       0.54       0.34      0.349      0.191\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_31/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 97.24it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_31/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.23G      1.759      2.649      2.283       1.26        108        640: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397      0.495      0.315      0.324      0.209      0.469      0.302      0.295      0.154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.06G      2.012       4.16      3.319       1.28        210        640: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397      0.499      0.316      0.326       0.21      0.471      0.305      0.297      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       7.4G      1.655      2.781      1.968       1.24        270        640: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397      0.487      0.323      0.327      0.211      0.467      0.307      0.299      0.156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.29G       2.64      4.441      4.586      1.433        233        640: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397      0.488      0.323      0.328      0.211      0.466      0.309      0.299      0.157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.05G      1.674      2.669      2.229      1.213        171        640: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397      0.491      0.324       0.33      0.213       0.47      0.312      0.303      0.159\n",
      "\n",
      "5 epochs completed in 0.038 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.36it/s]\n",
      "                   all        852      10397      0.493      0.323       0.33      0.212      0.481      0.307      0.303      0.159\n",
      "         Large_Vehicle        852      10397      0.493      0.323       0.33      0.212      0.481      0.307      0.303      0.159\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.43it/s]\n",
      "                   all        852       9278       0.54      0.353       0.37      0.245      0.536      0.336      0.343      0.185\n",
      "         Large_Vehicle        852       9278       0.54      0.353       0.37      0.245      0.536      0.336      0.343      0.185\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|██████████| 151/151 [00:01<00:00, 106.71it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      10.4G      2.192      3.842      6.219      1.595        131        640: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397     0.0199     0.0104     0.0103    0.00658     0.0165    0.00866    0.00851    0.00452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.97G      1.786      3.214      4.172       1.33        132        640: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.15it/s]\n",
      "                   all        852      10397      0.247      0.266      0.154     0.0929      0.225      0.244      0.127     0.0592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.62G      1.533       2.57      2.451      1.163        121        640: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.15it/s]\n",
      "                   all        852      10397       0.32      0.329      0.235      0.143      0.318      0.312      0.221      0.111\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.9G      1.389      2.452      1.827      1.146        164        640: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:28<00:00,  1.06s/it]\n",
      "                   all        852      10397      0.474      0.336      0.327      0.216      0.481      0.321      0.317      0.174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.64G      1.271      2.331      1.546      1.045        470        640: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.17it/s]\n",
      "                   all        852      10397      0.538      0.351      0.363      0.246      0.533      0.341      0.349      0.191\n",
      "\n",
      "5 epochs completed in 0.054 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.40it/s]\n",
      "                   all        852      10397      0.539      0.349      0.363      0.246       0.53      0.342      0.349      0.191\n",
      "         Large_Vehicle        852      10397      0.539      0.349      0.363      0.246       0.53      0.342      0.349      0.191\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:24<00:00,  2.20it/s]\n",
      "                   all        852       9278      0.551       0.38      0.394      0.273      0.543      0.372      0.377       0.21\n",
      "         Large_Vehicle        852       9278      0.551       0.38      0.394      0.273      0.543      0.372      0.377       0.21\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_32/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 63.15it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_32/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      6.41G      1.676      2.766      7.366     0.9894         30        640: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397      0.476      0.339      0.329      0.219      0.472      0.329      0.314      0.171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.07G      2.332      4.007      13.85      1.165         21        640: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.475      0.339       0.33      0.219       0.47       0.33      0.315      0.171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.06G       1.83      2.774      6.348      0.973         55        640: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397      0.481      0.338      0.331       0.22      0.472       0.33      0.316      0.172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.08G      1.959      3.487      10.25     0.9855         28        640: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.479      0.339      0.331       0.22      0.472      0.332      0.316      0.172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.06G      1.676      2.532      8.999      1.077         27        640: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.477       0.34      0.332      0.221      0.469      0.334      0.317      0.173\n",
      "\n",
      "5 epochs completed in 0.036 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397      0.476      0.342      0.332      0.221      0.468      0.334      0.317      0.173\n",
      "         Large_Vehicle        852      10397      0.476      0.342      0.332      0.221      0.468      0.334      0.317      0.173\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.45it/s]\n",
      "                   all        852       9278      0.539      0.365      0.374      0.255      0.534      0.355      0.355      0.195\n",
      "         Large_Vehicle        852       9278      0.539      0.365      0.374      0.255      0.534      0.355      0.355      0.195\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 161 images, 0 backgrounds, 0 corrupt: 100%|██████████| 161/161 [00:01<00:00, 118.63it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5        10G      2.251      3.971      6.176       1.68         12        640: 100%|██████████| 11/11 [00:10<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397     0.0349      0.017     0.0194     0.0136     0.0305     0.0149     0.0167    0.00916\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.5G      1.586      3.028      3.628      1.237         16        640: 100%|██████████| 11/11 [00:09<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.16it/s]\n",
      "                   all        852      10397      0.223      0.328      0.153     0.0925      0.209      0.307      0.136     0.0646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.66G      1.467      2.604      2.229      1.092         20        640: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397      0.419      0.303      0.289       0.18      0.418      0.288      0.275      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.87G      1.372      2.283      2.065      1.056          7        640: 100%|██████████| 11/11 [00:10<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397      0.563      0.358      0.364      0.241      0.553       0.34      0.339      0.177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.7G      1.344      2.184      3.299      1.023          1        640: 100%|██████████| 11/11 [00:10<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397      0.559      0.364      0.373      0.244      0.555      0.351      0.353      0.188\n",
      "\n",
      "5 epochs completed in 0.052 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397       0.56      0.364      0.373      0.244      0.556      0.352      0.353      0.188\n",
      "         Large_Vehicle        852      10397       0.56      0.364      0.373      0.244      0.556      0.352      0.353      0.188\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.54it/s]\n",
      "                   all        852       9278      0.583       0.39      0.405      0.274      0.577      0.381       0.39      0.213\n",
      "         Large_Vehicle        852       9278      0.583       0.39      0.405      0.274      0.577      0.381       0.39      0.213\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_33/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 104.54it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_33/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.29G      1.017      1.882      3.714     0.9263         28        640: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.463      0.349      0.324       0.21       0.46      0.337      0.307      0.163\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.07G      1.273      2.709      2.493     0.9782         77        640: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397       0.47      0.349      0.326      0.212      0.471      0.336       0.31      0.164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.07G      1.217      2.522      2.586      1.015         57        640: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.476       0.35      0.329      0.214      0.476      0.338      0.313      0.166\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.06G      1.196      2.184      2.013     0.9948         85        640: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.484      0.348      0.332      0.216      0.479      0.341      0.316      0.168\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.06G      1.344      2.328      2.785     0.9398         89        640: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397      0.488      0.351      0.335      0.218      0.489      0.339      0.319       0.17\n",
      "\n",
      "5 epochs completed in 0.037 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.38it/s]\n",
      "                   all        852      10397      0.488       0.35      0.335      0.217      0.488      0.339      0.319       0.17\n",
      "         Large_Vehicle        852      10397      0.488       0.35      0.335      0.217      0.488      0.339      0.319       0.17\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.48it/s]\n",
      "                   all        852       9278      0.532      0.377      0.378      0.252      0.534      0.366      0.364      0.198\n",
      "         Large_Vehicle        852       9278      0.532      0.377      0.378      0.252      0.534      0.366      0.364      0.198\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 171 images, 0 backgrounds, 0 corrupt: 100%|██████████| 171/171 [00:01<00:00, 124.42it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5        10G      2.139      4.026      6.174      1.648         65        640: 100%|██████████| 11/11 [00:10<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397      0.044     0.0241     0.0251     0.0171     0.0368     0.0202     0.0205     0.0107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5        10G      1.686      3.011      3.817      1.227        163        640: 100%|██████████| 11/11 [00:11<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.13it/s]\n",
      "                   all        852      10397       0.15      0.411      0.154     0.0927       0.14      0.384      0.132     0.0593\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.6G      1.518      2.551      2.063      1.146        111        640: 100%|██████████| 11/11 [00:11<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.20it/s]\n",
      "                   all        852      10397      0.385      0.337       0.28      0.175      0.379      0.322      0.259      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.9G       1.33      2.304      1.401      1.069        394        640: 100%|██████████| 11/11 [00:10<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397      0.518      0.363       0.35      0.232      0.497      0.343      0.316      0.165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5        11G      1.296      2.317      1.976      1.026        203        640: 100%|██████████| 11/11 [00:10<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397      0.531      0.355      0.352      0.232      0.523      0.344      0.332      0.177\n",
      "\n",
      "5 epochs completed in 0.053 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397      0.531      0.355      0.352      0.232      0.524      0.345      0.332      0.176\n",
      "         Large_Vehicle        852      10397      0.531      0.355      0.352      0.232      0.524      0.345      0.332      0.176\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.43it/s]\n",
      "                   all        852       9278       0.56      0.375      0.378      0.254      0.561      0.364      0.362      0.199\n",
      "         Large_Vehicle        852       9278       0.56      0.375      0.378      0.254      0.561      0.364      0.362      0.199\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_34/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 53.44it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_34/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      5.98G      1.443      2.186      3.038      1.092         42        640: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397       0.45      0.344      0.319      0.206      0.442      0.333      0.302       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.07G      1.232      2.016      2.552      1.067         57        640: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.453      0.345       0.32      0.207      0.445      0.334      0.302       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.06G      1.434      2.216      2.277     0.9781         90        640: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397      0.456      0.346      0.321      0.208      0.449      0.334      0.303       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.07G      0.942      1.612      1.363      1.061        114        640: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397      0.461      0.346      0.324       0.21      0.452      0.336      0.305      0.162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.17G     0.9242      1.588      1.466      1.005        190        640: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397      0.471      0.347      0.329      0.214       0.46      0.337      0.309      0.165\n",
      "\n",
      "5 epochs completed in 0.037 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.39it/s]\n",
      "                   all        852      10397       0.47      0.347      0.329      0.214       0.46      0.337      0.309      0.165\n",
      "         Large_Vehicle        852      10397       0.47      0.347      0.329      0.214       0.46      0.337      0.309      0.165\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.51it/s]\n",
      "                   all        852       9278      0.497      0.379      0.358      0.237      0.495      0.368      0.342      0.186\n",
      "         Large_Vehicle        852       9278      0.497      0.379      0.358      0.237      0.495      0.368      0.342      0.186\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 181 images, 0 backgrounds, 0 corrupt: 100%|██████████| 181/181 [00:01<00:00, 118.07it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.68G      2.137      3.943      6.171      1.636         32        640: 100%|██████████| 12/12 [00:11<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n",
      "                   all        852      10397     0.0457     0.0225     0.0267     0.0182     0.0387      0.019     0.0224     0.0126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.6G      1.701      3.087      3.519      1.224         34        640: 100%|██████████| 12/12 [00:11<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.17it/s]\n",
      "                   all        852      10397      0.281      0.283      0.185      0.114      0.265      0.266      0.163     0.0791\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.1G      1.375      2.408       1.79      1.093         53        640: 100%|██████████| 12/12 [00:11<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:24<00:00,  1.12it/s]\n",
      "                   all        852      10397      0.485      0.341      0.327      0.215      0.473      0.329      0.308      0.159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5        11G      1.262      2.151      1.837      1.064         41        640: 100%|██████████| 12/12 [00:11<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:25<00:00,  1.06it/s]\n",
      "                   all        852      10397      0.595      0.357      0.387      0.267      0.588      0.343      0.364      0.202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5        11G      1.222      1.976      1.537      1.027         34        640: 100%|██████████| 12/12 [00:11<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:24<00:00,  1.10it/s]\n",
      "                   all        852      10397      0.578      0.367      0.399      0.269      0.581      0.357      0.383      0.213\n",
      "\n",
      "5 epochs completed in 0.057 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.44it/s]\n",
      "                   all        852      10397      0.579      0.368      0.399      0.269      0.586      0.356      0.383      0.213\n",
      "         Large_Vehicle        852      10397      0.579      0.368      0.399      0.269      0.586      0.356      0.383      0.213\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.53it/s]\n",
      "                   all        852       9278      0.618      0.386      0.431      0.303      0.616      0.383      0.417      0.237\n",
      "         Large_Vehicle        852       9278      0.618      0.386      0.431      0.303      0.616      0.383      0.417      0.237\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_35/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 120.60it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_35/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.28G      1.415      1.964       2.15     0.9461        111        640: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397      0.547      0.358      0.379      0.252      0.544      0.351      0.362      0.201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.06G      1.193      2.176      1.827      1.028        105        640: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397      0.548      0.359       0.38      0.253      0.551      0.351      0.363      0.202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.07G      1.267      2.485      1.867      1.045        122        640: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397       0.55      0.361      0.382      0.254      0.557       0.35      0.365      0.203\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.09G      1.479      2.801      3.881      1.114         32        640: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397      0.553      0.361      0.382      0.255      0.558       0.35      0.365      0.203\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.06G      2.338      4.038      3.817      1.361         75        640: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397      0.552      0.362      0.383      0.255      0.564      0.349      0.366      0.203\n",
      "\n",
      "5 epochs completed in 0.036 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397       0.55      0.363      0.383      0.255      0.562       0.35      0.366      0.203\n",
      "         Large_Vehicle        852      10397       0.55      0.363      0.383      0.255      0.562       0.35      0.366      0.203\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.54it/s]\n",
      "                   all        852       9278      0.583      0.385      0.417      0.289      0.582       0.38      0.402      0.226\n",
      "         Large_Vehicle        852       9278      0.583      0.385      0.417      0.289      0.582       0.38      0.402      0.226\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 191 images, 0 backgrounds, 0 corrupt: 100%|██████████| 191/191 [00:01<00:00, 113.81it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.57G      2.018      3.867      6.132      1.484        192        640: 100%|██████████| 12/12 [00:12<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.28it/s]\n",
      "                   all        852      10397     0.0335     0.0181      0.019     0.0127     0.0266     0.0143     0.0151    0.00848\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5        11G      1.662      3.004      3.348      1.218        271        640: 100%|██████████| 12/12 [00:12<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.16it/s]\n",
      "                   all        852      10397      0.333      0.287      0.215      0.127      0.313      0.271      0.197     0.0956\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.4G      1.511      2.678      1.844      1.087        749        640: 100%|██████████| 12/12 [00:11<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397      0.447      0.322      0.309        0.2      0.426      0.308      0.285      0.148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5       9.8G       1.34       2.32      1.556      1.038        465        640: 100%|██████████| 12/12 [00:11<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.525      0.356      0.359      0.228      0.522      0.336      0.337      0.171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5       9.9G      1.218      2.109      1.464      1.016        300        640: 100%|██████████| 12/12 [00:12<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397      0.596      0.363      0.403      0.275       0.58      0.352      0.375        0.2\n",
      "\n",
      "5 epochs completed in 0.054 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397      0.596      0.363      0.403      0.275       0.58      0.351      0.375        0.2\n",
      "         Large_Vehicle        852      10397      0.596      0.363      0.403      0.275       0.58      0.351      0.375        0.2\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.51it/s]\n",
      "                   all        852       9278      0.597      0.389      0.414      0.288      0.587      0.378      0.393      0.217\n",
      "         Large_Vehicle        852       9278      0.597      0.389      0.414      0.288      0.587      0.378      0.393      0.217\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_36/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 47.88it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_36/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      7.71G      1.468      1.498      1.356      1.026        252        640: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.574       0.35      0.381      0.258      0.564      0.339      0.352      0.186\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      7.06G      1.704      2.298       2.15     0.9988        183        640: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.573      0.351      0.383      0.259      0.561      0.341      0.354      0.187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      7.06G      1.622      2.427      2.627     0.9466        155        640: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397       0.57      0.353      0.384       0.26       0.56      0.342      0.355      0.188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      7.06G      1.388      2.207      1.944     0.9702        140        640: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397      0.574      0.352      0.384      0.261      0.562      0.341      0.356      0.189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      7.06G      2.017      3.135      4.967      1.059        136        640: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397       0.57      0.355      0.385      0.262      0.558      0.342      0.356       0.19\n",
      "\n",
      "5 epochs completed in 0.037 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.40it/s]\n",
      "                   all        852      10397       0.57      0.355      0.385      0.262      0.556      0.343      0.356      0.189\n",
      "         Large_Vehicle        852      10397       0.57      0.355      0.385      0.262      0.556      0.343      0.356      0.189\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.49it/s]\n",
      "                   all        852       9278      0.579      0.378        0.4      0.276      0.567      0.366      0.375      0.204\n",
      "         Large_Vehicle        852       9278      0.579      0.378        0.4      0.276      0.567      0.366      0.375      0.204\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 201 images, 0 backgrounds, 0 corrupt: 100%|██████████| 201/201 [00:01<00:00, 108.75it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.8G      1.972      3.572      6.022      1.427        225        640: 100%|██████████| 13/13 [00:12<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397      0.111      0.149     0.0924     0.0581     0.0953      0.128     0.0754     0.0385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.75G      1.568      2.762      2.794      1.163        145        640: 100%|██████████| 13/13 [00:12<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.13it/s]\n",
      "                   all        852      10397      0.313      0.329      0.221      0.136      0.297       0.31      0.201        0.1\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5        11G       1.31      2.347      1.894      1.116        401        640: 100%|██████████| 13/13 [00:13<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:25<00:00,  1.06it/s]\n",
      "                   all        852      10397      0.469      0.333      0.321      0.207      0.463      0.324      0.303      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.85G      1.281      2.208      1.958      1.058        109        640: 100%|██████████| 13/13 [00:12<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:24<00:00,  1.09it/s]\n",
      "                   all        852      10397      0.538      0.352      0.368      0.248       0.52      0.344      0.346      0.186\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.7G      1.228      2.112      1.379      1.011        184        640: 100%|██████████| 13/13 [00:12<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.582      0.375      0.412      0.285      0.569      0.362      0.386      0.215\n",
      "\n",
      "5 epochs completed in 0.058 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.43it/s]\n",
      "                   all        852      10397      0.582      0.375      0.412      0.285       0.57      0.362      0.386      0.215\n",
      "         Large_Vehicle        852      10397      0.582      0.375      0.412      0.285       0.57      0.362      0.386      0.215\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:22<00:00,  2.43it/s]\n",
      "                   all        852       9278      0.584      0.403      0.436      0.306      0.591      0.393      0.417      0.236\n",
      "         Large_Vehicle        852       9278      0.584      0.403      0.436      0.306      0.591      0.393      0.417      0.236\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_37/train/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<00:00, 108.21it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_37/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.31G      1.591      2.602      2.253      1.029        204        640: 100%|██████████| 4/4 [00:03<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "                   all        852      10397      0.517      0.361      0.381      0.262      0.515      0.349      0.358      0.198\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.15G      1.862      2.953      2.858      1.091         88        640: 100%|██████████| 4/4 [00:03<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397      0.526      0.364      0.387      0.265      0.522       0.35      0.363      0.199\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.05G      1.345      2.322      2.559      1.019         28        640: 100%|██████████| 4/4 [00:03<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397      0.511      0.364      0.382      0.261      0.518      0.351      0.363      0.201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.04G      1.211      1.912      1.653      1.005         14        640: 100%|██████████| 4/4 [00:03<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397      0.541       0.37      0.396      0.272      0.531      0.362      0.375      0.207\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.14G      1.014      1.655      1.233     0.9613         66        640: 100%|██████████| 4/4 [00:03<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n",
      "                   all        852      10397      0.555      0.374      0.403      0.278      0.542      0.366       0.38       0.21\n",
      "\n",
      "5 epochs completed in 0.041 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397      0.555      0.374      0.403      0.278      0.545      0.364       0.38      0.211\n",
      "         Large_Vehicle        852      10397      0.555      0.374      0.403      0.278      0.545      0.364       0.38      0.211\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.46it/s]\n",
      "                   all        852       9278      0.598      0.391      0.432      0.303      0.598      0.385      0.415      0.233\n",
      "         Large_Vehicle        852       9278      0.598      0.391      0.432      0.303      0.598      0.385      0.415      0.233\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 251 images, 0 backgrounds, 0 corrupt: 100%|██████████| 251/251 [00:02<00:00, 119.27it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.78G      2.043      3.587      6.013      1.345        532        640: 100%|██████████| 16/16 [00:16<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397      0.257      0.279      0.167     0.0995      0.238      0.259      0.144      0.064\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.1G      1.504      2.495      2.216      1.145        339        640: 100%|██████████| 16/16 [00:15<00:00,  1.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397       0.45      0.321      0.297      0.191      0.436      0.313      0.279      0.149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      11.2G      1.233       2.05      1.749      1.068        299        640: 100%|██████████| 16/16 [00:15<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397      0.511       0.37      0.359      0.244      0.489      0.349      0.324      0.173\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      11.2G      1.179      1.997      1.519     0.9918        117        640: 100%|██████████| 16/16 [00:15<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397      0.651      0.376      0.432      0.291      0.644      0.364      0.403      0.209\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.3G      1.095      1.831      1.407     0.9689        111        640: 100%|██████████| 16/16 [00:15<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397      0.674      0.388      0.457      0.313      0.666      0.377      0.427      0.225\n",
      "\n",
      "5 epochs completed in 0.059 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.32it/s]\n",
      "                   all        852      10397      0.673      0.388      0.457      0.313      0.664      0.377      0.427      0.225\n",
      "         Large_Vehicle        852      10397      0.673      0.388      0.457      0.313      0.664      0.377      0.427      0.225\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:21<00:00,  2.50it/s]\n",
      "                   all        852       9278      0.651      0.425      0.471      0.332      0.655      0.413       0.45      0.244\n",
      "         Large_Vehicle        852       9278      0.651      0.425      0.471      0.332      0.655      0.413       0.45      0.244\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_38/train/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<00:00, 107.01it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_38/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.38G       1.68      2.963      3.274      1.036         55        640: 100%|██████████| 4/4 [00:03<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397      0.643      0.386      0.443      0.299      0.627      0.376      0.413      0.216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      8.94G      1.631      2.584      2.312      1.037         40        640: 100%|██████████| 4/4 [00:03<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397      0.647      0.384      0.443        0.3       0.63      0.372      0.409      0.215\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.05G      1.488       2.53      2.213      1.006         25        640: 100%|██████████| 4/4 [00:03<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397      0.593      0.391      0.432      0.292       0.59      0.373      0.401      0.211\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.04G      1.197      2.248      1.848     0.9862         10        640: 100%|██████████| 4/4 [00:03<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.32it/s]\n",
      "                   all        852      10397      0.597      0.387      0.435      0.297       0.59      0.379       0.41       0.22\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.04G      1.381      2.363      2.216      1.002         10        640: 100%|██████████| 4/4 [00:03<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.32it/s]\n",
      "                   all        852      10397      0.612      0.391       0.44      0.302      0.607      0.381      0.415      0.224\n",
      "\n",
      "5 epochs completed in 0.039 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.48it/s]\n",
      "                   all        852      10397      0.613       0.39       0.44      0.302      0.607      0.381      0.415      0.225\n",
      "         Large_Vehicle        852      10397      0.613       0.39       0.44      0.302      0.607      0.381      0.415      0.225\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:20<00:00,  2.66it/s]\n",
      "                   all        852       9278      0.637      0.414      0.471      0.333      0.648      0.407      0.454      0.251\n",
      "         Large_Vehicle        852       9278      0.637      0.414      0.471      0.333      0.648      0.407      0.454      0.251\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_39/train/labels... 100 images, 0 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:00<00:00, 112.39it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_39/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.98G      1.422      2.285       1.91       1.07         79        640: 100%|██████████| 7/7 [00:06<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397      0.603      0.384      0.429      0.291      0.596      0.374      0.404      0.216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.17G      1.224      1.976      1.762     0.9977         48        640: 100%|██████████| 7/7 [00:06<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397      0.641      0.395      0.455      0.303      0.628      0.381      0.418       0.22\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.09G      1.239      1.943       1.47      1.029         39        640: 100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.32it/s]\n",
      "                   all        852      10397      0.664      0.403       0.46      0.318      0.659      0.392      0.434      0.241\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.5G      1.162      2.008      1.489     0.9607         26        640: 100%|██████████| 7/7 [00:06<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.31it/s]\n",
      "                   all        852      10397      0.673      0.406      0.467      0.325      0.668      0.398      0.443      0.247\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.08G      1.181      1.997      1.507     0.9994         59        640: 100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.34it/s]\n",
      "                   all        852      10397      0.686      0.409      0.481      0.332      0.679      0.396      0.451       0.25\n",
      "\n",
      "5 epochs completed in 0.044 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.49it/s]\n",
      "                   all        852      10397      0.687      0.408      0.481      0.332      0.679      0.396      0.451       0.25\n",
      "         Large_Vehicle        852      10397      0.687      0.408      0.481      0.332      0.679      0.396      0.451       0.25\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:20<00:00,  2.64it/s]\n",
      "                   all        852       9278      0.677      0.435      0.501      0.353       0.67       0.43       0.48      0.267\n",
      "         Large_Vehicle        852       9278      0.677      0.435      0.501      0.353       0.67       0.43       0.48      0.267\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_40/train/labels... 100 images, 0 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:00<00:00, 112.32it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_40/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.29G      1.095       1.66      1.342     0.9482         23        640: 100%|██████████| 7/7 [00:06<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397      0.671      0.397      0.464      0.317      0.659      0.385      0.433      0.233\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.04G      1.085      1.781      1.455     0.9702         27        640: 100%|██████████| 7/7 [00:06<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.29it/s]\n",
      "                   all        852      10397      0.671      0.399      0.463      0.316      0.674       0.39      0.438      0.233\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.06G      1.131       1.78      1.435     0.9383         28        640: 100%|██████████| 7/7 [00:06<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.32it/s]\n",
      "                   all        852      10397      0.687      0.407      0.478      0.316      0.677      0.393      0.443      0.222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.37G     0.9909      1.455      1.334     0.9313         34        640: 100%|██████████| 7/7 [00:06<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397      0.671      0.411      0.475      0.322      0.671      0.396      0.445      0.234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.39G      1.062      1.649      1.138     0.9277         72        640: 100%|██████████| 7/7 [00:06<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.32it/s]\n",
      "                   all        852      10397       0.68      0.413      0.484      0.326       0.69      0.394      0.449      0.233\n",
      "\n",
      "5 epochs completed in 0.044 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.49it/s]\n",
      "                   all        852      10397      0.677      0.414      0.484      0.326       0.69      0.394      0.449      0.233\n",
      "         Large_Vehicle        852      10397      0.677      0.414      0.484      0.326       0.69      0.394      0.449      0.233\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:20<00:00,  2.68it/s]\n",
      "                   all        852       9278      0.684       0.45       0.51      0.356      0.681      0.438      0.481      0.256\n",
      "         Large_Vehicle        852       9278      0.684       0.45       0.51      0.356      0.681      0.438      0.481      0.256\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 501 images, 0 backgrounds, 0 corrupt: 100%|██████████| 501/501 [00:03<00:00, 126.71it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.69G      1.738      3.179      4.184      1.262         55        640: 100%|██████████| 32/32 [00:31<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397      0.432      0.334      0.297      0.188       0.43      0.317      0.275      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.9G      1.277      2.145      1.674      1.021        271        640: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "                   all        852      10397      0.594      0.382      0.404      0.258      0.579      0.364      0.366      0.181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      11.1G      1.239      2.064      1.575     0.9854        219        640: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "                   all        852      10397      0.667      0.374      0.443      0.284      0.649      0.355      0.404      0.205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5        11G      1.158      1.878      1.304     0.9483         37        640: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.34it/s]\n",
      "                   all        852      10397      0.688      0.424      0.492      0.324      0.683      0.409      0.453      0.234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5        11G      1.196      1.845      1.223     0.9564        233        640: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.38it/s]\n",
      "                   all        852      10397      0.633      0.453      0.507       0.33       0.63      0.427      0.467      0.239\n",
      "\n",
      "5 epochs completed in 0.081 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:17<00:00,  1.51it/s]\n",
      "                   all        852      10397      0.633      0.453      0.507       0.33       0.63      0.427      0.466      0.239\n",
      "         Large_Vehicle        852      10397      0.633      0.453      0.507       0.33       0.63      0.427      0.466      0.239\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:20<00:00,  2.58it/s]\n",
      "                   all        852       9278      0.682      0.473       0.53       0.36      0.677      0.457      0.497       0.26\n",
      "         Large_Vehicle        852       9278      0.682      0.473       0.53       0.36      0.677      0.457      0.497       0.26\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_41/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:04<00:00, 118.44it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_41/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5       9.1G      1.209      1.855      1.245     0.9656         61        640: 100%|██████████| 32/32 [00:31<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397      0.688      0.444      0.523      0.346      0.676      0.423      0.476      0.256\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.06G      1.232      1.881        1.3     0.9578         81        640: 100%|██████████| 32/32 [00:30<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.40it/s]\n",
      "                   all        852      10397      0.693      0.446      0.516      0.346      0.697      0.424      0.477      0.256\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.32G      1.175      1.798      1.213     0.9303         22        640: 100%|██████████| 32/32 [00:31<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.39it/s]\n",
      "                   all        852      10397      0.678       0.45      0.523      0.353      0.684      0.424      0.483      0.263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.22G       1.16      1.713      1.063     0.9341         33        640: 100%|██████████| 32/32 [00:31<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397      0.697      0.472      0.553      0.372      0.691      0.451      0.514      0.279\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.5G      1.185       1.73      1.105     0.9285         55        640: 100%|██████████| 32/32 [00:31<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.35it/s]\n",
      "                   all        852      10397      0.681      0.476      0.544      0.364      0.676      0.454      0.504      0.275\n",
      "\n",
      "5 epochs completed in 0.077 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:17<00:00,  1.58it/s]\n",
      "                   all        852      10397      0.697      0.472      0.553      0.372      0.691      0.451      0.514      0.279\n",
      "         Large_Vehicle        852      10397      0.697      0.472      0.553      0.372      0.691      0.451      0.514      0.279\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:18<00:00,  2.87it/s]\n",
      "                   all        852       9278      0.717      0.497      0.583      0.407      0.716       0.48      0.552      0.309\n",
      "         Large_Vehicle        852       9278      0.717      0.497      0.583      0.407      0.716       0.48      0.552      0.309\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_42/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:04<00:00, 115.96it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_42/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.91G      1.107      1.655      1.207     0.9529          3        640: 100%|██████████| 32/32 [00:31<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397      0.676      0.459      0.535      0.371      0.674      0.448      0.507      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.66G      1.114      1.672      1.032     0.9489        110        640: 100%|██████████| 32/32 [00:30<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.40it/s]\n",
      "                   all        852      10397      0.669      0.492      0.562      0.376      0.676      0.456      0.513      0.278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.5G       1.15      1.704      1.032     0.9491        140        640: 100%|██████████| 32/32 [00:30<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.40it/s]\n",
      "                   all        852      10397      0.672      0.448      0.532      0.355      0.669      0.429      0.495      0.261\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.5G      1.114      1.613      1.014      0.941         15        640: 100%|██████████| 32/32 [00:31<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397      0.678      0.486      0.553      0.369      0.673       0.46      0.507      0.265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.21G      1.089      1.592     0.9748      0.945         52        640: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.40it/s]\n",
      "                   all        852      10397      0.675      0.486       0.56      0.376      0.687      0.457      0.519      0.276\n",
      "\n",
      "5 epochs completed in 0.076 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:16<00:00,  1.59it/s]\n",
      "                   all        852      10397      0.677      0.459      0.535      0.371      0.674      0.448      0.507      0.293\n",
      "         Large_Vehicle        852      10397      0.677      0.459      0.535      0.371      0.674      0.448      0.507      0.293\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:18<00:00,  2.88it/s]\n",
      "                   all        852       9278      0.666        0.5      0.565      0.404      0.683      0.482      0.543      0.323\n",
      "         Large_Vehicle        852       9278      0.666        0.5      0.565      0.404      0.683      0.482      0.543      0.323\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_43/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:04<00:00, 117.88it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_43/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.93G      1.233      1.786      1.151     0.9377         59        640: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.39it/s]\n",
      "                   all        852      10397      0.697      0.482      0.558      0.378      0.726      0.448      0.519      0.279\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.05G      1.175      1.701      1.072     0.9443         27        640: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397      0.705      0.487      0.566      0.378      0.709       0.46      0.523      0.289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.07G      1.137        1.6      1.047     0.9196         57        640: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397      0.715      0.506      0.583      0.388      0.727      0.466      0.534      0.284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.04G      1.122      1.628      1.014     0.9401         41        640: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.42it/s]\n",
      "                   all        852      10397      0.741      0.495      0.575      0.384       0.73      0.476       0.54        0.3\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.5G      1.175       1.65      1.143      0.925         22        640: 100%|██████████| 32/32 [00:30<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.36it/s]\n",
      "                   all        852      10397      0.728      0.492      0.575      0.381      0.715       0.47      0.531      0.266\n",
      "\n",
      "5 epochs completed in 0.076 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:16<00:00,  1.60it/s]\n",
      "                   all        852      10397      0.741      0.495      0.575      0.384       0.73      0.476       0.54        0.3\n",
      "         Large_Vehicle        852      10397      0.741      0.495      0.575      0.384       0.73      0.476       0.54        0.3\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:19<00:00,  2.83it/s]\n",
      "                   all        852       9278      0.718      0.532      0.602      0.415      0.728      0.506       0.57      0.331\n",
      "         Large_Vehicle        852       9278      0.718      0.532      0.602      0.415      0.728      0.506       0.57      0.331\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_44/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:04<00:00, 123.21it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_44/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.92G      1.198      1.722      1.109     0.9553        146        640: 100%|██████████| 32/32 [00:30<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397      0.724      0.495      0.587      0.407      0.716      0.479      0.542      0.304\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.53G      1.096      1.564     0.9965     0.9234         71        640: 100%|██████████| 32/32 [00:30<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.17it/s]\n",
      "                   all        852      10397      0.735      0.503      0.588      0.394       0.73      0.468      0.537      0.295\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5       9.4G      1.136      1.614     0.9705     0.9309         54        640: 100%|██████████| 32/32 [00:30<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:23<00:00,  1.14it/s]\n",
      "                   all        852      10397      0.709      0.491      0.575      0.388      0.707       0.47      0.538      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.05G      1.126      1.586     0.9894     0.9196         75        640: 100%|██████████| 32/32 [00:31<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                   all        852      10397      0.725      0.505      0.594      0.404      0.738      0.481      0.556      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.5G      1.137      1.644     0.9873     0.9107         11        640: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397      0.725      0.493      0.586      0.395      0.727      0.472      0.546      0.301\n",
      "\n",
      "5 epochs completed in 0.080 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:17<00:00,  1.51it/s]\n",
      "                   all        852      10397      0.724      0.505      0.594      0.404      0.738      0.481      0.555      0.317\n",
      "         Large_Vehicle        852      10397      0.724      0.505      0.594      0.404      0.738      0.481      0.555      0.317\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:20<00:00,  2.68it/s]\n",
      "                   all        852       9278      0.725       0.54      0.615      0.435      0.731      0.519      0.581      0.342\n",
      "         Large_Vehicle        852       9278      0.725       0.54      0.615      0.435      0.731      0.519      0.581      0.342\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_45/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:04<00:00, 119.63it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_45/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.91G      1.197      1.734      1.078     0.9264         93        640: 100%|██████████| 32/32 [00:31<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397      0.707      0.526      0.603      0.413      0.713      0.498      0.563      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.05G      1.175      1.651      1.077     0.9281         62        640: 100%|██████████| 32/32 [00:30<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.36it/s]\n",
      "                   all        852      10397      0.708      0.503      0.581      0.388      0.719      0.469      0.542      0.295\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.07G      1.121      1.591      1.103     0.9204         53        640: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397       0.69      0.504      0.577      0.382      0.696      0.471       0.53      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.5G      1.112      1.593      0.938     0.9219         39        640: 100%|██████████| 32/32 [00:30<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.36it/s]\n",
      "                   all        852      10397      0.734      0.497      0.589      0.397      0.726      0.476      0.546      0.297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.04G      1.113      1.594     0.9967     0.9235         76        640: 100%|██████████| 32/32 [00:30<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397      0.715      0.481      0.573       0.39      0.713      0.458      0.528       0.29\n",
      "\n",
      "5 epochs completed in 0.076 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:17<00:00,  1.55it/s]\n",
      "                   all        852      10397      0.708      0.525      0.603      0.413      0.713      0.498      0.564      0.313\n",
      "         Large_Vehicle        852      10397      0.708      0.525      0.603      0.413      0.713      0.498      0.564      0.313\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:19<00:00,  2.71it/s]\n",
      "                   all        852       9278      0.696      0.567      0.632      0.445      0.729      0.523      0.594      0.343\n",
      "         Large_Vehicle        852       9278      0.696      0.567      0.632      0.445      0.729      0.523      0.594      0.343\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_46/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:04<00:00, 120.13it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_46/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.94G      1.105      1.626      1.047      0.944         40        640: 100%|██████████| 32/32 [00:31<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.32it/s]\n",
      "                   all        852      10397      0.703      0.502      0.585      0.399      0.706      0.479      0.547      0.302\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.06G      1.089      1.531     0.9819     0.9315         57        640: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397       0.72       0.52      0.611      0.411      0.729      0.493      0.573      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.08G      1.064      1.495     0.9754     0.9252         47        640: 100%|██████████| 32/32 [00:31<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.35it/s]\n",
      "                   all        852      10397      0.696      0.513      0.592      0.389      0.697      0.473      0.546       0.29\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.5G      1.053      1.526     0.9191     0.9225         47        640: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.35it/s]\n",
      "                   all        852      10397       0.71      0.514      0.597      0.405      0.714      0.484      0.552      0.299\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.12G      1.014       1.44      0.898     0.9063         61        640: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.35it/s]\n",
      "                   all        852      10397      0.715      0.521      0.607      0.411      0.732      0.483      0.563      0.303\n",
      "\n",
      "5 epochs completed in 0.077 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.42it/s]\n",
      "                   all        852      10397      0.719      0.521      0.611      0.411      0.729      0.493      0.573      0.311\n",
      "         Large_Vehicle        852      10397      0.719      0.521      0.611      0.411      0.729      0.493      0.573      0.311\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:20<00:00,  2.63it/s]\n",
      "                   all        852       9278      0.736      0.545      0.633      0.443      0.744      0.521      0.598       0.34\n",
      "         Large_Vehicle        852       9278      0.736      0.545      0.633      0.443      0.744      0.521      0.598       0.34\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 3501 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3501/3501 [00:28<00:00, 121.57it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.64G      1.341      2.206      2.086      1.048        234        640: 100%|██████████| 219/219 [03:40<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.30it/s]\n",
      "                   all        852      10397      0.667      0.445      0.521      0.348      0.673       0.42      0.477      0.253\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      11.1G      1.169      1.781      1.197     0.9466         82        640: 100%|██████████| 219/219 [03:34<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.38it/s]\n",
      "                   all        852      10397      0.701       0.45      0.533      0.362      0.707      0.432      0.501      0.268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5        11G      1.169      1.717      1.117     0.9447        161        640: 100%|██████████| 219/219 [03:33<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397      0.694      0.477      0.542      0.356      0.681      0.454      0.504      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.6G      1.182      1.686      1.072     0.9484        298        640: 100%|██████████| 219/219 [03:34<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397      0.728      0.508      0.594      0.392      0.728      0.476      0.546       0.28\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      11.1G       1.14       1.62       1.01     0.9305        245        640: 100%|██████████| 219/219 [03:34<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.42it/s]\n",
      "                   all        852      10397       0.73      0.495      0.583      0.394      0.724      0.478      0.548      0.305\n",
      "\n",
      "5 epochs completed in 0.335 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                   all        852      10397      0.726      0.496      0.583      0.394      0.725      0.478      0.548      0.305\n",
      "         Large_Vehicle        852      10397      0.726      0.496      0.583      0.394      0.725      0.478      0.548      0.305\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:20<00:00,  2.68it/s]\n",
      "                   all        852       9278      0.748      0.521      0.614      0.431      0.748      0.507      0.583      0.341\n",
      "         Large_Vehicle        852       9278      0.748      0.521      0.614      0.431      0.748      0.507      0.583      0.341\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_47/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:08<00:00, 57.54it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_47/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.04G      1.119      1.588     0.9709     0.9211         56        640: 100%|██████████| 32/32 [00:30<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.38it/s]\n",
      "                   all        852      10397      0.689       0.53      0.604      0.413      0.711      0.489       0.56      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.31G      1.087      1.573     0.9137     0.9154        169        640: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.42it/s]\n",
      "                   all        852      10397      0.738      0.524       0.62      0.429      0.739      0.499      0.579      0.331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.5G      1.112      1.575     0.9193     0.9079         46        640: 100%|██████████| 32/32 [00:29<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397      0.731      0.518      0.608      0.419      0.746      0.491       0.57      0.322\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.71G      1.105      1.575      1.014     0.9235          9        640: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.42it/s]\n",
      "                   all        852      10397       0.72      0.529       0.61      0.412      0.726      0.498       0.57      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.5G      1.052      1.491     0.8437      0.909         27        640: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.42it/s]\n",
      "                   all        852      10397      0.742      0.524      0.615      0.413      0.753      0.499      0.577      0.324\n",
      "\n",
      "5 epochs completed in 0.074 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:16<00:00,  1.60it/s]\n",
      "                   all        852      10397      0.738      0.523       0.62      0.428      0.738      0.499      0.579      0.331\n",
      "         Large_Vehicle        852      10397      0.738      0.523       0.62      0.428      0.738      0.499      0.579      0.331\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:18<00:00,  2.91it/s]\n",
      "                   all        852       9278      0.711      0.571      0.655      0.466      0.741      0.529      0.616      0.364\n",
      "         Large_Vehicle        852       9278      0.711      0.571      0.655      0.466      0.741      0.529      0.616      0.364\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_48/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:04<00:00, 117.80it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_48/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.91G      1.202      1.649     0.9841     0.9467         36        640: 100%|██████████| 32/32 [00:33<00:00,  1.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397      0.746      0.535      0.625      0.429      0.745      0.512      0.585      0.322\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.04G      1.111      1.562     0.9487     0.9244         36        640: 100%|██████████| 32/32 [00:32<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.39it/s]\n",
      "                   all        852      10397      0.718      0.531      0.611      0.418      0.724      0.509      0.579      0.328\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.47G      1.138      1.559     0.9254     0.9244         59        640: 100%|██████████| 32/32 [00:32<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.38it/s]\n",
      "                   all        852      10397      0.722      0.526      0.617       0.42      0.749      0.483      0.576      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.5G      1.137      1.553     0.8984     0.9198         77        640: 100%|██████████| 32/32 [00:31<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397      0.742       0.53      0.619      0.421      0.742      0.491      0.571      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.5G      1.107      1.556     0.9292     0.9198          7        640: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.38it/s]\n",
      "                   all        852      10397      0.756      0.538      0.633      0.437      0.752      0.512      0.593      0.338\n",
      "\n",
      "5 epochs completed in 0.078 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:16<00:00,  1.62it/s]\n",
      "                   all        852      10397      0.756      0.538      0.633      0.437      0.756      0.511      0.592      0.338\n",
      "         Large_Vehicle        852      10397      0.756      0.538      0.633      0.437      0.756      0.511      0.592      0.338\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:19<00:00,  2.75it/s]\n",
      "                   all        852       9278      0.763      0.565      0.657      0.467      0.762      0.538      0.619      0.366\n",
      "         Large_Vehicle        852       9278      0.763      0.565      0.657      0.467      0.762      0.538      0.619      0.366\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_49/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:04<00:00, 119.27it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_49/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.66G      1.068      1.522     0.9096      0.933         46        640: 100%|██████████| 32/32 [00:31<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397      0.757      0.544      0.639      0.438      0.765      0.508      0.588       0.33\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.5G      1.067      1.515     0.8735     0.9161         71        640: 100%|██████████| 32/32 [00:31<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.39it/s]\n",
      "                   all        852      10397      0.751      0.546      0.646      0.438      0.768      0.495      0.589      0.332\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.5G      1.011      1.429     0.8171     0.9071         69        640: 100%|██████████| 32/32 [00:31<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.39it/s]\n",
      "                   all        852      10397      0.751      0.532      0.628      0.409      0.756      0.481      0.566      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.5G      1.008      1.368     0.8061     0.9058        124        640: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.39it/s]\n",
      "                   all        852      10397      0.753      0.548      0.639      0.438      0.752      0.512      0.596      0.333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.5G      1.052      1.467     0.8554     0.9079         26        640: 100%|██████████| 32/32 [00:31<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.36it/s]\n",
      "                   all        852      10397      0.761      0.518      0.632      0.437      0.779       0.48       0.58      0.333\n",
      "\n",
      "5 epochs completed in 0.077 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:17<00:00,  1.57it/s]\n",
      "                   all        852      10397      0.754      0.548      0.638      0.438      0.752      0.512      0.596      0.333\n",
      "         Large_Vehicle        852      10397      0.754      0.548      0.638      0.438      0.752      0.512      0.596      0.333\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:19<00:00,  2.82it/s]\n",
      "                   all        852       9278      0.745      0.577       0.66      0.462      0.755      0.535      0.619      0.354\n",
      "         Large_Vehicle        852       9278      0.745      0.577       0.66      0.462      0.755      0.535      0.619      0.354\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 5001 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5001/5001 [00:44<00:00, 113.11it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      10.4G      1.298      2.104      1.918      1.023        165        640: 100%|██████████| 313/313 [05:23<00:00,  1.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:22<00:00,  1.22it/s]\n",
      "                   all        852      10397      0.699       0.46      0.548      0.362      0.737      0.424      0.496       0.26\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.9G      1.173      1.757      1.138     0.9435        118        640: 100%|██████████| 313/313 [05:14<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.36it/s]\n",
      "                   all        852      10397      0.704      0.491      0.572       0.39      0.697      0.471      0.537      0.292\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5        11G       1.16      1.661      1.075     0.9435         69        640: 100%|██████████| 313/313 [05:08<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.35it/s]\n",
      "                   all        852      10397        0.7      0.504      0.579      0.387      0.683      0.478      0.531      0.281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5        11G      1.144      1.629      1.004     0.9325         81        640: 100%|██████████| 313/313 [05:05<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.39it/s]\n",
      "                   all        852      10397      0.732      0.517      0.612      0.426      0.751       0.49      0.579      0.338\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      11.1G      1.124      1.581     0.9607     0.9291         88        640: 100%|██████████| 313/313 [05:07<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.36it/s]\n",
      "                   all        852      10397      0.725      0.541      0.621      0.424      0.734      0.498      0.572      0.318\n",
      "\n",
      "5 epochs completed in 0.469 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.45it/s]\n",
      "                   all        852      10397      0.732      0.517      0.612      0.426      0.747      0.491      0.579      0.338\n",
      "         Large_Vehicle        852      10397      0.732      0.517      0.612      0.426      0.747      0.491      0.579      0.338\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:19<00:00,  2.72it/s]\n",
      "                   all        852       9278      0.757       0.55      0.644       0.46      0.772      0.526      0.614       0.37\n",
      "         Large_Vehicle        852       9278      0.757       0.55      0.644       0.46      0.772      0.526      0.614       0.37\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_50/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:04<00:00, 114.61it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_50/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.04G      1.105      1.546     0.9931     0.9155         51        640: 100%|██████████| 32/32 [00:31<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397       0.73       0.55      0.635      0.434      0.726       0.51      0.581      0.331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.5G      1.124      1.517     0.9246     0.9018         70        640: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397      0.722      0.555      0.637       0.43      0.726      0.517      0.595      0.336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.5G      1.172      1.545     0.9081     0.9079         77        640: 100%|██████████| 32/32 [00:30<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.38it/s]\n",
      "                   all        852      10397      0.729      0.539      0.625      0.418      0.728      0.495      0.566      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.5G      1.101      1.536     0.8993     0.9109         26        640: 100%|██████████| 32/32 [00:31<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.42it/s]\n",
      "                   all        852      10397      0.715       0.54      0.619      0.416      0.737      0.496      0.569      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.5G      1.145      1.563      0.896     0.9062         32        640: 100%|██████████| 32/32 [00:29<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397      0.704      0.544      0.625       0.43      0.721      0.501      0.578      0.323\n",
      "\n",
      "5 epochs completed in 0.076 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:16<00:00,  1.59it/s]\n",
      "                   all        852      10397      0.727      0.552      0.637       0.43      0.727      0.517      0.595      0.336\n",
      "         Large_Vehicle        852      10397      0.727      0.552      0.637       0.43      0.727      0.517      0.595      0.336\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:18<00:00,  2.88it/s]\n",
      "                   all        852       9278      0.761      0.561      0.657      0.459       0.76      0.535      0.623      0.368\n",
      "         Large_Vehicle        852       9278      0.761      0.561      0.657      0.459       0.76      0.535      0.623      0.368\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/retrain/train/labels... 5501 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5501/5501 [00:44<00:00, 124.20it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      10.8G      1.302       2.09      1.841      1.022        223        640: 100%|██████████| 344/344 [05:48<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.34it/s]\n",
      "                   all        852      10397      0.694      0.461      0.543      0.366      0.688      0.437      0.496      0.268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5        11G      1.183      1.762      1.134     0.9455        191        640: 100%|██████████| 344/344 [05:43<00:00,  1.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.39it/s]\n",
      "                   all        852      10397      0.706       0.49      0.582      0.383      0.732      0.454      0.535      0.282\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5        11G      1.167      1.677      1.055     0.9404        215        640: 100%|██████████| 344/344 [05:40<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397      0.696      0.514       0.58      0.386      0.716      0.476       0.54      0.291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5        11G      1.144       1.63      1.003     0.9336        204        640: 100%|██████████| 344/344 [05:39<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.40it/s]\n",
      "                   all        852      10397      0.731      0.523      0.613      0.416      0.742      0.487      0.566      0.325\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.5G       1.11      1.571     0.9707     0.9255        144        640: 100%|██████████| 344/344 [05:34<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.40it/s]\n",
      "                   all        852      10397      0.731      0.524       0.61      0.422      0.739      0.491      0.568      0.321\n",
      "\n",
      "5 epochs completed in 0.509 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:17<00:00,  1.57it/s]\n",
      "                   all        852      10397      0.733      0.524      0.611      0.422      0.739       0.49      0.568      0.321\n",
      "         Large_Vehicle        852      10397      0.733      0.524      0.611      0.422      0.739       0.49      0.568      0.321\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:19<00:00,  2.76it/s]\n",
      "                   all        852       9278       0.75      0.556      0.641      0.453      0.747      0.521      0.597      0.351\n",
      "         Large_Vehicle        852       9278       0.75      0.556      0.641      0.453      0.747      0.521      0.597      0.351\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_51/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:04<00:00, 116.19it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_51/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      9.31G      1.091      1.495     0.9423     0.9215         19        640: 100%|██████████| 32/32 [00:31<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.35it/s]\n",
      "                   all        852      10397      0.715      0.562      0.642      0.438      0.732      0.515      0.595      0.331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      10.5G      1.115       1.54     0.9391     0.9193        190        640: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.39it/s]\n",
      "                   all        852      10397      0.754       0.55      0.645      0.437      0.746      0.508      0.584      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      10.5G      1.083      1.492     0.8684     0.9128         70        640: 100%|██████████| 32/32 [00:31<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.40it/s]\n",
      "                   all        852      10397      0.735      0.563      0.651      0.438      0.759      0.522      0.609      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.97G      1.098      1.458     0.8478      0.911         58        640: 100%|██████████| 32/32 [00:31<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.40it/s]\n",
      "                   all        852      10397      0.746      0.551      0.645      0.438      0.772      0.502      0.589      0.329\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      10.5G      1.097      1.445     0.9182     0.9159         12        640: 100%|██████████| 32/32 [00:30<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.40it/s]\n",
      "                   all        852      10397      0.747      0.556      0.649      0.439      0.752      0.509      0.594      0.329\n",
      "\n",
      "5 epochs completed in 0.077 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                   all        852      10397      0.735      0.563      0.651      0.438      0.759      0.522       0.61      0.344\n",
      "         Large_Vehicle        852      10397      0.735      0.563      0.651      0.438      0.759      0.522       0.61      0.344\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:18<00:00,  2.88it/s]\n",
      "                   all        852       9278      0.763      0.585      0.674       0.47      0.767      0.552      0.635      0.371\n",
      "         Large_Vehicle        852       9278      0.763      0.585      0.674       0.47      0.767      0.552      0.635      0.371\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for 50 last iterations with 0.001 threshold = 10.914345648877486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_52/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:04<00:00, 116.18it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_52/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.92G      1.242      1.792     0.9774     0.9427         66        640: 100%|██████████| 32/32 [00:31<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.37it/s]\n",
      "                   all        852      10397      0.729      0.556      0.634      0.435      0.743      0.511      0.579      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      9.41G      1.166       1.68     0.9748     0.9221         65        640: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397      0.754      0.543      0.636      0.433      0.735      0.509      0.579      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      9.09G      1.205      1.672      1.015     0.9254         15        640: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:20<00:00,  1.33it/s]\n",
      "                   all        852      10397      0.757      0.538      0.641       0.44      0.758      0.515      0.604      0.354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      10.5G      1.137      1.574     0.9008      0.917        106        640: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.40it/s]\n",
      "                   all        852      10397      0.748      0.552      0.648      0.437      0.752      0.511      0.594      0.337\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.56G      1.163      1.645     0.9141     0.9153         32        640: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397      0.765      0.531      0.633      0.429      0.761      0.496      0.579      0.324\n",
      "\n",
      "5 epochs completed in 0.075 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:16<00:00,  1.60it/s]\n",
      "                   all        852      10397      0.757      0.538      0.642       0.44      0.758      0.515      0.604      0.354\n",
      "         Large_Vehicle        852      10397      0.757      0.538      0.642       0.44      0.758      0.515      0.604      0.354\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:18<00:00,  2.89it/s]\n",
      "                   all        852       9278      0.758      0.573       0.67      0.471      0.783      0.534      0.632      0.378\n",
      "         Large_Vehicle        852       9278      0.758      0.573       0.67      0.471      0.783      0.534      0.632      0.378\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for 50 last iterations with 0.001 threshold = 10.87642190053373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.15 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/dataset/isaid_class_7/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5167709  ultralytics.nn.modules.head.Segment          [15, 32, 192, [192, 384, 576]]\n",
      "YOLOv8m-seg summary: 331 layers, 27248333 parameters, 27248317 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/temp_7_53/train/labels... 315 images, 0 backgrounds, 0 corrupt: 100%|██████████| 315/315 [00:02<00:00, 116.76it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/isaid_class_7/temp_7_53/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/valid_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/5      8.86G      1.238      1.777       1.14     0.9725         87        640: 100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.43it/s]\n",
      "                   all        852      10397      0.743      0.542      0.639      0.437      0.753      0.507      0.593      0.337\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/5      8.98G      1.137      1.594      1.012     0.9388         59        640: 100%|██████████| 20/20 [00:19<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397      0.744      0.562      0.652      0.442      0.745       0.52      0.607      0.339\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/5      8.99G     0.9898      1.417     0.8298     0.9311         84        640: 100%|██████████| 20/20 [00:19<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.41it/s]\n",
      "                   all        852      10397      0.745      0.559      0.656      0.455      0.742      0.513        0.6      0.341\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        4/5      9.12G      1.013       1.47     0.8152     0.9304        124        640: 100%|██████████| 20/20 [00:18<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:18<00:00,  1.44it/s]\n",
      "                   all        852      10397      0.748      0.559      0.657      0.461      0.754      0.523      0.612      0.357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        5/5      9.06G       1.07       1.52     0.8685     0.9183         80        640: 100%|██████████| 20/20 [00:18<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:19<00:00,  1.40it/s]\n",
      "                   all        852      10397      0.759      0.564      0.664      0.454      0.768      0.521      0.612      0.344\n",
      "\n",
      "5 epochs completed in 0.059 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:16<00:00,  1.62it/s]\n",
      "                   all        852      10397      0.749      0.558      0.657      0.461      0.754      0.522      0.612      0.356\n",
      "         Large_Vehicle        852      10397      0.749      0.558      0.657      0.461      0.754      0.522      0.612      0.356\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Ultralytics YOLOv8.0.200 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27231069 parameters, 0 gradients, 110.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/isaid_class_7/test_7/labels.cache... 852 images, 0 backgrounds, 0 corrupt: 100%|██████████| 852/852 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 54/54 [00:18<00:00,  2.90it/s]\n",
      "                   all        852       9278      0.766      0.584       0.68      0.491       0.78      0.547      0.639      0.387\n",
      "         Large_Vehicle        852       9278      0.766      0.584       0.68      0.491       0.78      0.547      0.639      0.387\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговый результат (инкрементальное обучение) для класса 7: \n",
      " defaultdict(<class 'list'>, {0: [0.0002586831134767624, 0.000705663424291446, 0.00011754793310984318], 1: [0.0004878796478256413, 0.0013623621454360256, 0.0002582614106734191], 2: [0.0008115027135247683, 0.0021772134007911575, 0.0007562730807498205], 3: [0.0013846986103416875, 0.003063766447620576, 0.001375814400925334], 4: [0.0020414622476870635, 0.004909765400474823, 0.0017799303998037189], 5: [0.0002352008413456722, 0.0004700874206775565, 0.0002353729948025873], 6: [0.0002452805409383965, 0.0005840416206929137, 0.00023358423163327154], 7: [3.265633844152079e-05, 0.00010885446147173596, 0.0], 8: [0.00020731150253717293, 0.0005981731638652602, 0.00019664159014212582], 9: [0.00020890099291226508, 0.00036826787902848854, 0.00024582029287059464], 10: [0.00023792272154353226, 0.0005996093047081531, 0.00019763636625670704], 11: [0.0004747993182314247, 0.0012059841410644492, 0.0003921277515441546], 12: [0.01127477593086841, 0.020858757830648916, 0.010897568134867367], 13: [0.006137883063506535, 0.011795954318317196, 0.00639266712206737], 14: [0.0073301097626501, 0.013576926086288339, 0.007392253647080697], 15: [0.07335383536332266, 0.14343773747368985, 0.06665180464713998], 16: [0.062338491128317186, 0.11820090048479158, 0.05737635394063695], 17: [0.0783330491023476, 0.15158101450067074, 0.07147536447394462], 18: [0.1011651457855508, 0.203504893872754, 0.08642061783610909], 19: [0.12305169433971752, 0.24657623959865022, 0.10926987517307203], 20: [0.11496082797822116, 0.23625777135208959, 0.1000902528693452], 21: [0.09608351566655347, 0.19680700264622245, 0.08197507271377703], 22: [0.10731322961987164, 0.22068525094196012, 0.08900755060778053], 23: [0.12272178976107533, 0.2434572240085994, 0.10918853723638693], 24: [0.11242073071173768, 0.22842665121555844, 0.09815371946297392], 25: [0.16426347480188327, 0.3112598209172952, 0.15541764405294287], 26: [0.1320053608948325, 0.2629754489542691, 0.11784762222160604], 27: [0.16141032242179343, 0.3165471358398812, 0.1436051404179788], 28: [0.18883172669030443, 0.3496893756919683, 0.183937903770641], 29: [0.19066817132778296, 0.3491123030882187, 0.18881583292535487], 30: [0.21045359642193073, 0.3768954118547848, 0.21677411115745693], 31: [0.21291996577617095, 0.39015020147055257, 0.21617020629063138], 32: [0.19915111580913408, 0.3624937010563809, 0.2026808559544842], 33: [0.23712090136001157, 0.417126015040587, 0.24958877535560042], 34: [0.21666411559856463, 0.39278306371082355, 0.22306872239794834], 35: [0.23590636588231423, 0.4170609213166336, 0.24867874392602032], 36: [0.2443183551588183, 0.44976900213015125, 0.24432359143806423], 37: [0.25108292447012615, 0.4537377832078614, 0.26123833597760004], 38: [0.2666010597312768, 0.4801734008214042, 0.27859290090075073], 39: [0.26041700331591217, 0.497308180009607, 0.2548309044740867], 40: [0.3087363960174005, 0.5522870000358497, 0.3152018583988447], 41: [0.3227138090836074, 0.5426739329221946, 0.3600023112703772], 42: [0.3312567964298148, 0.5696570023976122, 0.36019119814372286], 43: [0.3417812644189301, 0.5808935488965553, 0.37279795995380666], 44: [0.34277172673163225, 0.5940821828895145, 0.36875237692723056], 45: [0.34070140803672333, 0.5831046810408486, 0.3673077135389571], 46: [0.36425931699210895, 0.6159346186851495, 0.39716066132034317], 47: [0.36620769393694014, 0.6192890562007968, 0.4083913560902691], 48: [0.36966161213119403, 0.6144467258738063, 0.40708936910998933], 49: [0.35144817108450377, 0.5965173375840606, 0.3857255105824339], 50: [0.37097619360407486, 0.6352800773458154, 0.40366674425877], 51: [0.3776320688470117, 0.6320483060811306, 0.41638504122511505], 52: [0.38660333523291457, 0.6390405426415421, 0.43623139069274963]})\n",
      "Количество данных (train) для класса 7: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 4001, 4501, 5001, 5501, 6001, 6501, 6816]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABiX0lEQVR4nO3dd3gU5d7G8e/sbhohFUhooXfpVUARNQoerICioBSxd7EiKpb3CGI5omI9ip4jCjYQPYIoiA2k9yY9CIRQE0Lq7sz7x5JNFkLfQjb3x2uv7M48O/vbIe7eeeaZZwzLsixEREREQoQt2AWIiIiI+JLCjYiIiIQUhRsREREJKQo3IiIiElIUbkRERCSkKNyIiIhISFG4ERERkZDiCHYBgWaaJjt27CAmJgbDMIJdjoiIiJwEy7I4ePAg1atXx2Y7ft9MuQs3O3bsICUlJdhliIiIyGnYtm0bNWvWPG6bchduYmJiAPfOiY2NDXI1IiIicjKysrJISUnxfI8fT7kLN0WHomJjYxVuREREypiTGVKiAcUiIiISUhRuREREJKQo3IiIiEhIUbgRERGRkKJwIyIiIiFF4UZERERCisKNiIiIhBSFGxEREQkpCjciIiISUhRuRERE5Iy4TBcTlk+gywddiB8dT41Xa/DQDw+x5cCWoNRjWJZlBeWVgyQrK4u4uDgyMzN1+QUREZEz5DSd9P28L9+s+wabYcO0TADshp2osCh+vOlHzq157hm/zql8f6vnRkRERE7bv+b+i6nrpgJ4gg2Ay3KRW5jLlZ9dSYGrIKA1KdyIiIjIaTEtk7HzxmJRfBAo3GyMzYoD3AFnd85uvl7zdUDrUrgRERGR07Lz4E62H9zufmAZxBb2pWr+GCoXPAiW++rdYbYw5m6bG9C6HAF9NREREQkZdpsdAJsVT+WCh4gy2wBgGtkYhGFR4NUuUBRuRERE5LQkRyfTKPoqcvb0xU4CJnnsC3uHQ/afwN1xQ6FZyCX1LgloXQo3IiIicsoKnCavzFhH/p5bsQMFxmZ2h7+I0/a3p43D5qB+Qn16NOgR0NoUbkREROSUpO3N4d6JS1i27QAADWruYNaeh7DbTTDBwMDConpMdb4f8D02I7BDfBVuRERE5KR9u2wHT3y9goP5TmIjHYzp24qezXuxcEcb3ln4DiszVhIbEcu1za6lf4v+RIdHB7xGTeInIiIiJ5Rb4OLZb1cxccE2ANrVTmDs9a2pmVAhIK9/Kt/f6rkRERGR41qbnsW9ny5hfUY2hgF3d2/AA6kNcdjPzhllFG5ERESkVJZl8en8NJ77djX5TpOkmAhe69eaLg0qB7u041K4ERERkaNk5hby+FfLmbYyHYDujavwyrWtqFQxIsiVnZjCjYiIiHhZtHU/9322hO0HcgmzGzzWswk3d62LzWYEu7STonAjIiJSzmTmZfLJ8k+Yv2M+DsPBZQ0v46rGV2E3HLzz60ZemfEXLtOiVmIF3rihDa1S4oNd8ilRuBERESlHpq2fxrVfXEtOYQ42w4ZhGHy49ENqV2xBmwqvsWRrLgBXtqrOP69pTkxkWJArPnUKNyIiIuXEqoxVXDXxKpymEwsLl+UCCyJdbXHtHsYScokKs/HsVc25tl1NDKNsHIY6ksKNiIhIOfHK3FewDv8HgGUn3nkTcc6+gPsSCnemxnBd+5QgVnnmFG5ERETKia/XfI3T5STMqk2UqwPRrgsIt+oCcND+HQfCxvPHjkuBQcEt9Awp3IiIiIS4vEIXczftJfzQTdRwtsVhJXnWuchmb/hYcu1zAcgpzAlWmT6jcCMiUg4czD/IV2u+YnvWdpIrJtOnaR8SohKCXZb4UXpmHrPWZjBr7S7+2LCX3EIXFegJgEk+ebZl5NoXkGOfg2lkAmA37LRKbhXMsn1C4UZEJMS9teAtHp7xMHnOPOw2Oy7TxT3f38PTFzzN8POGB2zQaG4uTJkCmzZBYiL07g3JyQF56XLBNC2W/X3gcKDJYNWOLK/11eIiqVnlAP9Le5E823IsI//obVgmt7e/PVAl+43CjYhICPto6Ufc/f3dnsdO0wlAviufEbNGEG4P5+EuD/u9js8+gzvvhMxMcDjA5YL77oMHHoDRo8Fu93sJIelgXiG/r9/DzLUZzF6XwZ7sAs86w4DWKfFc3CSJi5ok07RaDKZlcsNXk/hy9UIMDM/AYrthx2W5eOXSV2hUqVGw3o7P6KrgIiIhymk6qfWvWuzM3nnMNjHhMaQ/nE6FMP9d2fm77+DKK6G0bxvDgIcfhjFj/PbyIWfLnkPMPHy4af7mfRS6indsTISDbo2qcFGTJLo3rlLqpRJcpot3F73La3++xvp96wHoVrsbj3Z5lF6NegXsfZyqU/n+VrgREQlRv279lQs+ugAsgzCrNpFmKyLMRoCFReHhWwHXNL2C5slNiAizEeGwE+GwEeGwEe44/DjM5llWvN5+eL3N8zx7KVPzWxa0bAmrVpUebsDdk7N9OyQllb4+1Pyy5RfeWvAWi3YuokJYBXo37c0d7e+gasWqpbYvdJks2LKPWWvch5s27Tnktb5e5WguapLERU2SaF8nkXDHyV2p27IscgpzcNgcRDjO/utFKdwch8KNiJQHaXtzGPfHT3w47w8iXS2xE+/317TbDO8QFGbDctlYv9aG5bRjOW3gsmEW2sldn8yhNdXBsmEY8PbbcHvZH+pxXJZl8dhPj/HSnJdw2ByeQ4Q2w0bF8Ir8eNOPdKzREYC92fnMXrebWesy+HXdbg7mOz3bcdgMOtZN9ASaelUqBuX9BNqpfH9rzI2ISAjIOJjH3I17+WPDHuZs3Mvf+3MBO9F0A8Akl3zbKvJsK7GMAgwrDINwDMK4rll/qlSoTn6hSb7TpMBpku90ke8s5XGhSYHLJL/Q/dhpFv997DItcgpc5BS4gELP8ohSOiSim6QT13UDmXMakP9XdfbtO7nehrJs4sqJvDTnJaB47BO4B/Fm52dz+ce3M7zjBH77az9Lth3w6umqFB1O98ZJXNw0ifMaVia2DF4SIZAUbkREyqCsvELmbdp3OMzs4a9d2V7rw+wGbVISWJn5FVtyfiDXWAuG06uNzbBRK64Wb98wHptxeuHCZVpHhZ+SwWjnLhfX3WCC3cRwmBh2F464XGLabiEs8RCVL19G4b717I9riNNVHYc9dEPOy3NfxmbYMC0TAMMKJ9JsSZSrI1FmBxy5VRj702ZP+2bVYrm4aRIXNkmiVc34Ug/7SenOinAzbtw4XnrpJdLT02nVqhVvvPEGHTt2POHzJk6cyA033MBVV13FlClT/F+oiEiQ5BW6WLR1P3M27uGPDXtZ/vcBSnSaYBjuL8OuDSrTpX4lOtZNpEK4gwXbHVzw0VvYXRYlxp1iM2zYDBvvX/H+aQcbcB+Kigq3ExV+jNOdasNFTWH6dPcZUkWy5tcjpu1WYjtuIiwxh8/TljHv1fXcc2EDrmlTI+RCTp4zj8U7FwMQZtYixtmLaNeF2CgeyG2ST+X4vTx04aVc2DiJ6vFRwSq3zAv6mJtJkyYxcOBA3nnnHTp16sRrr73GF198wbp160g6zuiyLVu2cN5551GvXj0SExNPOtxozI2IBFKeM49PV3zKR0s/Ij07nVpxtbil7S30adqHMPuxDy04XSYrtmcy5/ChpoVb91PgNL3a1K0cTZf6lejaoDKd61UiITq81G0t3rmYR398lJmbZ3qWdanZhdGpozm/9vm+eaPHsW4ddOoE2dneAcdmAxxObn9pK39mbmLfIfdpzLUSK7hDTtsahIVIyDmYn0PVf15KjPNyIs0WnuVOI4Nc2wJy7AsotK9iQKtr+fjqj4NY6dmrTA0o7tSpEx06dODNN98EwDRNUlJSuPfee3n88cdLfY7L5aJbt27cfPPN/Pbbbxw4cEDhRkTOOntz9nLRfy5i+a7lnsMRRT+71e7GtAHTPKdgW5bF+oxs/tjg7pmZt2mv1yBSgOTYCLrWr0yXw70zp/qX/d9Zf3tmKK4TX8dXb/OkrFsHDz0E339ffNZUq1YwahRcdhnkFDj55M+tvPfrJs9cLSmJUdxzYQN6t61ZZkPOrqw8Ppufxmfz09iV5Z40z8JFju1Psh3/I8+2HEocbfr3Ff9maNuhQar27FZmwk1BQQEVKlTgyy+/5Oqrr/YsHzRoEAcOHOCbb74p9XkjR45k+fLlTJ48mcGDBx833OTn55OfXzwLY1ZWFikpKQo3IuJ3V3x2BdPWT8NluY5aZzfs9G92L71qP8icjXuZs3Evuw96zxgbG+mg8+GemS71K1O/SnTAZhP2l/R02LrVPUNxw4ZHr88pcDLhzzTe/XWjJ+TUTIji7gsb0KdtzZM+zTmYLMti3uZ9/HfuVn5Yle4ZdF0x0uRv5+dkO6bhMvZ6Pcdu2ImLjGPbg9v8OudQWVZmzpbas2cPLpeL5CPm305OTmbt2rWlPuf333/ngw8+YOnSpSf1GqNGjeLZZ58901JFRE7Jxn0b+d9f//PMAAtgs2KJdLUi0nTffl1YjV8XrvCsjwyz0aFOIl3qV6Zrg0qcUz0u5AaRVq3qvh1LhXAHt3arx43n1mbCvK2888sm/t6fy/CvV/DmrA3cfWED+rY7O0NOdr6TyUu288ncrazbddCzvEOdBG7qXIcezZIZ8fMvvDJ371GngkeHR/O//v9TsPGRs2JA8ck6ePAgN910E++//z6VK1c+qecMHz6cYcOGeR4X9dyIiPjTb2m/eYKNYUWSUHgzFV09MSj+UrZwUT/JTq/mDehSvzJta8cT4dB1CACiwu3ccn49BnSqzafz03jnl41sP5DLE5NXMO7nDdx1YX2ubZdyVoScDRkH+e/crXy1eDvZhw8lRoXZubpNDW46tzbNqhf3Mrx86cv0atjLM4lfVFgUfZv25fb2t1M9pnqw3kLICWq4qVy5Mna7nV27dnkt37VrF1VLifYbN25ky5YtXHHFFZ5lpukeYOdwOFi3bh3169f3ek5ERAQREWf/zIsiElqKjviHm42pXPAQYZb7i6vA2EyebRl59mXk2VbyzhVfcVnDxsEs9awWFW5n6Hl1GdCpFp/OKw45IyavZNysDdx5YQOua18z4KHQ6TL5ac0u/jN3K3M2Fh9iqlc5mhvPrU2fdjWJiyp9wPiFdS/kwroXBqrUcimo4SY8PJx27doxc+ZMz5gb0zSZOXMm99xzz1HtmzRpwooVK7yWPfnkkxw8eJCxY8eqR0ZEzhrn1uhKXOEA4pzXYWDHaWSwN+w18uzLPW3CbGGeGWnl+CLD7Nx8Xl36d6rFxPlpvP3LRnZk5vHUlJW89fMG7upen+s6pPg95Ow+mM/E+Wl8Oj+NnZl5ANgMuLhpMgM716Zr/crYQuxQYlkU9MNSw4YNY9CgQbRv356OHTvy2muvcejQIYYMGQLAwIEDqVGjBqNGjSIyMpLmzZt7PT8+Ph7gqOUiIsGyISObRydlEO+8AYBs+yz2hb2LZRRfE8hu2BnYaiCVKlQKVpllUmSYncFd63J9x1pMWrCNt2dvZGdmHk99s4pxP2/kzu716dchhcgw34Ucy7JYtHU//5m7lWkrd3ouVFkpOpx+HVLo36kWNRM0VuZsEvRw069fP3bv3s3TTz9Neno6rVu3Zvr06Z5BxmlpadhswT+mKiJyIqZp8d8/t/LC92vId5rERtrJjf6IfTmfe9oUnQreoUYHXuv5WvCKLeMiw+wM6lKHfh1S+HzhNt76eSPpWXmMnLqKt2Zv4M4L6nN9x1rHDDmFhe4Ldh7v5LOcAidTluzgv39uZc3OLM/yNrXiGdi5Nv9oUU1jpM5SQZ/nJtA0z42I+EN6Zh6PfLmM39bvAeD8hpV5qW8rYqJc/GfZf/hw6Yfsyt5Frbha3Nr2Vq5vfn2ZuBJzWZHvdPH5wr956+cNnsNFybER3HFBfW44HHJyc+H112HcONi2DcLCoG9feOwx95w7RTbtzua/f27ly0V/czDPPUA4wmHjqtbVGdi5Ds1rxAXjLZZ7ZWaem2BQuBERX/t22Q6enLKSzNxCIsNsPPGPptx0bu0yPydNWZTvdPHF4ZCz43DIqRITwc2d6/PxU7VY8Kcds8REzw6He6bkqd9aGDV28d8/t3oCKkDtShW46dza9G1Xk/gKpc8ALYGhcHMcCjci4iuZOYU8PXUl3yzdAUDLmnG8el1rGiRVDHJlku908eWiv3nrZ/fZVQCu7Agy59Uje2ltLKf7cJItKp+YVtuIbZuGLcbdzjDgosZJ3NS5Nt0aVtEA4bOEws1xKNyIiC/8sWEPD3+xjJ2ZedhtBndf2IB7L2pQZi8TEKoKnCaT5v/NiAkbPOHFlR1B1qI6hFXKJrrJTgyHuyungj2Mm85L4cZOtUlJ1ADhs02ZmaFYRKSsySt0MWb6Oj78YzPgvnjlq9e1ok2thCBXJqUJd9g4v3ottr1Tk4rN/yau8wYc8bkkXLDO0yZ/Rxw5y+tw1UXVGH6ZBgiHAoUbEZGTtHJ7Jg9OWsr6jGwAbjy3Fk/8oykVwvVRejaLiABMG9nLa5G90h1yos/ZjjOzAgcX16YgPR6HA6L/EexKxVf0f6SIyAm4TIt3ftnIv378C6dpUSUmgjF9W3Jh46RglyYnoWpV99lQK1aAWRRyltfyauN0QonJ76WMU7gRETmOtL05PPj5UhZt3Q9Az3Oq8kLvFiRG68yZssIw4Mkn4dprS19vt8O557pvEho08k1EpBSWZTFxfho9x/7Koq37qRjh4JVrW/H2jW0VbMqgvn3hpZfcp33b7e6fjsN/3rdqBZMnH39CPylb1HMjEsJyC3PJd+UTFxGnOVdOwe6D+Qz/ejk/rckAoGPdRF69rpWm2C/jHn7YHXI++ADWroWYGHdvTo8e7rAjoUPhRiQEzdw0k1G/j2Lm5pkA1Iipwb0d7+WBcx/QrLgnMGNVOsO/XsHeQwWE22083KMRQ8+rh11znYSEOnXg+eeDXYX4m+a5EQkx45eMZ+jUodgMGy7L5VluM2xcUPsCpg2YpoBTiux8J89/u5pJC7cB0KRqDP/q15qm1fQ5IXI2OJXvb3XEiYSQ9Ox0bv/udiwsr2ADYFomv2z9hTfnvxmk6s5eC7fs47KxvzJp4TYMA26/oB7f3NNVwUakjFK4EQkhHy750CvU2K1KRLia4jCrY1hRmKbJG/PfCEgtG/dt5N7v7yXppSSiX4im7btt+ffif1PoKgzI65+MAqfJi9PXct27c9m2L5ca8VFMvPVchl/WVFd7FinDNOZGJIQs37WScFcTIl3tiHJ1INyq57XeJI/CXfu55q3fSY6JokpMBFViIkg6/LPoVik6gnDH6f/t80faH1z6yaUUuApwmu6rKi9LX8at397Kl6u/ZOoNUwm3+/+Mo4MH4eOP4b//hb17oVEjuO02uPJK2LD7IA9MXMrqnVkA9G1Xk5FXNCMmMszvdYmIf2nMjUgZl5lTyC/rdzNrzS7+t3Izhc7i8TQWJi5jNzYrBhundqZPQoWwEuEn0n2/oncIqlIxgvgKYV5nYuU780n5Vwp7c/diWuZR27UZNp7r/hwjuo04/Td9EtLS4IILYOtW92PLcp8C7HJZdB68mT011lHgNEmoEMao3i3o2byaX+sRkTOjC2ceh8KNlHWWZfHXrmxmrc3g57UZLErbj8ss/t/YRTZ59sXk2uaTa1+Mabh7JgwrknAqc17Ny3io07Pszs5n98F8MrLyPfd3H8xnT3Y+TvPkPxbC7AaVKxb3AGUV/s2MLV/hMvbjMvZjsh+XkYVl5GNRgEUBSdEJbH/ob+w2/xz6sSzo2BGWLnXPPFvEHpNL5V7LiKy9F4ALG1fhxb4tSYqJ9EsdIuI7CjfHoXAjZVFeoYs5G/ccDjS72X4g12t9o+SKXNgkie6NKnPL9Iv5a98az+GgIgYGhmHw+5Df6ZzS+ZivZZoWB3ILPWEn42Ce537JELQ7O58DOac/fibMbhDpsBMRZicyzEaEw0ZkmN3zs+R9z88wGxEOd3v3c71/FrXZsNbOoBttWE47ltP9M6p+BomXrMQW6cQssJP/Z1O2zKxFVJRO8RYpCxRujkPhRsqK7QdyPb0zczbuIa+w+BBPhMNG5/qVuLhJEt0bJ5GSWHzIacfBHfT8pCcrMlbgsDnAApflIsIRwX+u/g/XnnOMOehPQ77TxZ7sguLAczCfCUunMm/bWmxmHDYSsFsJ2K1YDMIxzoJhfvk74tnzXWuc+6NZtAjatg12RSJyMk7l+zv4nzQiPpbvzGf17tVYWDSr0oxIR+APOew+tJtftv6C03TSvnp7GiQ2OOFznC6TxWkHPIFm3a6DXuurx0VyYZMkLmqSRJf6lYkKL/2QTvWY6iy9Yyk/bPiBqeumkufKo1VyKwa1GkRCVIJP3l+RCIedGvFR1IiP8ixLrtKU1P/eW/oTLBs2ImhcqTk/3jibfKdJXqFJvtN11M/8QpO8op+FruL7np/u5fklfuYXusgrdLF7n0nWIReGw8RwuDBsYBbayPqzAZlz64PlHixdvv60Eyk/FG4kZBS6Cvm/X/+P1+e/zoG8AwDERcRxV4e7eKb7MwE5Oye3MJf7p9/P+KXjvQ4LXVr/UsZfNZ7qMdW92u8/VMAvf+1m1toMfvlrN5m5xYd5bAa0rZXAhU2SuLhpEo2TY076Ego2w8ZlDS/jsoaX+eaNnYKL6l5Ei6QWrNlz9KExDBOTXB7vdg81/Hgpg7lzoUuXokcW2A6nGLP4DLC4ODjnHL+VICJBpMNSEhJMy6Tv532ZsnYKFt6/0jbDRo/6Pfj2hm/9NoC1qIZ/TPgHP2768aizhBw2BzViarDotkXsOhDGz+symLU2gyVp+yk5dje+QhgXNKrCRU2S6NawCgll9AKNaZlpXPTxRWzcvxGbYcO0TBw2B07TyYjzR/D8hc/79VpXlgXt28Py5d4DiovYbPD44/DPf/qtBBHxMY25OQ6Fm9A0dd1Urpp41XHbTOo7ievOuc5vNfyw4Qd6Tuh51HLDiiDSbEUFsyPJjos4lOcdWJpUjfEcbmqTEo/DHhpza+Y58/hi1Rd8sfoLMvMzaV6lObe1u41WVVsF5PW3bIFu3eDvv92Pi08Fh1694OuvIbxsZkeRcknh5jgUbkLT5Z9ezvQN0z2z84aZdYkwmwA291lC2GiQ2IC7O9yDhft0agDTsrAsDi8DC8szDsOyLEzLe7nlXuFpb5a4P3XdVNbtWYeJxeFzkwgzU4g0W2JQ/C0aGWaja/3KXNgkiQubJHmNVxHfysyE8eOLJ/Fr2NA9iV/v3u6gIyJlh8LNcSjchKbGbzTmr31/ARDl6kyVgscxOHu+vZzGLnJtC3CGL2PXE78RGXb21CYiUhbobCkpdypVqISxzyDC1ZYqBY9iYCffWIvT2AtYYJjER8TTs2FPDMAwOPzTKP7pWVY0J8zh+542JZYffg6A7fBzp63/nnV712JSNN7GwkUmefZFFBppYECd+DoKNiIifqZwIyFhQIsBLNl6iCoFT2AQxiH7r+wJexkMd9CwGTYeTx3DQ13a+K2Gczdu59JPHjnmepth49a2t/rt9UVExC00Ri5Kudcy4SqSC0diI4Ic2zz2hL3iCTYOw0H1mOoMbTvUrzVcXO9iejXshc04+n8rh+GgTnwd7upwl19rEBERhRsJASv+zuSuT1aBFUFY1EZ2h4/GbgO74T780zy5Ob8O/pX4yHi/1mEzbHx53Zfc0f4Orzl1DAx6NujJHzf/4fcaREREA4qDXY6coXXpB+n33lwO5BTSsU4iHw3pwIrdi5i9ZTYWFt1qd6Nzzc5+nVOlNPty9/Hr1l89MxTXia8T0NcXEQk1OlvqOBRuQsem3dlc9+6f7MnOp1VKPJ8M7UhMZFiwyxIRET84le9vHZaSMmnbvhwG/Hsee7LzaVotlv8MUbARERE3hRspc9Iz8+j/7z/ZmZlH/SrR/HdoR+IqKNiIiIibwo2UKbsP5tP/33+ybV8utStV4NNbz6VyxYhglyUiImcRhRspMw7kFHDTB/PYtPsQ1eMimXBLJ5JjI4NdloiInGUUbqRMyMorZOCH81mbfpAqMRFMuPVcaiZUCHZZIiJyFlK4kbNeToGTm8cvYPnfmSRUCGPCLZ2oWzk62GWJiMhZSuFGzmp5hS5u/c9CFm7dT0ykg/8O7USj5JhglyUiImcxhRs5axU4Te6asJg/NuwlOtzOxzd3pHmNuGCXJSIiZzmFGzkrOV0mD0xawqy1GUQ4bHwwuANtayUEuywRESkDFG7krGOaFo9+uZzvV6QTbrfx3sD2nFuvUrDLEhGRMkLhRs4qlmUxYspKvl6yHbvN4M3+bbigUZVglyUiImWIwo2cNSzL4vnv1vDZ/DQMA/7VrzWXnlM12GWJiEgZo3AjZ41XZvzFh39sBuDFPi25slX1IFckIiJlkcKNnBXG/byBN3/eAMDzV53Dde1TglyRiIiUVQo3EnQf/L6Zl35YB8AT/2jCTZ3rBLcgEREp0xRuJKg+nZfG89+tBuCB1Ibc1q1+kCsSEZGyTuFGgmbykr8ZMWUFALdfUI/7L24Y5IpERCQUKNxIUHy/YicPfb4My4JBnWvzeM8mGIYR7LJERCQEKNxIwM1au4v7PluCacF17Wsy8opzFGxERMRnFG4koP7YsIc7PlmM07S4slV1RvVuic2mYCMiIr6jcCMBs2DLPm75eCEFTpNLmyXzynWtsCvYiIiIjyncSEAs23aAIeMXkFvo4oJGVXijfxvC7Pr1ExER39O3i/jdmp1ZDPxwPtn5Ts6tl8g7N7YjwmEPdlkiIhKiHMEuQEJHxqEMPlzyIXO3zcVus5NaL5Wu1Xoz9KMVZOYW0qZWPP8e1IGocAUbERHxH4Ub8Ylv133LdV9eR4GrANMyMTD4dvVcqhXEYLMSOad6LB8N6UjFCP3KiYiIf+mwlJyx1btX0/vz3uQ78zEtEwCbWYnkgv/DZiXism1jbP+GxEWFBblSEREpDxRu5IyN/XMsABYWADYrnuSC/8NhVaXQ2E56xJNM+euTYJYoIiLliMKNnLFv1n2D03QCYFgRJOc/T5hVE6exi13hI3Cyl6nrpga5ShERKS8UbuSMFboKPfcTCm8j3KqLk33sCh+By7YHgHxXfrDKExGRckbhRs5YhxodsBt2olydiXH1wMJkT/hLOG3pADhsDjrV6BTkKkVEpLxQuJEzdm/He8GMp1LBvQBkOb4i377Cs95luriz/Z3BKk9ERMoZhRs5Yz3rX0abyFexE0uBbQMHHBMAcBju075fv+x1mlZpGswSRUSkHNGkI3LGPvxjC7sPVCLMYZFccyYZGRY2I4xL6l/CQ50f4qK6FwW7RBERKUcUbuSMrNqRyZgf1gLw3JUtuaHjVCzLwjB0QUwREQkOHZaS05Zb4OK+z5ZQ6LK4tFky13dIAVCwERGRoFK4kdP2z+9Xs3H3IZJiIhjdp6VCjYiInBXOinAzbtw46tSpQ2RkJJ06dWL+/PnHbPv111/Tvn174uPjiY6OpnXr1vz3v/8NYLUC8NPqXXzyZxoAr1zXisTo8CBXJCIi4hb0cDNp0iSGDRvGyJEjWbx4Ma1ataJHjx5kZGSU2j4xMZERI0Ywd+5cli9fzpAhQxgyZAg//PBDgCsvvzIO5vHoV8sBuPX8upzfsEqQKxIRESlmWJZlBbOATp060aFDB958800ATNMkJSWFe++9l8cff/ykttG2bVt69erF888/f8K2WVlZxMXFkZmZSWxs7BnVXh6ZpsXgjxbw61+7aVotlil3dyHCYQ92WSIiEuJO5fs7qD03BQUFLFq0iNTUVM8ym81Gamoqc+fOPeHzLcti5syZrFu3jm7dupXaJj8/n6ysLK+bnL6P527h1792E+Gw8fr1rRVsRETkrBPUcLNnzx5cLhfJycley5OTk0lPTz/m8zIzM6lYsSLh4eH06tWLN954g0suuaTUtqNGjSIuLs5zS0lJ8el7KE/Wpmcxapr7tO8nezWlYXJMkCsSERE5WtDH3JyOmJgYli5dyoIFC/jnP//JsGHDmD17dqlthw8fTmZmpue2bdu2wBYbIvIKXdz/2VIKnCYXNUnixnNrB7skERGRUgV1Er/KlStjt9vZtWuX1/Jdu3ZRtWrVYz7PZrPRoEEDAFq3bs2aNWsYNWoU3bt3P6ptREQEERERPq27PBo9bS3rdh2kcsUIxvTVad8iInL2CmrPTXh4OO3atWPmzJmeZaZpMnPmTDp37nzS2zFNk/z8fH+UKMDP6zL4aM4WAF6+tiWVKyosiojI2Svol18YNmwYgwYNon379nTs2JHXXnuNQ4cOMWTIEAAGDhxIjRo1GDVqFOAeQ9O+fXvq169Pfn4+33//Pf/97395++23g/k2Qtae7Hwe+cJ92vfgLnXo3jgpyBWJiIgcX9DDTb9+/di9ezdPP/006enptG7dmunTp3sGGaelpWGzFXcwHTp0iLvuuou///6bqKgomjRpwieffEK/fv2C9RZClmVZPPblcvZk59M4OYbHL2sS7JJEREROKOjz3ASa5rk5ef/9cytPTVlJuMPG1Hu60qSq9peIiARHmZnnRs5e63cd5P++Ww3A4z2bKNiIiEiZoXAjR8l3urhv4lLynSbdGlVhcJc6wS5JRETkpCncyFFe/mEda3ZmkRgdzsvXtsRm02nfIiJSdijciJff1+/h/d82AzCmT0uSYiKDXJGIiMipCfrZUnJq1u5ZyzdrvyGnMIcWyS24svGVhNvDfbLt/YcKGPb5UgBuPLcWqc2Sj/8EERGRs5DCTRmRXZDNoMmD+Hrt19gNOzbDRqFZSJUKVfi0z6ek1ks98UaOw7IsHv96ORkH86lfJZoR/2jmo8pFREQCS4elygDLsuj7eV++WfcNAC7LRaFZCMDe3L30+rQXi3cuPqPXmLhgGz+s2kWY3WDs9W2ICtfVvkVEpGxSuCkD5m2fxw8bf8BluY5aZ1ompmXywm8vnPb2N+7O5rlv3ad9P9KjMc1rxJ32tkRERIJN4aYMmLRyEg5b8RHEKFdHEgpuAcu9zGk6mbx2MnnOvFPedoHT5IGJS8ktdNG1QSVuOa+ez+oWEREJBo25KQMO5B+Aw/NI26wYKhc8jI0KFNrSyHbMANw9ODmFOUQ6Tu3spn/99BcrtmcSXyGMV65trdO+RUSkzFPPTRnQIKEB1uF0E+O8ChsVAIh2XehpEx8RT1zEqR1OmrtxL+/8shGA0b1bUjVOp32LiEjZp3BTBgxuPRgLC5sVTazzCs/ySLMFdrMKdsPOre1uxW47+UHAmTmFDPt8KZYF13dIoWfzqv4oXUREJOAUbsqAGrE1GJM65nCvTTQFxhbybMsBiDEvol5CPR4/7/GT3p5lWTwxeQU7M/OoWzmapy7Xad8iIhI6FG7KiFva3EdV4wYAMsM+I9s+C4DqjquZc/McEqMST3pbXy76m/+t2InDZvBav9ZER2jolYiIhA59q5URH/2xhbxCg0bJFZkxcDz7Dh1i0Hs7OZQbw879YVSOPrntbNlziGemrgLgwUsa0Sol3n9Fi4iIBIF6bsqArLxCPvh9EwD3XtSQRpUacm6t1lxy+PIIXy/5+6S2U+gyeWDSUg4VuOhUN5E7Lqjvt5pFRESCReGmDPj4jy1k5TlpkFSRf7So5ll+TZsaAHy7bAdOl3nC7bwxcz1Ltx0gNtLBv/q1xq7TvkVEJAQp3Jylsguy2bBvA2n7M/j37+6rdN97UQOvQNKtURUSo8PZk13Abxv2HHd7C7bs482fNwDwQu8WVI+P8l/xIiIiQaRwc5ZJy0xj8JTBJL6YSMM3GtLilXvIzC2keryNy1tW92obZrdxRUt3T86UJduPuc2svEIemLgU04I+bWsetR0REZFQonBzFtlyYAvt32vPhOUTKDQLMaxIYp1XA7Ay9xVmbf7pqOdc07YmAD+sSic731nqdp+aspLtB3KplViBZ67Uad8iIhLaFG7OIvdPv599uftwWu6QEuPshZ04Co3tHLL9wsApA3Ga3gGmVc046lWOJq/QZPrK9KO2OWXJdr5ZugO7zeC161sTExkWkPciIiISLAo3Z4mdB3fy7bpvPVf+NqwIYp29Ach0TMLESXp2OtPWT/N6nmEYXH14YPGRh6a27cvhqSkrAbj/4oa0rZXg77chIiISdAo3Z4mN+zd6rh8FEO3qfrjXZgeH7LMBsBt21u1dd9Rzr27tDjd/bNjDj7/nsXIl5BeYPDhpKQfznbSvncBd3XXat4iIlA8KN2eJmPAYr8eRrjYAZNt/AsN9mrdpmUe1A4hzVCDBmYAF9H1oOy1aQMOrN7Jw635iItynfTvs+qcWEZHyQd94Z4kWyS2oG1/X/cAyiDRbAJB/+BpSADbDxlVNrvJ6XnY2dOsGm2a5e2+iz9lOePX9GM3XA9AsrzkpiRUC8A5ERETODgo3ZwmbYeO5C58DIMyqhZ04THLJt7lDioHBHe3voGpF76t3v/EGrFwJ2WuqYTlthCcdJKn3QgybxaFV1fl8TA1WrQr42xEREQkahZsgycyEVavg7xJXTrix5Y283vN1oi33IakC+xrsNnewGdp2KP/q8a+jtvP222CaYOaFk7uxCgD26AKcmVHsndEchwM++CAgb0lEROSsoHATYNu3w8CBUKUKNG8OKSlQpw6MG+def2+ne7mq7iMAtKsdy7Pdn2X9vet5/4r3CbN7n8ZtmrBtW/Hj7NXuQ1OWCXu+bY1VEIbTCZs2BeKdiYiInB10VfAA+vtv6NgRMjLA5SpevnUr3HMPjB0LP820WJKWDcA/LxtE6+Nctdtmg4oV3eNuAHLXVyVzTn0K9sSQvz0RAIcD4o+9CRERkZCjnpsAGj786GBT0vr1cMFVWWTmFlIxwkHz6rEn3OaAAe4AA4BlcOC3JuSsqeFZ73TCDTf4oHgREZEyQuEmQA4cgIkTSwYbi4iUvRgRhV7t9jr2AtCxbuJJnb798MMQGQl2+9Hr7Hbo0gUuueTMahcRESlLFG4CJC3N3YtSpGLLbVTt/ye1HphBTLvNcHgCv8ha7nCTsbIS+/adeLsNGsCsWVDjcGeNw1EcdHr0gP/9z334SkREpLzQmJsAiYvzfhzdbIfnfmLqahzxOeyf1ZTIFHeimflpJc6dCnPnQqVKx992hw7uQcMzZsCiRRARAb16QTNdI1NERMohhZsAqV0b2raFxYvdjy3T8Fof234LjoRD2CKcuPIc5KXHsskGI0fCm2+eePt2O1x2mfsmIiJSnumARQA9/3yJB0eEG4AK9XcDkJ9WCSwDlwvGj4ecnAAVKCIiEgIUbgLoH/+Ajz92j4GxrOJw48oNY+/05p7HeWnFx6Fyctxz44iIiMjJOaPDUjt27ODdd99lw4YNVKtWjVtuuYUmTZr4qraQNHCgezxM9ycNDh5eZjltZC+rjeW0E9VwF4dW1vR6TsWKga9TRESkrDqlnpsKFSqwe7f70Mnq1atp1qwZn376KYWFhfzvf/+jXbt2LF++/ARbkUqV4PzzintuLKf79KZDq2qyZ0o7zHz3TMQ2m3uwcLVqQSlTRESkTDqlcJOXl4dluU9ZfuKJJ+jWrRtr1qzh888/Z9WqVVx55ZWMGDHCL4WGGptRYsyNq/R/BtN0DygWERGRk3faY24WL17MI488guPw9Lg2m41HH32URYsW+ay4UGa3FYebmGh3z43DAWFhYBju07k/+MB9CEtERERO3imNuTEMA+Nwj4PNZiPuiMlb4uPj2b9/v++qC2Elw03zJjY+XQRffglZWdC4Mdx4IyQkBLFAERGRMuqUwo1lWTRq1AjDMMjOzmb58uW0bNnSs37Dhg1UrVrV50WGIkeJcGOzGbRt654HR0RERM7MKYWb8ePHez1u0KCB1+M///yTa6655syrKgdK9tyIiIiI75xSuBk0aNBx1z/11FNnVEz5onAjIiLiD5rEL0hcphnsEkRERELSKYWbmJgYhg4dypw5c/xVT7nhdFme++rDERER8Z1TCjeHDh1i3rx5nHfeeTRt2pRXXnnFM6mfnBqnaZ24kYiIiJyyUz4sNWvWLJYsWUJqaiovvPACNWvWpE+fPkybNs0zwZ8cX0EBbN5afFjqr/Wg6YFERER847TG3LRq1Yo33niDHTt28NFHH5GZmcnll19OrVq1ePrpp31dY0hJT3ef8j1vfnEQTN8B7dvDAw+A8qGIiMiZOaVwYxjeo0MiIiK44YYb+Omnn9i4cSODBw/mo48+8mV9IcWyoHdvWLcOsFleywHGjoW33w5ObSIiIqHilMLN8Q471alTh+eff56tW7eecVGhasECmDsXnE4w7CXPlioOjWPGuK8pJSIiIqfnlMLNyJEjqVix4nHbHNm7I8V++MF9/SgAw1Z6UNy6FTZsCGBRIiIiIeaUJvEbqUtUnzaXC5Yscf8EvA5LHfitkVfbwsIAFiYiIhJiTqnnxjRNXnzxRbp27UqHDh14/PHHyc3N9VdtIaOwEK6+GiZPLh5fY9jcx572fNeK/O2JnrZxcVC/fhCKFBERCRGnFG7++c9/8sQTT1CxYkVq1KjB2LFjufvuu/1VW8gYNQq+++6IhYd7bszcsOJFNrj9doiMDGBxIiIiIeaUws1//vMf3nrrLX744QemTJnCt99+y4QJEzA1AvaYCgvdZ0F5sZmeMTeWWfxP0KULPPNM4GoTEREJRacUbtLS0vjHP/7heZyamophGOzYscPnhYWKzZth377ix2FVski5fwbhyVkAWGbxAOzx4yEqKtAVioiIhJZTCjdOp5PII46ZhIWFUagRsMdkO2IPh1fNxBbuKl7gKm5w8GCAihIREQlhp3S2lGVZDB48mIiICM+yvLw87rjjDqKjoz3Lvv76a99VWMbVrQvx8XDggPux9/w2YFnunhvDgBo1AlubiIhIKDqlcDNo0KCjlt14440+KyYU2e3w6KPwxBPux4bD5d3gcM/N5ZdDUlKAixMREQlBpxRuxo8f7686Qtpjj7nPlpozBwzHET03pkF0NLz4YpCKExERCTGndeHM0liWxbRp0+jbt6+vNhkybDb4/XcYMQLCI73DTbs2BvPmQdOmQSpOREQkxJxxuNm8eTNPPfUUtWrV4pprriEvL88XdYUcw4D/+z8Y9oh3uPl0go1zzglSUSIiIiHotMJNfn4+EyZM4KKLLqJx48a88MILDBs2jIyMDL47arY6KWJZsGqN95ibvr0NJk0qnrlYREREzswphZtFixZx1113UbVqVV577TWuvvpqtm3bhs1mo0ePHsTGxvqrzpDwxBMwbYZ3z82KZQbXX+8elyMiIiJn7pTCTadOnYiIiODPP/9kwYIF3HfffSQnJ/urtpDy228wevTRA4pdTvc/wUsvwezZQShMREQkxJxSuLn44ov54IMPeO6555g+fTqWj46ljBs3jjp16hAZGUmnTp2YP3/+Mdu+//77nH/++SQkJJCQkEBqaupx258t3noLHI5STgU/PEOxwwHjxgWhMBERkRBzSuHmhx9+YNWqVTRu3Jg777yTatWqcf/99wNgGMYJnl26SZMmMWzYMEaOHMnixYtp1aoVPXr0ICMjo9T2s2fP5oYbbuDnn39m7ty5pKSkcOmll7J9+/bTev1AWbgQnM5jT+LndMKiRcGoTEREJLQY1hl0v/z444+MHz+eyZMnk5KSQt++fenTpw/t2rU76W106tSJDh068OabbwJgmiYpKSnce++9PP744yd8vsvlIiEhgTfffJOBAweesH1WVhZxcXFkZmYGdIxQy5awYgUkXTufqHq7MfMdHFpdnX0zWnjaNG0Kq1cHrCQREZEy41S+v8/oVPBLLrmETz/9lB07dnDfffcxbdo0OnbseNLPLygoYNGiRaSmphYXZLORmprK3LlzT2obOTk5FBYWkpiYWOr6/Px8srKyvG7B0Lu3e74bw+4+LLV3eguvYGO3Q58+QSlNREQkpJzSDMUl5eXlsXz5cjIyMjBNk1q1avHss8+ycePGk97Gnj17cLlcRw1KTk5OZu3atSe1jccee4zq1at7BaSSRo0axbPPPnvSNfnL7bfDq6+CEeY+LGU5i3Olzea+GvgddwSrOhERkdBxWuFm+vTpDBw4kD179hy1zjAMHnzwwTMu7GSMHj2aiRMnMnv27KOuVl5k+PDhDBs2zPM4KyuLlJSUgNRXUrVqMGMGXPtvd7gxLDt2O5gmxMW5L8+gC2eKiIicudM6LHXvvfdy7bXXsnPnTkzT9Lq5XK4Tb+CwypUrY7fb2bVrl9fyXbt2UbVq1eM+9+WXX2b06NHMmDGDli1bHrNdREQEsbGxXrdgOfdcaNjYvX8u6majXz94913Ytg26dAlaWSIiIiHltMLNrl27GDZs2BnPcRMeHk67du2YOXOmZ5lpmsycOZPOnTsf83ljxozh+eefZ/r06bRv3/6MagikHTvgwEF3z83dd9qYMAFuvRWio4NcmIiISAg5rXDTt29fZvtoxrlhw4bx/vvv8/HHH7NmzRruvPNODh06xJAhQwAYOHAgw4cP97R/8cUXeeqpp/jwww+pU6cO6enppKenk52d7ZN6/CEzE66/HlJSIGOvO9xcdbmd3r1h794gFyciIhJiTmvMzZtvvsm1117Lb7/9RosWLQgLC/Naf9999530tvr168fu3bt5+umnSU9Pp3Xr1kyfPt3TK5SWlobNVpzB3n77bQoKCo66+vjIkSN55plnTuft+FVBAVxyCSxe7B5fUzRDsem0MXUqbNgAf/4JFSoEuVAREZEQcVrz3HzwwQfccccdREZGUqlSJa8J/AzDYNOmTT4t0pcCPc/NJ5/ATTcVP04ZNg1bmMnfb1+IK6sChgHvvAO33eb3UkRERMosv89zM2LECJ599lkyMzPZsmULmzdv9tzO5mATDB9+6D7V283y9NxYruJd/8EHga9LREQkVJ1WuCkoKKBfv35eh4ukdNu2uQ9HARjhLoo6uaxCu/un5R5oLCIiIr5xWulk0KBBTJo0yde1hKSDB4vvh1VyP3BmR2AVuMcpGYbmtxEREfGl0xpQ7HK5GDNmDD/88AMtW7Y8akDxq6++6pPiyrpNm6DkFD7hSe5wU7g7xrPMsmDo0EBXJiIiErpOK9ysWLGCNm3aALBy5Uqvdad7dfBQ9M037p6ZoiHbYZXd4aagRLgBKENT9YiIiJz1Tivc/Pzzz76uIyQdOuS+IKbT6X7siMsFwLnfe9a+U5jUWURERE5AI4L96JxzioMNgGEvumim3bMsLAzq1w90ZSIiIqFL4caPLr8ckpJKnApuKzoN3H3ozuFwz1yckBCkAkVEREKQwo0fhYXBhAnuEGO3g2E/PPjGtGG3Q82aMGZMcGsUEREJNQo3fpaaCnPmuHtxig5LRYQb3H03zJ8PJ7j4uYiIiJwihZsAaNcOpkyBtu3cPTeTPrMxdixUqRLcukREREKRwk0AuSx3z01UuHa7iIiIv+hbNoAKXe5w47BrLiARERF/UbgJoEKX+7BUmF27XURExF/0LRtAzsM9N2HquREREfEbhZsAKlDPjYiIiN/pWzaAnKZ6bkRERPxN4SaACp2HBxTbtNtFRET8Rd+yAVRoHj4s5dBuFxER8Rd9ywaQZ0CxTYelRERE/EXhJkBcpsXhjhsNKBYREfEjfcsGSNEEfqBJ/ERERPzJEewCQpllwbx5MHEiZOw3oZp7uXpuRERE/Effsn6SkwNXXAGdO8O4cfDlV5Zn3egXbFjWcZ4sIiIip03hxk+GDoVp09z3nU4wcR+Wskx49hmDDz4IYnEiIiIhTOHGDzZtgkmTwDRLLLQd7qox3bv8+eePWC8iIiI+oXDjB99+C0aJMcORdXeTfMOfAFgu9y5PS4OVK4NRnYiISGjTgGI/yM0Fm624Zyb5uvmedZZpeLUTERER31LPjR+0aOEeZ1Oqwz03YWHQsGHgahIRESkvFG78oGdPqFnT3XtzJMs0cDjg+ushMTHwtYmIiIQ6hRs/sNvdc9tERIDjyAN/po1ateDll4NSmoiISMhTuPGTrl1h/ny47jrv5ZHhBhMmQFJScOoSEREJdQo3ftS8OVx5pfeynEM2OneGG27QgGIRERF/ULjxo59+coeYkiyne5d//jkMGRKEokREREKcwo0fjRzpPd8NAIdPBTdN90R/a9cGvi4REZFQpnDjJ+npMGfO0bMQF03iB+6Bx198EeDCREREQpzCjZ9kZZW+vOQkfjbbsduJiIjI6VG48ZMaNSAy8ujlltPuue90QqNGASxKRESkHFC48ZPoaLjxxqPnuSkZbqKi3JP5iYiIiO8o3PjR//0fVK/uvcxy2rDZ3AON33sPYmKCU5uIiEioUrjxo+RkmDfPe5nltNOhA3z/PQwYEJy6REREQpmuCu5nVat6P755kI2Xbii9rYiIiJw59dwEWKV4+4kbiYiIyGlTuAmwCId2uYiIiD/pmzbAIsPUcyMiIuJPCjcBpp4bERER/9I3bYCp50ZERMS/FG4CTD03IiIi/qVv2gBTz42IiIh/KdwEmHpuRERE/EvftAHgsBVfCVw9NyIiIv6lcONnWVmAVRxuJn9lY9++4NUjIiIS6hRu/GjuXKhdGwryi8PNuNdtpKTAjBlBLExERCSEKdz4ya5d0KOHu+fGMovDjem0kZcHV10FGzcGsUAREZEQpXDjJ++9B4cOgWkCZondbBmYJhQWwrhxQStPREQkZCnc+Mk33xwONgAlem6w3D9cLpgyJdBViYiIhD6FGz/Jzy++b1nF952ZFUptIyIiIr6hcOMnHTuCw+G9LH3CuVhO96ngDgd06BCEwkREREKcwo0fLFsGmzaB0+l+bBw+KmXmh3naOJ1w771BKE5ERCTEOU7cRE7Fb79BaioUFJRYaBw+LlVivpvHHoOLLw5sbSIiIuWBem58yOWC/v2PCDZQIty4f0RHw9NPB7Q0ERGRckPhxodmzIC//y6xwGYSViULe4VCAKzDPTeHDsFXXwWhQBERkXJA4caHVq0CW4k9WvmKpVS/+bej2jkcsHRp4OoSEREpTxRufCg6usTcNkB0k53eDQ733FgWREQEsDAREZFyROHGhy6//AQNSkzgd+WVfi9HRESkXFK48aGUFBg8+DgNLAObDbp2hU6dAlWViIhI+RL0cDNu3Djq1KlDZGQknTp1Yv78+cdsu2rVKvr06UOdOnUwDIPXXnstcIWepFdegUqVSl9nWVCvHkyeXDz3jYiIiPhWUMPNpEmTGDZsGCNHjmTx4sW0atWKHj16kJGRUWr7nJwc6tWrx+jRo6latWqAqz05r74K+/cfY6VlsGkTpKUFtCQREZFyJajh5tVXX+XWW29lyJAhNGvWjHfeeYcKFSrw4Ycfltq+Q4cOvPTSS1x//fVEnIUjcgsL4a23vAcVezl8RfALL4Rj5DcRERE5Q0ELNwUFBSxatIjU1NTiYmw2UlNTmTt3rs9eJz8/n6ysLK+bv+zYcZxeG/BM5pedDe+847cyREREyrWghZs9e/bgcrlITk72Wp6cnEx6errPXmfUqFHExcV5bikpKT7b9pFO1JlkONxdOpYFn3zitzJERETKtaAPKPa34cOHk5mZ6blt27bNb6+VnAytWh17vSsn3HPfjx1IIiIi5VrQwk3lypWx2+3s2rXLa/muXbt8Olg4IiKC2NhYr5u/GAY8+WTp63I3V8Y6fFVwux0aN/ZbGSIiIuVa0MJNeHg47dq1Y+bMmZ5lpmkyc+ZMOnfuHKyyzljfvnD77UcvL0iP89x3ueCOOwJYlIiISDniCOaLDxs2jEGDBtG+fXs6duzIa6+9xqFDhxgyZAgAAwcOpEaNGowaNQpwD0JevXq15/727dtZunQpFStWpEGDBkF7H0caNw5+/hnySyyzTHeONAz3TMbXXRec2kREREJdUMNNv3792L17N08//TTp6em0bt2a6dOnewYZp6WlYStxJcodO3bQpk0bz+OXX36Zl19+mQsuuIDZs2cHuvxjGjEC/voLapdc6Cq+rtTgwe5DUyIiIuJ7hmVZVrCLCKSsrCzi4uLIzMz0y/iblSuhZUt3iKn92P88y/f/3ISs+fUxDGja1N1OsxSLiIicnFP5/g75s6UCKTcXUlPdweZIllncc7N6NaxdG+DiREREygmFGx+aOBGOOPnLw3J57+rjTvYnIiIip03hxoc+/fTYh5qKTgMHd5vatUtvJyIiImdG4caH9uwpeUjK+9iUWVA8grhnT6hRI3B1iYiIlCcKNz7UuHGJs6Bs3uHGchaHm169AliUiIhIOaNw40O33uqeoA+KryNVxCp0hxvDgG++CXRlIiIi5YfCjQ9ddBEkJLjvG3bvcGMeHnNjWbBsWaArExERKT8UbnyoaA4b8A43B5fUonBPRc/jqKhAVyYiIlJ+KNz4WJ8+7pBjONzHp8wCO/tmtADcp1HZ7XDttUEsUEREJMQp3PjYkCFQqRLYw909NyXnt7HZICIC7r47WNWJiIiEPoUbH4uOdl8V3HZ4QLHltHnmvomLgx9+gDp1glefiIhIqAvqhTNDTX6++zTvWbMgrJp3z43D4Z7k77zzglmhiIhI6FPPjQ+NGQM//+w+I8ozoNhlw7LANGHAAMjLC26NIiIioU7hxkecTnjzTXeIgeJ5boom7zNN2LcPvvwyWBWKiIiUDwo3PrJzJ2RkFD8u6rkpOaA4LAwWLAh0ZSIiIuWLwo2POI4YvVR0KrjlLN7FlgXh4YGsSkREpPxRuPGRI2cd9vTclLimlNMJ//hHIKsSEREpfxRufOTDD93z2BSJqLkf8O65iYyE7t0DXJiIiEg5o3DjI5s2FQ8mBohpnQaArUKBZ1lEBJ45b0RERMQ/FG58JCnJu+emiCMmz6uNiIiI+JfCjY/cdJN3z42HYQHu4DN4cEBLEhERKZcUbnykTx9o27ao98YqXmG4D0UlJcEddwSrOhERkfJD4cZHwsPh6afdp3t7s7As95lSBw8GozIREZHyReHGR1wu99W+DQPPoSgAw+a+v38/PPBAcGoTEREpTxRufGTGDNi+/fC4m5JnRB2+73LB1KnumYxFRETEfxRufGT1arAXzddXouemcH8Fz33ThPXrA1yYiIhIOaNw4yMxMSUumlmi52bvtJZe7SpWDGBRIiIi5ZDCjY9ccUWJeW5K9Ny4Mot7bmrXhtatA1uXiIhIeaNw4yPVqsGttxYNKC5eXvLsqWeeKX2iPxEREfEdfdX60NixMHAglJznxmZzXzF8zBhN4iciIhIICjc+FB4OH30E8xcULxv1gsH27fDII0ErS0REpFxxBLuAUFS/fnHPzUPDDOyKkCIiIgGjr10/KDlJsU1XARcREQkohRs/MEuMIjYMpRsREZFAUrjxg6Jwo14bERGRwFO48YOijhubem1EREQCTuHGD4p6bpRtREREAk/hxg/Mwz03Gm8jIiISeAo3fmCaGnMjIiISLAo3fqAxNyIiIsGjcOMHFkU9Nwo3IiIigaZw4wfFY26CW4eIiEh5pHDjB56zpYJch4iISHmkcOMHVtEkfhpRLCIiEnAKN35gakCxiIhI0Cjc+IEuvyAiIhI8Cjd+YJrun5rET0REJPAUbvyg+FTwIBciIiJSDinc+EHRJH6GzpcSEREJOIUbP9CYGxERkeBRuPEDXThTREQkeBRu/MDTc6O9KyIiEnD6+vUDzyR+6rkREREJOIUbP9AkfiIiIsGjcOMHli6cKSIiEjQKN36gC2eKiIgEj8KNj+3fD3PmuMON6VK8ERERCTSFGx/Jy4O774Zq1WDEk+5l69YZXHcd7N0b3NpERETKE4UbHzBNuOYaeOcdyM8HjMODbiz4+mvo1g2ys4NaooiISLmhcOMD06bB9OnFF8z0DLaxDFwuWL0a/v3vYFUnIiJSvijc+MD48WC3Fz+OrOU+DlV01hS4e3VERETE/xRufCAtDVyu4sdx524EwBGX61m2YYN32BERERH/ULjxgWrVSjwwTM9de1Sh577LBX/+GcCiREREyimFGx/o0KH4vhHmOma7zz8PQDEiIiLlnMKND8zc8LPn/vHCzbZtgahGRESkfFO4OUM3fnUjs9f/CRy+WKaj+LBU+oRzvdrWrRvIykRERMqnsyLcjBs3jjp16hAZGUmnTp2YP3/+cdt/8cUXNGnShMjISFq0aMH3338foEq9rclYw4QfV8Kcxyg6/9sIcwLgOhRO/t+VvNoPGxboCkVERMqfoIebSZMmMWzYMEaOHMnixYtp1aoVPXr0ICMjo9T2c+bM4YYbbmDo0KEsWbKEq6++mquvvpqVK1cGuHLo/p/u8PEMinajLTqPmLZbATALS5wbjsUllxwx8FhERET8Iujh5tVXX+XWW29lyJAhNGvWjHfeeYcKFSrw4Ycfltp+7Nix9OzZk0ceeYSmTZvy/PPP07ZtW958880AVw4ZW+MgL8nzuNqgP4hpkwaA5RVuDGrWDHBxIiIi5VRQw01BQQGLFi0iNTXVs8xms5GamsrcuXNLfc7cuXO92gP06NHjmO3z8/PJysryuvlCoasQtnf0PK7QZAeOmDzPYzMvzKv98uU+eVkRERE5gaCGmz179uByuUhOTvZanpycTHp6eqnPSU9PP6X2o0aNIi4uznNLSUnxSe12mx0i93ke521L9NzPT48l849GXu0TEnzysiIiInICjmAX4G/Dhw9nWImRvFlZWT4JODbDRrVWq9n5mQnYMA9Fsu2NVMyccIovLlVs5MgzfkkRERE5CUHtualcuTJ2u51du3Z5Ld+1axdVq1Yt9TlVq1Y9pfYRERHExsZ63Xxl3JX/gqZfeB6bORGUFmwqVYLzzvPZy4qIiMhxBDXchIeH065dO2bOnOlZZpomM2fOpHPnzqU+p3Pnzl7tAX788cdjtvena5pew8hxa6HyUormuXErvh8VBVu3BroyERGR8ivoZ0sNGzaM999/n48//pg1a9Zw5513cujQIYYMGQLAwIEDGT58uKf9/fffz/Tp03nllVdYu3YtzzzzDAsXLuSee+4JSv3PXDiStA2VOP/xFyBiH0XBJjzC4o03ICcHoqODUpqIiEi5FPQxN/369WP37t08/fTTpKen07p1a6ZPn+4ZNJyWlobNVpzBunTpwqeffsqTTz7JE088QcOGDZkyZQrNmzcP1lsgJS6FX0eNgFFBK0FEREQOMyzLsk7cLHRkZWURFxdHZmamT8ffiIiIiP+cyvd30A9LiYiIiPiSwo2IiIiEFIUbERERCSkKNyIiIhJSFG5EREQkpCjciIiISEhRuBEREZGQonAjIiIiIUXhRkREREJK0C+/EGhFEzJnZWUFuRIRERE5WUXf2ydzYYVyF24OHjwIQEpKSpArERERkVN18OBB4uLijtum3F1byjRNduzYQUxMDIZh+HTbv/76K1dcccVpPXfbtm2AO3Rt27aN2NhYsrKyvB4XOdbyE60LFNWgGlTD2VnD2VKHagjtGvz1vizL4uDBg1SvXt3rgtqlKXc9NzabjZo1a/pl29HR0af93JK/ALGxscd9fKLlJ1oXKKpBNaiGs7OGs6UO1RDaNfhjmyfqsSmiAcUiIiISUhRuREREJKSUu8NS/lSrVi1sNhuWZREZGUlcXJxnXI/NZuOaa65hyZIldOjQgQULFnh+nn/++URERAAwcuRIz/2IiAivx0WOtfxE6wJFNagG1XB21nC21KEaQruGs+F9lbsBxSIiIhLadFhKREREQorCjYiIiIQUhRsREREJKQo3IiIiElIUbk5Dly5dMAwj6Lf4+Hh27dpFXl4ed999N5UqVSI8PJyEhATCw8Np3bq1p+b77ruPdu3aERER4bX8WIpmW65evTqGYTBlyhSv9ZZl8fTTT1OtWjWioqJITU1l/fr1Xm327dvHgAEDiI2NJT4+nqFDh5Kdne1Zn5eXx+DBg2nRogUOh4Orr776lGoYPHjwUfukZ8+ePq1h1KhRdOjQgZiYGJKSkrj66qtZt26dV5uS+79ixYr06dOHXbt2ebVJS0ujV69eVKhQgaSkJB555BGcTqdn/c6dO+nfvz+NGjXCZrPxwAMPnFIN3bt3P2pf3HHHHT6r4e2336Zly5aeSbk6d+7MtGnTArYPTqYGf++D0owePRrDMLzaBWJfnKgGf++LZ5555qjtN2nSJKD74EQ1BOr3Yfv27dx4441UqlSJqKgoWrRowcKFCz3rA/FZeaIaTuez8vrrr+f666/3bLN58+Zcfvnlnhouv/xy7rnnHmrWrElUVBTNmjXjnXfe8drme++9R/fu3YmNjcUwDA4cOHDU/gP43//+R6dOnYiKiiIhIeGo93c6FG5Ow5YtW3yynVO5/IPdbqdjx47Y7XYSExNJTU2lsLCQ3r178+CDD/Ltt9/yxRdf0Lt3b+Lj44mPjz9qGzfffDP9+vU7qdc7dOgQrVq1Yty4caWuHzNmDK+//jrvvPMO8+bNIzo6mh49epCXl+dpM2DAAFatWsWPP/7Id999x6+//sptt93mWe9yuYiKiuK+++4jNTX1lGsA6NmzJzt37vTcPvvsM6/1Z1rDL7/8wt13382ff/7Jjz/+SGFhIZdeeimHDh3ytCm5/3/55Rd27NhB7969vV6jV69eFBQUMGfOHD7++GM++ugjnn76aU+b/Px8qlSpwpNPPkmrVq1OuQaAW2+91WtfjBkzxmc11KxZk9GjR7No0SIWLlzIRRddxFVXXcWqVasCsg9OpgZ/74MjLViwgHfffZeWLVt6LQ/EvjhRDYHYF+ecc47X9n///feA74Pj1RCIfbB//366du1KWFgY06ZNY/Xq1bzyyiskJCR42vj7s/JkaoBT+6z87LPP+Oqrr5g/f75nmy+88AKxsbGeGlauXMn06dP55JNPWLNmDQ888AD33HMPU6dO9WwzJyeHnj178sQTT5T67wfw1VdfcdNNNzFkyBCWLVvGH3/8Qf/+/Y/Z/qRZctpGjhxpAad9q127tuVwOKyIiAjPMsMwLMByOBxebSMiIqywsDDr2muvtVq1amWNHDnSaty4saftF1984alrzZo1FmA1aNCg1JpbtWp1Su8TsCZPnux5bJqmVbVqVeull17yLDtw4IAVERFhffbZZ5ZlWdbq1astwFqwYIGnzbRp0yzDMKzt27cf9RqDBg2yrrrqqpOu4WSe4+saLMuyMjIyLMD65ZdfLMtyv++wsLBS9//cuXMty7Ks77//3rLZbFZ6erqnzdtvv23FxsZa+fn5R73GBRdcYN1///0nXcPJPMfXNViWZSUkJFj//ve/g7IPjqzhZJ7jyxoOHjxoNWzY0Prxxx+92gVyXxyrhkDsi+N9jgRqH5zosywQvw+PPfaYdd555x3zNQLxWXmiGkp7zpGOrOGxxx6zzjnnnOPWEBMTYz333HNey9u2bWuNGDHiqPY///yzBVj79+/3Wl5YWGjVqFHD8/+wL6nnJoi2bt2Ky+WioKDAs8w6PO3Qkb06BQUFFBYWMmPGDLZu3UpmZiaRkZEkJSXhdDq90nyTJk2Ii4sjJyfHL3Vv3ryZ9PR0r9eMi4ujU6dOzJ07F4C5c+cSHx9P+/btPW1SU1Ox2WzMmzfPZ7XMnj2bpKQkGjduzJ133snevXs96/xRQ2ZmJgCJiYkALFq0iMLCwqP2f61atbz2RYsWLUhOTva06dGjB1lZWV69DqdbQ5EJEyZQuXJlmjdvzvDhw73+/X1Zg8vlYuLEiRw6dIjOnTsHZR8cWUOg98Hdd99Nr169jvorOpD74lg1FPH3vli/fj3Vq1enXr16DBgwgLS0tIDvg2PVEKh9MHXqVNq3b8+1115LUlISbdq04f333/esD8Rn5YlqKHIqn5VTp07l4osvxrIsmjZtWuo2ExMTmTp1Ktu3b8eyLH7++Wf++usvLr300pPadwCLFy9m+/bt2Gw22rRpQ7Vq1bjssstYuXLlSW/jWDRD8RlYunTpGW/DsiyqVKnC7t27vZaXPO4LkJCQQFZWFpdffjmTJ09m/PjxpKSkULFiRfbu3XvUYajo6GgKCwvPuL7SpKenA3h9KBQ9LlqXnp5OUlKS13qHw0FiYqKnzZnq2bMnvXv3pm7dumzcuJEnnniCyy67jLlz52K3231eg2maPPDAA3Tt2pXmzZsD7vcZHh5+1P4/cl+Utq+K1p1pDQD9+/endu3aVK9eneXLl/PYY4+xbt06vv76a5/VsGLFCjp37kxeXh4VK1Zk8uTJNGvWjKVLlwZsHxyrhkDtA4CJEyeyePFiFixYcNS6QP0+HK8G8P++6NSpEx999BGNGzdm586dPPvss5x//vmsXLkyYPvgeDXExMQE5Pdh06ZNvP322wwbNownnniCBQsWcN999xEeHs6gQYMC8ll5ohrg1D8rN23axLvvvktUVBR33303derUOWqbLVq0IDExkZo1a+JwOLDZbLz//vt069btpPZd0euAe/zUq6++Sp06dXjllVfo3r07f/3111F/wJ0KhZvTtG3bNn777TefbGv37t3ExsaSlZXlWWYdMXF0hQoVyM7OpkGDBtSrV4/169dz4MABwsPDfVJDWXT99dd77rdo0YKWLVtSv359Zs+ezcUXX+zz17v77rtZuXLlUcf1A+lYNZQ8Pt+iRQuqVavGxRdfzMaNG6lfv75PXrtx48YsXbqUzMxMvvzySwYNGsQvv/zik22faQ3NmjULyD7Ytm0b999/Pz/++CORkZE+2aY/avD3vrjssss891u2bEmnTp2oXbs2n3/+OVFRUWe8/TOtYejQoQH5fTBNk/bt2/PCCy8A0KZNG1auXMk777zjCQH+djI1nOpnZdE2N2zYQEpKCrfddttR29y8eTN//fUXU6dOpXbt2vz666/cfffdVK9e/Zi9iaW9DsCIESPo06cPAOPHj6dmzZp88cUX3H777ae9X3RY6jQtWrSIffv2nfF27HY7wFGDQ4/kcDgoKCggLy8Pu91OpUqVKCgoIDs7G5fLddQo9EOHDhEWFnbG9ZWmatWqAEed/bBr1y7PuqpVq5KRkeG13ul0sm/fPk8bX6tXrx6VK1dmw4YNPq/hnnvu4bvvvuPnn3+mZs2anuVVq1aloKDgqP1/5L4obV8VrTvTGkrTqVMnAK99caY1hIeH06BBA9q1a8eoUaNo1aoVY8eODeg+OFYNpfHHPli0aBEZGRm0bdsWh8OBw+Hgl19+4fXXX8fhcJCcnOz3fXGiGlwu11HP8ce+KCk+Pp5GjRqxYcOGgP4+HKuG0vhjH1SrVs3Tc1ikadOmnsNjgfisPFENpTnRZ2W1atVo0qSJVw0lt+l0Olm9ejWvvvoqV1xxBS1btuSee+6hX79+vPzyyyesueTrAF71R0REUK9evePWfzIUbk6DZVl899132GxnvvtM08QwDM8H0rHOoIqKiiIsLIxNmzbhcrk8wSojIwOHw8HMmTM9bdetW0dmZiYVKlQ44/pKU7duXapWrer1mllZWcybN88z/qFz584cOHCARYsWedrMmjUL0zQ9HzK+9vfff7N3717P/zC+qMGyLO655x4mT57MrFmzqFu3rtf6du3aERYWdtT+T0tL89oXK1as8Prw+PHHH4mNjT3qQ+l0aihN0SHTkvviTGoojWma5OfnB2QfnKiG0vhjH1x88cWsWLGCpUuXem7t27dnwIABnvv+3hcnqqHoDyZ/74uSsrOz2bhxI9WqVQva70PJGkrjj33QtWvXo6Zl+Ouvv6hduzYQmM/KE9VQmhN9Vnbt2pX58+d71VBym6ZpYlnWUd+Bdrvd0xtzMoqmJylZf2FhIVu2bDlu/SfF50OUy4H+/fuf0VlSpd2KzpI61q1ixYpW8+bNrbCwMM8tPDzcatGihdW3b1+rVq1a1qxZs6zJkydbLVu2tJKTk61GjRpZS5YssZYsWWKtWrXKWrJkiXX77bd7LS/trADLcp+JUdQGsF599VVryZIl1tatWy3LsqzRo0db8fHx1jfffGMtX77cuuqqq6y6detaubm5nm307NnTatOmjTVv3jzr999/txo2bGjdcMMNXq9TVNcVV1xhde/e3fOaJ6rh4MGD1sMPP2zNnTvX2rx5s/XTTz9Zbdu2tRo2bGjl5eX5rIY777zTiouLs2bPnm3t3LnTc8vJyfE8/4477vDs/4ULF1qdO3e2Onfu7FnvdDqt5s2bW5deeqm1dOlSa/r06VaVKlWs4cOHe9VR9Lrt2rWz+vfv7/l3O1ENGzZssJ577jlr4cKF1ubNm61vvvnGqlevntWtWzef1fD4449bv/zyi7V582Zr+fLl1uOPP24ZhmHNmDEjIPvAsqzj1hCIfXAsR55FE4h9cbwaArEvHnroIWv27NnW5s2brT/++MNKTU21KleubGVkZARsHxyvhkD9PsyfP99yOBzWP//5T2v9+vXWhAkTrAoVKliffPKJ5/n+/qw8UQ2n81n5/vvvW4DVsmVLr22++OKLnhri4uKs+vXrW++//761adMma/z48VZkZKT11ltveba5c+dOa8mSJZ7t/frrr9aSJUusvXv3etrcf//9Vo0aNawffvjBWrt2rTV06FArKSnJ2rdvn3UmFG5Og6+DjS9uN954o5WQkGDZbLZS13fq1KnU5Zs3by71PRadunfkbdCgQZZluU9xfOqpp6zk5GQrIiLCuvjii61169Z5bWPv3r3WDTfcYFWsWNGKjY21hgwZYh08eNCrTe3atUt9nRPVkJOTY1166aVWlSpVrLCwMKt27drWrbfe6nVapy9qONb+Hj9+vOf5ubm51l133WUlJCRYFSpUsK655hpr586dXq+xZcsW67LLLrOioqKsypUrWw899JBVWFh4wt+rY9VWsoa0tDSrW7duVmJiohUREWE1aNDAeuSRR6zMzEyf1XDzzTdbtWvXtsLDw60qVapYF198sSfYBGIfWJZ13BoCsQ+O5chwE4h9cbwaArEv+vXrZ1WrVs0KDw+3atSoYfXr18/asGFDQPfB8WoI5O/Dt99+azVv3tyKiIiwmjRpYr333ntezw/EZ+Xxajjdz8rU1FSrWbNmXts8Vg2RkZFW48aNrVdeecUyTdOzzWNNl1Ly87OgoMB66KGHrKSkJCsmJsZKTU21Vq5caZ0pw7KOGLkqIiIiUoZpzI2IiIiEFIUbERERCSkKNyIiIhJSFG5EREQkpCjciIiISEhRuBEREZGQonAjIiIiIUXhRkREREKKwo2InBUsy+K2224jMTERwzBYunQp3bt354EHHvC0qVOnDq+99ppf65g5cyZNmzYt9QKUvjB48GCuvvrqk25fUFBAnTp1WLhwoV/qEQlFCjci5dDgwYMxDIPRo0d7LZ8yZcoxL97qb9OnT+ejjz7iu+++Y+fOnTRv3pyvv/6a559/PqB1PProozz55JOeC1A+88wztG7d2mfbHzt2LB999NFJtw8PD+fhhx/mscce81kNIqFO4UaknIqMjOTFF19k//79wS4FwHNF5y5dulC1alUcDgeJiYnExMQErIbff/+djRs30qdPn1N+bmFh4Um1i4uLIz4+/pS2PWDAAH7//XdWrVp1ynWJlEcKNyLlVGpqKlWrVmXUqFHHbFNar8Vrr71GnTp1PI+LDrO88MILJCcnEx8fz3PPPYfT6eSRRx4hMTGRmjVrMn78+GO+zuDBg7n33ntJS0vDMAzP9o88LHWkAwcOcMstt1ClShViY2O56KKLWLZsmWf9smXLuPDCC4mJiSE2NpZ27dod9/DOxIkTueSSS4iMjATgo48+4tlnn2XZsmUYhoFhGJ5eF8MwePvtt7nyyiuJjo7mn//8Jy6Xi6FDh1K3bl2ioqJo3LgxY8eOPeq9ljws1b17d+677z4effRREhMTqVq1Ks8884zXcxISEujatSsTJ048Zu0iUswR7AJEJDjsdjsvvPAC/fv357777qNmzZqnva1Zs2ZRs2ZNfv31V/744w+GDh3KnDlz6NatG/PmzWPSpEncfvvtXHLJJaW+ztixY6lfvz7vvfceCxYs8BwSOpFrr72WqKgopk2bRlxcHO+++y4XX3wxf/31F4mJiQwYMIA2bdrw9ttvY7fbWbp0KWFhYcfc3m+//Ub//v09j/v168fKlSuZPn06P/30E+DueSnyzDPPMHr0aF577TUcDgemaVKzZk2++OILKlWqxJw5c7jtttuoVq0a11133TFf9+OPP2bYsGHMmzePuXPnMnjwYLp27coll1ziadOxY0d+++23k9ovIuWdwo1IOXbNNdfQunVrRo4cyQcffHDa20lMTOT111/HZrPRuHFjxowZQ05ODk888QQAw4cPZ/To0fz+++9cf/31Rz0/Li6OmJgY7HY7VatWPanX/P3335k/fz4ZGRlEREQA8PLLLzNlyhS+/PJLbrvtNtLS0njkkUdo0qQJAA0bNjzuNrdu3Ur16tU9j6OioqhYsSIOh6PUuvr378+QIUO8lj377LOe+3Xr1mXu3Ll8/vnnxw03LVu2ZOTIkZ4a33zzTWbOnOkVbqpXr87WrVuPW7+IuOmwlEg59+KLL/Lxxx+zZs2a097GOeecg81W/HGSnJxMixYtPI/tdjuVKlUiIyPjjGotadmyZWRnZ1OpUiUqVqzouW3evJmNGzcCMGzYMG655RZSU1MZPXq0Z/mx5Obmeg5JnYz27dsftWzcuHG0a9eOKlWqULFiRd577z3S0tKOu52WLVt6Pa5WrdpR+yoqKoqcnJyTrk2kPFO4ESnnunXrRo8ePRg+fPhR62w2G5ZleS0rbeDskYd6DMModZlpmj6o2C07O5tq1aqxdOlSr9u6det45JFHAPdho1WrVtGrVy9mzZpFs2bNmDx58jG3Wbly5VMaYB0dHe31eOLEiTz88MMMHTqUGTNmsHTpUoYMGUJBQcFxt3My+2rfvn1UqVLlpGsTKc90WEpEGD16NK1bt6Zx48Zey6tUqUJ6ejqWZXlOEV+6dGkQKjxa27ZtSU9Px+FweA1wPlKjRo1o1KgRDz74IDfccAPjx4/nmmuuKbVtmzZtWL16tdey8PDwk57z5o8//qBLly7cddddnmUn6i06WStXrqRNmzY+2ZZIqFPPjYjQokULBgwYwOuvv+61vHv37uzevZsxY8awceNGxo0bx7Rp04JUpbfU1FQ6d+7M1VdfzYwZM9iyZQtz5sxhxIgRLFy4kNzcXO655x5mz57N1q1b+eOPP1iwYAFNmzY95jZ79OjB77//7rWsTp06bN68maVLl7Jnzx7y8/OP+fyGDRuycOFCfvjhB/766y+eeuopFixY4JP3+9tvv3HppZf6ZFsioU7hRkQAeO655446FNK0aVPeeustxo0bR6tWrZg/fz4PP/xwkCr0ZhgG33//Pd26dWPIkCE0atSI66+/nq1bt5KcnIzdbmfv3r0MHDiQRo0acd1113HZZZd5Dfg90oABA1i1ahXr1q3zLOvTpw89e/bkwgsvpEqVKnz22WfHfP7tt99O79696devH506dWLv3r1evTina+7cuWRmZtK3b98z3pZIeWBYRx5QFxEpxx555BGysrJ49913g12KR79+/WjVqpXn7DMROT713IiIlDBixAhq167t08HPZ6KgoIAWLVrw4IMPBrsUkTJDPTciIiISUtRzIyIiIiFF4UZERERCisKNiIiIhBSFGxEREQkpCjciIiISUhRuREREJKQo3IiIiEhIUbgRERGRkKJwIyIiIiHl/wF9VDd6aYXSPAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/dataset/isaid_class_7/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "FIB_FLAG = True\n",
    "PREV_NUM = 50\n",
    "THRESHOLD = 0.001\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "\n",
    "# exp_inc.train_test_val_split(KEEP_PERC)\n",
    "# cls_tl_dict, cls_fif_dict = exp_inc.take_piece(PIECE_PERC, FIB_FLAG)\n",
    "\n",
    "# exp_inc.increm_learning(KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "# exp_inc.plot_ram_usage()\n",
    "\n",
    "exp_inc.increm_learning_one_class('7', KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "exp_inc.plot_ram_usage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ae6cd4",
   "metadata": {
    "papermill": {
     "duration": 3.87945,
     "end_time": "2024-05-14T05:38:29.373356",
     "exception": false,
     "start_time": "2024-05-14T05:38:25.493906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Сравнение базового и инкрементального обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4de4a5e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.850572Z",
     "iopub.status.idle": "2023-11-08T18:23:06.850969Z",
     "shell.execute_reply": "2023-11-08T18:23:06.850802Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.850768Z"
    },
    "papermill": {
     "duration": 3.874445,
     "end_time": "2024-05-14T05:38:37.048145",
     "exception": false,
     "start_time": "2024-05-14T05:38:33.173700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/feet-14/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_base = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "result_dict_base = exp_base.base_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_base.plot_ram_usage()\n",
    "del(exp_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51e55a7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.852484Z",
     "iopub.status.idle": "2023-11-08T18:23:06.852881Z",
     "shell.execute_reply": "2023-11-08T18:23:06.852713Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.852691Z"
    },
    "papermill": {
     "duration": 3.888147,
     "end_time": "2024-05-14T05:38:44.849427",
     "exception": false,
     "start_time": "2024-05-14T05:38:40.961280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC, 1, 1)\n",
    "result_dict_inc, color_dict_inc = exp_inc.increm_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_inc.plot_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71366d07",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.854063Z",
     "iopub.status.idle": "2023-11-08T18:23:06.854396Z",
     "shell.execute_reply": "2023-11-08T18:23:06.854260Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.854245Z"
    },
    "papermill": {
     "duration": 3.889884,
     "end_time": "2024-05-14T05:38:52.599218",
     "exception": false,
     "start_time": "2024-05-14T05:38:48.709334",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import math \n",
    "\n",
    "map_base_list = [j[0] for j in result_dict_base.values()]\n",
    "map_inc_list = [j[0] for j in result_dict_inc.values()]\n",
    "mse = 0\n",
    "for map_base, map_inc in zip(map_base_list, map_inc_list):\n",
    "    dev = (map_base - map_inc)\n",
    "    mse += dev**2\n",
    "print(f\"MSE = {mse}\\nRMSE = {math.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c3965",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.856319Z",
     "iopub.status.idle": "2023-11-08T18:23:06.856674Z",
     "shell.execute_reply": "2023-11-08T18:23:06.856526Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.856509Z"
    },
    "papermill": {
     "duration": 3.703476,
     "end_time": "2024-05-14T05:39:00.197805",
     "exception": false,
     "start_time": "2024-05-14T05:38:56.494329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "for i, metric in enumerate(metrics_names):\n",
    "    plt.plot(list(result_dict_base.keys()),\n",
    "             [j[i] for j in result_dict_base.values()],\n",
    "             marker='o',\n",
    "             color=\"green\",\n",
    "             linestyle='-',\n",
    "             zorder=0,\n",
    "             label = \"Базовое обучение\")\n",
    "    \n",
    "    plt.scatter(list(result_dict_inc.keys()),\n",
    "                [j[i] for j in result_dict_inc.values()],\n",
    "                color=list(color_dict_inc.values()),\n",
    "                zorder=1)\n",
    "    plt.plot(list(result_dict_inc.keys()),\n",
    "             [j[i] for j in result_dict_inc.values()],\n",
    "             linestyle='-',\n",
    "             label = \"Инкрементальное обучение\")\n",
    "    \n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"Keep percent (%)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468497c8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.858132Z",
     "iopub.status.idle": "2023-11-08T18:23:06.858483Z",
     "shell.execute_reply": "2023-11-08T18:23:06.858342Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.858326Z"
    },
    "papermill": {
     "duration": 3.87086,
     "end_time": "2024-05-14T05:39:08.009331",
     "exception": false,
     "start_time": "2024-05-14T05:39:04.138471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "num_folders = 1 / PIECE_PERC\n",
    "for folder in range(int(num_folders)):\n",
    "    dir_path = f\"temp_{folder+1}/train/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/train/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), '\\n')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5000676,
     "sourceId": 8403939,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29642.115488,
   "end_time": "2024-05-14T05:39:15.786661",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-13T21:25:13.671173",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
