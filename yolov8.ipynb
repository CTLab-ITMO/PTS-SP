{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0466c95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T17:29:12.521799Z",
     "iopub.status.busy": "2023-11-28T17:29:12.521317Z",
     "iopub.status.idle": "2023-11-28T17:30:47.118268Z",
     "shell.execute_reply": "2023-11-28T17:30:47.117504Z"
    },
    "id": "tKyXaYbpvLMm",
    "outputId": "421a4599-fff2-4e30-9da2-d15013fbe64d",
    "papermill": {
     "duration": 94.606489,
     "end_time": "2023-11-28T17:30:47.120711",
     "exception": false,
     "start_time": "2023-11-28T17:29:12.514222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.0 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\r\n",
      "pytoolconfig 1.2.6 requires packaging>=22.0, but you have packaging 21.3 which is incompatible.\r\n",
      "tensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\r\n",
      "ydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m--2023-11-28 17:30:21--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\r\n",
      "Resolving github.com (github.com)... 140.82.112.3\r\n",
      "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231128%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231128T173021Z&X-Amz-Expires=300&X-Amz-Signature=05334157ceee0c480af4df685bb91fbfb65ef23499ab0e1a2c9c474feacb9bb7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream [following]\r\n",
      "--2023-11-28 17:30:21--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/a67767a2-6acf-4b1b-9d2a-2836e18fbcfd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231128%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231128T173021Z&X-Amz-Expires=300&X-Amz-Signature=05334157ceee0c480af4df685bb91fbfb65ef23499ab0e1a2c9c474feacb9bb7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8m-seg.pt&response-content-type=application%2Foctet-stream\r\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\r\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 54899779 (52M) [application/octet-stream]\r\n",
      "Saving to: ‘yolov8m-seg.pt’\r\n",
      "\r\n",
      "yolov8m-seg.pt      100%[===================>]  52.36M   230MB/s    in 0.2s    \r\n",
      "\r\n",
      "2023-11-28 17:30:22 (230 MB/s) - ‘yolov8m-seg.pt’ saved [54899779/54899779]\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.219, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in feet-14 to yolov8:: 100%|██████████| 696075/696075 [00:12<00:00, 55948.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to feet-14 in yolov8:: 100%|██████████| 9508/9508 [00:02<00:00, 3925.56it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip -q install roboflow\n",
    "!pip -q install ultralytics\n",
    "! pip -q install ruamel.yaml\n",
    "! wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import sys\n",
    "import ruamel.yaml\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import psutil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import locale\n",
    "from IPython.display import clear_output\n",
    "import ctypes\n",
    "import ctypes.util\n",
    "import torch\n",
    "import random\n",
    "\n",
    "\n",
    "# deterministic set\n",
    "torch.manual_seed(43)\n",
    "random.seed(43)\n",
    "np.random.seed(43)\n",
    "\n",
    "\n",
    "rf = Roboflow(api_key=\"tD9RSesaXxGqmwVD6eVZ\")\n",
    "project = rf.workspace(\"roboarm\").project(\"feet-qevah\")\n",
    "dataset = project.version(14).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb8ff5a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T17:30:47.156531Z",
     "iopub.status.busy": "2023-11-28T17:30:47.156103Z",
     "iopub.status.idle": "2023-11-28T17:30:47.189641Z",
     "shell.execute_reply": "2023-11-28T17:30:47.188644Z"
    },
    "papermill": {
     "duration": 0.053388,
     "end_time": "2023-11-28T17:30:47.191513",
     "exception": false,
     "start_time": "2023-11-28T17:30:47.138125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/feet-14\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/feet-14\n",
    "\n",
    "# trying to optimize RAM usage\n",
    "gc.enable()\n",
    "\n",
    "libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8eb0331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T17:30:47.227881Z",
     "iopub.status.busy": "2023-11-28T17:30:47.227585Z",
     "iopub.status.idle": "2023-11-28T17:30:47.325003Z",
     "shell.execute_reply": "2023-11-28T17:30:47.324208Z"
    },
    "papermill": {
     "duration": 0.118625,
     "end_time": "2023-11-28T17:30:47.327267",
     "exception": false,
     "start_time": "2023-11-28T17:30:47.208642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YoloModel:\n",
    "    def __init__(self, path_to_model: str, path_to_yaml: str,\n",
    "                 train_perc: float, test_perc: float, val_perc: float,\n",
    "                 ttvs_flag = 0, tp_flag = 0):\n",
    "        \"\"\"Инициализация переменных\n",
    "\n",
    "        Args:\n",
    "            path_to_model (str): путь до весов yolov8.pt\n",
    "            path_to_yaml (str): путь до data.yaml файла датасета\n",
    "            train_perc (float): доля тренировочных данных \n",
    "            test_perc (float): доля тестовых данных\n",
    "            val_perc (float): доля валидационных данных\n",
    "        \"\"\"        \n",
    "        self.path_to_model = path_to_model\n",
    "        self.path_to_yaml = path_to_yaml\n",
    "        self.train_path = Path('train') if os.path.exists(Path('train')) else None\n",
    "        self.test_path = Path('test') if os.path.exists(Path('test')) else None\n",
    "        self.val_path = Path('valid') if os.path.exists(Path('valid')) else None\n",
    "        self.train_perc = train_perc\n",
    "        self.test_perc = test_perc\n",
    "        self.val_perc = val_perc\n",
    "        \n",
    "        self.ttvs_flag = ttvs_flag\n",
    "        self.tp_flag = tp_flag\n",
    "        \n",
    "        self.ram_usage = []\n",
    "        \n",
    "        assert self.train_path != None, 'Директория train отсутствует'\n",
    "        if (self.val_path == None):\n",
    "            os.mkdir(\"valid\", mode=0o777)\n",
    "            os.mkdir(\"valid/images\", mode=0o777)\n",
    "            os.mkdir(\"valid/labels\", mode=0o777)\n",
    "            self.val_path = Path(\"valid\")\n",
    "        if (self.test_path == None):\n",
    "            os.mkdir(\"test\", mode=0o777)\n",
    "            os.mkdir(\"test/images\", mode=0o777)\n",
    "            os.mkdir(\"test/labels\", mode=0o777)\n",
    "            self.test_path = Path(\"test\")\n",
    "    \n",
    "    def get_ram_usage(self,):\n",
    "        \"\"\"Gets the current RAM usage of the system.\n",
    "\n",
    "        Returns:\n",
    "            float: RAM usage in GB.\n",
    "        \"\"\"\n",
    "        return psutil.virtual_memory().used / 1e9\n",
    "\n",
    "    def train(self, folder_name: str, iters: int) -> YOLO: \n",
    "        \"\"\"Инициализация модели и обучение\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): название директории с частью данных\n",
    "            iters (int): кол-во интераций\n",
    "\n",
    "        Returns:\n",
    "            YOLO: экземпляр обученной модели\n",
    "        \"\"\"        \n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        # yaml.preserve_quotes = True\n",
    "        with open('data.yaml', 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = './'+folder_name+'/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(\n",
    "            # Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def retrain(self, folder_name: str, iters: int,) -> YOLO:\n",
    "        \"\"\"Обучение модели на всех предыдущих частях данных для профилакти просадки метрики\n",
    "\n",
    "        Args:\n",
    "            folder_name (str): название директории с частью данных\n",
    "            iters (int): кол-во интераций\n",
    "\n",
    "        Returns:\n",
    "            YOLO: экземпляр обученной модели\n",
    "        \"\"\"        \n",
    "        os.mkdir(\"retrain\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/images\", mode=0o777)\n",
    "        os.mkdir(\"retrain/train/labels\", mode=0o777)\n",
    "\n",
    "        # собираем список всех кусков данных до нашего folder_name\n",
    "        folder_num = np.arange(1, int(folder_name.split('_')[-1]) + 1)\n",
    "        cls = folder_name.split(\"_\")[1]\n",
    "        source_pathes = [f\"temp_{cls}_{i}\" for i in folder_num]\n",
    "\n",
    "        # копируем все собранные куски данных в папку retrain\n",
    "        for path in source_pathes:\n",
    "            # собираем все файлы\n",
    "            all_images_train = os.listdir(path+\"/train/images\")\n",
    "            all_labels_train = os.listdir(path+\"/train/labels\")\n",
    "\n",
    "            for image in all_images_train:\n",
    "                shutil.copyfile(path+\"/train/images/\" + image,\n",
    "                                \"retrain/train/images/\" + image)\n",
    "            for label in all_labels_train:\n",
    "                shutil.copyfile(path+\"/train/labels/\" + label,\n",
    "                                \"retrain/train/labels/\" + label)\n",
    "\n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open('data.yaml', 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "        \n",
    "        self.ram_usage.append(self.get_ram_usage())\n",
    "        # load a pretrained model (recommended for training)\n",
    "        model = YOLO(self.path_to_model)\n",
    "        model.train(# Random Seed parameters\n",
    "            deterministic=True,\n",
    "            seed=43,\n",
    "            data=self.path_to_yaml, \n",
    "            pretrained=True,\n",
    "            exist_ok=True,\n",
    "            epochs=iters,\n",
    "            optimizer=\"SGD\",\n",
    "            device=0,)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def test(self, folder_name: str, model: YOLO):\n",
    "        \"\"\"Тестирование модели\n",
    "\n",
    "        Args:\n",
    "            model (YOLO): экземпляр обученной модели\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"        \n",
    "        # Корректируем data.yaml файл\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        with open('data.yaml', 'r+') as fp:\n",
    "            data = yaml.load(fp)\n",
    "            for elem in data:\n",
    "                if elem == 'train':\n",
    "                    data[elem] = 'retrain/train/images'\n",
    "                elif elem == 'val':\n",
    "                    data[elem] = f\"./valid_{folder_name.split('_')[1]}/images\"\n",
    "                elif elem == 'test':\n",
    "                    data[elem] = f\"./test_{folder_name.split('_')[1]}/images\"\n",
    "            fp.truncate(0)\n",
    "            fp.seek(0)\n",
    "            yaml.dump(data, fp)\n",
    "            \n",
    "        metrics = model.val(data=self.path_to_yaml, split=\"test\")\n",
    "        return metrics\n",
    "    \n",
    "    def train_test_val_split(self, keep_perc: float):\n",
    "        \"\"\"Разделение изначального датасета на заданные доли train/test/val. Удаление 1-keep_perc доли данных \n",
    "\n",
    "        Args:\n",
    "            keep_perc (float): доля данных, которую нужно оставить\n",
    "        \"\"\"        \n",
    "        # создаем директории для объединения всех файлов\n",
    "        os.mkdir(\"temp\", mode=0o777)\n",
    "        os.mkdir(\"temp/images\", mode=0o777)\n",
    "        os.mkdir(\"temp/labels\", mode=0o777)\n",
    "            \n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels',\\\n",
    "                        self.test_path / 'images', self.test_path / 'labels',\\\n",
    "                        self.val_path / 'images', self.val_path / 'labels',)\n",
    "        destination = Path('temp')\n",
    "\n",
    "        for path in source_pathes:\n",
    "            # собираем все файлы\n",
    "            allfiles = os.listdir(path)\n",
    "            # итерируем по всем файлам, чтобы переместить их в папку назначения\n",
    "            sub_folder = path.name # images or labels\n",
    "            for f in allfiles:\n",
    "                src_path = os.path.join(path, f)\n",
    "                dst_path = os.path.join(destination / sub_folder, f)\n",
    "                os.rename(src_path, dst_path)\n",
    "        total_num = len(allfiles)\n",
    "        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"temp/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n",
    "                # а остальное - координаты сегментации\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"Пустой файл: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "        print(f\"Кол-во пустых файлов - {empty_count}\")\n",
    "        # Оставляем указанный процент данных\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(pathes)\n",
    "            num_to_del = num_files*(1-keep_perc)\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 >= num_to_del:\n",
    "                    break\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                try:\n",
    "                    Path(\"temp\",'images',\".\".join(f)).unlink()\n",
    "                    file_path.unlink()\n",
    "                except OSError as e:\n",
    "                    # Файл не найден (скорее всего имеет несколько классов и был уже перемещен)\n",
    "                    pass\n",
    "                classes[cls].remove(file_path)\n",
    "        for cls in classes.keys():\n",
    "            os.mkdir(f\"valid_{cls}\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}\", mode=0o777)\n",
    "\n",
    "\n",
    "            os.mkdir(f\"valid_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"valid_{cls}/images\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/labels\", mode=0o777)\n",
    "            os.mkdir(f\"test_{cls}/images\", mode=0o777)\n",
    "        # Распределяем данные по директориям train, test, val с учетом указанных пропорций\n",
    "        class_copy = copy.deepcopy(classes)\n",
    "        for cls, pathes in zip(list(classes.keys()), list(classes.values())):\n",
    "            num_files = len(class_copy[cls])\n",
    "            num_to_mv_train = int(num_files * self.train_perc)\n",
    "            num_to_mv_test = int(num_files * self.test_perc)\n",
    "            num_to_mv_val = int(num_files * self.val_perc)\n",
    "            # print(num_files, num_to_mv, len(pathes))\n",
    "            temp_dict_name = \"train\"\n",
    "            for i, file_path in enumerate(pathes.copy()):\n",
    "                if i+1 > num_to_mv_train and i+1 < num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"valid_{cls}\"\n",
    "                elif i+1 > num_to_mv_val + num_to_mv_train:\n",
    "                    temp_dict_name = f\"test_{cls}\"\n",
    "                f = file_path.name.split('.')[:-1]\n",
    "                f.append('jpg')\n",
    "                shutil.copyfile(Path(\"temp\", \"images\", \".\".join(f)),\n",
    "                                Path(temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                shutil.copyfile(file_path,\n",
    "                                Path(temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                if temp_dict_name != \"train\":\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                classes[cls].remove(file_path)\n",
    "            dir_path = f\"valid_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "            dir_path = f\"test_{cls}/images\"\n",
    "            print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "        dir_path = f\"train/labels\"\n",
    "        print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        \n",
    "        shutil.rmtree(\"temp\")\n",
    "    \n",
    "    def __train_set_of(self,n):\n",
    "        x = []\n",
    "        temp = 2\n",
    "        while temp < n:\n",
    "            x.append(temp)\n",
    "            if temp < 10:\n",
    "                temp+=2\n",
    "            elif temp >= 10 and temp < 30:\n",
    "                temp += 3\n",
    "            elif temp >= 30 and temp < 100:\n",
    "                temp += 5\n",
    "            elif temp >= 100 and temp < 200:\n",
    "                temp += 10\n",
    "            elif temp >= 200 and temp < 300:\n",
    "                temp += 50\n",
    "            elif temp >= 300 and temp < 500:\n",
    "                temp +=100\n",
    "            elif temp >= 500:\n",
    "                temp += 500\n",
    "        if x[-1] != n:\n",
    "            x.append(n)\n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "    def take_piece(self, piece_perc: float = None, fib_flag:bool = False) -> (dict, dict):\n",
    "        \"\"\"Разделение исходного датасета на части равные доле piece_perc по директориям temp_{n}, n = {1..1/piece_perc}\n",
    "\n",
    "        Args:\n",
    "            piece_perc (float): доля части данных, на которые нужно поделить датасет\n",
    "        \"\"\"\n",
    "\n",
    "        source_pathes = (self.train_path / 'images', self.train_path / 'labels')\n",
    "        \n",
    "        # Создаем словарь, где ключ - метка класса, значение - множество путей к label файлам данного класса\n",
    "        classes = defaultdict(set)\n",
    "        empty_count = 0\n",
    "        for txt_path in Path(\"train/labels\").glob(\"*.txt\"):\n",
    "            with txt_path.open() as f:\n",
    "                text = f.read()\n",
    "                # Каждому объекту на изображении соотвествует одна строка, где первое значение - метка класса,\n",
    "                # а остальное - координаты сегментации\n",
    "                for obj in text.split('\\n'):\n",
    "                    if len(obj) > 0:\n",
    "                        classes[obj.split()[0]].add(txt_path)\n",
    "                    else:\n",
    "                        print(f\"Пустой файл: {txt_path}\")\n",
    "                        empty_count += 1\n",
    "                        \n",
    "        print(f\"Кол-во пустых файлов - {empty_count}\")\n",
    "        d_c = {key: len(value) for key, value in zip(classes.keys(), classes.values())}\n",
    "        print(*[f\"Класс {key} содержит {value} объекта(-ов)\\n\" for key, value in zip(d_c.keys(), d_c.values())])\n",
    "        \n",
    "        cls_tl_dict = defaultdict(list) # key - class, value - result of __train_set_of(n)\n",
    "        cls_fif_dict = defaultdict(int) # key - class, value - num folders\n",
    "        # Разделить сначала по классам, а потом внутри класса разделить по __train_set_of\n",
    "        for cls in classes.keys():\n",
    "            print(f\"Класс {cls}\")\n",
    "            total_num = len(classes[cls])\n",
    "            print(f\"\\tКол-во train класса {cls}: {total_num}\")\n",
    "            if fib_flag == True:\n",
    "                n = total_num\n",
    "                train_list = self.__train_set_of(n)\n",
    "                files_in_folder = []\n",
    "                for i in range(len(train_list)):\n",
    "                    if i == 0:\n",
    "                        files_in_folder.append(train_list[i])\n",
    "                        continue\n",
    "                    files_in_folder.append(train_list[i] - train_list[i-1])\n",
    "                print(f\"\\tКоличество данных (train) на каждой итерации класса {cls}: {train_list}\")\n",
    "                cls_tl_dict[cls] = train_list\n",
    "                cls_fif_dict[cls] = len(files_in_folder)\n",
    "\n",
    "            if fib_flag == True:\n",
    "                self.num_folders = len(files_in_folder)\n",
    "                print(f\"\\tКол-во директорий для класса {cls}: {self.num_folders} \")\n",
    "            else:\n",
    "                self.num_folders = 1 / piece_perc\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train\", mode=0o777)\n",
    "\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/labels\", mode=0o777)\n",
    "                os.mkdir(f\"temp_{cls}_{folder+1}/train/images\", mode=0o777)\n",
    "            \n",
    "            # Распределяем данные по директориям  \n",
    "            class_copy = copy.deepcopy(classes)\n",
    "            for f_i, folder in enumerate(range(int(self.num_folders))):\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                num_to_mv_train = int(num_files * piece_perc) if fib_flag == False else files_in_folder[f_i]\n",
    "                print(f\"\\tnum_to_mv_train {num_to_mv_train}, folder {folder}, cls {cls}\")\n",
    "                # print(num_files, num_to_mv, len(pathes))\n",
    "                temp_dict_name = \"train\"\n",
    "                for i, file_path in enumerate(classes[cls].copy()):\n",
    "                    if i+1 > num_to_mv_train:\n",
    "                        break\n",
    "                    f = file_path.name.split('.')[:-1]\n",
    "                    f.append('jpg')\n",
    "                    shutil.copyfile(Path(\"train\", \"images\", \".\".join(f)),\n",
    "                                    Path(folder_name, temp_dict_name, \"images\").joinpath(Path(\"train\", \"images\", \".\".join(f)).name))\n",
    "                    shutil.copyfile(file_path,\n",
    "                                    Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))\n",
    "                    # remove another classes in label file\n",
    "                    orig_lines = [line.strip() for line in open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name))]\n",
    "                    new_lines = [l for l in orig_lines if l.split()[0] == str(cls)]\n",
    "\n",
    "                    with open(Path(folder_name, temp_dict_name, \"labels\").joinpath(file_path.name), 'w') as fp:\n",
    "                        print(*new_lines, sep='\\n', file=fp)\n",
    "                    classes[cls].remove(file_path)\n",
    "            for folder in range(int(self.num_folders)):\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/labels\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "                dir_path = f\"temp_{cls}_{folder+1}/train/images\"\n",
    "                print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), \"\\n\")\n",
    "        return cls_tl_dict, cls_fif_dict\n",
    "    \n",
    "    def plot_result(self, result_dict: dict, color_dict = \"green\", fib_list:list = None):\n",
    "        '''Функция для отрисовки графиков зависимости метрик от размера обучающей выборки\n",
    "\n",
    "        Args:\n",
    "            result_dict (dict): словарь с метриками {доля данных: массив метрик}\n",
    "            color_dict (dict): словарь с индикаторами повторного обучения\n",
    "        '''\n",
    "        metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "        colors = list(color_dict.values()) if color_dict != 'green' else color_dict\n",
    "        if fib_list == None:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(list(result_dict.keys()), [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(list(result_dict.keys()), [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(result_dict.keys())) \n",
    "                plt.show()\n",
    "        else:\n",
    "            for i, metric in enumerate(metrics_names):\n",
    "                plt.scatter(fib_list, [j[i] for j in result_dict.values()], color=colors, zorder=1)\n",
    "                plt.plot(fib_list, [j[i] for j in result_dict.values()], linestyle='-')\n",
    "                plt.ylabel(metric)\n",
    "                plt.xlabel(\"Num files (train)\")\n",
    "                plt.xticks(ticks=list(fib_list)) \n",
    "                plt.show()\n",
    "\n",
    "    def plot_ram_usage(self,):\n",
    "        '''Функция для отрисовки использования RAM в процессе обучения'''\n",
    "        plt.plot(self.ram_usage, marker='o', linestyle='-', color='b')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('RAM Usage (GB)')\n",
    "        plt.title('RAM Usage During Training')\n",
    "        plt.show()\n",
    "    \n",
    "    def __early_stopping(self, result_dict: dict, prev_num: int, threshold: float) -> bool:\n",
    "        keys_sorted = sorted(result_dict.keys())\n",
    "        prev_results = np.array([result_dict[i][0] for i in keys_sorted[-prev_num-1:-1]])\n",
    "        res = result_dict[keys_sorted[-1]][0] - prev_results\n",
    "        print(f\"Progress for {prev_num} last iterations with {threshold} threshold = {np.sum(res)}\")\n",
    "        if np.sum(res) < threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def increm_learning(self, keep_perc: float, iters: int, piece_perc:float = None, fib_flag:bool = None, prev_num:int = 3, threshold:float = 0.01) -> (list,list):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            cls_tl_dict, cls_fif_dict = self.take_piece(piece_perc, fib_flag)\n",
    "            self.tp = 1\n",
    "        else:\n",
    "            assert fib_flag == False\n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        # Инкрементальное обучение \n",
    "        for cls in cls_tl_dict.keys():\n",
    "            result_dict = defaultdict(list)\n",
    "            # словарь с индикаторами повторного обучения\n",
    "            color_dict = defaultdict(str)\n",
    "            # переменная для отслеживания максимального map в целях профилактики просадок метрики\n",
    "            max_map = 0\n",
    "            self.path_to_model = native_path_to_model\n",
    "            for folder in range(cls_fif_dict[cls]):\n",
    "                if (folder > prev_num):\n",
    "                    if self.__early_stopping(result_dict, prev_num, threshold):\n",
    "                        break\n",
    "                libc = ctypes.CDLL(ctypes.util.find_library('c'))\n",
    "                libc.malloc_trim(ctypes.c_int(0))\n",
    "\n",
    "                torch.set_num_threads(1)\n",
    "                folder_name = f\"temp_{cls}_{folder+1}\"\n",
    "                # дообучаем модель\n",
    "                model = self.train(folder_name, iters)\n",
    "                # тестируем модель\n",
    "                metrics = self.test(folder_name, model)\n",
    "                # проверяем, что метрика улучшается\n",
    "                if metrics.seg.map > max_map:\n",
    "                    max_map = metrics.seg.map\n",
    "                    # заносим метрики в словарь\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"green\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                else:\n",
    "                    self.path_to_model = native_path_to_model\n",
    "                    # дообучаем модель\n",
    "                    model = self.retrain(folder_name, iters)\n",
    "                    # тестируем модель\n",
    "                    metrics = self.test(folder_name, model)\n",
    "                    if metrics.seg.map > max_map:\n",
    "                        max_map = metrics.seg.map\n",
    "                    # заносим метрики в словарь\n",
    "                    result_dict[folder].append(metrics.seg.map)\n",
    "                    result_dict[folder].append(metrics.seg.map50)\n",
    "                    result_dict[folder].append(metrics.seg.map75)\n",
    "                    color_dict[folder] = \"blue\"\n",
    "#                     clear_output(wait=True)\n",
    "                    del(model)\n",
    "                    del(metrics)\n",
    "                    gc.collect()\n",
    "                    self.path_to_model = \"./runs/segment/train/weights/last.pt\"\n",
    "                    shutil.rmtree(\"retrain\")\n",
    "                \n",
    "            print(f\"Итоговый результат (инкрементальное обучение) для класса {cls}: \\n {result_dict}\")\n",
    "            print(f\"Количество данных (train) для класса {cls}: {cls_tl_dict[cls]}\")\n",
    "            self.plot_result(result_dict, color_dict) if fib_flag == False else self.plot_result(result_dict, color_dict, cls_tl_dict[cls][:len(result_dict.keys())])\n",
    "\n",
    "    def base_learning(self, keep_perc: float, piece_perc: float, iters: int):\n",
    "        os.environ['WANDB_DISABLED'] = 'true'\n",
    "        # делим датасет на тренировочную/тестовую/валидационную выборку\n",
    "        if self.ttvs_flag == 0:\n",
    "            self.train_test_val_split(keep_perc)\n",
    "            self.ttvs = 1\n",
    "        if self.tp_flag == 0:\n",
    "            self.take_piece(piece_perc)\n",
    "            self.tp_flag = 1\n",
    "        else: \n",
    "            self.num_folders = 1 / piece_perc\n",
    "        # путь к изначальным весам yolov8 для повторного обучения при понижении метрики\n",
    "        native_path_to_model = self.path_to_model\n",
    "        # словарь с метриками {доля данных: массив метрик}\n",
    "        result_dict = {k_p:[] for k_p in range(int(self.num_folders))}\n",
    "        \n",
    "        for folder in range(int(self.num_folders)):\n",
    "            folder_name = f\"temp_{folder+1}\"\n",
    "            # дообучаем модель\n",
    "            model = self.retrain(folder_name, iters)\n",
    "            # тестируем модель\n",
    "            metrics = self.test(model)\n",
    "            # заносим метрики в словарь\n",
    "            result_dict[folder].append(metrics.seg.map)\n",
    "            result_dict[folder].append(metrics.seg.map50)\n",
    "            result_dict[folder].append(metrics.seg.map75)\n",
    "            clear_output(wait=True)\n",
    "            del(model)\n",
    "            del(metrics)\n",
    "            gc.collect()\n",
    "            shutil.rmtree(\"retrain\")\n",
    "            \n",
    "        print(f\"Итоговый результат (базовое обучение): \\n {result_dict}\")\n",
    "        self.plot_result(result_dict)\n",
    "        \n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eabeb840",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T17:30:47.363955Z",
     "iopub.status.busy": "2023-11-28T17:30:47.363265Z",
     "iopub.status.idle": "2023-11-29T04:20:50.708475Z",
     "shell.execute_reply": "2023-11-29T04:20:50.707338Z"
    },
    "papermill": {
     "duration": 39006.761676,
     "end_time": "2023-11-29T04:20:54.106837",
     "exception": false,
     "start_time": "2023-11-28T17:30:47.345161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во пустых файлов - 0\n",
      "valid_0/images 474\n",
      "test_0/images 476\n",
      "valid_1/images 474\n",
      "test_1/images 476\n",
      "train/labels 3798 \n",
      "\n",
      "Кол-во пустых файлов - 0\n",
      "Класс 1 содержит 3798 объекта(-ов)\n",
      " Класс 0 содержит 3798 объекта(-ов)\n",
      "\n",
      "Класс 1\n",
      "\tКол-во train класса 1: 3798\n",
      "\tКоличество данных (train) на каждой итерации класса 1: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 3798]\n",
      "\tКол-во директорий для класса 1: 47 \n",
      "\tnum_to_mv_train 2, folder 0, cls 1\n",
      "\tnum_to_mv_train 2, folder 1, cls 1\n",
      "\tnum_to_mv_train 2, folder 2, cls 1\n",
      "\tnum_to_mv_train 2, folder 3, cls 1\n",
      "\tnum_to_mv_train 2, folder 4, cls 1\n",
      "\tnum_to_mv_train 3, folder 5, cls 1\n",
      "\tnum_to_mv_train 3, folder 6, cls 1\n",
      "\tnum_to_mv_train 3, folder 7, cls 1\n",
      "\tnum_to_mv_train 3, folder 8, cls 1\n",
      "\tnum_to_mv_train 3, folder 9, cls 1\n",
      "\tnum_to_mv_train 3, folder 10, cls 1\n",
      "\tnum_to_mv_train 3, folder 11, cls 1\n",
      "\tnum_to_mv_train 5, folder 12, cls 1\n",
      "\tnum_to_mv_train 5, folder 13, cls 1\n",
      "\tnum_to_mv_train 5, folder 14, cls 1\n",
      "\tnum_to_mv_train 5, folder 15, cls 1\n",
      "\tnum_to_mv_train 5, folder 16, cls 1\n",
      "\tnum_to_mv_train 5, folder 17, cls 1\n",
      "\tnum_to_mv_train 5, folder 18, cls 1\n",
      "\tnum_to_mv_train 5, folder 19, cls 1\n",
      "\tnum_to_mv_train 5, folder 20, cls 1\n",
      "\tnum_to_mv_train 5, folder 21, cls 1\n",
      "\tnum_to_mv_train 5, folder 22, cls 1\n",
      "\tnum_to_mv_train 5, folder 23, cls 1\n",
      "\tnum_to_mv_train 5, folder 24, cls 1\n",
      "\tnum_to_mv_train 5, folder 25, cls 1\n",
      "\tnum_to_mv_train 10, folder 26, cls 1\n",
      "\tnum_to_mv_train 10, folder 27, cls 1\n",
      "\tnum_to_mv_train 10, folder 28, cls 1\n",
      "\tnum_to_mv_train 10, folder 29, cls 1\n",
      "\tnum_to_mv_train 10, folder 30, cls 1\n",
      "\tnum_to_mv_train 10, folder 31, cls 1\n",
      "\tnum_to_mv_train 10, folder 32, cls 1\n",
      "\tnum_to_mv_train 10, folder 33, cls 1\n",
      "\tnum_to_mv_train 10, folder 34, cls 1\n",
      "\tnum_to_mv_train 10, folder 35, cls 1\n",
      "\tnum_to_mv_train 50, folder 36, cls 1\n",
      "\tnum_to_mv_train 50, folder 37, cls 1\n",
      "\tnum_to_mv_train 100, folder 38, cls 1\n",
      "\tnum_to_mv_train 100, folder 39, cls 1\n",
      "\tnum_to_mv_train 500, folder 40, cls 1\n",
      "\tnum_to_mv_train 500, folder 41, cls 1\n",
      "\tnum_to_mv_train 500, folder 42, cls 1\n",
      "\tnum_to_mv_train 500, folder 43, cls 1\n",
      "\tnum_to_mv_train 500, folder 44, cls 1\n",
      "\tnum_to_mv_train 500, folder 45, cls 1\n",
      "\tnum_to_mv_train 297, folder 46, cls 1\n",
      "temp_1_1/train/labels 2\n",
      "temp_1_1/train/images 2 \n",
      "\n",
      "temp_1_2/train/labels 2\n",
      "temp_1_2/train/images 2 \n",
      "\n",
      "temp_1_3/train/labels 2\n",
      "temp_1_3/train/images 2 \n",
      "\n",
      "temp_1_4/train/labels 2\n",
      "temp_1_4/train/images 2 \n",
      "\n",
      "temp_1_5/train/labels 2\n",
      "temp_1_5/train/images 2 \n",
      "\n",
      "temp_1_6/train/labels 3\n",
      "temp_1_6/train/images 3 \n",
      "\n",
      "temp_1_7/train/labels 3\n",
      "temp_1_7/train/images 3 \n",
      "\n",
      "temp_1_8/train/labels 3\n",
      "temp_1_8/train/images 3 \n",
      "\n",
      "temp_1_9/train/labels 3\n",
      "temp_1_9/train/images 3 \n",
      "\n",
      "temp_1_10/train/labels 3\n",
      "temp_1_10/train/images 3 \n",
      "\n",
      "temp_1_11/train/labels 3\n",
      "temp_1_11/train/images 3 \n",
      "\n",
      "temp_1_12/train/labels 3\n",
      "temp_1_12/train/images 3 \n",
      "\n",
      "temp_1_13/train/labels 5\n",
      "temp_1_13/train/images 5 \n",
      "\n",
      "temp_1_14/train/labels 5\n",
      "temp_1_14/train/images 5 \n",
      "\n",
      "temp_1_15/train/labels 5\n",
      "temp_1_15/train/images 5 \n",
      "\n",
      "temp_1_16/train/labels 5\n",
      "temp_1_16/train/images 5 \n",
      "\n",
      "temp_1_17/train/labels 5\n",
      "temp_1_17/train/images 5 \n",
      "\n",
      "temp_1_18/train/labels 5\n",
      "temp_1_18/train/images 5 \n",
      "\n",
      "temp_1_19/train/labels 5\n",
      "temp_1_19/train/images 5 \n",
      "\n",
      "temp_1_20/train/labels 5\n",
      "temp_1_20/train/images 5 \n",
      "\n",
      "temp_1_21/train/labels 5\n",
      "temp_1_21/train/images 5 \n",
      "\n",
      "temp_1_22/train/labels 5\n",
      "temp_1_22/train/images 5 \n",
      "\n",
      "temp_1_23/train/labels 5\n",
      "temp_1_23/train/images 5 \n",
      "\n",
      "temp_1_24/train/labels 5\n",
      "temp_1_24/train/images 5 \n",
      "\n",
      "temp_1_25/train/labels 5\n",
      "temp_1_25/train/images 5 \n",
      "\n",
      "temp_1_26/train/labels 5\n",
      "temp_1_26/train/images 5 \n",
      "\n",
      "temp_1_27/train/labels 10\n",
      "temp_1_27/train/images 10 \n",
      "\n",
      "temp_1_28/train/labels 10\n",
      "temp_1_28/train/images 10 \n",
      "\n",
      "temp_1_29/train/labels 10\n",
      "temp_1_29/train/images 10 \n",
      "\n",
      "temp_1_30/train/labels 10\n",
      "temp_1_30/train/images 10 \n",
      "\n",
      "temp_1_31/train/labels 10\n",
      "temp_1_31/train/images 10 \n",
      "\n",
      "temp_1_32/train/labels 10\n",
      "temp_1_32/train/images 10 \n",
      "\n",
      "temp_1_33/train/labels 10\n",
      "temp_1_33/train/images 10 \n",
      "\n",
      "temp_1_34/train/labels 10\n",
      "temp_1_34/train/images 10 \n",
      "\n",
      "temp_1_35/train/labels 10\n",
      "temp_1_35/train/images 10 \n",
      "\n",
      "temp_1_36/train/labels 10\n",
      "temp_1_36/train/images 10 \n",
      "\n",
      "temp_1_37/train/labels 50\n",
      "temp_1_37/train/images 50 \n",
      "\n",
      "temp_1_38/train/labels 50\n",
      "temp_1_38/train/images 50 \n",
      "\n",
      "temp_1_39/train/labels 100\n",
      "temp_1_39/train/images 100 \n",
      "\n",
      "temp_1_40/train/labels 100\n",
      "temp_1_40/train/images 100 \n",
      "\n",
      "temp_1_41/train/labels 500\n",
      "temp_1_41/train/images 500 \n",
      "\n",
      "temp_1_42/train/labels 500\n",
      "temp_1_42/train/images 500 \n",
      "\n",
      "temp_1_43/train/labels 500\n",
      "temp_1_43/train/images 500 \n",
      "\n",
      "temp_1_44/train/labels 500\n",
      "temp_1_44/train/images 500 \n",
      "\n",
      "temp_1_45/train/labels 500\n",
      "temp_1_45/train/images 500 \n",
      "\n",
      "temp_1_46/train/labels 500\n",
      "temp_1_46/train/images 500 \n",
      "\n",
      "temp_1_47/train/labels 297\n",
      "temp_1_47/train/images 297 \n",
      "\n",
      "Класс 0\n",
      "\tКол-во train класса 0: 3798\n",
      "\tКоличество данных (train) на каждой итерации класса 0: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 3798]\n",
      "\tКол-во директорий для класса 0: 47 \n",
      "\tnum_to_mv_train 2, folder 0, cls 0\n",
      "\tnum_to_mv_train 2, folder 1, cls 0\n",
      "\tnum_to_mv_train 2, folder 2, cls 0\n",
      "\tnum_to_mv_train 2, folder 3, cls 0\n",
      "\tnum_to_mv_train 2, folder 4, cls 0\n",
      "\tnum_to_mv_train 3, folder 5, cls 0\n",
      "\tnum_to_mv_train 3, folder 6, cls 0\n",
      "\tnum_to_mv_train 3, folder 7, cls 0\n",
      "\tnum_to_mv_train 3, folder 8, cls 0\n",
      "\tnum_to_mv_train 3, folder 9, cls 0\n",
      "\tnum_to_mv_train 3, folder 10, cls 0\n",
      "\tnum_to_mv_train 3, folder 11, cls 0\n",
      "\tnum_to_mv_train 5, folder 12, cls 0\n",
      "\tnum_to_mv_train 5, folder 13, cls 0\n",
      "\tnum_to_mv_train 5, folder 14, cls 0\n",
      "\tnum_to_mv_train 5, folder 15, cls 0\n",
      "\tnum_to_mv_train 5, folder 16, cls 0\n",
      "\tnum_to_mv_train 5, folder 17, cls 0\n",
      "\tnum_to_mv_train 5, folder 18, cls 0\n",
      "\tnum_to_mv_train 5, folder 19, cls 0\n",
      "\tnum_to_mv_train 5, folder 20, cls 0\n",
      "\tnum_to_mv_train 5, folder 21, cls 0\n",
      "\tnum_to_mv_train 5, folder 22, cls 0\n",
      "\tnum_to_mv_train 5, folder 23, cls 0\n",
      "\tnum_to_mv_train 5, folder 24, cls 0\n",
      "\tnum_to_mv_train 5, folder 25, cls 0\n",
      "\tnum_to_mv_train 10, folder 26, cls 0\n",
      "\tnum_to_mv_train 10, folder 27, cls 0\n",
      "\tnum_to_mv_train 10, folder 28, cls 0\n",
      "\tnum_to_mv_train 10, folder 29, cls 0\n",
      "\tnum_to_mv_train 10, folder 30, cls 0\n",
      "\tnum_to_mv_train 10, folder 31, cls 0\n",
      "\tnum_to_mv_train 10, folder 32, cls 0\n",
      "\tnum_to_mv_train 10, folder 33, cls 0\n",
      "\tnum_to_mv_train 10, folder 34, cls 0\n",
      "\tnum_to_mv_train 10, folder 35, cls 0\n",
      "\tnum_to_mv_train 50, folder 36, cls 0\n",
      "\tnum_to_mv_train 50, folder 37, cls 0\n",
      "\tnum_to_mv_train 100, folder 38, cls 0\n",
      "\tnum_to_mv_train 100, folder 39, cls 0\n",
      "\tnum_to_mv_train 500, folder 40, cls 0\n",
      "\tnum_to_mv_train 500, folder 41, cls 0\n",
      "\tnum_to_mv_train 500, folder 42, cls 0\n",
      "\tnum_to_mv_train 500, folder 43, cls 0\n",
      "\tnum_to_mv_train 500, folder 44, cls 0\n",
      "\tnum_to_mv_train 500, folder 45, cls 0\n",
      "\tnum_to_mv_train 297, folder 46, cls 0\n",
      "temp_0_1/train/labels 2\n",
      "temp_0_1/train/images 2 \n",
      "\n",
      "temp_0_2/train/labels 2\n",
      "temp_0_2/train/images 2 \n",
      "\n",
      "temp_0_3/train/labels 2\n",
      "temp_0_3/train/images 2 \n",
      "\n",
      "temp_0_4/train/labels 2\n",
      "temp_0_4/train/images 2 \n",
      "\n",
      "temp_0_5/train/labels 2\n",
      "temp_0_5/train/images 2 \n",
      "\n",
      "temp_0_6/train/labels 3\n",
      "temp_0_6/train/images 3 \n",
      "\n",
      "temp_0_7/train/labels 3\n",
      "temp_0_7/train/images 3 \n",
      "\n",
      "temp_0_8/train/labels 3\n",
      "temp_0_8/train/images 3 \n",
      "\n",
      "temp_0_9/train/labels 3\n",
      "temp_0_9/train/images 3 \n",
      "\n",
      "temp_0_10/train/labels 3\n",
      "temp_0_10/train/images 3 \n",
      "\n",
      "temp_0_11/train/labels 3\n",
      "temp_0_11/train/images 3 \n",
      "\n",
      "temp_0_12/train/labels 3\n",
      "temp_0_12/train/images 3 \n",
      "\n",
      "temp_0_13/train/labels 5\n",
      "temp_0_13/train/images 5 \n",
      "\n",
      "temp_0_14/train/labels 5\n",
      "temp_0_14/train/images 5 \n",
      "\n",
      "temp_0_15/train/labels 5\n",
      "temp_0_15/train/images 5 \n",
      "\n",
      "temp_0_16/train/labels 5\n",
      "temp_0_16/train/images 5 \n",
      "\n",
      "temp_0_17/train/labels 5\n",
      "temp_0_17/train/images 5 \n",
      "\n",
      "temp_0_18/train/labels 5\n",
      "temp_0_18/train/images 5 \n",
      "\n",
      "temp_0_19/train/labels 5\n",
      "temp_0_19/train/images 5 \n",
      "\n",
      "temp_0_20/train/labels 5\n",
      "temp_0_20/train/images 5 \n",
      "\n",
      "temp_0_21/train/labels 5\n",
      "temp_0_21/train/images 5 \n",
      "\n",
      "temp_0_22/train/labels 5\n",
      "temp_0_22/train/images 5 \n",
      "\n",
      "temp_0_23/train/labels 5\n",
      "temp_0_23/train/images 5 \n",
      "\n",
      "temp_0_24/train/labels 5\n",
      "temp_0_24/train/images 5 \n",
      "\n",
      "temp_0_25/train/labels 5\n",
      "temp_0_25/train/images 5 \n",
      "\n",
      "temp_0_26/train/labels 5\n",
      "temp_0_26/train/images 5 \n",
      "\n",
      "temp_0_27/train/labels 10\n",
      "temp_0_27/train/images 10 \n",
      "\n",
      "temp_0_28/train/labels 10\n",
      "temp_0_28/train/images 10 \n",
      "\n",
      "temp_0_29/train/labels 10\n",
      "temp_0_29/train/images 10 \n",
      "\n",
      "temp_0_30/train/labels 10\n",
      "temp_0_30/train/images 10 \n",
      "\n",
      "temp_0_31/train/labels 10\n",
      "temp_0_31/train/images 10 \n",
      "\n",
      "temp_0_32/train/labels 10\n",
      "temp_0_32/train/images 10 \n",
      "\n",
      "temp_0_33/train/labels 10\n",
      "temp_0_33/train/images 10 \n",
      "\n",
      "temp_0_34/train/labels 10\n",
      "temp_0_34/train/images 10 \n",
      "\n",
      "temp_0_35/train/labels 10\n",
      "temp_0_35/train/images 10 \n",
      "\n",
      "temp_0_36/train/labels 10\n",
      "temp_0_36/train/images 10 \n",
      "\n",
      "temp_0_37/train/labels 50\n",
      "temp_0_37/train/images 50 \n",
      "\n",
      "temp_0_38/train/labels 50\n",
      "temp_0_38/train/images 50 \n",
      "\n",
      "temp_0_39/train/labels 100\n",
      "temp_0_39/train/images 100 \n",
      "\n",
      "temp_0_40/train/labels 100\n",
      "temp_0_40/train/images 100 \n",
      "\n",
      "temp_0_41/train/labels 500\n",
      "temp_0_41/train/images 500 \n",
      "\n",
      "temp_0_42/train/labels 500\n",
      "temp_0_42/train/images 500 \n",
      "\n",
      "temp_0_43/train/labels 500\n",
      "temp_0_43/train/images 500 \n",
      "\n",
      "temp_0_44/train/labels 500\n",
      "temp_0_44/train/images 500 \n",
      "\n",
      "temp_0_45/train/labels 500\n",
      "temp_0_45/train/images 500 \n",
      "\n",
      "temp_0_46/train/labels 500\n",
      "temp_0_46/train/images 500 \n",
      "\n",
      "temp_0_47/train/labels 297\n",
      "temp_0_47/train/images 297 \n",
      "\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 13.5MB/s]\n",
      "2023-11-28 17:31:05,156\tINFO util.py:129 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-11-28 17:31:06,961\tINFO util.py:129 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.23M/6.23M [00:00<00:00, 69.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_1/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 151.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_1/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<00:00, 821.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/feet-14/valid_1/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       1.6G      1.751      5.913      4.359      2.067          3        640: 100%|██████████| 1/1 [00:04<00:00,  4.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.247      0.319      0.147     0.0369      0.434      0.502      0.359     0.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.61G     0.7643      2.366      4.536      1.201          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.256      0.312      0.147     0.0367       0.44      0.502       0.36     0.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       1.6G      1.381      2.693      4.538      1.529          3        640: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.263      0.318      0.149     0.0371      0.436        0.5      0.357      0.086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.62G      2.621      4.622      5.112      2.638          3        640: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.259      0.316      0.147      0.037      0.442      0.502      0.355     0.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       1.6G     0.4162      2.349      4.524      1.071          1        640: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.263      0.314      0.149     0.0378      0.439      0.506      0.356      0.087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.263      0.314      0.148     0.0376       0.44      0.506      0.355     0.0868\n",
      "                  legs        474        474      0.263      0.314      0.148     0.0376       0.44      0.506      0.355     0.0868\n",
      "Speed: 0.9ms preprocess, 12.9ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁█▂▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▆█▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▂▁▄▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▅▅▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▅█▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▇▃█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▁█▆▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▃▃▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▅▂▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▃▃█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅▂▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▁▂▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▄▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▆▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▄▇█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▃▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.14841\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.35523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.03758\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.0868\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.2627\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.44026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.31435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.50633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.26\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.41615\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.52389\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.07109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.34851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.7605\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.3643\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.567\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.10043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_173128-6wnu28to\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_173128-6wnu28to/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<00:00, 963.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/feet-14/test_1/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.352      0.275      0.185     0.0466      0.476       0.46      0.411      0.106\n",
      "                  legs        476        476      0.352      0.275      0.185     0.0466      0.476       0.46      0.411      0.106\n",
      "Speed: 0.8ms preprocess, 28.6ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_2/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 516.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_2/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.56G      1.189      2.562      3.702       1.51          5        640: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.247      0.308      0.146     0.0382      0.408      0.454      0.343     0.0878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       1.6G      1.349      3.001      2.735      1.705          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.254      0.316      0.146     0.0384      0.408      0.466      0.343     0.0875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.47G      1.198      4.312      2.376       1.61          2        640: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.251      0.316      0.147     0.0383      0.413      0.468      0.342     0.0871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       1.5G      1.343      1.788      3.571      1.259          3        640: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.261      0.316      0.147     0.0382      0.416      0.486      0.339     0.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.47G      1.185      2.239      4.013      1.696          2        640: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.263      0.314      0.149     0.0389      0.419      0.477      0.338     0.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.253      0.309      0.148     0.0384      0.408      0.458      0.343     0.0878\n",
      "                  legs        474        474      0.253      0.309      0.148     0.0384      0.408      0.458      0.343     0.0878\n",
      "Speed: 0.6ms preprocess, 13.1ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▅▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ██▇▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁█▅▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▇▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▄▃█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁███▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▄█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▇▃▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅█▇▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▃▄█▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▄▇█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▁▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▅▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▆█▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.14767\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.3425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.03839\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.08779\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.25292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.40832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.30855\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.45781\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.962\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.18473\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.01325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.69585\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.2395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.75814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.35238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.52013\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.24327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_173522-xwqk3zwq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_173522-xwqk3zwq/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.344       0.29      0.186     0.0488      0.474       0.45      0.414      0.109\n",
      "                  legs        476        476      0.344       0.29      0.186     0.0488      0.474       0.45      0.414      0.109\n",
      "Speed: 0.8ms preprocess, 29.0ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_3/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 597.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.44G      1.712      2.045      3.677       1.86          5        640: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.256      0.308       0.16     0.0423      0.396      0.453      0.359     0.0911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.59G      2.353      2.308      3.557      2.817          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.268       0.31      0.162     0.0433      0.404      0.449      0.362     0.0925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.49G      2.474      1.081      7.673      2.408          1        640: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.262      0.281      0.163      0.044        0.4      0.428      0.362     0.0936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.47G     0.6032     0.8909       6.88      1.115          1        640: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.257      0.298      0.163     0.0447      0.399      0.454      0.361     0.0939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.47G      1.495      2.908      3.385      2.011          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.266      0.297      0.165     0.0455      0.419      0.454      0.361     0.0952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.266      0.295      0.166     0.0456      0.414      0.445      0.355     0.0946\n",
      "                  legs        474        474      0.266      0.295      0.166     0.0456      0.414      0.445      0.355     0.0946\n",
      "Speed: 0.7ms preprocess, 13.0ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▅█▇▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁█▄▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▃▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▇█▁▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▇▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▅██▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▁█▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▄█▆▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅▆▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▁▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▂▅█▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.16592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.3547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.04561\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.09461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.26636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.41447\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.29536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.44515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.073\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.49486\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.3847\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.01085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.90784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.69422\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.28323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.41479\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.24258\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_173852-vt9mkp37\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_173852-vt9mkp37/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.334      0.321      0.207     0.0574      0.501      0.482      0.429      0.117\n",
      "                  legs        476        476      0.334      0.321      0.207     0.0574      0.501      0.482      0.429      0.117\n",
      "Speed: 0.7ms preprocess, 29.4ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_4/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 906.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_4/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.43G     0.9273      2.331      3.095      1.483          5        640: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.238      0.327      0.164     0.0482      0.403      0.418      0.345     0.0944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.59G     0.7238      4.575      4.754      1.281          3        640: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.254      0.293      0.166     0.0486      0.421       0.43      0.351     0.0954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.48G     0.7618      6.916      5.213        1.3          2        640: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.255      0.302      0.166      0.049      0.408      0.432      0.352      0.096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       1.5G      1.051       4.25      4.244      1.701          5        640: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.256      0.308      0.165     0.0488      0.409      0.449      0.354     0.0959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.48G      1.406      2.413      3.356      2.179          2        640: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.255      0.319      0.163     0.0488       0.42      0.451      0.355     0.0962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.256      0.304      0.167      0.049      0.406       0.43      0.351      0.096\n",
      "                  legs        474        474      0.256      0.304      0.167      0.049      0.406       0.43      0.351      0.096\n",
      "Speed: 0.7ms preprocess, 13.0ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▇▇▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▆▆█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▄█▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▅█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁█▃▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▁▃▄▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▄█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▃▁▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▆█▅▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▃▁▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▄█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▅▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▄▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▄▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.16668\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.35056\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.04901\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.09597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.25619\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.40641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.3038\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.43038\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.40642\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.35594\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.17949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.41266\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.12814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.29383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.29712\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_174229-nw3g69t2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_174229-nw3g69t2/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.299      0.324      0.212      0.063      0.436      0.471      0.398      0.118\n",
      "                  legs        476        476      0.299      0.324      0.212      0.063      0.436      0.471      0.398      0.118\n",
      "Speed: 0.7ms preprocess, 29.2ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_5/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 1277.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_5/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.53G      1.385      2.594      2.669       1.84          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.22      0.315      0.158     0.0532      0.413      0.325      0.287     0.0878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       1.6G       1.27      4.613      2.293      1.801          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.242      0.266      0.155     0.0505      0.396      0.365      0.301      0.089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.59G      0.807      3.158      2.007      1.663          2        640: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.25        0.3      0.158     0.0506      0.402      0.395      0.314     0.0904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       1.6G      0.993      1.964       4.54      1.496          2        640: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.247      0.303      0.161     0.0505      0.403      0.405      0.326     0.0917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       1.6G      1.505      2.228      2.598      2.514          2        640: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.245      0.291      0.161     0.0505      0.407      0.403      0.322     0.0912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.248      0.304      0.161     0.0504      0.405      0.403      0.326     0.0919\n",
      "                  legs        474        474      0.248      0.304      0.161     0.0504      0.405      0.403      0.326     0.0919\n",
      "Speed: 0.6ms preprocess, 13.0ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▄▁▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▄▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▁▃▄▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▁▆▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▇▆▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▃▂▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▃▃▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▃█▄▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▄▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▃▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.16109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.32558\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.05044\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.09195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.24845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.40516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.3038\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.40295\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.50469\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.59821\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.5141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.22822\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.59505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.13395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.18372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.55846\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_174602-waz3v2a0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_174602-waz3v2a0/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476       0.28      0.349      0.197     0.0634      0.404      0.433       0.35      0.111\n",
      "                  legs        476        476       0.28      0.349      0.197     0.0634      0.404      0.433       0.35      0.111\n",
      "Speed: 0.9ms preprocess, 29.6ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 1104.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.66G       1.43      3.052      2.714      1.851         15        640: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.241      0.316      0.145     0.0361      0.427      0.504      0.356     0.0855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.44G      1.401      4.217      3.448       1.73         20        640: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.245      0.314      0.144     0.0364      0.427      0.505      0.353     0.0852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      5.31G      1.194      3.528      3.416      1.688         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.247       0.31      0.145     0.0366      0.442        0.5       0.35     0.0857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       5.3G      1.268      3.957      3.773      1.876         14        640: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.25      0.312      0.146      0.037      0.446      0.494      0.349     0.0856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      5.31G      1.541      2.656      3.299      2.007         15        640: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.257      0.316      0.148     0.0376      0.444      0.486       0.35      0.086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.255      0.318      0.147     0.0377      0.442      0.492      0.351      0.086\n",
      "                  legs        474        474      0.255      0.318      0.147     0.0377      0.442      0.492      0.351      0.086\n",
      "Speed: 0.7ms preprocess, 13.0ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▂▁▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▅▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▃▁▅▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▆█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▇▅▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ██▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▆▅▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▆▆█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅▂▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▃█▅▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▃▆█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▆▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.14739\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.35057\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.03774\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.08599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.25532\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.44164\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.31754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.49156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.068\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.54074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.29883\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.00681\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.65602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.74779\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.3504\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.53281\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.0567\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_174843-0qrrrk9d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_174843-0qrrrk9d/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.317      0.292      0.184     0.0462      0.495      0.445       0.41      0.105\n",
      "                  legs        476        476      0.317      0.292      0.184     0.0462      0.495      0.445       0.41      0.105\n",
      "Speed: 0.8ms preprocess, 29.5ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_6/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 968.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_6/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.92G      1.322      2.952      3.264      1.857          8        640: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.255      0.289      0.143      0.038      0.431      0.447      0.352     0.0886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.15G     0.8622      2.746      2.822        1.5          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.253      0.292      0.143     0.0381      0.421      0.447      0.348      0.088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.04G      1.598      3.124      2.626      2.276          5        640: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.256      0.295      0.146     0.0388      0.413      0.447      0.345     0.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.04G      1.118      2.598      3.509      1.767          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.264      0.304      0.147     0.0392      0.418      0.462      0.349      0.089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.06G      1.685      3.144      2.742      2.082          8        640: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.266      0.306      0.147     0.0391      0.418      0.468      0.347     0.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.262        0.3      0.147     0.0392      0.418      0.462      0.349     0.0893\n",
      "                  legs        474        474      0.262        0.3      0.147     0.0392      0.418      0.462      0.349     0.0893\n",
      "Speed: 0.8ms preprocess, 13.1ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▄▁▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▄▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▂▁▃█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▄▁▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▄█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▅▁▇▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▆▃▁█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▄▁█▃▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▆▃█▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▇█▆▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▄▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▅█▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.14716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.34887\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.03922\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.08927\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.26212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.41757\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.29958\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.46203\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.68517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.74209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.08169\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.14392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.72834\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.33953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.46783\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.18494\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_175320-e5aco7u5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_175320-e5aco7u5/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.325      0.293      0.184     0.0486      0.488       0.45      0.411       0.11\n",
      "                  legs        476        476      0.325      0.293      0.184     0.0486      0.488       0.45      0.411       0.11\n",
      "Speed: 1.1ms preprocess, 29.5ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 13 images, 0 backgrounds, 0 corrupt: 100%|██████████| 13/13 [00:00<00:00, 1041.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.86G     0.9703      3.785      3.602       1.44         22        640: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.248      0.321      0.145     0.0366      0.419      0.506       0.36     0.0863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       7.1G      1.481      3.467      3.424      1.809         28        640: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.247      0.314      0.145     0.0368      0.431      0.506      0.357     0.0863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5         7G      1.473      4.264      3.591      1.798         27        640: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.249      0.312      0.146      0.037      0.439      0.504      0.353     0.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5         7G      1.675      3.936      3.419      2.006         28        640: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.253      0.316      0.147     0.0379      0.438      0.504      0.353     0.0866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5         7G      1.492      3.505      3.196       1.85         22        640: 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.258      0.323      0.149     0.0383      0.448      0.504      0.358     0.0875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.258      0.323      0.149     0.0384      0.452      0.502      0.358     0.0876\n",
      "                  legs        474        474      0.258      0.323      0.149     0.0384      0.452      0.502      0.358     0.0876\n",
      "Speed: 0.8ms preprocess, 12.9ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▂▁▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▅▁▂▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▂▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▁▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▅▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▇▂▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ██▅▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▆▆█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▅█▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▆▅█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄▁█▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▂▁▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▆▆▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.14893\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.35783\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.03841\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.08758\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.2582\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.45194\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.32278\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.50211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.49206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.1957\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.84999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.50483\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.74634\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.3426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.53146\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.99564\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_175603-rlu7imq9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_175603-rlu7imq9/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.317      0.307      0.186     0.0466      0.482      0.455      0.413      0.106\n",
      "                  legs        476        476      0.317      0.307      0.186     0.0466      0.482      0.455      0.413      0.106\n",
      "Speed: 1.0ms preprocess, 29.3ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_7/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 4536.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_7/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.03G      1.543       2.78      2.974      1.864          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.251      0.302      0.144      0.038      0.425      0.447      0.352     0.0891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G      1.159      2.249      3.944      1.665          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.254      0.306      0.145     0.0382      0.422       0.46      0.359     0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.16G     0.8501      2.322      2.504      1.422          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.25      0.306      0.144     0.0384      0.424      0.462      0.356     0.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.16G     0.6065      1.026      1.982      1.148          4        640: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.249      0.308      0.147     0.0384      0.419       0.46      0.357     0.0884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.17G     0.9928      4.616      2.832       1.48          8        640: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.254       0.31      0.148     0.0386      0.417      0.465      0.352     0.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.254      0.306      0.145     0.0382      0.421      0.458      0.354     0.0887\n",
      "                  legs        474        474      0.254      0.306      0.145     0.0382      0.421      0.458      0.354     0.0887\n",
      "Speed: 0.7ms preprocess, 13.2ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▂▃▁█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁█▅▆▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▆██▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▆▁▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▄█▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▅▇▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▆▆█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▇█▇▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▅▃▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▅█▃▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▆▄▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄▃▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▂▂█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▄▆█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.14497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.35396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.03823\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.08867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.25407\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.42112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.30591\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.45781\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.151\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.99283\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.83189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.48035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 4.61591\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.73615\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.34512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.4866\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.13814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_180046-4011gown\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_180046-4011gown/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.341      0.296      0.185      0.048      0.491      0.456      0.414      0.109\n",
      "                  legs        476        476      0.341      0.296      0.185      0.048      0.491      0.456      0.414      0.109\n",
      "Speed: 0.8ms preprocess, 29.4ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 16 images, 0 backgrounds, 0 corrupt: 100%|██████████| 16/16 [00:00<00:00, 948.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         8G      1.172      3.396      2.908      1.663         33        640: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.245      0.319      0.145     0.0364      0.417      0.511      0.357     0.0856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.48G      1.349      3.909      3.076       1.78         36        640: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.248      0.319      0.144     0.0366      0.429      0.511      0.358     0.0863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.35G      1.329      4.074      3.059      1.819         32        640: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.254      0.314      0.145     0.0368      0.448      0.511      0.357     0.0864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.04G      1.315      2.855      3.305      1.836         33        640: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.254      0.316      0.149     0.0376      0.442      0.511      0.354      0.087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.37G      1.291      3.117      3.197      1.701         30        640: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.257      0.327       0.15     0.0383      0.448      0.509      0.359     0.0877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.258      0.327      0.151     0.0383      0.451      0.507      0.359     0.0879\n",
      "                  legs        474        474      0.258      0.327      0.151     0.0383      0.451      0.507      0.359     0.0879\n",
      "Speed: 0.8ms preprocess, 13.0ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▂▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▅▇▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▇▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▃▃▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ████▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▇▇▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▄▄█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▆▇█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄▇█▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▁▄█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▇█▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.15081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.35913\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.0383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.08788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.25785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.45146\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.507\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.014\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.29141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.19701\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.70112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.11702\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.74131\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.35161\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.52987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.97959\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_180330-1601ivrk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_180330-1601ivrk/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.312      0.309      0.187     0.0464      0.494       0.45      0.414      0.106\n",
      "                  legs        476        476      0.312      0.309      0.187     0.0464      0.494       0.45      0.414      0.106\n",
      "Speed: 1.1ms preprocess, 29.2ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_8/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 1183.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_8/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.07G      1.117      3.392      3.718      1.553          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.262      0.306      0.144     0.0371       0.43      0.449      0.358     0.0888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.17G      1.581      1.226      6.108      2.245          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.252      0.302      0.143     0.0371      0.426      0.441      0.351     0.0876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.04G      1.397      1.318      3.255      1.717          4        640: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.246      0.312      0.144     0.0374      0.418      0.439      0.344     0.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.04G      1.562      3.218       3.96      1.721          4        640: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.245      0.306      0.145     0.0375      0.402      0.457       0.34     0.0864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.05G       1.61      2.644      3.275      2.096          5        640: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.241      0.297       0.14     0.0367      0.399      0.458      0.338     0.0857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.263      0.312      0.144     0.0371      0.427      0.451      0.358     0.0888\n",
      "                  legs        474        474      0.263      0.312      0.144     0.0371      0.427      0.451      0.358     0.0888\n",
      "Speed: 0.7ms preprocess, 13.1ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▆▁▇█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▅▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▂▁▆█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▄▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▇▄▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▇▅▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▄▁█▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▅▂▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▂█▁▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁█▃▃▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▁▁▇▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ██▄▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▄▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.14413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.35773\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.03714\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.08885\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.26348\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.42673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.31224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.45148\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.6103\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.27545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.09556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.64421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.70436\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.38463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.44957\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 3.12422\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_180817-fk4655xo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_180817-fk4655xo/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.338       0.29      0.183      0.048      0.488      0.456      0.415      0.108\n",
      "                  legs        476        476      0.338       0.29      0.183      0.048      0.488      0.456      0.415      0.108\n",
      "Speed: 0.8ms preprocess, 29.0ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 19 images, 0 backgrounds, 0 corrupt: 100%|██████████| 19/19 [00:00<00:00, 1398.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.24G      1.321      3.628      3.297      1.643          5        640: 100%|██████████| 2/2 [00:01<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.25      0.316      0.145     0.0365       0.43      0.506      0.357     0.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.15G      1.413        3.4       3.23       1.77          6        640: 100%|██████████| 2/2 [00:00<00:00,  2.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.255      0.316      0.148     0.0372       0.44      0.502      0.353     0.0864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.08G       1.54       3.21      3.589      1.803          9        640: 100%|██████████| 2/2 [00:00<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.254      0.323      0.149     0.0381      0.445       0.49      0.359     0.0884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.16G     0.8962      2.954      3.569      1.506          3        640: 100%|██████████| 2/2 [00:00<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.267       0.33      0.152       0.04      0.454      0.496      0.363     0.0901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.18G      1.489      3.397       3.68      1.812          7        640: 100%|██████████| 2/2 [00:00<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.283      0.327      0.154     0.0412      0.467      0.511      0.371     0.0923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.279      0.329      0.155     0.0411      0.468      0.508      0.367     0.0921\n",
      "                  legs        474        474      0.279      0.329      0.155     0.0411      0.468      0.508      0.367     0.0921\n",
      "Speed: 0.8ms preprocess, 13.1ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▃▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▁▄█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▇▆▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▆▇█▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▂▁▇▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▄▇█▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▄▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ███▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ██▇▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.15489\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.3671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.04112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.09211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.27863\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.46833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.32911\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.50844\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.48946\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.67961\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.81244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.39714\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.71372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.25412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.48489\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.51635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_181059-kydnlhl5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_181059-kydnlhl5/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.337      0.311      0.201     0.0519      0.504      0.471      0.429      0.115\n",
      "                  legs        476        476      0.337      0.311      0.201     0.0519      0.504      0.471      0.429      0.115\n",
      "Speed: 0.7ms preprocess, 29.7ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_9/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 6316.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_9/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.16G     0.8887       1.99      3.354      1.325          6        640: 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.269      0.314      0.158     0.0421      0.437      0.473      0.365     0.0944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G      1.346       2.96       3.38      1.748          5        640: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.27      0.316      0.158     0.0418      0.434      0.481      0.365     0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.17G     0.9175      2.077      2.568      1.412          5        640: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.269      0.319      0.159     0.0427      0.433      0.485      0.364     0.0944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.16G       1.64      2.573      3.619      1.956          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.274      0.314      0.162     0.0431      0.439      0.488      0.364      0.095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.18G      1.129      1.912      2.982      1.505          9        640: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.277      0.329      0.161     0.0431      0.447        0.5      0.366     0.0953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.275      0.319       0.16      0.043      0.446      0.496      0.366     0.0954\n",
      "                  legs        474        474      0.275      0.319       0.16      0.043      0.446      0.496      0.366     0.0954\n",
      "Speed: 0.7ms preprocess, 13.1ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▂█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▅▃▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▂▁▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▄▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▃▂▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅█▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▅▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▆▆▁█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▆▂█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▂█▂▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▄▆█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▂▁▃█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.15973\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.36603\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.04302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.09542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.27545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.4461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.31857\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.49578\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.998\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.1285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.98223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.50501\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.91221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.66955\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.26227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.39871\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.58062\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_181547-cc9nh1me\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_181547-cc9nh1me/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476       0.32       0.34      0.207     0.0554      0.497      0.473      0.432      0.119\n",
      "                  legs        476        476       0.32       0.34      0.207     0.0554      0.497      0.473      0.432      0.119\n",
      "Speed: 0.8ms preprocess, 29.6ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_10/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 477.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_10/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.55G      1.515      4.395      3.699      1.779          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.249      0.321      0.171     0.0474      0.402      0.443      0.371     0.0985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.17G       1.49      3.709      2.694      2.146          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.239      0.319      0.165     0.0465      0.407      0.445      0.369     0.0977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.16G     0.7407      4.363      3.375      1.331          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.238      0.321      0.165     0.0472      0.409      0.461       0.37     0.0986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.16G     0.6096      1.542       2.97       1.25          4        640: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.244      0.327      0.161     0.0462      0.404      0.462      0.374     0.0993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.15G      1.061       3.08      2.775      1.248          7        640: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.246      0.321      0.158     0.0461      0.407      0.466      0.374        0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.251      0.321      0.172     0.0475      0.399      0.443       0.37      0.099\n",
      "                  legs        474        474      0.251      0.321      0.172     0.0475      0.399      0.443       0.37      0.099\n",
      "Speed: 0.5ms preprocess, 13.2ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▄▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▄▁▂█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▃▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▄▁▅█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▇▁▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▃▆█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▃▁▃█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂██▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ██▂▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▁▆▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅█▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆█▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▂▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▄▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▄▆█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▄▇█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.17187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.37037\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.04748\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.09896\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.25088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.39935\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.32068\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.44323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.06075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.77468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.24804\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.07959\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.62912\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.20594\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.28253\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.70456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_181931-1i6xxido\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_181931-1i6xxido/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.313       0.33        0.2     0.0564      0.485      0.492      0.426      0.118\n",
      "                  legs        476        476      0.313       0.33        0.2     0.0564      0.485      0.492      0.426      0.118\n",
      "Speed: 0.7ms preprocess, 29.1ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 25 images, 0 backgrounds, 0 corrupt: 100%|██████████| 25/25 [00:00<00:00, 1060.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       8.3G      1.516      3.782      3.234      1.849         21        640: 100%|██████████| 2/2 [00:02<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.246      0.316      0.144     0.0365      0.424      0.504      0.354     0.0855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.16G      1.143      3.092      3.095      1.638         15        640: 100%|██████████| 2/2 [00:01<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.246       0.31      0.144     0.0367      0.435      0.504      0.353     0.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.05G      1.048      2.475      3.172      1.424         18        640: 100%|██████████| 2/2 [00:01<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.259      0.319      0.151     0.0383      0.447      0.506      0.359     0.0879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.17G      1.252       3.23      3.253      1.667         23        640: 100%|██████████| 2/2 [00:01<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.268      0.329      0.152     0.0396      0.455      0.511      0.362     0.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.16G      1.454      3.451      3.276      1.842         20        640: 100%|██████████| 2/2 [00:01<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.276      0.338      0.162     0.0423      0.465      0.505      0.373     0.0931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.275      0.338      0.162     0.0422      0.464      0.504      0.373     0.0931\n",
      "                  legs        474        474      0.275      0.338      0.162     0.0422      0.464      0.504      0.373     0.0931\n",
      "Speed: 1.0ms preprocess, 13.2ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▃▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▁▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▂▁▄▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▆▁▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▄▁▅▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▇▇█▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▇▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ██▇▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.16171\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.37307\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.04217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.09307\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.27549\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.46418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.33755\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.50422\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.131\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.45404\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.27647\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.8419\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 3.45074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.69001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.25493\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.46249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.4424\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_182213-vss1gy7i\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_182213-vss1gy7i/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.332      0.326      0.199     0.0513      0.498      0.473      0.425      0.113\n",
      "                  legs        476        476      0.332      0.326      0.199     0.0513      0.498      0.473      0.425      0.113\n",
      "Speed: 0.8ms preprocess, 29.8ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_11/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 1516.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_11/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.16G      1.289      1.992      3.523       1.62          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.287      0.299      0.159     0.0421      0.445      0.458       0.37      0.094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.15G       1.62      3.505      3.609      1.568          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.288        0.3      0.159     0.0426      0.442      0.464      0.366     0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.05G       1.35      4.062      4.611       1.86          3        640: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.291      0.306      0.159     0.0427      0.444      0.464      0.362     0.0931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.04G      1.174      1.603      2.854      1.614          3        640: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.283      0.308      0.157     0.0427      0.441      0.468      0.367     0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.04G      1.159      2.239      3.691      1.457          5        640: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.29      0.302      0.158     0.0427      0.448       0.46      0.372     0.0947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.289        0.3      0.158     0.0428      0.446       0.46      0.372     0.0948\n",
      "                  legs        474        474      0.289        0.3      0.158     0.0428      0.446       0.46      0.372     0.0948\n",
      "Speed: 0.6ms preprocess, 13.1ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▆▆█▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▇▄▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▆▇▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▅▄▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▅▅█▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▆▁▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▁▆█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅▅█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▃█▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▄▄█▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▄▃█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▂▆█▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▁▂▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▄█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.1583\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.37198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.04282\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.09479\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.28917\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.44613\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.30039\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.45992\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.957\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.15884\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.69126\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.45654\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.2388\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.6776\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.25717\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.40815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.59721\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_182706-x75c05ui\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_182706-x75c05ui/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.339      0.303        0.2     0.0543      0.489      0.464      0.431      0.117\n",
      "                  legs        476        476      0.339      0.303        0.2     0.0543      0.489      0.464      0.431      0.117\n",
      "Speed: 0.8ms preprocess, 29.2ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<00:00, 1455.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.26G      1.288      3.604      3.409      1.641         29        640: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.245      0.319      0.145     0.0365      0.417      0.508      0.355     0.0859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.48G      1.449      3.249      3.373      1.972         19        640: 100%|██████████| 2/2 [00:01<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.251      0.316      0.145     0.0372      0.435      0.492      0.354      0.087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.37G      1.446      3.152      3.389      1.846         28        640: 100%|██████████| 2/2 [00:01<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.258      0.319      0.147     0.0377      0.441      0.506      0.356     0.0876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.37G      1.341      2.493      3.274      1.743         25        640: 100%|██████████| 2/2 [00:01<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.275      0.338      0.154     0.0398      0.459      0.517      0.369     0.0905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.21G      1.227      2.932      3.283      1.613         25        640: 100%|██████████| 2/2 [00:01<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.281      0.329      0.156     0.0417      0.461      0.513      0.373     0.0927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.281      0.329      0.156     0.0417      0.462      0.515      0.373     0.0928\n",
      "                  legs        474        474      0.281      0.329      0.156     0.0417      0.462      0.515      0.373     0.0928\n",
      "Speed: 0.8ms preprocess, 13.1ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▂▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▂▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▂▁▂█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▆▁▅█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▃██▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▇▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂█▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▅▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ███▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ██▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ███▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.15555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.37305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.04172\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.09279\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.28063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.46178\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.32911\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.51477\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.22734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.28318\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.61323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.93178\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.63783\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.2508\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.40529\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.32735\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_182951-12n9i768\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_182951-12n9i768/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.334      0.309      0.199     0.0517      0.514      0.452      0.423      0.113\n",
      "                  legs        476        476      0.334      0.309      0.199     0.0517      0.514      0.452      0.423      0.113\n",
      "Speed: 0.9ms preprocess, 29.7ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.012161002078312638\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_12/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 5125.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_12/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.17G       1.28      1.785      2.826      1.863          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.265      0.325      0.158     0.0434      0.438       0.47      0.365     0.0961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.17G      1.127      2.496      3.182      1.422          6        640: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.275      0.325      0.157     0.0436      0.445      0.477      0.363     0.0956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.06G      1.354       2.62      2.649      1.809          7        640: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.279      0.327      0.157     0.0439      0.451      0.481      0.366     0.0971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.04G      1.095      1.416      1.596      2.011          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.286      0.316      0.158      0.045      0.452      0.473      0.365     0.0974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.06G     0.9389      1.171      2.158      1.476          8        640: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.282      0.323      0.157     0.0444      0.451      0.485      0.365     0.0972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.285      0.316      0.158     0.0447      0.453      0.477      0.366     0.0975\n",
      "                  legs        474        474      0.285      0.316      0.158     0.0447      0.453      0.477      0.366     0.0975\n",
      "Speed: 0.9ms preprocess, 13.1ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▆▂▁█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▆▁█▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▃█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▃▁▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▄▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▇▇█▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅█▂▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▇▄█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▆█▆▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▆▁▆█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄▇█▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▃▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇█▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▄▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▂▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.15755\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.36563\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.04472\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.09746\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.28525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.45268\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.31646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.47679\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.9389\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.15798\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.47624\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.17143\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.61666\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.2265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.31042\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.44475\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_183443-2ynox4ez\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_183443-2ynox4ez/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.337      0.317      0.207      0.057      0.505      0.468      0.424      0.118\n",
      "                  legs        476        476      0.337      0.317      0.207      0.057      0.505      0.468      0.424      0.118\n",
      "Speed: 0.8ms preprocess, 29.2ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 31 images, 0 backgrounds, 0 corrupt: 100%|██████████| 31/31 [00:00<00:00, 1088.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.26G      1.299      3.333      3.337        1.7         32        640: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.243      0.319      0.145     0.0366       0.42      0.504      0.354     0.0856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.17G      1.251      3.379       3.19      1.711         25        640: 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.248       0.31      0.144     0.0366      0.437        0.5      0.351     0.0854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.02G      1.216      3.169      3.183      1.803         31        640: 100%|██████████| 2/2 [00:01<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.264      0.326       0.15     0.0389      0.451      0.506       0.36     0.0887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.12G      1.202      2.948      3.137      1.629         25        640: 100%|██████████| 2/2 [00:01<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.28      0.338      0.157     0.0408       0.46      0.513      0.368     0.0911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.49G      1.177      2.505      3.365      1.631         30        640: 100%|██████████| 2/2 [00:01<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.283      0.338      0.156     0.0412       0.46      0.514       0.37      0.092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.283       0.34      0.156     0.0412      0.461      0.515      0.369     0.0919\n",
      "                  legs        474        474      0.283       0.34      0.156     0.0412      0.461      0.515      0.369     0.0919\n",
      "Speed: 0.9ms preprocess, 13.3ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▄█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▂▁▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▃▁▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▃▁▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▇▃▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▄▄█▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ██▆▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ██▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ██▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ██▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.1557\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.36933\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.04115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.09193\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.28289\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.46052\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.33966\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.51477\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.044\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.17705\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.36549\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.63059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.50459\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.66882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.27454\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.44025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.45835\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_183727-f493ylw9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_183727-f493ylw9/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.335      0.312      0.198     0.0512       0.52      0.452      0.423      0.113\n",
      "                  legs        476        476      0.335      0.312      0.198     0.0512       0.52      0.452      0.423      0.113\n",
      "Speed: 0.7ms preprocess, 29.6ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.005604813262499966\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_13/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 1492.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_13/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.25G     0.9007      2.637      3.074      1.353         10        640: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.264      0.306      0.156     0.0421      0.437      0.462      0.364      0.094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.13G     0.9453      2.403      3.318      1.299         10        640: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.262      0.311      0.155     0.0424      0.437      0.455      0.366     0.0946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.02G      1.083      3.749       2.73      1.645         11        640: 100%|██████████| 1/1 [00:00<00:00,  3.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.259      0.319      0.154     0.0424      0.441      0.468      0.365     0.0951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G      1.107      3.749       3.32      1.495          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.264      0.323      0.157     0.0431      0.442      0.481      0.368     0.0962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.03G      1.574      2.039      3.043      2.117         12        640: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.267      0.327      0.157     0.0436      0.444      0.475      0.366     0.0958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.263      0.323      0.157     0.0432      0.443      0.481      0.368     0.0964\n",
      "                  legs        474        474      0.263      0.323      0.157     0.0432      0.443      0.481      0.368     0.0964\n",
      "Speed: 0.8ms preprocess, 13.0ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▇▄▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▅▃██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▅▁█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▃▁▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▁▃▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▅█▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▁▄▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▃▂██▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▄▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▃▆█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.15681\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.36801\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.04322\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.09636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.26293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.44296\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.32278\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.48101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.57352\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.04334\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 2.11663\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.03911\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.62909\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.23658\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.34245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.55441\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_184220-8lydljoo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_184220-8lydljoo/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.335      0.319      0.198     0.0545      0.505      0.463      0.431      0.117\n",
      "                  legs        476        476      0.335      0.319      0.198     0.0545      0.505      0.463      0.431      0.117\n",
      "Speed: 0.9ms preprocess, 29.2ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<00:00, 863.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.36G      1.347      3.237      3.189      1.871          7        640: 100%|██████████| 3/3 [00:03<00:00,  1.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.248      0.314      0.146     0.0368      0.433      0.508      0.355     0.0859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.23G      1.044      3.231      3.349      1.494         11        640: 100%|██████████| 3/3 [00:01<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.255      0.319      0.147     0.0375      0.448      0.502      0.353     0.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.65G      1.123      2.636      3.495      1.618          7        640: 100%|██████████| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.271      0.315      0.158     0.0409      0.458        0.5      0.365     0.0913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.59G       1.13      2.546      3.245      1.631         10        640: 100%|██████████| 3/3 [00:01<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.28      0.333      0.169     0.0475      0.458      0.492      0.371     0.0973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.59G     0.9764      2.421      3.053      1.485          9        640: 100%|██████████| 3/3 [00:01<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.299      0.321      0.194     0.0622      0.469      0.489      0.394      0.111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.301      0.322      0.193      0.062       0.47      0.485      0.395      0.111\n",
      "                  legs        474        474      0.301      0.322      0.193      0.062       0.47      0.485      0.395      0.111\n",
      "Speed: 1.0ms preprocess, 13.1ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▂▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▂▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▁█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▆▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▂▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▃▆█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▁▃▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ██▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ██▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ██▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▇▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.08629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.19322\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.39466\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.062\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.11136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.3007\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.46956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.32205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.48523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.113\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.97643\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.05254\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.48509\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.42132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.44478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.88196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.19744\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.98179\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_184508-alj5uw7n\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_184508-alj5uw7n/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.358      0.309      0.232     0.0681      0.528      0.439      0.429      0.126\n",
      "                  legs        476        476      0.358      0.309      0.232     0.0681      0.528      0.439      0.429      0.126\n",
      "Speed: 1.0ms preprocess, 29.7ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.13665355258952078\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_14/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 3561.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_14/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.05G      1.328      2.295      4.107      1.724          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.283      0.329      0.191     0.0607      0.421      0.437      0.383      0.112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G      1.158       2.45      3.858      1.435          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.287      0.335      0.192     0.0609      0.433      0.446      0.386      0.112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.02G      1.281      2.003      3.358      1.637          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.288      0.342       0.19     0.0605      0.431      0.463      0.387      0.112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G      1.056      1.286      2.971      1.632          7        640: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.287      0.342       0.19     0.0606      0.437       0.46      0.389      0.112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G      1.211      2.085      3.895      1.626          8        640: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.288      0.344      0.188       0.06      0.436      0.459      0.383      0.111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.285      0.338      0.192     0.0608      0.433      0.447      0.385      0.112\n",
      "                  legs        474        474      0.285      0.338      0.192     0.0608      0.433      0.447      0.385      0.112\n",
      "Speed: 0.5ms preprocess, 13.2ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▄█▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▄▆█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▄█▁▂▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▇▂▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▇█▇▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▆▅█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄▇▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▃▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▁▆▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▇█▅▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▂▃▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▃▃▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▅▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▅▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.19204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.38549\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.06077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.11238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.28524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.43285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.33755\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.44726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.2107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.89517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.62636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.08543\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.43688\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.90279\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.13836\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.07155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_185007-lyjw29oc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_185007-lyjw29oc/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.331      0.321      0.233     0.0711        0.5      0.452      0.429       0.13\n",
      "                  legs        476        476      0.331      0.321      0.233     0.0711        0.5      0.452      0.429       0.13\n",
      "Speed: 0.8ms preprocess, 29.3ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.16748593250208477\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_15/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 1847.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_15/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.64G     0.7789      1.625      3.055      1.303          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.265      0.333      0.193     0.0625      0.388      0.437      0.352      0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G       1.32      2.966      3.068      1.716          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.258      0.308      0.188     0.0617      0.389      0.439      0.354      0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.02G     0.8205      1.436      2.895        1.6          8        640: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.261      0.308      0.187     0.0612      0.396      0.424       0.35      0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.01G     0.6637      1.835      2.764      1.085          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.26      0.289      0.184     0.0606      0.416      0.403       0.35      0.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G     0.8913      1.741      2.835      1.422          9        640: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.266      0.291      0.187     0.0606      0.403      0.392      0.345      0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.264      0.333      0.191     0.0625      0.386      0.439      0.352       0.11\n",
      "                  legs        474        474      0.264      0.333      0.191     0.0625      0.386      0.439      0.352       0.11\n",
      "Speed: 0.5ms preprocess, 13.1ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▄▃▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▄█▁▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▅▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▇▅▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▁▄▃▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▄▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ██▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▂█▃▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ██▄▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▃█▇▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▂█▁▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▁▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▂▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.19105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.35209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.06246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.10967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.26376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.38629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.33333\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.43882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.978\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.89133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.83495\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.4224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.74065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.39432\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.93053\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.05336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.19109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_185354-8y4o8qkv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_185354-8y4o8qkv/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.327      0.319      0.213     0.0654      0.485      0.454      0.408      0.122\n",
      "                  legs        476        476      0.327      0.319      0.213     0.0654      0.485      0.454      0.408      0.122\n",
      "Speed: 0.9ms preprocess, 29.2ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 46 images, 0 backgrounds, 0 corrupt: 100%|██████████| 46/46 [00:00<00:00, 916.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.41G      1.109       3.36      3.152      1.564         31        640: 100%|██████████| 3/3 [00:03<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.244      0.312      0.146     0.0367      0.434      0.506      0.352     0.0857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.24G      1.265      3.176      3.063      1.718         25        640: 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.251      0.321      0.146     0.0372      0.443      0.498      0.351     0.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.61G      1.308       3.03      3.056       1.78         26        640: 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.26      0.325      0.153     0.0407      0.447       0.49      0.367     0.0903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.28G       1.25      3.032      3.353      1.657         26        640: 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.281      0.338      0.176     0.0508      0.476      0.511      0.391      0.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.25G      1.181       2.19      3.058      1.661         30        640: 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.303      0.354      0.198     0.0621      0.482      0.494      0.402      0.114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.304      0.356      0.197     0.0617      0.485      0.496      0.404      0.114\n",
      "                  legs        474        474      0.304      0.356      0.197     0.0617      0.485      0.496      0.404      0.114\n",
      "Speed: 1.0ms preprocess, 13.3ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▆▄▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▆█▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▃▁▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▇▆▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ██▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ██▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ██▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.08629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.1965\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.40433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.06173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.11366\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.30414\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.48474\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.35592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.49619\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.18124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.05814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.66101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.18977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.39554\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.90757\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.10939\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.91539\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_185640-85rd6ed7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_185640-85rd6ed7/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.368      0.338      0.244     0.0732      0.521      0.479      0.455      0.133\n",
      "                  legs        476        476      0.368      0.338      0.244     0.0732      0.521      0.479      0.455      0.133\n",
      "Speed: 1.0ms preprocess, 29.5ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.18283464763451487\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_16/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 942.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_16/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.75G      1.114       2.37      2.945      1.658          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.33      0.344      0.213     0.0685      0.452      0.483        0.4      0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G     0.9607      2.518      3.713      1.274          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.321      0.344      0.215     0.0717      0.452      0.494      0.409      0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.03G      1.099      3.941      3.401      1.583          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.317      0.342      0.217     0.0717      0.445      0.481      0.401      0.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G     0.7205      2.945        3.1      1.312          7        640: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.324      0.348      0.216     0.0716      0.448      0.481        0.4      0.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G      1.274      1.916      3.865      1.494          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.321      0.348      0.215     0.0713      0.446      0.475        0.4       0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.322      0.344      0.215     0.0719      0.457      0.496      0.411      0.122\n",
      "                  legs        474        474      0.322      0.344      0.215     0.0719      0.457      0.496      0.411      0.122\n",
      "Speed: 0.8ms preprocess, 13.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▅█▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▇▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▇▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▃▁▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▅▅▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▃▃▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▂▇▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▆▄▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▇▄▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▁▇▂▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▃▃█▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▆█▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▇█▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▅▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.21478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.41094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.07186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.12218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.32208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.45667\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.34388\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.49578\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.936\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.2737\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.86474\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.4936\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.91571\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.39607\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.84825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.06464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.9985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_190144-hfxvtx3a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_190144-hfxvtx3a/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.358      0.345      0.244     0.0773      0.508      0.477      0.457      0.138\n",
      "                  legs        476        476      0.358      0.345      0.244     0.0773      0.508      0.477      0.457      0.138\n",
      "Speed: 1.0ms preprocess, 28.9ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.206546163156167\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_17/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 2100.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_17/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.75G     0.7828      3.225      2.115      1.343         11        640: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.304      0.376      0.231     0.0789      0.444      0.475      0.405      0.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.13G      1.438      3.216      2.674      1.704          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.315      0.353       0.23     0.0786      0.438      0.462      0.412       0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.02G      1.216      2.022      2.478      1.825          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.309      0.371      0.228     0.0775      0.429       0.48      0.401      0.128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G       1.53      3.256       2.59      2.364          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.312      0.359      0.228      0.078      0.443      0.456      0.395      0.126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G      1.056      2.922      2.409      1.582         12        640: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.316      0.349      0.228     0.0775       0.45      0.443      0.399      0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.303      0.371      0.229     0.0786      0.444      0.477      0.407      0.131\n",
      "                  legs        474        474      0.303      0.371      0.229     0.0786      0.444      0.477      0.407      0.131\n",
      "Speed: 0.8ms preprocess, 13.1ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▆▂▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▅█▃▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▆▁▃▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▆▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▂█▅▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▅▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▁▇▃▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▆▃█▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▇▅█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▆▇▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▃▄█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ██▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▂▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▄▃▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▅█▃▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.22867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.40661\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.0786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.13082\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.30347\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.44376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.37135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.47679\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.983\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.05639\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.40932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.58159\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.922\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.35602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.8068\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.97227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.10316\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_190532-lkjd7ubu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_190532-lkjd7ubu/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.366      0.353       0.24     0.0808      0.502      0.487      0.437      0.139\n",
      "                  legs        476        476      0.366      0.353       0.24     0.0808      0.502      0.487      0.437      0.139\n",
      "Speed: 0.8ms preprocess, 29.0ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.1855657161860372\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_18/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 9110.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_18/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.43G      1.647      2.559      2.648      1.909         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.282      0.323      0.213     0.0747       0.44      0.406      0.346      0.117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.15G       1.01      1.985      2.708      1.645          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.291      0.348      0.225     0.0771      0.421      0.426      0.353       0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.01G      1.589      2.856      3.099      1.881          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.304      0.365      0.225     0.0781      0.414      0.454      0.358      0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.03G      1.587      2.061      3.303      1.795          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.311      0.373      0.225     0.0791      0.411      0.468      0.364      0.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.03G      1.059      1.446      2.966      1.494          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.298      0.376      0.228     0.0801       0.42      0.481       0.37      0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.291      0.384      0.227     0.0794      0.417       0.48       0.37      0.127\n",
      "                  legs        474        474      0.291      0.384      0.227     0.0794      0.417       0.48       0.37      0.127\n",
      "Speed: 0.7ms preprocess, 13.0ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▅▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▆█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▃▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▁▇▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▂▆█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▄█▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▇▄█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▅▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▁▁▄▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▅▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.22732\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.37006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.0794\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.12656\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.29111\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.41683\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.38397\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.47953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.996\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.05932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.96581\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.49411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.44561\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.35745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.73954\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.90684\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.20881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_190920-vvyiqbe6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_190920-vvyiqbe6/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.364      0.385      0.249     0.0863      0.522      0.475      0.426      0.142\n",
      "                  legs        476        476      0.364      0.385      0.249     0.0863      0.522      0.475      0.426      0.142\n",
      "Speed: 0.8ms preprocess, 29.4ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.18326357120445796\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_19/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 1804.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_19/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.43G     0.9512      1.458      2.328      1.546         11        640: 100%|██████████| 1/1 [00:00<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.265      0.295       0.19     0.0712      0.339      0.371      0.286      0.103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G       1.09      2.014      3.046      1.475          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.287      0.302      0.201      0.074      0.368      0.384      0.303      0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.03G      1.025      3.117      3.278      1.604          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.28      0.313      0.204     0.0753      0.379      0.391       0.32      0.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.03G     0.8917      2.296      2.369      1.374         10        640: 100%|██████████| 1/1 [00:00<00:00,  3.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.321      0.287      0.214     0.0781      0.376      0.418      0.319      0.114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.01G      1.683      2.641      2.978      1.989         10        640: 100%|██████████| 1/1 [00:00<00:00,  3.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.289      0.357      0.222     0.0809      0.377      0.437      0.334      0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.289      0.357      0.221     0.0799      0.376      0.442      0.335      0.119\n",
      "                  legs        474        474      0.289      0.357      0.221     0.0799      0.376      0.442      0.335      0.119\n",
      "Speed: 0.9ms preprocess, 13.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▄▃█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▆██▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▂▂▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▂▃▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▆█▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▃▂▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▃█▅▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▃▂▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.22141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.33502\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.07994\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.11926\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.28929\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.37555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.35654\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.44155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.946\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.68262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.97825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.98903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.64131\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.33992\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.69818\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.86659\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 2.44332\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_191313-z6i5z1xx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_191313-z6i5z1xx/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.331       0.34      0.232     0.0795      0.483      0.456      0.395      0.133\n",
      "                  legs        476        476      0.331       0.34      0.232     0.0795      0.483      0.456      0.395      0.133\n",
      "Speed: 0.8ms preprocess, 29.3ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 66 images, 0 backgrounds, 0 corrupt: 100%|██████████| 66/66 [00:00<00:00, 804.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.07G      1.291      2.916      3.315      1.745          4        640: 100%|██████████| 5/5 [00:04<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.249      0.312      0.144     0.0365      0.432      0.502      0.351      0.086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       8.6G      1.215      2.953       3.04      1.655          6        640: 100%|██████████| 5/5 [00:02<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.298      0.348      0.174     0.0493      0.483      0.521      0.401      0.103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.28G      1.098      1.761      2.893      1.513          2        640: 100%|██████████| 5/5 [00:02<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.344      0.454      0.273      0.102      0.491      0.595      0.473      0.157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.29G      1.019      1.978      2.399      1.519          6        640: 100%|██████████| 5/5 [00:02<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.354      0.493      0.345       0.15       0.46       0.57      0.486      0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.59G     0.9221      1.634      2.457      1.465          4        640: 100%|██████████| 5/5 [00:02<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.361      0.553      0.395      0.185      0.474      0.565      0.501       0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.363      0.542      0.394      0.185      0.475      0.564      0.501      0.231\n",
      "                  legs        474        474      0.363      0.542      0.394      0.185      0.475      0.564      0.501      0.231\n",
      "Speed: 0.9ms preprocess, 13.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▄▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▇█▄▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂█▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▇▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▅▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▆▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ██▂▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.39354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.50099\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.18457\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.23057\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.3632\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.47527\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.54219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.56369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.92207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.45683\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.46497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.63404\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.01974\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.10067\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.66852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.66238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_191604-tgjmzr96\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_191604-tgjmzr96/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.412      0.506      0.409      0.188      0.498      0.586      0.524      0.241\n",
      "                  legs        476        476      0.412      0.506      0.409      0.188      0.498      0.586      0.524      0.241\n",
      "Speed: 0.9ms preprocess, 29.8ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.1410791679015477\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_20/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 401.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_20/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.05G     0.5182      1.822      1.973      1.021         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.331      0.542      0.352      0.168      0.409      0.551      0.427      0.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.13G     0.8213      2.723      2.374      1.255          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.339      0.559      0.357       0.17      0.394      0.576      0.429      0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.03G     0.8556      2.262      2.866      1.276          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.336      0.552      0.357      0.169      0.402      0.574       0.43      0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G     0.7165      2.033      2.722      1.376          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.349      0.544      0.358       0.17      0.406      0.574      0.433      0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.03G     0.9902      2.005      2.315      1.529         11        640: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.35      0.544      0.361      0.171      0.428      0.565      0.436       0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.351      0.551      0.362      0.172       0.43      0.563      0.437       0.21\n",
      "                  legs        474        474      0.351      0.551      0.362      0.172       0.43      0.563      0.437       0.21\n",
      "Speed: 0.8ms preprocess, 13.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▅▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▅▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▄▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▄▁▃▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁█▅▂▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁█▇▇▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▅▆▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▄█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁█▄▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▄▁▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▁▂▂▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.36207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.43737\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.1717\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.21038\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.35054\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.42959\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.55063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.56329\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.99023\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.31547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.52909\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.00525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.03276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.15331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.64916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.73296\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_192112-er2andzy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_192112-er2andzy/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.386      0.502      0.392      0.185      0.441      0.576      0.479      0.228\n",
      "                  legs        476        476      0.386      0.502      0.392      0.185      0.441      0.576      0.479      0.228\n",
      "Speed: 1.2ms preprocess, 29.2ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 71 images, 0 backgrounds, 0 corrupt: 100%|██████████| 71/71 [00:00<00:00, 859.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.25G       1.17      3.244      3.309      1.662         12        640: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.254      0.321      0.146     0.0373      0.446      0.494      0.351     0.0863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.47G      1.181      2.697      3.032      1.652         21        640: 100%|██████████| 5/5 [00:02<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.316      0.348      0.193     0.0556      0.491      0.538      0.422      0.111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.19G      1.261      2.305      3.032      1.737         10        640: 100%|██████████| 5/5 [00:02<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.37      0.477      0.331      0.137      0.486      0.589      0.494       0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.16G      1.006      1.928      2.582      1.479         15        640: 100%|██████████| 5/5 [00:02<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.363      0.546      0.371      0.168      0.442      0.641      0.485      0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       8.2G     0.8816      1.706      2.453      1.412         16        640: 100%|██████████| 5/5 [00:02<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.416      0.538      0.411      0.183      0.539      0.627      0.555      0.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.025 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.417      0.538       0.41      0.182      0.539      0.627      0.554      0.238\n",
      "                  legs        474        474      0.417      0.538       0.41      0.182      0.539      0.627      0.554      0.238\n",
      "Speed: 0.8ms preprocess, 13.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▄▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▅▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▅█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▆▇█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▆▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▆▆█▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.41009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.55384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.18242\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.23767\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.41681\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.53937\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.53797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.62747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.8816\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.45266\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.41195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.70565\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.9735\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.95582\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.6533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.62736\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_192359-6ne77pup\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_192359-6ne77pup/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.427      0.538      0.429      0.192      0.549      0.611       0.57       0.25\n",
      "                  legs        476        476      0.427      0.538      0.429      0.192      0.549      0.611       0.57       0.25\n",
      "Speed: 0.9ms preprocess, 29.4ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.113422988378436\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_21/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 800.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_21/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.14G     0.9444      1.489      2.357      1.358         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.36      0.572      0.378      0.169      0.443      0.622       0.49      0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G     0.7656      1.614      2.705      1.332          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.37      0.557      0.382      0.169      0.457      0.608      0.492      0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.02G     0.7868     0.7321      2.232      1.543          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.367      0.546      0.379      0.168      0.467      0.582      0.493      0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G     0.8152      1.443      1.889      1.352          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.369      0.538      0.381      0.169      0.478       0.58      0.498      0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G     0.6848      1.643      2.598      1.206          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.371       0.54       0.38      0.169      0.471      0.584      0.499      0.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.372       0.54      0.381       0.17      0.473      0.576        0.5      0.225\n",
      "                  legs        474        474      0.372       0.54      0.381       0.17      0.473      0.576        0.5      0.225\n",
      "Speed: 0.7ms preprocess, 13.1ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁█▂▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▄▄▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▇▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▆█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▅▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▆▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▃▄▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▅█▄▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▄▄█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▇█▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▂▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃▃██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.38125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.50019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.16969\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.22477\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.37207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.47323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.54008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.57595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.68484\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.59823\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.64332\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.00279\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.02465\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.64582\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.67908\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_192908-4dicbta0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_192908-4dicbta0/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476        0.4      0.511      0.424      0.188      0.511      0.605      0.556      0.247\n",
      "                  legs        476        476        0.4      0.511      0.424      0.188      0.511      0.605      0.556      0.247\n",
      "Speed: 0.9ms preprocess, 29.2ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 76 images, 0 backgrounds, 0 corrupt: 100%|██████████| 76/76 [00:00<00:00, 870.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.23G      1.216      3.129      3.324      1.703         10        640: 100%|██████████| 5/5 [00:04<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.257      0.319      0.147     0.0372      0.435      0.504      0.354     0.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.18G      1.182      3.462      3.244      1.612         19        640: 100%|██████████| 5/5 [00:03<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.294       0.34      0.169     0.0453      0.483       0.53      0.386     0.0978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.45G      1.036      2.106      3.023       1.48         27        640: 100%|██████████| 5/5 [00:03<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.361      0.477      0.308      0.129      0.468      0.576      0.447      0.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.51G     0.9403      1.791      2.588      1.437         24        640: 100%|██████████| 5/5 [00:02<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.391       0.49      0.374      0.174      0.482       0.58      0.478      0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.15G     0.8625      1.685      2.258      1.401         27        640: 100%|██████████| 5/5 [00:03<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.388      0.542      0.416      0.204        0.5      0.596      0.514      0.247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.025 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.388      0.542      0.417      0.204      0.496      0.593      0.514      0.248\n",
      "                  legs        474        474      0.388      0.542      0.417      0.204      0.496      0.593      0.514      0.248\n",
      "Speed: 0.7ms preprocess, 13.3ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▇▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▇▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▇▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▇█▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▇▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.41664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.51415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.20439\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.24791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.38787\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.49602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.54219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.59283\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.159\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.8625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.25832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.40068\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.68539\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.93065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.96594\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.63865\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.64435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_193157-rdlio1ef\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_193157-rdlio1ef/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.398      0.521      0.421      0.196      0.486       0.59      0.525      0.243\n",
      "                  legs        476        476      0.398      0.521      0.421      0.196      0.486       0.59      0.525      0.243\n",
      "Speed: 0.9ms preprocess, 29.6ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.908144864537013\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_22/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 598.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_22/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.19G      1.015      1.615       2.33      1.602         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.375      0.523      0.377      0.189      0.424      0.546      0.439      0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G     0.8669      1.817      2.509      1.419          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.373      0.525      0.377      0.188      0.423      0.584      0.439      0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.02G     0.7535      2.157      2.335      1.555          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.365      0.529      0.379      0.189      0.429      0.576      0.438      0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G     0.8033      2.073       2.54      1.301         10        640: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.361      0.525      0.379       0.19      0.423      0.576      0.439      0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.03G       1.45      2.122      2.548      1.708         12        640: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.364      0.523       0.38       0.19       0.42      0.574       0.44      0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.361      0.527      0.379       0.19      0.413      0.576       0.44      0.229\n",
      "                  legs        474        474      0.361      0.527      0.379       0.19      0.413      0.576       0.44      0.229\n",
      "Speed: 0.5ms preprocess, 13.3ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂█▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▆▇▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▅▁▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▃▃▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▇▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▆▅█▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃█▃▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁█▆▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▄▂▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▇▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▆▃▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▄█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▁▁▃▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▆█▇▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▃█▁▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.37929\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.43967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.19008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.22911\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.36121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.41327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.5273\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.57595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.968\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.44955\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.54843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.70803\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.1225\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.96412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.02904\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.63482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.69372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_193710-o5v6jqfg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_193710-o5v6jqfg/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.441       0.46      0.394      0.189      0.485      0.548      0.472      0.232\n",
      "                  legs        476        476      0.441       0.46      0.394      0.189      0.485      0.548      0.472      0.232\n",
      "Speed: 0.8ms preprocess, 29.4ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 81 images, 0 backgrounds, 0 corrupt: 100%|██████████| 81/81 [00:00<00:00, 931.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.42G      1.251      3.081       3.31      1.668          3        640: 100%|██████████| 6/6 [00:05<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.274      0.323      0.151     0.0381      0.462      0.504       0.37     0.0901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.42G      1.143      2.901      3.089      1.596          3        640: 100%|██████████| 6/6 [00:03<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.314      0.376      0.191     0.0549      0.523      0.536      0.426       0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.28G       1.12      2.118      2.448      1.548          4        640: 100%|██████████| 6/6 [00:03<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.35      0.464      0.312      0.121      0.528      0.599      0.507      0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.29G      1.119      2.064      2.405      1.523          2        640: 100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.379      0.544      0.391      0.173      0.489      0.608      0.509      0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.33G      1.069      2.217      2.715      1.534          1        640: 100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.457      0.544      0.455       0.23      0.508      0.605      0.533      0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.025 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.455      0.544      0.455       0.23      0.507      0.612      0.533      0.268\n",
      "                  legs        474        474      0.455      0.544      0.455       0.23      0.507      0.612      0.533      0.268\n",
      "Speed: 0.9ms preprocess, 13.4ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▇█▄▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▁▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▇▁▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.45463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.5334\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.22957\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.2683\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.45482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.50671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.5443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.61181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.06949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.7154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.53418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.21741\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.9367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.86088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.62956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.59523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_193958-4hlh1tuj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_193958-4hlh1tuj/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.471      0.553      0.464      0.224      0.554      0.601      0.563       0.27\n",
      "                  legs        476        476      0.471      0.553      0.464      0.224      0.554      0.601      0.563       0.27\n",
      "Speed: 0.7ms preprocess, 29.5ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.0443053229269514\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_23/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 556.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_23/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.42G      1.114      2.056      2.534      1.474          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.392      0.591      0.423      0.218      0.454      0.574      0.484      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G      1.116      3.055      2.507      1.542         10        640: 100%|██████████| 1/1 [00:00<00:00,  3.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.396      0.589      0.425       0.22      0.446      0.597      0.482      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.02G     0.9603      1.659       2.63      1.479          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.389      0.584      0.424      0.219      0.442      0.605      0.482      0.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G     0.9766      1.867      2.998       1.54          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.39      0.578      0.422      0.219      0.453      0.593       0.48      0.255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G      1.266      2.044      3.067      1.883          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.393      0.573      0.423      0.219      0.438      0.588       0.48      0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.389      0.585      0.424       0.22      0.441      0.613      0.481      0.258\n",
      "                  legs        474        474      0.389      0.585      0.424       0.22      0.441      0.613      0.481      0.258\n",
      "Speed: 0.9ms preprocess, 13.1ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▄█▆▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▅▄▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁█▆▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▆▅▇▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▄█▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▄▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▇▅▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅▇▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▅▅▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▁▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▂▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▃█▁▂▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▃▂▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▃█▁▂▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▅▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.424\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.48109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.21967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.25809\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.38924\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.44056\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.58487\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.61306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.26564\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.0673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.88257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.044\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.97819\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.9091\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.63543\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.65198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_194510-z8o19oxb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_194510-z8o19oxb/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.439      0.563      0.436      0.219      0.491      0.622      0.514       0.26\n",
      "                  legs        476        476      0.439      0.563      0.436      0.219      0.491      0.622      0.514       0.26\n",
      "Speed: 0.9ms preprocess, 29.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 86 images, 0 backgrounds, 0 corrupt: 100%|██████████| 86/86 [00:00<00:00, 877.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.91G      1.211      3.266      3.183      1.632         15        640: 100%|██████████| 6/6 [00:05<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.256      0.319      0.146     0.0378      0.448      0.505      0.353     0.0872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.25G      1.256      3.013      3.203      1.722         11        640: 100%|██████████| 6/6 [00:03<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.304      0.361      0.202     0.0609      0.498      0.519      0.415      0.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.13G      1.072      2.115      2.686      1.552         11        640: 100%|██████████| 6/6 [00:03<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.373      0.485      0.355      0.148      0.509      0.576      0.521      0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       8.2G      0.965      1.644      2.464      1.425         16        640: 100%|██████████| 6/6 [00:03<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.404      0.555      0.431      0.188      0.553      0.584      0.558       0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.21G     0.9206      1.536       2.34      1.408         16        640: 100%|██████████| 6/6 [00:03<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.468      0.627      0.495      0.224      0.574       0.66      0.608      0.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.026 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.469      0.627      0.495      0.224      0.576      0.661      0.608      0.276\n",
      "                  legs        474        474      0.469      0.627      0.495      0.224      0.576      0.661      0.608      0.276\n",
      "Speed: 0.7ms preprocess, 13.2ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▇█▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ██▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▆█▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▇▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.49512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.60776\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.22414\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.27571\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.46869\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.57575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.62658\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.66138\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.92059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.33987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.40754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.53566\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.89433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.82387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.56096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.61159\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_194758-vlk57x8l\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_194758-vlk57x8l/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.472       0.58       0.49      0.229      0.561      0.664      0.629      0.282\n",
      "                  legs        476        476      0.472       0.58       0.49      0.229      0.561      0.664      0.629      0.282\n",
      "Speed: 0.6ms preprocess, 29.7ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.0067303588119527\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_24/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 468.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_24/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.26G      1.267      2.564      2.809      1.652         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.49      0.557      0.491      0.224      0.561      0.622      0.567      0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G     0.8576      1.894      2.999      1.313          7        640: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.477      0.557      0.486      0.224      0.563      0.622      0.566      0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.02G      0.912      2.769      2.317      1.474          9        640: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.47      0.586      0.486      0.224      0.582       0.61      0.564      0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G      1.177      2.044      2.979      1.462          9        640: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.484       0.57      0.487      0.225      0.585      0.605      0.571       0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G     0.4889      1.294      2.108     0.9895          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.478      0.577       0.49      0.226      0.594      0.615      0.572       0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.481      0.578       0.49      0.226      0.592      0.614      0.572       0.27\n",
      "                  legs        474        474      0.481      0.578       0.49      0.226      0.592      0.614      0.572       0.27\n",
      "Speed: 0.7ms preprocess, 13.1ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▁▂▂▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▄▃▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▄▂▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▄▁▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▁█▄▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ██▃▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄▅▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▇█▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▄▆▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▇▄█▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▃▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▃▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.49042\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.57212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.22563\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.26997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.481\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.59232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.57806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.61392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.919\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.48892\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.10823\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.98952\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.29391\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.93885\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.82786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.56426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.70122\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_195311-dt3fpr35\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_195311-dt3fpr35/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.451       0.58      0.473      0.227      0.572      0.635      0.591      0.276\n",
      "                  legs        476        476      0.451       0.58      0.473      0.227      0.572      0.635      0.591      0.276\n",
      "Speed: 0.9ms preprocess, 29.2ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 91 images, 0 backgrounds, 0 corrupt: 100%|██████████| 91/91 [00:00<00:00, 1005.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.36G      1.268      3.413      3.415      1.682         25        640: 100%|██████████| 6/6 [00:05<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.25      0.316      0.146     0.0374      0.444      0.511      0.355     0.0869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.26G      1.227      2.969      3.196      1.668         22        640: 100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.277      0.329      0.175      0.052      0.441      0.475      0.368      0.101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.29G      1.026        1.9      2.675      1.516         21        640: 100%|██████████| 6/6 [00:03<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.354      0.449      0.338       0.17      0.409      0.511      0.404      0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.31G     0.8703      1.765      2.375      1.429         20        640: 100%|██████████| 6/6 [00:03<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.35      0.523      0.381      0.189      0.408      0.557      0.448      0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.27G     0.9012      1.708      2.256      1.432         21        640: 100%|██████████| 6/6 [00:03<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.381      0.565      0.427      0.206      0.459      0.612      0.514      0.249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.025 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.38      0.555      0.426      0.206      0.461      0.614      0.514      0.249\n",
      "                  legs        474        474       0.38      0.555      0.426      0.206      0.461      0.614      0.514      0.249\n",
      "Speed: 0.6ms preprocess, 13.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▇▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▆▅▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▁▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▃▁▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▇▄▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ██▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.4261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.51385\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.20564\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.24865\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.38023\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.46114\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.55485\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.61392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.145\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.90121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.25612\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.43244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.70809\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.92139\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.98549\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.61871\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.59345\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_195557-y7zggs81\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_195557-y7zggs81/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.404      0.501      0.412      0.203      0.494      0.588      0.512      0.245\n",
      "                  legs        476        476      0.404      0.501      0.412      0.203      0.494      0.588      0.512      0.245\n",
      "Speed: 0.9ms preprocess, 29.6ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.4852723339997952\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_25/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 531.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_25/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.53G     0.7775      1.865      2.435       1.37          9        640: 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.36      0.513      0.401      0.199      0.411      0.565      0.459      0.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.13G     0.9486      1.378      2.592      1.441          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.364      0.544      0.406      0.198      0.406      0.576      0.464      0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.03G      1.131      2.038      2.891      1.611          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.376      0.527       0.41      0.199      0.446      0.551       0.47      0.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.03G     0.8535      1.637      2.417      1.352          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.383      0.508      0.407      0.198      0.441      0.545      0.471      0.239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.03G     0.9543      1.898      2.587      1.324         12        640: 100%|██████████| 1/1 [00:00<00:00,  3.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.409      0.477      0.411      0.199      0.461      0.525      0.474      0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.406      0.471      0.412      0.199       0.46      0.523      0.475      0.241\n",
      "                  legs        474        474      0.406      0.471      0.412      0.199       0.46      0.523      0.475      0.241\n",
      "Speed: 0.8ms preprocess, 13.1ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▇▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▅▂▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▂▁▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▅█▆▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▇█▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▄█▃▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▄█▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂▄█▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▆▁█▄▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▅█▃▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▃▅▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▄▅█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.41184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.47469\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.19949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.24144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.40626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.46018\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.47059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.52321\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.854\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.95425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.58745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.32383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.89827\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.93798\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.08455\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.60555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.67496\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_200108-g401d5ay\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_200108-g401d5ay/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.407      0.496      0.383      0.191      0.473       0.58      0.458      0.228\n",
      "                  legs        476        476      0.407      0.496      0.383      0.191      0.473       0.58      0.458      0.228\n",
      "Speed: 0.7ms preprocess, 29.2ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 96 images, 0 backgrounds, 0 corrupt: 100%|██████████| 96/96 [00:00<00:00, 899.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.36G      1.291      3.335      3.329       1.75         35        640: 100%|██████████| 6/6 [00:05<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.25      0.321      0.146     0.0376      0.438      0.496      0.352     0.0866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       8.3G      1.157      2.918      3.163      1.577         36        640: 100%|██████████| 6/6 [00:03<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.314      0.384      0.213     0.0693      0.479      0.523      0.422      0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.26G      1.021      1.946      2.529      1.483         27        640: 100%|██████████| 6/6 [00:03<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.385        0.5      0.365      0.166      0.452       0.58      0.476       0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       8.3G     0.9034      1.898      2.377      1.395         27        640: 100%|██████████| 6/6 [00:04<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.389       0.54      0.409      0.206      0.452       0.61      0.493      0.247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       8.3G     0.8964      1.807      2.289      1.379         32        640: 100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.441      0.572      0.483      0.244      0.502      0.627      0.567      0.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.026 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.438      0.572      0.483      0.244      0.505      0.629      0.568      0.285\n",
      "                  legs        474        474      0.438      0.572      0.483      0.244      0.505      0.629      0.568      0.285\n",
      "Speed: 0.7ms preprocess, 13.2ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▅▂▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▆▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▇▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.48276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.56819\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.24393\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.28545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.43792\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.50527\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.572\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.62869\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.8964\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.28923\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.37931\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.80693\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.87991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.826\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.53428\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.63788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_200357-1a37nnpi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_200357-1a37nnpi/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.453      0.574      0.498      0.247      0.523       0.64       0.61      0.296\n",
      "                  legs        476        476      0.453      0.574      0.498      0.247      0.523       0.64       0.61      0.296\n",
      "Speed: 0.8ms preprocess, 29.5ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.873289479711323\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_26/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 640.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_26/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.87G      1.044       1.95      2.261      1.545          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.414      0.607      0.451      0.229      0.461      0.671       0.51      0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G      0.924      1.793      1.776      1.461          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.407      0.591      0.447      0.229      0.458      0.643      0.508      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.03G     0.9123      1.467      2.666      1.342          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.402       0.58      0.446       0.23      0.457      0.635      0.508      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G       0.82      1.366      2.162      1.276          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474        0.4      0.597      0.445      0.231       0.45      0.635      0.505      0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G     0.9327      1.241      2.259      1.398          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.402      0.593      0.449      0.231      0.459      0.633       0.51      0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.401      0.597      0.449      0.231      0.459      0.633       0.51      0.268\n",
      "                  legs        474        474      0.401      0.597      0.449      0.231      0.459      0.633       0.51      0.268\n",
      "Speed: 0.7ms preprocess, 13.4ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▃▂▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▅▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▂▁▅█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▅▁▂██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▆▅▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▄▁▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▃▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄▄▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▅▁█▄▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▆▃▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▂▁▂▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▅▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.4489\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.50962\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.23083\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.26847\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.40092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.4591\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.59705\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.63291\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.886\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.93271\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.2592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.39769\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.24089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.91999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.87633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.53169\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.66482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_200910-cj0ij1w3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_200910-cj0ij1w3/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.463      0.574      0.475      0.238      0.534      0.588      0.552       0.28\n",
      "                  legs        476        476      0.463      0.574      0.475      0.238      0.534      0.588      0.552       0.28\n",
      "Speed: 0.8ms preprocess, 29.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 101 images, 0 backgrounds, 0 corrupt: 100%|██████████| 101/101 [00:00<00:00, 959.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       8.4G      1.229      3.437       3.28      1.598         11        640: 100%|██████████| 7/7 [00:05<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.249      0.316      0.148     0.0379      0.448      0.511      0.356     0.0875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.37G       1.27      2.517      2.961      1.699          9        640: 100%|██████████| 7/7 [00:04<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.361      0.486      0.321      0.129      0.499      0.599      0.485      0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.37G      1.055      1.898      2.578      1.539         11        640: 100%|██████████| 7/7 [00:04<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.393      0.557      0.424      0.199      0.451      0.637      0.517      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       8.3G     0.9141      1.736      2.298      1.437         13        640: 100%|██████████| 7/7 [00:03<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.441      0.622      0.477      0.235      0.496      0.665      0.553      0.286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.24G     0.8542      1.611      2.105      1.378         10        640: 100%|██████████| 7/7 [00:03<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.525      0.681      0.569      0.296      0.579      0.705      0.627      0.339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.026 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.526      0.677      0.569      0.296      0.579      0.707      0.627      0.339\n",
      "                  legs        474        474      0.526      0.677      0.569      0.296      0.579      0.707      0.627      0.339\n",
      "Speed: 0.9ms preprocess, 13.2ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▇█▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▆█▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.56905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.62702\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.29577\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.33872\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.52578\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.57854\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.67722\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.70675\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.85418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.10475\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.37752\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.61113\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.86494\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.48728\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.46346\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.49484\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_201157-5x4ky3yj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_201157-5x4ky3yj/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476       0.52      0.609      0.563      0.291      0.612      0.681      0.657      0.338\n",
      "                  legs        476        476       0.52      0.609      0.563      0.291      0.612      0.681      0.657      0.338\n",
      "Speed: 1.2ms preprocess, 29.5ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.131261955759925\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_27/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 616.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_27/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.66G      1.006      1.773      2.277       1.39         17        640: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.463      0.654      0.526      0.281      0.526      0.667      0.573      0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.03G     0.9585      2.559      2.417      1.616         12        640: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.459      0.667      0.529      0.284      0.505      0.675      0.573      0.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.94G     0.8652      1.828      2.237      1.355         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.461       0.68       0.53      0.283      0.522      0.684      0.578      0.327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.91G     0.8687      1.182      2.793      1.326         13        640: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.465      0.673      0.528      0.282      0.508       0.69      0.575      0.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.93G      1.071      1.911      2.455      1.579         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.46      0.675       0.53      0.286       0.52      0.675      0.575      0.328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.468      0.669      0.529      0.285      0.525      0.673      0.575      0.327\n",
      "                  legs        474        474      0.468      0.669      0.529      0.285      0.525      0.673      0.575      0.327\n",
      "Speed: 0.8ms preprocess, 13.0ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▆█▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▅▅▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄█▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▄▁▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▁▇▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅█▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▆█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▆▄▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▂▃▁█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▃█▂▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄█▄▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▂▄█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▃▅▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃▆█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ██▇▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.52917\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.57494\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.28479\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.32677\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.46813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.52456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.66878\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.998\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.07073\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.45537\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.57853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.91133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.89864\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.56658\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.46956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.53245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_201712-mgfjy4gd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_201712-mgfjy4gd/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.509      0.601      0.564      0.297      0.544      0.666       0.64      0.342\n",
      "                  legs        476        476      0.509      0.601      0.564      0.297      0.544      0.666       0.64      0.342\n",
      "Speed: 0.8ms preprocess, 29.5ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.972241739790731\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_28/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 532.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_28/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.64G     0.8964      1.017      2.082      1.321         19        640: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.435      0.605      0.461      0.246      0.478      0.619        0.5      0.283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.03G     0.6927      1.355      2.088      1.187         14        640: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.436      0.622      0.463      0.248       0.47      0.654      0.503      0.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.93G     0.6305      1.282      1.875      1.223         22        640: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.449      0.627       0.47      0.254      0.476      0.662      0.508       0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.91G     0.8109      1.326      2.065      1.329         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.442       0.65      0.475      0.259      0.481      0.672      0.514      0.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.92G     0.8286        1.3      2.049       1.35         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.448      0.639      0.482      0.265      0.478      0.677      0.521        0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.453      0.639      0.483      0.265       0.48      0.677      0.522        0.3\n",
      "                  legs        474        474      0.453      0.639      0.483      0.265       0.48      0.677      0.522        0.3\n",
      "Speed: 0.7ms preprocess, 13.2ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▁▆▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▆▁▅█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄▄█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▃▁▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ██▁▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▇▁▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁█▆▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.48313\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.52178\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.26505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.29987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.45337\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.48031\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.63924\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.67722\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.82865\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.04921\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.34961\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.2997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.9331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.5834\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.48331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.62395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_202100-76eg8wv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_202100-76eg8wv5/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.481      0.607      0.521      0.272      0.516       0.67      0.583      0.317\n",
      "                  legs        476        476      0.481      0.607      0.521      0.272      0.516       0.67      0.583      0.317\n",
      "Speed: 0.7ms preprocess, 29.4ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 121 images, 0 backgrounds, 0 corrupt: 100%|██████████| 121/121 [00:00<00:00, 870.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.26G      1.187      3.025      3.333      1.628         17        640: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.251      0.308      0.146     0.0378      0.422       0.47      0.347     0.0855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.24G      1.124      2.468       2.88      1.584         16        640: 100%|██████████| 8/8 [00:04<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.334      0.489      0.312      0.143      0.404      0.565      0.406      0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.27G       0.89      1.746      2.406      1.409         18        640: 100%|██████████| 8/8 [00:04<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.413      0.534      0.465      0.258      0.445      0.563      0.497      0.292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.14G     0.8937       1.73      2.185      1.396         22        640: 100%|██████████| 8/8 [00:04<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.471      0.688      0.563       0.33      0.509      0.699      0.603       0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.17G     0.7829       1.31      1.881      1.274         19        640: 100%|██████████| 8/8 [00:04<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.579      0.728      0.694      0.421      0.601      0.755      0.729      0.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.027 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.579      0.728      0.694      0.421        0.6      0.757      0.729      0.436\n",
      "                  legs        474        474      0.579      0.728      0.694      0.421        0.6      0.757      0.729      0.436\n",
      "Speed: 0.7ms preprocess, 13.4ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▂▁▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▇▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▇▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▃▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.69385\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.72941\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.42061\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.43646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.57877\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.59999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.72785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.75738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.178\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.78293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.88141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.27368\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.30981\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.81395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.16812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.34408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.4423\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_202348-g9u24yf8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_202348-g9u24yf8/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.638      0.708      0.694      0.413      0.665      0.727      0.745      0.442\n",
      "                  legs        476        476      0.638      0.708      0.694      0.413      0.665      0.727      0.745      0.442\n",
      "Speed: 0.8ms preprocess, 29.7ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.770053051606421\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_29/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 592.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_29/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.88G     0.8566      1.021        2.1      1.352         15        640: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.603      0.711      0.659      0.393      0.622      0.732      0.681      0.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.05G     0.7783      1.342      1.957      1.273         21        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.589      0.705      0.659      0.393      0.609      0.726      0.682      0.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.93G     0.9488      1.076      1.992      1.292         22        640: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.588      0.694      0.663      0.397      0.608      0.717      0.685      0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       4.9G     0.7158     0.7148      2.197      1.228         14        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.586      0.711      0.668        0.4      0.608      0.731      0.689      0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.92G     0.6752      1.086      1.885      1.173         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.58      0.709      0.668        0.4      0.597       0.73      0.689      0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.592      0.698      0.667        0.4       0.61      0.719      0.689      0.417\n",
      "                  legs        474        474      0.592      0.698      0.667        0.4       0.61      0.719      0.689      0.417\n",
      "Speed: 0.6ms preprocess, 13.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▅█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▃██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▂▂▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▂▁▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▅▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▅▁▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▆▄█▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▆▃▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄█▅▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▃▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.66718\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.68895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.39971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.41663\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.59246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.6098\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.69831\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.71876\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.894\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.67519\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.88536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.17296\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.0864\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.84832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.15406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.35941\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.47374\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_202905-igj45e5w\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_202905-igj45e5w/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.599        0.7      0.672      0.401      0.627      0.725      0.715      0.434\n",
      "                  legs        476        476      0.599        0.7      0.672      0.401      0.627      0.725      0.715      0.434\n",
      "Speed: 0.9ms preprocess, 29.2ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 131 images, 0 backgrounds, 0 corrupt: 100%|██████████| 131/131 [00:00<00:00, 1044.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.21G      1.414      3.127      3.187      1.838          7        640: 100%|██████████| 9/9 [00:06<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474        0.3      0.344      0.176     0.0481      0.503       0.52      0.399      0.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.58G      1.109      2.105       2.84      1.554          5        640: 100%|██████████| 9/9 [00:05<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.374      0.483      0.373      0.183      0.438      0.569      0.449      0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.27G     0.9237      1.766      2.362        1.4          6        640: 100%|██████████| 9/9 [00:05<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.475      0.551      0.485      0.264      0.515      0.593      0.526       0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.65G     0.8101      1.401      1.999      1.299          8        640: 100%|██████████| 9/9 [00:04<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.565      0.686       0.68      0.397      0.577        0.7      0.704      0.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.17G     0.7817      1.557      1.881      1.243          5        640: 100%|██████████| 9/9 [00:05<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.618      0.799      0.769      0.486       0.63      0.804      0.783      0.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.028 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.621      0.799      0.769      0.486      0.631      0.806      0.783      0.505\n",
      "                  legs        474        474      0.621      0.799      0.769      0.486      0.631      0.806      0.783      0.505\n",
      "Speed: 0.7ms preprocess, 13.3ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▃▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▅▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▄▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▃▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.05692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.76909\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.7835\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.48604\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.50469\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.6212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.63063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.79919\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.80591\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.78165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.88075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.24313\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.55722\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.79762\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.06281\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.26398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.36201\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_203151-ln9j7bat\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_203151-ln9j7bat/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.678      0.767      0.787      0.488      0.716      0.756      0.803      0.516\n",
      "                  legs        476        476      0.678      0.767      0.787      0.488      0.716      0.756      0.803      0.516\n",
      "Speed: 0.8ms preprocess, 29.8ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 2.216795957616207\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_30/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 532.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_30/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.77G       1.02      1.301      1.905      1.447         18        640: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.624      0.707      0.736      0.463      0.631      0.715       0.75      0.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.06G     0.9829      1.426      1.734      1.297         21        640: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.633      0.717      0.744      0.468       0.64      0.725      0.758      0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.94G     0.9004      1.004      1.746      1.338         22        640: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.62      0.757      0.748      0.473      0.636      0.753      0.768      0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       4.9G     0.8631      1.557      2.375      1.419         14        640: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.613      0.755       0.75      0.473      0.623      0.768       0.77      0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.91G      0.876      1.215      2.134      1.359         14        640: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.617      0.762      0.752      0.475      0.628      0.775      0.772      0.499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.614      0.764      0.752      0.475      0.625      0.776      0.773      0.499\n",
      "                  legs        474        474      0.614      0.764      0.752      0.475      0.625      0.776      0.773      0.499\n",
      "Speed: 0.6ms preprocess, 13.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▅▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▄▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▅▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▅█▃▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▄█▆▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▆▃▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▃▁▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▁▃▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅▆▁█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▄▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.75228\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.77293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.47457\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.49887\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.61445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.62463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.76371\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.77637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.902\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.87599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.13361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.35882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.21542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.82923\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.07344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.27985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.40663\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_203712-juslgn1e\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_203712-juslgn1e/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.697      0.705      0.757      0.463      0.711      0.716      0.774      0.493\n",
      "                  legs        476        476      0.697      0.705      0.757      0.463      0.711      0.716      0.774      0.493\n",
      "Speed: 0.9ms preprocess, 29.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 141 images, 0 backgrounds, 0 corrupt: 100%|██████████| 141/141 [00:00<00:00, 863.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.92G       1.24      3.198       3.32      1.665         29        640: 100%|██████████| 9/9 [00:07<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.271      0.326      0.152     0.0404      0.463      0.496      0.371     0.0919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.29G      1.033      2.062      2.919      1.485         23        640: 100%|██████████| 9/9 [00:05<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.408      0.451      0.403      0.188      0.441      0.563       0.48      0.233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.16G     0.9291      1.543      2.237      1.424         20        640: 100%|██████████| 9/9 [00:05<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.486       0.65      0.572      0.295      0.564      0.696      0.668      0.344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.15G     0.8829      1.465      1.962      1.337         30        640: 100%|██████████| 9/9 [00:05<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.588      0.614      0.637      0.393      0.605      0.627      0.654      0.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.21G     0.8189      1.372      1.801      1.259         22        640: 100%|██████████| 9/9 [00:05<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.672      0.684      0.744      0.471      0.705      0.665      0.754      0.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.028 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.671      0.681      0.743       0.47      0.705      0.664      0.753      0.494\n",
      "                  legs        474        474      0.671      0.681      0.743       0.47      0.705      0.664      0.753      0.494\n",
      "Speed: 0.7ms preprocess, 13.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▂▁▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃█▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.05692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.74273\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.75311\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.46983\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.4937\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.67053\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.70468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.68143\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.66449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.161\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.8189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.80128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.25927\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.37246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.81382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.06367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.26002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.37117\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_204001-o413wjl4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_204001-o413wjl4/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.616      0.731      0.725      0.454      0.646      0.737      0.744      0.476\n",
      "                  legs        476        476      0.616      0.731      0.725      0.454      0.646      0.737      0.744      0.476\n",
      "Speed: 0.6ms preprocess, 29.7ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.5381390802312769\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_31/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 457.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_31/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.13G     0.9442      1.703      1.885      1.301         19        640: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.617      0.698      0.716      0.446      0.632      0.699      0.727      0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.03G      1.014      2.245       1.85      1.411         19        640: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.618      0.707      0.722       0.45      0.627      0.713      0.732      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.94G      0.763      1.877      1.747      1.193         21        640: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.607      0.724      0.722       0.45      0.642      0.709      0.734      0.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.93G     0.7366      1.594      2.287       1.17         11        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.644      0.681      0.726      0.455      0.657      0.679      0.737      0.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.93G     0.7706        1.4      1.882      1.231         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.643      0.692      0.728      0.457      0.658       0.69       0.74      0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.641      0.692      0.728      0.457      0.658      0.694       0.74      0.484\n",
      "                  legs        474        474      0.641      0.692      0.728      0.457      0.658      0.694       0.74      0.484\n",
      "Speed: 0.8ms preprocess, 13.2ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▄▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▃▃▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▂▁▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▄▅█▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▅█▇▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▆█▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▃▂▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅█▂▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄█▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▆█▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▅█▂▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.72787\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.73969\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.45675\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.48443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.64149\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.65785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.69198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.69409\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.966\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.77064\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.88153\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.23106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.39951\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.82433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.12029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.26464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.42355\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_204523-379rycin\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_204523-379rycin/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.624      0.752      0.713       0.44       0.65      0.772      0.732      0.466\n",
      "                  legs        476        476      0.624      0.752      0.713       0.44       0.65      0.772      0.732      0.466\n",
      "Speed: 0.7ms preprocess, 29.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|██████████| 151/151 [00:00<00:00, 1051.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.91G      1.256      3.031      3.299      1.706         12        640: 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.303      0.329      0.173      0.049       0.47      0.496      0.389      0.101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.26G     0.9807      1.922      2.609      1.447         13        640: 100%|██████████| 10/10 [00:05<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.372      0.604      0.452      0.218      0.448      0.646      0.531      0.255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.16G     0.8061      1.605      2.181      1.305         10        640: 100%|██████████| 10/10 [00:05<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.598      0.755      0.693      0.367      0.688      0.739      0.751      0.401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.19G     0.7651      1.356      1.782       1.25         14        640: 100%|██████████| 10/10 [00:05<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.66      0.715      0.735      0.458      0.653      0.724      0.743       0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.19G     0.8043      1.373      1.669      1.268         10        640: 100%|██████████| 10/10 [00:05<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.72      0.775      0.811      0.539      0.732       0.78      0.817      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.028 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.719      0.772      0.811      0.539      0.731      0.778      0.817      0.555\n",
      "                  legs        474        474      0.719      0.772      0.811      0.539      0.731      0.778      0.817      0.555\n",
      "Speed: 0.7ms preprocess, 13.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▂▁▇▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▅▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.05202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.8112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.81653\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.53886\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.55465\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.71944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.73052\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.77215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.77781\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.80433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.66886\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.26759\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.37306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.76768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.79501\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.23879\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.27489\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_204813-lty163fh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_204813-lty163fh/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.693      0.767      0.793       0.51        0.7      0.775      0.805      0.529\n",
      "                  legs        476        476      0.693      0.767      0.793       0.51        0.7      0.775      0.805      0.529\n",
      "Speed: 0.8ms preprocess, 29.4ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.8362157257080771\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_32/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 619.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_32/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.54G     0.7062      1.311      1.611      1.194         18        640: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.726      0.764      0.793      0.513      0.731      0.776      0.798      0.537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.06G     0.9092      1.511      1.701      1.278         25        640: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.726      0.759      0.795      0.515      0.738      0.772      0.801      0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.94G      1.068      1.401      1.609       1.38         21        640: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.733      0.758      0.795      0.516      0.742       0.77      0.799      0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.92G     0.8317      1.356      1.822      1.371         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.729      0.766      0.797      0.518      0.733      0.775      0.802      0.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.92G     0.7004      1.187      1.606      1.292         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.738      0.764      0.799      0.519      0.743      0.772      0.803      0.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.74      0.764      0.798      0.519      0.748      0.772      0.803      0.542\n",
      "                  legs        474        474       0.74      0.764      0.798      0.519      0.748      0.772      0.803      0.542\n",
      "Speed: 0.6ms preprocess, 13.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▅▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▅▅█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▁▄▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▅▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▆▂▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▃▁▆▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▅█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▄▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▄██▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄█▆▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▆▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▁▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.7982\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.80253\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.51873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.54237\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.74048\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.74796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.76371\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.77215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.70042\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.6065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.29227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.1872\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.78261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.81981\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.24419\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.29414\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_205334-drsuwbpu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_205334-drsuwbpu/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.657       0.81      0.776      0.493      0.662      0.824      0.793      0.518\n",
      "                  legs        476        476      0.657       0.81      0.776      0.493      0.662      0.824      0.793      0.518\n",
      "Speed: 1.1ms preprocess, 29.7ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 161 images, 0 backgrounds, 0 corrupt: 100%|██████████| 161/161 [00:00<00:00, 907.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.93G      1.395      3.222      3.487      1.862          1        640: 100%|██████████| 11/11 [00:08<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.322      0.357      0.204     0.0592      0.511      0.511      0.425      0.116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.31G      1.027      2.016      2.766      1.467          1        640: 100%|██████████| 11/11 [00:06<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.356      0.528      0.352       0.17      0.421      0.589      0.414      0.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.35G     0.8226      1.431       2.11      1.366          1        640: 100%|██████████| 11/11 [00:06<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.576      0.707      0.648       0.37      0.602      0.724      0.677      0.384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.16G     0.7882      1.375      1.872      1.275          1        640: 100%|██████████| 11/11 [00:06<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.573      0.733      0.683      0.443       0.61      0.711      0.706      0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.22G      0.679      1.382      1.422      1.205          2        640: 100%|██████████| 11/11 [00:06<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.712      0.758      0.814      0.555      0.725      0.762      0.823       0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.029 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.715      0.755      0.815      0.556      0.727      0.764      0.825      0.571\n",
      "                  legs        474        474      0.715      0.755      0.815      0.556      0.727      0.764      0.825      0.571\n",
      "Speed: 0.8ms preprocess, 13.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▆▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▃▁▅▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▃▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.04712\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.81506\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.82465\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.55553\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.57066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.71456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.72698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.75527\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.76398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.138\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.679\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.42173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.20504\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.38166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.73503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.80621\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.21124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.20737\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_205623-lidowa1f\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_205623-lidowa1f/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.758      0.712      0.812      0.546      0.785      0.729      0.832      0.574\n",
      "                  legs        476        476      0.758      0.712      0.812      0.546      0.785      0.729      0.832      0.574\n",
      "Speed: 0.8ms preprocess, 29.5ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 2.005271886218359\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_33/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 553.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_33/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.18G     0.6884      1.217      1.364      1.196         20        640: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.71      0.722      0.781       0.53      0.714      0.741       0.79       0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.06G     0.7285      1.178      1.806      1.162         23        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.714       0.73      0.784      0.532      0.723      0.741      0.793      0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.93G     0.9139      1.356       1.53      1.244         19        640: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.715       0.73      0.786      0.532      0.723      0.745      0.795      0.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.92G     0.7493     0.9758      1.439      1.208         15        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474        0.7      0.743      0.785      0.531        0.7      0.762      0.794      0.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.93G     0.8469      1.252       1.39      1.317         21        640: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.723      0.723      0.785       0.53      0.702      0.762      0.794      0.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.715       0.73      0.786      0.531      0.719      0.747      0.795      0.551\n",
      "                  legs        474        474      0.715       0.73      0.786      0.531      0.719      0.747      0.795      0.551\n",
      "Speed: 0.8ms preprocess, 13.1ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▅█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▅█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▇█▄▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▄▁█▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▆██▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▅██▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄▄█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▁▂█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▂█▃▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▃▁▅▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅▅█▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁█▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▆▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.7859\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.7947\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.53133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.55128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.71492\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.7195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.7301\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.74684\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.84687\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.38993\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.31745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.25235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.75379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.86022\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.22639\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.23586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_210148-pvoy7pwz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_210148-pvoy7pwz/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.742        0.7      0.811      0.534      0.747      0.744       0.83      0.567\n",
      "                  legs        476        476      0.742        0.7      0.811      0.534      0.747      0.744       0.83      0.567\n",
      "Speed: 0.6ms preprocess, 29.2ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 171 images, 0 backgrounds, 0 corrupt: 100%|██████████| 171/171 [00:00<00:00, 1058.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.07G      1.245      3.237      3.349      1.677         15        640: 100%|██████████| 11/11 [00:08<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.298      0.365      0.195     0.0597      0.477       0.53      0.417      0.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.59G      1.002      1.795      2.557      1.471         29        640: 100%|██████████| 11/11 [00:06<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.382       0.53      0.385      0.185      0.458      0.576      0.485      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       8.2G     0.8834      1.649      2.271      1.357         24        640: 100%|██████████| 11/11 [00:06<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.584      0.622      0.612      0.339      0.596      0.635      0.637       0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.48G     0.7362      1.349       1.76      1.217         18        640: 100%|██████████| 11/11 [00:06<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.646      0.653      0.673       0.44      0.654      0.671      0.683      0.457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.16G     0.7847      1.433      1.672      1.227         22        640: 100%|██████████| 11/11 [00:06<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.695      0.759      0.797      0.527      0.703      0.768      0.806      0.548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.030 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.696      0.755      0.797      0.528      0.704      0.772      0.807      0.549\n",
      "                  legs        474        474      0.696      0.755      0.797      0.528      0.704      0.772      0.807      0.549\n",
      "Speed: 0.8ms preprocess, 13.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▂▁▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▅▃▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▅▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.04712\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.79745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.80656\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.5275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.54859\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.69637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.70407\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.75483\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.77215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.78469\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.67214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.22712\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.43285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.8194\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.85414\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.27213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.30921\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_210436-t945mnhw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_210436-t945mnhw/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.661      0.773      0.786      0.524      0.681      0.777      0.808      0.544\n",
      "                  legs        476        476      0.661      0.773      0.786      0.524      0.681      0.777      0.808      0.544\n",
      "Speed: 0.8ms preprocess, 29.4ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.4029729167192504\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_34/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 366.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_34/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.53G     0.9081      1.514       1.89      1.279         21        640: 100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.666      0.747      0.753      0.489      0.691      0.728       0.76      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.04G     0.8002      1.114      1.773      1.248         20        640: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.685      0.717      0.754      0.489      0.691      0.724      0.761      0.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.91G     0.7855      1.038      2.144       1.24         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.68      0.726      0.757       0.49      0.685      0.734      0.764      0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.94G     0.8609      1.571      2.041      1.308         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.68      0.735      0.759      0.492      0.686      0.743      0.766      0.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.92G     0.8084      1.275      1.648      1.317         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.685      0.732      0.762      0.495      0.689      0.744      0.769      0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.688      0.731      0.761      0.495      0.693      0.741      0.769      0.521\n",
      "                  legs        474        474      0.688      0.731      0.761      0.495      0.693      0.741      0.769      0.521\n",
      "Speed: 0.7ms preprocess, 13.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▂▃▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▇▆▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▇▇▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▁▃▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▃▁▅█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▂▁▅▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▄▃█▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅▂▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▇▂▁█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▂▁▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▃▁▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▁▇▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.76141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.76905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.49526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.52123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.68819\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.69259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.73104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.74051\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.80837\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.64805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.31698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.27521\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.83143\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.84473\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.28459\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.37119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_211003-6pfumvwq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_211003-6pfumvwq/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.691      0.722       0.77      0.508      0.705      0.746      0.793      0.536\n",
      "                  legs        476        476      0.691      0.722       0.77      0.508      0.705      0.746      0.793      0.536\n",
      "Speed: 0.8ms preprocess, 29.1ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 181 images, 0 backgrounds, 0 corrupt: 100%|██████████| 181/181 [00:00<00:00, 879.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.28G      1.291      2.866      3.351        1.7          9        640: 100%|██████████| 12/12 [00:08<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.31       0.34      0.201     0.0646       0.48      0.483      0.409      0.117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.27G     0.9993      1.869      2.497       1.45         15        640: 100%|██████████| 12/12 [00:07<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.492      0.622      0.507       0.24      0.565      0.671      0.604      0.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.15G     0.8365      1.406      2.005      1.269         11        640: 100%|██████████| 12/12 [00:07<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.644      0.753      0.731      0.447      0.652       0.77      0.743      0.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       8.2G     0.7903      1.249      1.671      1.236          7        640: 100%|██████████| 12/12 [00:06<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.741      0.814      0.844      0.569      0.743      0.817      0.847      0.584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.45G     0.6927      1.161      1.232      1.165         11        640: 100%|██████████| 12/12 [00:06<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.822      0.808      0.902      0.625      0.818      0.833      0.905      0.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.030 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.819      0.808      0.902      0.625      0.815      0.833      0.905      0.645\n",
      "                  legs        474        474      0.819      0.808      0.902      0.625      0.815      0.833      0.905      0.645\n",
      "Speed: 0.6ms preprocess, 13.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.04223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.9021\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.90491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.6248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.64549\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.81922\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.81514\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.80802\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.83333\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.19\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.69266\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.23199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.16516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.16066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.79425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.29804\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.23334\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.16458\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_211251-jke4w0k3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_211251-jke4w0k3/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.834      0.832      0.898      0.616      0.835       0.84      0.905      0.642\n",
      "                  legs        476        476      0.834      0.832      0.898      0.616      0.835       0.84      0.905      0.642\n",
      "Speed: 1.0ms preprocess, 29.5ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 2.1139770827112994\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_35/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 573.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_35/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.54G     0.9919      1.149      1.586      1.358         20        640: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.794      0.795      0.867      0.596      0.796      0.797      0.871      0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.05G     0.9094      1.194      1.382      1.249         22        640: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.803      0.793      0.868      0.597      0.805      0.794      0.873      0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.94G     0.7981      1.363      1.493      1.344         21        640: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.792      0.797      0.869      0.597      0.796      0.801      0.875      0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.92G     0.9865      1.876      1.789      1.283         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.774      0.819      0.868      0.596      0.793      0.808      0.875      0.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.91G     0.6839      1.586      1.804      1.243         19        640: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.798      0.797      0.867      0.596      0.805      0.804      0.875      0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.793      0.798      0.868      0.596        0.8        0.8      0.875      0.619\n",
      "                  legs        474        474      0.793      0.798      0.868      0.596        0.8        0.8      0.875      0.619\n",
      "Speed: 0.8ms preprocess, 13.0ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▅█▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▄▇█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁█▇▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▅█▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▆█▅▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▃█▃▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▂▁▂█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▃▁▅█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▆▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▄▁▃██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▁▇▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▁▃█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ██▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▆▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.86842\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.8747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.59602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.6186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.79252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.79966\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.79777\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.79998\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.918\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.68395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.80362\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.24254\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.5863\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.79089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.34559\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.23221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.18607\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_211820-gvrpfsj1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_211820-gvrpfsj1/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.808       0.83      0.874        0.6      0.812      0.851      0.892      0.624\n",
      "                  legs        476        476      0.808       0.83      0.874        0.6      0.812      0.851      0.892      0.624\n",
      "Speed: 0.8ms preprocess, 29.0ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 191 images, 0 backgrounds, 0 corrupt: 100%|██████████| 191/191 [00:00<00:00, 1024.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.43G      1.213      2.786      3.134       1.63         30        640: 100%|██████████| 12/12 [00:09<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.299      0.359      0.222     0.0741      0.444      0.464      0.399      0.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.25G     0.9367       1.79      2.522      1.454         23        640: 100%|██████████| 12/12 [00:07<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.415      0.591      0.452      0.262      0.443       0.61      0.479      0.289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.19G     0.8308      1.415      1.933      1.299         32        640: 100%|██████████| 12/12 [00:07<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.594      0.686      0.689      0.426      0.601      0.694      0.699      0.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.21G     0.7691       1.31      1.591      1.233         27        640: 100%|██████████| 12/12 [00:07<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.689      0.777      0.802      0.538      0.701      0.781      0.818       0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.16G     0.7046      1.159      1.359      1.165         29        640: 100%|██████████| 12/12 [00:07<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.79      0.787      0.874      0.599      0.804      0.797      0.883      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.031 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.791      0.789      0.874      0.599      0.803      0.798      0.883      0.627\n",
      "                  legs        474        474      0.791      0.789      0.874      0.599      0.803      0.798      0.883      0.627\n",
      "Speed: 0.7ms preprocess, 13.3ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▄▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.04223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.87405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.88265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.59913\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.62719\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.79117\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.80259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.78903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.79767\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.373\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.70456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.35928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.16505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.15892\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.76746\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.41292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.20223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.17311\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_212107-n37l5msz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_212107-n37l5msz/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.767      0.805      0.858      0.581      0.774      0.819      0.876      0.619\n",
      "                  legs        476        476      0.767      0.805      0.858      0.581      0.774      0.819      0.876      0.619\n",
      "Speed: 0.9ms preprocess, 29.4ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.49592318949898\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_36/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 481.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_36/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.19G     0.6971      1.482      1.356      1.105         18        640: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.775      0.764      0.858      0.587      0.778      0.768      0.863      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5         5G      0.854      1.775      1.765      1.221         13        640: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.768      0.766      0.856      0.585      0.759      0.775      0.862      0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.94G     0.6902      1.143       1.08      1.147         20        640: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.734      0.791      0.855      0.587      0.753       0.79      0.861       0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.88G     0.6769      1.327      1.442      1.154         12        640: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.723      0.797      0.856       0.59      0.784      0.753      0.862      0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.92G     0.6363      1.104      1.087      1.206         15        640: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.733      0.797      0.855       0.59      0.811      0.745      0.861      0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.734      0.797      0.854      0.591      0.815      0.741      0.862      0.614\n",
      "                  legs        474        474      0.734      0.797      0.854      0.591      0.815      0.741      0.862      0.614\n",
      "Speed: 0.7ms preprocess, 13.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▅▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▂▁▄▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▃▁▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▂▁▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▇▃▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▄▂▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▁▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▅▆█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▃█▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▄█▁▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁█▄▄▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅█▁▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▆█▇▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ██▇▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.85443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.86166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.59093\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.61379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.73374\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.8145\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.79747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.74051\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.912\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.63632\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.08746\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.20621\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.10359\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.79214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.45027\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.23747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_212637-rhw11ku1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_212637-rhw11ku1/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.783      0.763      0.835      0.556      0.763      0.798      0.856      0.596\n",
      "                  legs        476        476      0.783      0.763      0.835      0.556      0.763      0.798      0.856      0.596\n",
      "Speed: 0.7ms preprocess, 29.2ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 201 images, 0 backgrounds, 0 corrupt: 100%|██████████| 201/201 [00:00<00:00, 1128.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.93G      1.229      3.055      3.138       1.66         16        640: 100%|██████████| 13/13 [00:09<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.328      0.443      0.329      0.149      0.438      0.502      0.448      0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.31G     0.9452      1.798      2.441      1.404         12        640: 100%|██████████| 13/13 [00:07<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.49      0.627       0.54      0.288       0.55      0.622      0.605      0.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.15G     0.8137      1.496      1.835      1.278         17        640: 100%|██████████| 13/13 [00:08<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.683      0.726      0.764      0.495      0.699      0.743      0.774      0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.12G     0.7519      1.286      1.481      1.208         19        640: 100%|██████████| 13/13 [00:07<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.788      0.762      0.865      0.568      0.781      0.789      0.875      0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.15G     0.7311      1.157      1.214      1.201         14        640: 100%|██████████| 13/13 [00:07<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474        0.8      0.759      0.862      0.604      0.808      0.768      0.872      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.031 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.797      0.757      0.862      0.603      0.805      0.766      0.872      0.637\n",
      "                  legs        474        474      0.797      0.757      0.862      0.603      0.805      0.766      0.872      0.637\n",
      "Speed: 0.8ms preprocess, 13.5ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▄▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▇█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▁▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▃▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▇▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.03733\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.86159\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.87241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.60293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.63673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.79656\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.80543\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.75738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.76582\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.308\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.73112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.21396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.20135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.15658\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.78461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.32752\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.2096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.16187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_212924-8yupd7jk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_212924-8yupd7jk/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.768      0.771      0.847      0.586      0.773       0.78      0.852      0.616\n",
      "                  legs        476        476      0.768      0.771      0.847      0.586      0.773       0.78      0.852      0.616\n",
      "Speed: 0.8ms preprocess, 29.6ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.1389723285674234\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_37/train/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<00:00, 463.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_37/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.01G     0.7408      1.091      1.208      1.221          4        640: 100%|██████████| 4/4 [00:03<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.775      0.743      0.841      0.582       0.78      0.745      0.848      0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      7.76G     0.8311       1.51      1.184      1.265          3        640: 100%|██████████| 4/4 [00:02<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.723      0.759      0.818      0.561      0.727      0.768      0.831      0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.74G     0.7096      1.128      1.269      1.141          2        640: 100%|██████████| 4/4 [00:02<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.832      0.828      0.909      0.629      0.843      0.835      0.917      0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      7.75G     0.8381      1.145      1.161      1.227          4        640: 100%|██████████| 4/4 [00:02<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.899      0.846      0.939      0.638      0.908      0.857      0.945      0.668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      7.77G     0.6618      1.023      1.083      1.132          3        640: 100%|██████████| 4/4 [00:01<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.89      0.852      0.942      0.646      0.894      0.858      0.948      0.672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.888      0.852      0.942      0.645      0.892      0.858      0.948      0.673\n",
      "                  legs        474        474      0.888      0.852      0.942      0.645      0.892      0.858      0.948      0.673\n",
      "Speed: 0.8ms preprocess, 13.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▂▁▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▂▁▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▃▁▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▃▁▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▃▁▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▃▁▅█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▄█▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▆▅█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▆█▁▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▂█▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▄▃█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▇█▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▅▃██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ██▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.9421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.94776\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.64543\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.67253\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.88848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.8925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.85232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.85824\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.66185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.08337\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.13214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.02267\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.81386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.22977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.24214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.11133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_213457-wra1f1sw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_213457-wra1f1sw/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.837       0.88      0.926      0.633      0.843      0.887      0.931      0.661\n",
      "                  legs        476        476      0.837       0.88      0.926      0.633      0.843      0.887      0.931      0.661\n",
      "Speed: 0.7ms preprocess, 29.5ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.3130128287702627\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_38/train/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<00:00, 512.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_38/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.91G     0.7697      1.204        1.4      1.224          3        640: 100%|██████████| 4/4 [00:03<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.814      0.871      0.922      0.626      0.823      0.878      0.929      0.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.07G     0.9353      1.036      1.451      1.279          3        640: 100%|██████████| 4/4 [00:02<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.879      0.838       0.93      0.638      0.884      0.842      0.936       0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       7.8G     0.8677      1.227      1.245      1.303          3        640: 100%|██████████| 4/4 [00:02<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.827      0.827      0.907      0.635      0.824      0.838      0.912      0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       7.8G     0.6991     0.8831      1.206      1.168          3        640: 100%|██████████| 4/4 [00:02<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.814       0.84      0.906      0.638      0.828      0.844      0.912      0.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      7.74G     0.8149      1.211      1.548      1.183          3        640: 100%|██████████| 4/4 [00:01<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.851      0.829      0.912      0.644      0.855      0.833      0.916      0.668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.879      0.838       0.93      0.637      0.895      0.842      0.936      0.669\n",
      "                  legs        474        474      0.879      0.838       0.93      0.637      0.895      0.842      0.936      0.669\n",
      "Speed: 0.7ms preprocess, 13.0ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▆█▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▆█▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁█▆█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁█▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁█▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▇▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▃▁▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▂▁▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▃█▆▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▅▆▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▄▇█▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▄█▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▇▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.93024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.93614\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.63711\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.66902\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.87902\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.89528\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.83755\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.84177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.81492\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.54843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.18345\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.21085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.75204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.15462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.20535\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.11649\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_213857-qjl4d7xf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_213857-qjl4d7xf/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.782      0.851      0.899      0.613      0.794       0.85      0.907      0.645\n",
      "                  legs        476        476      0.782      0.851      0.899      0.613      0.794       0.85      0.907      0.645\n",
      "Speed: 0.8ms preprocess, 29.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 301 images, 0 backgrounds, 0 corrupt: 100%|██████████| 301/301 [00:00<00:00, 1036.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.27G      1.183      2.564      3.087      1.602         24        640: 100%|██████████| 19/19 [00:14<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.313      0.498      0.318      0.172       0.34       0.54      0.363        0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.53G     0.8871       1.53      2.129      1.352         29        640: 100%|██████████| 19/19 [00:11<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.61      0.732      0.697      0.444      0.617      0.741       0.71      0.465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.37G     0.7766      1.181      1.385      1.222         31        640: 100%|██████████| 19/19 [00:11<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.763      0.831      0.872        0.6      0.784      0.827       0.88       0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.41G     0.7653      1.065      1.063      1.168         21        640: 100%|██████████| 19/19 [00:11<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.938      0.884      0.967      0.679      0.928       0.89      0.971      0.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.37G     0.7168      1.127     0.8145      1.148         22        640: 100%|██████████| 19/19 [00:11<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.92      0.943      0.976      0.704       0.92      0.943      0.976      0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.036 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.921      0.945      0.976      0.705      0.921      0.945      0.976      0.723\n",
      "                  legs        474        474      0.921      0.945      0.976      0.705      0.921      0.945      0.976      0.723\n",
      "Speed: 0.8ms preprocess, 13.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▅▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▅▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▅▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▅▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▄▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▁▃▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.97591\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.97625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.70495\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.72291\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.92057\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.92057\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.94515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.94515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.409\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.71684\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.81454\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.14809\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.12745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.81855\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.78538\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.21925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.08416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_214153-xov8jlz6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_214153-xov8jlz6/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476       0.91       0.93      0.971      0.702      0.915      0.929      0.975      0.708\n",
      "                  legs        476        476       0.91       0.93      0.971      0.702      0.915      0.929      0.975      0.708\n",
      "Speed: 0.8ms preprocess, 29.5ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.4645822827626414\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_39/train/labels... 100 images, 0 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:00<00:00, 434.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_39/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.08G      0.843      1.245     0.8704      1.193          8        640: 100%|██████████| 7/7 [00:05<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.932       0.93      0.972      0.698      0.936      0.937      0.978      0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.17G      0.835       1.43     0.9644      1.181          7        640: 100%|██████████| 7/7 [00:04<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.966       0.92      0.979      0.713      0.966       0.92      0.979       0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.11G     0.7571      1.249     0.8132      1.136         10        640: 100%|██████████| 7/7 [00:03<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.974      0.931      0.982      0.724      0.976      0.933      0.982      0.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.09G     0.7002      1.213     0.7656      1.124          9        640: 100%|██████████| 7/7 [00:03<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.958      0.945      0.984      0.737      0.961      0.947      0.984      0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      7.78G     0.6557      1.039     0.6986      1.101         10        640: 100%|██████████| 7/7 [00:03<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.964      0.955      0.986      0.724      0.966      0.957      0.988       0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.025 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.957      0.945      0.984      0.737      0.959      0.947      0.984      0.744\n",
      "                  legs        474        474      0.957      0.945      0.984      0.737      0.959      0.947      0.984      0.744\n",
      "Speed: 0.9ms preprocess, 13.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▅▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▄▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▇█▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▆█▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▄▁▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▅▁▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ██▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▆█▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▇▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅█▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▂▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▆▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▃▁▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▃▇▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.98383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.9843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.73713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.74425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.95701\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.95914\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.94515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.94726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.65568\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.69863\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.10147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.03851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.81082\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.67038\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.20772\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.02846\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_214743-k8l2zvuo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_214743-k8l2zvuo/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.956       0.95      0.987      0.737      0.965      0.958       0.99      0.748\n",
      "                  legs        476        476      0.956       0.95      0.987      0.737      0.965      0.958       0.99      0.748\n",
      "Speed: 0.7ms preprocess, 29.6ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.5909060628448537\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_40/train/labels... 100 images, 0 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:00<00:00, 460.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_40/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.86G     0.7026     0.9687     0.7445      1.114         12        640: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.961      0.956      0.984      0.735      0.961      0.956      0.985      0.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      7.85G     0.7527     0.9444     0.8607      1.142          7        640: 100%|██████████| 7/7 [00:04<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.941      0.935       0.98      0.743      0.941      0.935      0.981      0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.02G     0.8443      1.117     0.8335      1.247          7        640: 100%|██████████| 7/7 [00:03<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.943      0.951      0.987      0.753      0.946      0.953      0.987      0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      7.74G     0.6361     0.9406      0.722      1.089         11        640: 100%|██████████| 7/7 [00:03<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.954      0.954      0.988      0.758      0.954      0.954      0.987      0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      7.77G     0.6844      1.099     0.7862      1.122          9        640: 100%|██████████| 7/7 [00:03<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.95      0.947      0.985      0.761       0.95      0.947      0.985      0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.949      0.947      0.985      0.761      0.949      0.947      0.985      0.765\n",
      "                  legs        474        474      0.949      0.947      0.985      0.761      0.949      0.947      0.985      0.765\n",
      "Speed: 0.9ms preprocess, 13.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▅▁██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▅▁██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▁▂▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▁▂▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▁▆▇▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▁▇▇▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▃▅█▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▂█▇▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂▃█▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▂▁█▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▇█▃▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.98519\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.98519\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.76112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.76514\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.94928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.94928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.94726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.94726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.68438\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.78623\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.12191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.09942\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.70987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.62381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.1533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.96942\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_215148-tbwkhxfj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_215148-tbwkhxfj/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.948      0.961      0.988      0.759      0.948      0.961      0.988      0.766\n",
      "                  legs        476        476      0.948      0.961      0.988      0.759      0.948      0.961      0.988      0.766\n",
      "Speed: 0.8ms preprocess, 29.8ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.538249633691843\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_41/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:01<00:00, 437.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_41/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.86G     0.7723      1.034     0.7861      1.157          6        640: 100%|██████████| 32/32 [00:21<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.96      0.937      0.983      0.733      0.965      0.944      0.987      0.743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      7.86G     0.7211      1.043     0.7678      1.109         13        640: 100%|██████████| 32/32 [00:19<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.854      0.941      0.904       0.63      0.855      0.943      0.906      0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.76G      0.716      1.039     0.7516      1.093         11        640: 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.961      0.927      0.983      0.733      0.962      0.928      0.983      0.746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.09G     0.7502      1.039     0.7314       1.11          5        640: 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.897      0.916      0.956      0.686       0.92      0.917      0.961      0.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.06G     0.7438       1.01     0.6733      1.111          7        640: 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.932      0.932      0.973      0.693      0.938      0.931      0.972       0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.044 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.961      0.927      0.983      0.733      0.962      0.928      0.983      0.746\n",
      "                  legs        474        474      0.961      0.927      0.983      0.733      0.962      0.928      0.983      0.746\n",
      "Speed: 0.7ms preprocess, 13.1ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▁█▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▁█▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▁█▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▁█▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▁█▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▁█▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▇█▄▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ██▄▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▂▁▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▇▆▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▃▁▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▆█▇▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▄▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▂█▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▄▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▃▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.98334\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.98336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.73279\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.7461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.96063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.96226\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.92671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.92827\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.74382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.67326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.11147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.00982\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.93099\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.61332\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.27469\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.20356\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_215553-gj0t2l24\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_215553-gj0t2l24/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:19<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.972      0.933      0.988      0.742      0.969      0.931      0.985      0.756\n",
      "                  legs        476        476      0.972      0.933      0.988      0.742      0.969      0.931      0.985      0.756\n",
      "Speed: 0.9ms preprocess, 29.0ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 1001 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1001/1001 [00:01<00:00, 954.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.47G     0.9633      1.809      2.118      1.369         18        640: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.856      0.821      0.911      0.639      0.861      0.825      0.917      0.666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       8.3G     0.7489      1.098     0.9576      1.172         13        640: 100%|██████████| 63/63 [00:38<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.948      0.914      0.974      0.701      0.948      0.916      0.976      0.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.28G     0.7345      1.119      0.791      1.128         16        640: 100%|██████████| 63/63 [00:38<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.886      0.865      0.932       0.67      0.888      0.867      0.933       0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.28G     0.7639      1.101     0.7339      1.131         15        640: 100%|██████████| 63/63 [00:37<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.925       0.92      0.969      0.732      0.932      0.932      0.977      0.738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.32G     0.7322      1.025     0.6735       1.12         21        640: 100%|██████████| 63/63 [00:37<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.963      0.881      0.961      0.711      0.963      0.881       0.96      0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.072 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.924       0.92      0.969      0.732      0.931      0.932      0.977      0.739\n",
      "                  legs        474        474      0.924       0.92      0.969      0.732      0.931      0.932      0.977      0.739\n",
      "Speed: 0.9ms preprocess, 13.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▅▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁█▃▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁█▃██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▆▃██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▂▆▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁█▃▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁█▃▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁█▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▇▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▂▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▆█▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▃▃▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▄█▇▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▂▁█▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.96923\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.97671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.73232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.73885\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.92386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.93053\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.91983\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.93249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.73221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.6735\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.11967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.02462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.83565\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.66716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.21859\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.1833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_220010-556tjzm9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_220010-556tjzm9/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.942      0.935      0.982      0.749      0.946      0.939      0.983      0.749\n",
      "                  legs        476        476      0.942      0.935      0.982      0.749      0.946      0.939      0.983      0.749\n",
      "Speed: 0.9ms preprocess, 29.0ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.0837491350392578\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_42/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:01<00:00, 429.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_42/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.94G      0.706      1.028     0.5957      1.111          7        640: 100%|██████████| 32/32 [00:21<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.981      0.971      0.993      0.772      0.983      0.973      0.994      0.791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      7.89G     0.7249      1.014     0.6256      1.124          5        640: 100%|██████████| 32/32 [00:19<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.968      0.948      0.982      0.732      0.968      0.948      0.982      0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.81G     0.7297      1.026     0.5953      1.117          7        640: 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.958      0.965      0.989      0.758      0.958      0.965      0.989      0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      7.74G     0.7011     0.9449     0.6125      1.117          8        640: 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.958       0.96      0.988      0.765      0.956      0.965      0.987      0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.07G     0.6567     0.9314     0.5361      1.092          6        640: 100%|██████████| 32/32 [00:19<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.959      0.935      0.987      0.743      0.959      0.928      0.979      0.752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.044 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.981       0.97      0.993      0.772      0.983      0.972      0.994      0.791\n",
      "                  legs        474        474      0.981       0.97      0.993      0.772      0.983      0.972      0.994      0.791\n",
      "Speed: 0.7ms preprocess, 13.1ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▁▆▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▁▅▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▁▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▁▅▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▄▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▄▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▁▆▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▁▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▆██▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▆█▆▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅█▇▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▇█▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁█▃▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▄█▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▆▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁█▂▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99352\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.77163\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.79128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.98081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.98294\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.97038\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.97249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.65672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.53612\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.09187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.93139\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.81706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.52398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.24767\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.06597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_220808-rxw7tdhw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_220808-rxw7tdhw/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.961      0.981      0.993      0.782      0.961      0.982      0.993      0.794\n",
      "                  legs        476        476      0.961      0.981      0.993      0.782      0.961      0.982      0.993      0.794\n",
      "Speed: 1.1ms preprocess, 28.8ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.3157832245085626\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_43/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:01<00:00, 439.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_43/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.88G     0.7292      1.036     0.5722      1.158         10        640: 100%|██████████| 32/32 [00:21<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.953       0.97      0.991      0.771      0.953       0.97      0.991      0.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      7.83G     0.7268      1.013     0.5672      1.154         10        640: 100%|██████████| 32/32 [00:19<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.956      0.969      0.991      0.764      0.956      0.969      0.991      0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.73G     0.6975     0.9631     0.6128      1.132          7        640: 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.95       0.97      0.989      0.722      0.949      0.973       0.99      0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.09G     0.6681     0.9619     0.5887      1.086         13        640: 100%|██████████| 32/32 [00:19<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.971      0.964      0.992      0.748      0.971      0.964      0.992      0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.11G     0.6839      1.022     0.5863      1.088         12        640: 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.968      0.952      0.985      0.763      0.962      0.956      0.986      0.787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.044 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.952      0.971      0.991       0.77      0.952      0.971      0.991      0.795\n",
      "                  legs        474        474      0.952      0.971      0.991       0.77      0.952      0.971      0.991      0.795\n",
      "Speed: 0.7ms preprocess, 13.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▆▇▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▆▇▁█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▇▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▅▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▂▃▁█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▂▃▁█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▇▆▇▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▆▅█▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ██▄▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▂▁█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ██▅▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▁▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▂▁█▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▃█▄▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▂▂█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▇▅█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99111\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99117\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.77027\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.79509\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.95241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.95241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.6839\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.58629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.08838\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.02245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.7559\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.53913\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.17203\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.98576\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_221325-2pivgh02\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_221325-2pivgh02/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.978      0.966      0.992      0.789      0.981      0.968      0.992      0.809\n",
      "                  legs        476        476      0.978      0.966      0.992      0.789      0.981      0.968      0.992      0.809\n",
      "Speed: 1.1ms preprocess, 29.1ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.2389379375881573\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_44/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:01<00:00, 420.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_44/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       7.9G     0.7356      1.019     0.6368      1.144          8        640: 100%|██████████| 32/32 [00:21<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.974      0.985      0.994      0.789      0.974      0.985      0.994      0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      7.87G      0.706     0.8949     0.5561      1.101          5        640: 100%|██████████| 32/32 [00:19<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.964      0.977      0.991      0.788      0.964      0.977      0.991      0.813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       7.8G     0.7096     0.8875     0.5583      1.104          8        640: 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.958      0.966      0.987      0.739      0.958      0.966      0.986       0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.06G     0.6969     0.9372     0.5659      1.113          9        640: 100%|██████████| 32/32 [00:19<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.953      0.983      0.985      0.754      0.953      0.983      0.985      0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.07G     0.7055     0.9437     0.5608      1.121         11        640: 100%|██████████| 32/32 [00:18<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.966      0.949       0.99      0.761       0.97      0.957       0.99      0.787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.044 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.964      0.977      0.991      0.788      0.964      0.977      0.991      0.813\n",
      "                  legs        474        474      0.964      0.977      0.991      0.788      0.964      0.977      0.991      0.813\n",
      "Speed: 0.7ms preprocess, 13.0ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▆▂▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▆▁▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ██▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▇█▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▅▃▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▅▃▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▅▁▇▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▅▁▇▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▃▃▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▁▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▁▁▃▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▁▁▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▂█▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▃█▇▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▂▁█▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▁█▃▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.78776\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.81301\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.96426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.96426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.97679\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.97679\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.70547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.56085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.12093\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.94372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.76845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.49181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.17966\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.00777\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_221843-txfp39rn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_221843-txfp39rn/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.975      0.981      0.992      0.783      0.975      0.981      0.992      0.805\n",
      "                  legs        476        476      0.975      0.981      0.992      0.783      0.975      0.981      0.992      0.805\n",
      "Speed: 1.4ms preprocess, 29.0ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 2501 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2501/2501 [00:02<00:00, 912.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.51G     0.8485      1.458      1.535      1.283         12        640: 100%|██████████| 157/157 [01:40<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.941       0.92      0.975      0.756      0.936       0.92      0.977      0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.65G     0.7376      1.049     0.7158      1.117          7        640: 100%|██████████| 157/157 [01:35<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.952      0.952      0.981      0.762      0.954      0.954      0.984      0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.33G       0.75      1.027     0.6741      1.136         15        640: 100%|██████████| 157/157 [01:34<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.938       0.95      0.984      0.737      0.938       0.95      0.985      0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.29G     0.7538      1.013     0.6352      1.126         11        640: 100%|██████████| 157/157 [01:34<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.974      0.939      0.986      0.755      0.974      0.939      0.985      0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.24G     0.7384      1.032     0.6337       1.13         11        640: 100%|██████████| 157/157 [01:34<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.953      0.968      0.986      0.754      0.955       0.97      0.988      0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.151 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.975      0.939      0.986      0.754      0.975      0.939      0.985      0.777\n",
      "                  legs        474        474      0.975      0.939      0.986      0.754      0.975      0.939      0.985      0.777\n",
      "Speed: 0.7ms preprocess, 13.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▅▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▅▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▆█▁▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▄▅▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▂▄▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁██▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁█▇▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▁▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▁▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▃█▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃█▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▅█▄▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.98566\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.98481\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.75393\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.77662\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.97459\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.97459\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.93882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.93882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.7384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.63368\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.13005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.03157\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.77607\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.50115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.21539\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 1.03345\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_222301-7n5incry\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_222301-7n5incry/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476       0.96      0.953      0.984      0.761      0.961      0.954      0.986      0.777\n",
      "                  legs        476        476       0.96      0.953      0.984      0.761      0.961      0.954      0.986      0.777\n",
      "Speed: 0.8ms preprocess, 29.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.6618404106959224\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_45/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:01<00:00, 434.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_45/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.62G     0.7648      1.003     0.5745      1.172          9        640: 100%|██████████| 32/32 [00:20<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.976      0.989      0.993      0.788      0.975       0.99      0.994      0.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      7.86G     0.7029     0.8915     0.5389      1.119          6        640: 100%|██████████| 32/32 [00:19<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.982      0.966      0.992      0.771      0.982      0.966      0.992      0.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.77G     0.7258     0.9081      0.584      1.111         10        640: 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.975       0.97      0.991      0.753      0.977      0.975      0.991      0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.08G      0.687     0.9372     0.5411       1.09         11        640: 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.967      0.975      0.991      0.778      0.967      0.975      0.991      0.797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.09G     0.6551     0.9153     0.5176      1.059         10        640: 100%|██████████| 32/32 [00:18<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.967      0.958      0.989      0.759      0.967      0.958      0.989      0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.044 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.976      0.989      0.993      0.788      0.975       0.99      0.994      0.811\n",
      "                  legs        474        474      0.976      0.989      0.993      0.788      0.975       0.99      0.994      0.811\n",
      "Speed: 0.6ms preprocess, 13.0ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▆▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▅▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▅▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▅▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▅█▅▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▅█▆▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▁▂▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▁▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▇▃█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▁▂▄▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▄▃█▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▄█▂▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▇▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▂▁▇▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99333\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.78782\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.81128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.97601\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.97506\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98945\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.98975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.65512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.51763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.05877\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.91528\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.77126\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.50468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.18118\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.99077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_223545-mny40md0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_223545-mny40md0/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:19<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.975      0.991      0.994       0.81      0.975      0.991      0.994      0.832\n",
      "                  legs        476        476      0.975      0.991      0.994       0.81      0.975      0.991      0.994      0.832\n",
      "Speed: 0.8ms preprocess, 29.0ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.068942670711503\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_46/train/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:01<00:00, 427.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_46/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.85G     0.7207      1.005     0.5563       1.12          8        640: 100%|██████████| 32/32 [00:21<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.971      0.989      0.992      0.813      0.973      0.992      0.994      0.835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      7.86G     0.6616     0.9501      0.525      1.086         11        640: 100%|██████████| 32/32 [00:19<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.951      0.979      0.991      0.794      0.951      0.979      0.991      0.823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.73G     0.6932     0.9165      0.543      1.118          7        640: 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.976      0.975      0.993      0.756       0.98      0.979      0.994      0.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      7.78G     0.6589     0.9583       0.53      1.069          5        640: 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.973      0.987       0.99      0.776      0.973      0.987       0.99      0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      7.74G     0.6746     0.9228     0.5046      1.085         10        640: 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.96      0.975       0.99      0.788       0.96      0.975       0.99      0.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.044 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.971      0.989      0.992      0.813      0.973      0.992      0.993      0.835\n",
      "                  legs        474        474      0.971      0.989      0.992      0.813      0.973      0.992      0.993      0.835\n",
      "Speed: 0.9ms preprocess, 13.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▆▃█▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▃█▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▆▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▆▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▇▁█▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▆▁█▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▃▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▁▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▁▅▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▄▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▃█▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▄▁▄▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▂█▇▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▇█▅▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▁█▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99348\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.81278\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.83471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.97077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.97298\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98945\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.99156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.434\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.67465\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.50456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.08508\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.92282\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.74319\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.45078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.16708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.90888\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_224103-4upmvssd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_224103-4upmvssd/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476       0.98      0.992      0.994      0.809      0.978      0.989      0.994      0.826\n",
      "                  legs        476        476       0.98      0.992      0.994      0.809      0.978      0.989      0.994      0.826\n",
      "Speed: 0.8ms preprocess, 29.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 3501 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3501/3501 [00:04<00:00, 865.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.46G     0.8152      1.361      1.386      1.256         25        640: 100%|██████████| 219/219 [02:18<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.959      0.951      0.988      0.738      0.959      0.951      0.988       0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.33G     0.7228      1.014     0.6758       1.12         30        640: 100%|██████████| 219/219 [02:13<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.97      0.947      0.987      0.746      0.944      0.979      0.988      0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.23G     0.7597      1.025       0.65      1.136         26        640: 100%|██████████| 219/219 [02:12<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.952      0.947      0.982       0.71      0.952      0.947      0.982      0.734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.22G      0.749      1.023     0.6165      1.129         23        640: 100%|██████████| 219/219 [02:12<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.974      0.961       0.99      0.754      0.976      0.964      0.991      0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.22G     0.7431     0.9667     0.5832      1.107         24        640: 100%|██████████| 219/219 [02:12<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.972      0.981      0.989      0.762      0.973      0.981      0.991      0.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.205 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.971      0.981      0.989      0.761      0.972      0.981      0.991      0.796\n",
      "                  legs        474        474      0.971      0.981      0.989      0.761      0.972      0.981      0.991      0.796\n",
      "Speed: 1.0ms preprocess, 13.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▅▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▆▅▁█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▆▆▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▅▆▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▄▄▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▃▇▁█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▄▁▃█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▂▁▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▂█▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▁▄▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▃█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▂▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▃▃█▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▅█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.98873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.76122\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.79594\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.97139\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.97243\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.98101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.74307\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.58322\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.10696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.96671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.76513\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.4877\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.15854\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.93467\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_224519-moho2w8g\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_224519-moho2w8g/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.975      0.977       0.99      0.775      0.983      0.977      0.991      0.802\n",
      "                  legs        476        476      0.975      0.977       0.99      0.775      0.983      0.977      0.991      0.802\n",
      "Speed: 0.8ms preprocess, 29.4ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.5581566114117459\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_1_47/train/labels... 297 images, 0 backgrounds, 0 corrupt: 100%|██████████| 297/297 [00:00<00:00, 415.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_1_47/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_1/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.62G     0.7562      1.067     0.6199      1.129         12        640: 100%|██████████| 19/19 [00:13<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.987      0.987      0.994      0.794      0.987      0.987      0.994      0.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.15G     0.6815     0.9204     0.5176      1.079         19        640: 100%|██████████| 19/19 [00:11<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.985      0.989      0.994      0.811      0.987      0.991      0.995      0.831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.75G     0.6647     0.8623     0.4967      1.059         30        640: 100%|██████████| 19/19 [00:11<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.982      0.979      0.994      0.813      0.982      0.979      0.994      0.834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      7.73G     0.6642     0.9325     0.5197      1.056         21        640: 100%|██████████| 19/19 [00:11<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.989       0.99      0.995      0.807      0.992      0.992      0.995      0.828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      7.79G     0.5868     0.8061     0.4493      1.015         20        640: 100%|██████████| 19/19 [00:11<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.991      0.998      0.995      0.826      0.991      0.998      0.995      0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.035 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.991      0.998      0.995      0.826      0.991      0.998      0.995      0.842\n",
      "                  legs        474        474      0.991      0.998      0.995      0.826      0.991      0.998      0.995      0.842\n",
      "Speed: 1.3ms preprocess, 13.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▅▂▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▆▂█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▅▅▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄▅▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▅▄▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▅▅▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▄▅▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▄▅▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▅▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▄▃▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▄▃▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▁▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▁▃▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▂▁▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99481\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99481\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.8261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.84173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.99105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.99105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.99789\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.99789\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.329\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.58685\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.44933\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.01484\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.80607\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.68385\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.35347\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.10167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.80664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_230120-0mmwadxx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_230120-0mmwadxx/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_1/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.993      0.998      0.995      0.831      0.993      0.998      0.995      0.841\n",
      "                  legs        476        476      0.993      0.998      0.995      0.831      0.993      0.998      0.995      0.841\n",
      "Speed: 0.9ms preprocess, 29.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Итоговый результат (инкрементальное обучение) для класса 1: \n",
      " defaultdict(<class 'list'>, {0: [0.10571936678890921, 0.4114368650397775, 0.01799734335521755], 1: [0.10888511622627965, 0.4138714745777447, 0.021077700611988676], 2: [0.11726620833725068, 0.4286574313858903, 0.02802130007205463], 3: [0.11790913999135093, 0.39753339982814206, 0.03539988291953119], 4: [0.1049686294600746, 0.409813361568093, 0.017769368541754458], 5: [0.10558377089123425, 0.4131182159588333, 0.01818143282856528], 6: [0.10637967693399294, 0.414254252152611, 0.018509244805014743], 7: [0.11463333382766776, 0.42874203230043473, 0.022271144771761973], 8: [0.11946769078033201, 0.4322792015536244, 0.027276490713533667], 9: [0.11272321253783715, 0.4253176287648541, 0.022675308395290313], 10: [0.11256971478532418, 0.42315786085498314, 0.022685317333226988], 11: [0.11259913070338441, 0.42342117810785923, 0.0227563975797496], 12: [0.12607540608379697, 0.4287895100408066, 0.03518298658920874], 13: [0.130039563849708, 0.42879643185662214, 0.04396855042173547], 14: [0.13278747774878671, 0.4549830237961278, 0.04291304623733296], 15: [0.13794051412982314, 0.4573737893827544, 0.04755791803769268], 16: [0.13907814375666905, 0.4374707662192737, 0.05734154550858715], 17: [0.14211777594077873, 0.4260185126544228, 0.0654245503670645], 18: [0.2406477798217988, 0.524197191580388, 0.18714632261170305], 19: [0.2500001707736343, 0.5701605779955666, 0.18813809610875193], 20: [0.24320005421307173, 0.5248807702894622, 0.19309221657082437], 21: [0.2698791339948403, 0.5631793770193452, 0.23257029402423396], 22: [0.2818496379124861, 0.628671520465017, 0.2257092141020589], 23: [0.2452812586141392, 0.5124238571102371, 0.21140198824273768], 24: [0.2956071426617351, 0.6103394974386941, 0.2627077478243142], 25: [0.33768635675789016, 0.6566702696236226, 0.3126727699813507], 26: [0.34175891942377745, 0.6399721166025518, 0.3255274767145567], 27: [0.4418081281720573, 0.7451261073116066, 0.45413735416404394], 28: [0.5164514539961638, 0.8028664607146383, 0.5774822004028756], 29: [0.47616613367510724, 0.7444865413191245, 0.5392055809458078], 30: [0.5285903945129345, 0.8046286698093815, 0.6110263716457229], 31: [0.574035044593949, 0.832355571705169, 0.6941831874579997], 32: [0.544220738703949, 0.8075463444819416, 0.6450473558255204], 33: [0.6415582653823002, 0.9054481340405678, 0.7748498649592869], 34: [0.6193805767378844, 0.8761616513920064, 0.7399974173022913], 35: [0.6160628340523436, 0.8522197857206579, 0.7391161539756222], 36: [0.6613045318020729, 0.931027441030204, 0.7775405787521446], 37: [0.7084160384391404, 0.9748439284939133, 0.8525707895886746], 38: [0.7477092074740699, 0.9895047541491764, 0.9009362701007356], 39: [0.7655693399065594, 0.9883156241049726, 0.9171396017589912], 40: [0.7490596106644462, 0.9826502511599968, 0.9022470881578795], 41: [0.7943099412265278, 0.9929936586084901, 0.9650135666435466], 42: [0.8086529021977451, 0.992372852732209, 0.9593986742486492], 43: [0.7773863658579012, 0.9863459295396607, 0.9342729427536264], 44: [0.8316794019070194, 0.9944319603107077, 0.9789986003775597], 45: [0.8018306784939572, 0.9906060863936618, 0.957600623977472], 46: [0.841206822095106, 0.994957805907173, 0.9775348779850506]})\n",
      "Количество данных (train) для класса 1: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 3798]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_1/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 2744.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_1/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:01<00:00, 420.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/feet-14/valid_0/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.17G     0.4137     0.5446      4.092     0.7996          5        640: 100%|██████████| 1/1 [00:00<00:00,  3.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0556     0.0274    0.00721    0.00645     0.0556     0.0274    0.00782    0.00682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       1.6G     0.5603     0.9723      5.248     0.9266          2        640: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0587     0.0295    0.00761    0.00688     0.0587     0.0295    0.00827    0.00726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       1.6G     0.5379      1.027      5.144     0.8972          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0479      0.038    0.00783    0.00708     0.0479      0.038    0.00855    0.00747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.62G     0.4629     0.6506      4.298     0.9933          5        640: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0462     0.0443    0.00811     0.0074     0.0418     0.0506    0.00887     0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.61G     0.7983      1.786      5.033      0.941          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00342      0.167    0.00815    0.00732    0.00416      0.203    0.00881    0.00756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0468     0.0443    0.00814    0.00742     0.0423     0.0506    0.00888    0.00772\n",
      "                  card        474        474     0.0468     0.0443    0.00814    0.00742     0.0423     0.0506    0.00888    0.00772\n",
      "Speed: 0.7ms preprocess, 13.0ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▄▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▄▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▆█▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▇█▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▄▃▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▇▂▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▆▅█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▃▄▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▃▁▂█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▃▂▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00888\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00742\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00772\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.04683\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.04232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.0443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.79832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 5.03317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.94105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.78588\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.48242\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.63491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.90575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.82484\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_230608-p4tfnmra\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_230608-p4tfnmra/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:01<00:00, 453.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/feet-14/test_0/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.217     0.0168     0.0171     0.0153      0.217     0.0168     0.0182     0.0158\n",
      "                  card        476        476      0.217     0.0168     0.0171     0.0153      0.217     0.0168     0.0182     0.0158\n",
      "Speed: 0.8ms preprocess, 29.5ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_2/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 892.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_2/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.56G     0.5863      2.101      4.178     0.9314          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00353      0.285    0.00801    0.00693    0.00418      0.338    0.00875    0.00729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.58G     0.4728      2.258      5.596     0.8752          2        640: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00498      0.624    0.00779    0.00667    0.00523      0.656    0.00842     0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.47G     0.4417       1.37      4.928     0.9709          2        640: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00492      0.618     0.0078    0.00661     0.0052      0.654    0.00863    0.00706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.47G     0.4446      2.388      4.702     0.9255          3        640: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00475      0.597    0.00731    0.00615    0.00504      0.633    0.00806    0.00665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.47G     0.7497      2.756      5.658     0.9983          3        640: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00465      0.586    0.00683    0.00575    0.00495      0.624    0.00752    0.00616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00372      0.403    0.00794    0.00682    0.00417      0.451    0.00858    0.00716\n",
      "                  card        474        474    0.00372      0.403    0.00794    0.00682    0.00417      0.451    0.00858    0.00716\n",
      "Speed: 0.7ms preprocess, 13.0ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▆▆▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▅▇▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▆▅▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▆▅▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁██▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁██▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁██▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁██▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▄▂▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▅▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▄▁▆▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅▅▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▅▁▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▅▇▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00794\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00858\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00682\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.00372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.00417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.40295\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.45148\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.74974\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 5.65783\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.75558\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.49821\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.66236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.90975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.9027\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_230947-7hpo1p6z\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_230947-7hpo1p6z/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.158     0.0168     0.0145     0.0129      0.166     0.0189     0.0155     0.0132\n",
      "                  card        476        476      0.158     0.0168     0.0145     0.0129      0.166     0.0189     0.0155     0.0132\n",
      "Speed: 1.0ms preprocess, 29.2ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<00:00, 5880.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.48G     0.3291     0.7332      4.346     0.8395          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.051     0.0274    0.00708    0.00625      0.051     0.0274     0.0076    0.00663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.98G     0.5857      3.416      6.981     0.9773          2        640: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.046     0.0401    0.00726    0.00647      0.046     0.0401    0.00773    0.00674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.98G     0.5154      1.033      4.558     0.9653          5        640: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.034     0.0485    0.00745    0.00648      0.034     0.0485    0.00799    0.00679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.88G     0.4068      1.305      4.167     0.9127          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0145     0.0717    0.00752    0.00669     0.0166     0.0823    0.00815    0.00699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.88G     0.4444      1.035      4.513     0.9579          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00495      0.139    0.00825    0.00737    0.00622      0.175    0.00901     0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00488      0.137    0.00827    0.00735    0.00624      0.175    0.00903     0.0078\n",
      "                  card        474        474    0.00488      0.137    0.00827    0.00735    0.00624      0.175    0.00903     0.0078\n",
      "Speed: 0.8ms preprocess, 13.1ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▂▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▂▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▇▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▇▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▂▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▂▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▆▃▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁█▇▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁█▂▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▇▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▇▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃█▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▃▄▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00827\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00735\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.0078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.00488\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.00624\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.13713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.17511\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.048\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.44438\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.5127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.95786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.03549\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.48196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.59058\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.90682\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.83001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_231231-1f67m2nv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_231231-1f67m2nv/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.178     0.0147     0.0167     0.0148      0.178     0.0147      0.018     0.0156\n",
      "                  card        476        476      0.178     0.0147     0.0167     0.0148      0.178     0.0147      0.018     0.0156\n",
      "Speed: 0.8ms preprocess, 29.7ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_3/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 494.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.98G     0.4191     0.8633      4.213     0.9761          5        640: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00521      0.654    0.00829    0.00714    0.00543      0.681    0.00905    0.00752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.59G     0.5508     0.3445      4.157     0.9174          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00518      0.654    0.00811    0.00697    0.00539      0.679    0.00877     0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      1.48G     0.3947     0.6378       4.46     0.8268          2        640: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00512      0.648    0.00792    0.00663     0.0053      0.671    0.00868    0.00713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.47G     0.5157     0.8983      4.215     0.8648          3        640: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00506      0.641    0.00785    0.00647    0.00527      0.669    0.00867     0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.48G     0.7562     0.5878      4.966      1.027          2        640: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00474      0.584    0.00753    0.00621    0.00497      0.614    0.00833    0.00661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00519      0.652    0.00826    0.00711    0.00541      0.679    0.00904    0.00749\n",
      "                  card        474        474    0.00519      0.652    0.00826    0.00711    0.00541      0.679    0.00904    0.00749\n",
      "Speed: 0.8ms preprocess, 13.0ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▅▂▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▃▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▆▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▄▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▇▄▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▆▂▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ██▅▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▇▂▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▄▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▁▄▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▆▄▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▁▅█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▂▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▂▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00826\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00904\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00711\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00749\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.00519\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.00541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.6519\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.67932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.946\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.75615\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.96638\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.02679\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.58784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.48199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.6537\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.90681\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.89626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_231717-34q78kbs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_231717-34q78kbs/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.125     0.0252     0.0146     0.0131      0.125     0.0252     0.0159     0.0134\n",
      "                  card        476        476      0.125     0.0252     0.0146     0.0131      0.125     0.0252     0.0159     0.0134\n",
      "Speed: 0.7ms preprocess, 29.0ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 6 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6/6 [00:00<00:00, 809.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.68G     0.6254       1.87       4.18     0.9303         12        640: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0477     0.0232    0.00702    0.00621     0.0477     0.0232     0.0075    0.00654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      4.02G     0.4972      1.669       5.04     0.8398          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0448     0.0401    0.00704    0.00619     0.0448     0.0401    0.00757     0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.88G     0.9765      2.924      5.641     0.9775          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0178     0.0549    0.00702    0.00614     0.0191     0.0591    0.00741    0.00638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.88G     0.6199      2.309      4.645     0.9317          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00561     0.0907    0.00708    0.00621     0.0077      0.124    0.00766    0.00647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.88G     0.6974      2.635      5.784     0.9488          5        640: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00319      0.333     0.0067    0.00585    0.00375      0.392    0.00747    0.00628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0477     0.0232      0.007    0.00621     0.0504     0.0274    0.00748    0.00652\n",
      "                  card        474        474     0.0477     0.0232      0.007    0.00621     0.0504     0.0274    0.00748    0.00652\n",
      "Speed: 0.8ms preprocess, 13.2ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▃▅▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▄▅▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▆▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▆▁▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ██▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▇▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▃▁█▃▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▅▇▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▆▁█▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▂▁█▅▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▆█▄▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▇▁█▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.007\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00748\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00621\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00652\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.04768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.05039\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.02321\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.02743\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.183\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.69738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 5.78397\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.94876\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.63549\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.48629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.63761\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.90921\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.84053\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_232002-xowg18ek\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_232002-xowg18ek/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.154     0.0147     0.0136     0.0122      0.151     0.0147     0.0141     0.0125\n",
      "                  card        476        476      0.154     0.0147     0.0136     0.0122      0.151     0.0147     0.0141     0.0125\n",
      "Speed: 0.8ms preprocess, 29.4ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_4/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 526.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_4/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.82G      0.286     0.7649      4.338     0.8343          5        640: 100%|██████████| 1/1 [00:00<00:00,  2.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00492      0.614    0.00717    0.00595    0.00519      0.648    0.00772    0.00626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.59G     0.5328      1.333      5.488       1.08          2        640: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00484      0.605     0.0072    0.00605    0.00509      0.637    0.00785    0.00646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       1.5G     0.8332      1.883      4.679      1.167          2        640: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00484      0.608    0.00733    0.00601    0.00508      0.637    0.00787    0.00643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      1.47G     0.4625     0.7377      5.661     0.8759          1        640: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00475      0.595    0.00674    0.00566    0.00507      0.635    0.00759    0.00595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.48G     0.2333     0.6687      4.788     0.7846          2        640: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00492      0.616    0.00742    0.00625    0.00526      0.658    0.00834    0.00657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00494      0.618    0.00751    0.00631    0.00528       0.66    0.00838    0.00664\n",
      "                  card        474        474    0.00494      0.618    0.00751    0.00631    0.00528       0.66    0.00838    0.00664\n",
      "Speed: 0.8ms preprocess, 13.1ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▅▅▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▂▃▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▄▅▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▄▆▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▇▄▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▅▂▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▇▄▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▅▂▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▂▄█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▇▃█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂▆█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▂▅█▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▇▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00751\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00838\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00631\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.00494\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.00528\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.61814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.66034\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.933\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.23333\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.7876\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.78459\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.66865\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.5019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.62535\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.91661\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.92909\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_232441-5fpk4a8k\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_232441-5fpk4a8k/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.128     0.0105      0.013     0.0115      0.121     0.0105     0.0148      0.012\n",
      "                  card        476        476      0.128     0.0105      0.013     0.0115      0.121     0.0105     0.0148      0.012\n",
      "Speed: 0.9ms preprocess, 29.3ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 8 images, 0 backgrounds, 0 corrupt: 100%|██████████| 8/8 [00:00<00:00, 2543.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.46G     0.4077      1.132      4.271     0.8447         13        640: 100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0561     0.0274    0.00704    0.00626     0.0561     0.0274    0.00764    0.00662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      4.91G      0.514       1.49      4.764     0.9251         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0499     0.0274    0.00724    0.00645     0.0499     0.0274    0.00785    0.00684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.69G     0.3512      1.525      4.677     0.9161         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0359     0.0401    0.00718    0.00629     0.0359     0.0401    0.00791     0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.69G     0.5479      2.507      4.264     0.9712         11        640: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0447     0.0401    0.00739    0.00646     0.0389     0.0443    0.00803     0.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.69G     0.8441      1.688       5.42     0.9729          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00928     0.0844     0.0076    0.00641     0.0111      0.101    0.00823    0.00686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:14<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00929     0.0844    0.00754    0.00639     0.0112      0.101    0.00815    0.00679\n",
      "                  card        474        474    0.00929     0.0844    0.00754    0.00639     0.0112      0.101    0.00815    0.00679\n",
      "Speed: 1.1ms preprocess, 13.3ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁█▂█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▂█▁▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▇▅▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▇▅▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▁▃▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▁▂▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▂▃▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▄▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▅▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▃▃█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▅▅▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▇▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▁▅▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00639\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00679\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.00929\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.01115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.08439\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.10127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.84405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 5.42021\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.97292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.68751\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.48705\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.64144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.90884\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.8415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_232730-v5jsgiwx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_232730-v5jsgiwx/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.184     0.0147     0.0149     0.0134      0.181     0.0147      0.016     0.0139\n",
      "                  card        476        476      0.184     0.0147     0.0149     0.0134      0.181     0.0147      0.016     0.0139\n",
      "Speed: 0.9ms preprocess, 29.4ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_5/train/labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 4169.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_5/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.53G     0.5517      1.125      4.265     0.8984          5        640: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00465      0.184    0.00769    0.00644    0.00571      0.226    0.00832    0.00677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      1.59G      0.848      1.314      4.931      1.034          3        640: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00496       0.62    0.00731    0.00615     0.0052       0.65    0.00798    0.00656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       1.6G     0.5095      1.723      5.645      1.214          2        640: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0049      0.614    0.00719    0.00607    0.00516      0.646    0.00785    0.00642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       1.5G     0.6902      1.436      4.248     0.9581          5        640: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00324      0.312    0.00698     0.0059     0.0039      0.376    0.00778    0.00631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      1.47G     0.5012      1.035      5.197      1.103          2        640: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00398       0.46    0.00662    0.00564    0.00447      0.517    0.00727    0.00593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00605      0.148     0.0077    0.00646    0.00718      0.175    0.00834    0.00678\n",
      "                  card        474        474    0.00605      0.148     0.0077    0.00646    0.00718      0.175    0.00834    0.00678\n",
      "Speed: 0.8ms preprocess, 13.0ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▄▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▃▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▄▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▅▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▅▅▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▅▄▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▂██▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▂██▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▂█▁▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▄█▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▄█▂▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▂▄█▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▂▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▄▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.0077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00834\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00678\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.00605\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.00718\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.14768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.17511\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.50124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 5.19719\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.10275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.03474\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.50165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.71254\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.91407\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.93002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_233217-pqvibsa1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_233217-pqvibsa1/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.113     0.0231      0.012     0.0104      0.113     0.0231     0.0129     0.0108\n",
      "                  card        476        476      0.113     0.0231      0.012     0.0104      0.113     0.0231     0.0129     0.0108\n",
      "Speed: 1.3ms preprocess, 29.3ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 1925.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.35G     0.6294      1.575      4.206      0.955         19        640: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0525     0.0232    0.00696    0.00618     0.0548     0.0274    0.00748    0.00649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.42G     0.6208     0.8418      4.972     0.9828         12        640: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0473     0.0359    0.00712    0.00635     0.0473     0.0359     0.0077    0.00668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      5.32G      0.651      1.458      4.369     0.9377         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0315     0.0464    0.00708     0.0062     0.0233     0.0485    0.00744    0.00643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      5.31G     0.5444      1.595      4.472     0.9991         13        640: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00908     0.0823    0.00696    0.00615     0.0112      0.101    0.00763    0.00642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      5.32G     0.4582      1.011      4.513     0.9711         15        640: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00313      0.154    0.00679    0.00596    0.00394      0.194    0.00743    0.00629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0472     0.0359    0.00709    0.00633     0.0439     0.0401     0.0077    0.00668\n",
      "                  card        474        474     0.0472     0.0359    0.00709    0.00633     0.0439     0.0401     0.0077    0.00668\n",
      "Speed: 0.7ms preprocess, 13.1ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁█▆▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▂█▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▂█▃▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▃█▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▇▅▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▇▃▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▄█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▃█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▇▇█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▂▃▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▃▆▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▁▇█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▃▁▃█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▁▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▂▁▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▂▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.0077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00668\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.04715\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.04394\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.03586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.04008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.4582\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.51339\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.97106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.0111\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.48733\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.64978\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.90872\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.8418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_233501-709bjctt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_233501-709bjctt/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.155     0.0147     0.0138     0.0124      0.155     0.0147     0.0143     0.0126\n",
      "                  card        476        476      0.155     0.0147     0.0138     0.0124      0.155     0.0147     0.0143     0.0126\n",
      "Speed: 0.7ms preprocess, 29.5ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_6/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 512.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_6/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.04G     0.2882     0.9913      3.975     0.9683          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00504      0.629    0.00735    0.00625    0.00529       0.66    0.00794    0.00665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G     0.6895      1.335      4.842      1.159          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00494      0.618    0.00742    0.00627    0.00521      0.652    0.00807    0.00678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.05G     0.3777     0.9131      4.706     0.9615          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0048      0.601    0.00734    0.00628    0.00505      0.633    0.00802    0.00668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.05G       0.48      2.219      4.886     0.8662          3        640: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0048      0.601    0.00747     0.0064    0.00507      0.635    0.00833    0.00689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.06G     0.4879      2.552      3.815     0.8845          7        640: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00357      0.386    0.00699    0.00599    0.00415      0.449    0.00788     0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00474      0.578    0.00743    0.00635    0.00503      0.614    0.00823    0.00682\n",
      "                  card        474        474    0.00474      0.578    0.00743    0.00635    0.00503      0.614    0.00823    0.00682\n",
      "Speed: 0.8ms preprocess, 13.0ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▂▅▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▂█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂▂█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▅▂█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▆▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▆▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▇▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▇▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▃▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▂█▇█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▃█▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▃▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▃▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00743\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00823\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00682\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.00474\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.00503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.57806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.61392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.48795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.81451\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.88446\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.55178\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.50106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.65783\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.91127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.93814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_233944-vp0yputb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_233944-vp0yputb/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.147     0.0167     0.0117     0.0102      0.149      0.021     0.0127     0.0107\n",
      "                  card        476        476      0.147     0.0167     0.0117     0.0102      0.149      0.021     0.0127     0.0107\n",
      "Speed: 0.8ms preprocess, 29.2ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 13 images, 0 backgrounds, 0 corrupt: 100%|██████████| 13/13 [00:00<00:00, 935.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.41G     0.3509     0.6639       4.52     0.8579         20        640: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0523     0.0253    0.00698    0.00622     0.0508     0.0274     0.0076    0.00655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       7.2G     0.4186     0.7683      4.522     0.8552         18        640: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0445     0.0401    0.00697    0.00608     0.0421      0.038    0.00738    0.00635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      6.99G     0.4708      1.058      4.217     0.8871         22        640: 100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0299     0.0443    0.00689    0.00604     0.0299     0.0443    0.00761    0.00633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      6.99G     0.5531      1.691      4.517     0.9381         14        640: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0184     0.0591    0.00681    0.00593      0.021     0.0675    0.00753    0.00633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5         7G     0.4792      1.139       4.43     0.8824         22        640: 100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00912     0.0844    0.00676    0.00595     0.0112      0.103    0.00751    0.00639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.056     0.0272    0.00696    0.00619     0.0508     0.0274    0.00758    0.00652\n",
      "                  card        474        474      0.056     0.0272    0.00696    0.00619     0.0508     0.0274    0.00758    0.00652\n",
      "Speed: 0.8ms preprocess, 13.1ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ██▄▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▁█▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▅▄▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▂▁▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▇▆▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▆▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▃▅█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ██▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▁▄█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▂▄█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▁▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▃█▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00758\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00619\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00652\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.056\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.05084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.02716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.02743\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.47916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.42957\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.88238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.13913\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.48847\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.65043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.9099\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.84745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_234230-wbl18ibj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_234230-wbl18ibj/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:57<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.145     0.0147     0.0131     0.0118      0.143     0.0147     0.0135      0.012\n",
      "                  card        476        476      0.145     0.0147     0.0131     0.0118      0.143     0.0147     0.0135      0.012\n",
      "Speed: 0.8ms preprocess, 29.2ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_7/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 892.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_7/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.81G     0.7565      2.679      4.494       1.26          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00504      0.629    0.00738     0.0062    0.00533      0.665    0.00797    0.00656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G     0.5033     0.9727      4.912      1.122          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00505      0.631     0.0075    0.00631    0.00528       0.66    0.00804    0.00666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.05G      0.707       2.15       4.87     0.9653          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.005      0.627    0.00751    0.00631     0.0052      0.652    0.00809    0.00666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.05G     0.6358      1.112      5.335      1.094          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00493      0.618    0.00748    0.00642    0.00513      0.643    0.00822    0.00674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.04G     0.3836       1.46      4.171     0.9555          6        640: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00488      0.614     0.0074    0.00636    0.00511      0.643    0.00812    0.00676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0049      0.614    0.00745    0.00639    0.00512      0.641    0.00822    0.00673\n",
      "                  card        474        474     0.0049      0.614    0.00745    0.00639    0.00512      0.641    0.00822    0.00673\n",
      "Speed: 0.9ms preprocess, 13.1ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▇█▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▅▅█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▅▅█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ██▆▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▆▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▇█▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▃▇▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▃▅▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▁▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▁▆▂▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▆▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▂▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00822\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00639\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.0049\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.00512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.61392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.64135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.058\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.38364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.17143\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.95552\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.46028\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.50116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.64745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.91055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.92875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_234716-7wd5xvuz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_234716-7wd5xvuz/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476     0.0945     0.0273     0.0124     0.0108     0.0945     0.0273     0.0132     0.0111\n",
      "                  card        476        476     0.0945     0.0273     0.0124     0.0108     0.0945     0.0273     0.0132     0.0111\n",
      "Speed: 0.8ms preprocess, 29.5ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 16 images, 0 backgrounds, 0 corrupt: 100%|██████████| 16/16 [00:00<00:00, 974.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.03G     0.4608      1.132      4.104     0.9663         27        640: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0505     0.0274    0.00697    0.00621     0.0505     0.0274    0.00759    0.00656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.58G      0.403      1.212      4.997      0.956         17        640: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0455     0.0401    0.00711     0.0062     0.0431      0.038    0.00749    0.00647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.04G     0.5127      1.087      4.667     0.9561         23        640: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.023     0.0464    0.00698    0.00615     0.0171     0.0527    0.00742    0.00638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.04G     0.5881      1.282      4.647     0.9652         21        640: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00913     0.0823    0.00706     0.0062     0.0112      0.101    0.00772     0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.38G     0.5073      1.341       4.04     0.9324         27        640: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00255      0.188    0.00682    0.00606    0.00321      0.236    0.00755    0.00638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0526     0.0253    0.00698    0.00624     0.0504     0.0274    0.00758    0.00657\n",
      "                  card        474        474     0.0526     0.0253    0.00698    0.00624     0.0504     0.0274    0.00758    0.00657\n",
      "Speed: 0.8ms preprocess, 13.0ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁█▂▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▅▃▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▆▅▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▄▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▇▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▇▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▃▁▅█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▆▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▆▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▂▄▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▂▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▂▄▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▂▅▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00758\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00624\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00657\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.05257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.05039\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.02532\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.02743\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.061\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.50735\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.03983\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.93236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.34121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.48673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.64667\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.90891\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.8479\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_235003-pi35crwt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_235003-pi35crwt/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.154     0.0147     0.0133      0.012      0.144     0.0147     0.0138     0.0122\n",
      "                  card        476        476      0.154     0.0147     0.0133      0.012      0.144     0.0147     0.0138     0.0122\n",
      "Speed: 0.8ms preprocess, 29.3ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_8/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 491.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_8/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.99G     0.3749     0.7386       4.08     0.7357          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00479       0.58    0.00709    0.00588    0.00508      0.616    0.00763    0.00619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G     0.6838      2.497      4.093     0.8938          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.005      0.627    0.00713    0.00598    0.00518       0.65    0.00763    0.00634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.05G     0.4126     0.9271      4.356     0.9079          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00494       0.62    0.00696    0.00583    0.00514      0.646    0.00747    0.00614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.06G     0.3614      1.155      4.502     0.8272          3        640: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00488      0.614    0.00668     0.0056     0.0051      0.641    0.00716    0.00591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.04G      0.499     0.7776      4.024     0.9108          5        640: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00494      0.622    0.00695    0.00581    0.00517      0.652    0.00766     0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00496      0.622    0.00704    0.00591    0.00517      0.648    0.00755    0.00627\n",
      "                  card        474        474    0.00496      0.622    0.00704    0.00591    0.00517      0.648    0.00755    0.00627\n",
      "Speed: 0.8ms preprocess, 13.1ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▇█▅▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ██▆▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▆█▅▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▆█▅▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁█▆▄▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁█▅▂▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁█▇▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁█▇▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▂▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▂▂▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▇█▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁█▂▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▂▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▅▆▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▄▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.00704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.00755\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00591\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.00627\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.00496\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.00517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.62236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.64768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.139\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.49898\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.02351\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.91077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.77757\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.49797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.64759\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.90978\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.92611\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_235452-1a1ixvng\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_235452-1a1ixvng/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476     0.0835     0.0273     0.0109    0.00949     0.0835     0.0273     0.0118    0.00985\n",
      "                  card        476        476     0.0835     0.0273     0.0109    0.00949     0.0835     0.0273     0.0118    0.00985\n",
      "Speed: 0.8ms preprocess, 29.6ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 19 images, 0 backgrounds, 0 corrupt: 100%|██████████| 19/19 [00:00<00:00, 880.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       8.4G     0.5568      1.733      5.015     0.9191          2        640: 100%|██████████| 2/2 [00:01<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0518     0.0232    0.00691    0.00622      0.051     0.0253    0.00753    0.00651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.61G     0.4459      0.872      4.336     0.9391          4        640: 100%|██████████| 2/2 [00:00<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0459     0.0274     0.0071    0.00631     0.0457     0.0313    0.00787    0.00665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.49G     0.5122      1.637      3.995     0.9059          5        640: 100%|██████████| 2/2 [00:00<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.012     0.0675     0.0068    0.00591     0.0138     0.0781    0.00748    0.00632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       8.5G     0.4988      1.006      4.459     0.8861          3        640: 100%|██████████| 2/2 [00:00<00:00,  2.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0731     0.0232     0.0136     0.0121    0.00619      0.743     0.0149     0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       8.6G     0.7418      1.136      4.239       1.04          4        640: 100%|██████████| 2/2 [00:00<00:00,  2.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.168     0.0992     0.0496     0.0441      0.168     0.0992     0.0514     0.0451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.168     0.0992     0.0495      0.044      0.168     0.0992     0.0512      0.045\n",
      "                  card        474        474      0.168     0.0992     0.0495      0.044      0.168     0.0992     0.0512      0.045\n",
      "Speed: 0.7ms preprocess, 13.0ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▃▃▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▃▃▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▁▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▁▂█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▄▁▃▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▃▁▄▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂▃▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▁▇▂▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▅▆█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ███▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▅▆█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▅▇█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.0495\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.05123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.04398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.16814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.16814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.09916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.09916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.74175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.23945\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.04024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.13623\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.48342\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.12673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.89944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.81695\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231128_235741-5o9z3347\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231128_235741-5o9z3347/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.292     0.0336     0.0743     0.0679      0.292     0.0336     0.0773     0.0679\n",
      "                  card        476        476      0.292     0.0336     0.0743     0.0679      0.292     0.0336     0.0773     0.0679\n",
      "Speed: 0.8ms preprocess, 29.7ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_9/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 552.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_9/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.15G     0.6292     0.9681      3.715     0.9476          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.114     0.0211     0.0588     0.0518      0.114     0.0211     0.0606     0.0521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G     0.5943     0.8667      4.363      1.039          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.139     0.0338     0.0577     0.0509      0.139     0.0338     0.0595     0.0513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.05G     0.5091      1.109      3.711      0.943          4        640: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.15     0.0506     0.0534     0.0468       0.15     0.0506     0.0546     0.0473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.05G      1.032      1.239      4.265       1.17          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.138     0.0852     0.0529     0.0465      0.138     0.0852     0.0543     0.0468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.06G     0.4478      1.018      3.822     0.9812          7        640: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.127      0.162     0.0481     0.0421      0.127      0.162     0.0507     0.0425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.114     0.0211     0.0588     0.0518      0.122     0.0232     0.0606      0.052\n",
      "                  card        474        474      0.114     0.0211     0.0588     0.0518      0.122     0.0232     0.0606      0.052\n",
      "Speed: 0.8ms preprocess, 13.0ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▇▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▇▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▇▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▇▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆█▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▆█▆▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▃▃▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▁▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▄▁█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▃▁▆█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁██▃▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▂▇▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▅▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▅▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.05883\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.06065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.05184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.05204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.11372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.12154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.0211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.02321\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.986\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.44781\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.82181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.98124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.01766\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.49231\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 4.10364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.89878\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.88384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_000233-l4bpa51f\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_000233-l4bpa51f/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.223      0.042     0.0736     0.0655      0.223      0.042     0.0748     0.0647\n",
      "                  card        476        476      0.223      0.042     0.0736     0.0655      0.223      0.042     0.0748     0.0647\n",
      "Speed: 1.0ms preprocess, 29.6ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 22 images, 0 backgrounds, 0 corrupt: 100%|██████████| 22/22 [00:00<00:00, 1096.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.97G     0.5298      1.394      4.582     0.9618          5        640: 100%|██████████| 2/2 [00:01<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0473     0.0316    0.00698    0.00622     0.0442     0.0295    0.00757    0.00656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.48G     0.5561      1.115      4.362     0.9806          7        640: 100%|██████████| 2/2 [00:01<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00596     0.0992    0.00701    0.00616    0.00711      0.118    0.00757    0.00646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.47G     0.5195       1.03      3.948     0.9131         10        640: 100%|██████████| 2/2 [00:00<00:00,  2.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00605      0.722     0.0122     0.0108    0.00619      0.738     0.0132     0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.44G     0.5346      1.049      4.278     0.9241          8        640: 100%|██████████| 2/2 [00:00<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00646      0.774     0.0307     0.0274    0.00666      0.797     0.0321      0.028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.52G     0.4459     0.9759      3.791     0.8866         13        640: 100%|██████████| 2/2 [00:00<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.34     0.0684      0.178      0.159      0.351     0.0743      0.178      0.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.339     0.0681      0.178      0.159      0.339     0.0681      0.178      0.157\n",
      "                  card        474        474      0.339     0.0681      0.178      0.159      0.339     0.0681      0.178      0.157\n",
      "Speed: 0.6ms preprocess, 13.1ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▂▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▂▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂██▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▇█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▆█▆▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▂▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▇█▃▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▇██▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▇▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▇█▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▆█▇▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.1783\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.17832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.15944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.15668\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.33886\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.33886\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.06813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.06813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.098\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.44595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.79054\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.88664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.97588\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.47653\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.88218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.89344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.79967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_000518-xyc2j55s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_000518-xyc2j55s/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.416      0.063      0.201      0.184      0.416      0.063      0.203       0.18\n",
      "                  card        476        476      0.416      0.063      0.201      0.184      0.416      0.063      0.203       0.18\n",
      "Speed: 0.8ms preprocess, 29.7ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_10/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 584.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_10/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.05G     0.7694      1.448      3.894      1.195          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.354     0.0878      0.172      0.152      0.354     0.0878      0.172       0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G     0.5154      3.254      4.401      1.044          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.358      0.094      0.168      0.149      0.358      0.094      0.168      0.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.16G     0.7063      3.095       4.16      1.017          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.368      0.101      0.166      0.147      0.368      0.101      0.166      0.144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.04G     0.6322      1.417       4.56     0.9808          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.362     0.0969      0.161      0.142      0.362     0.0969      0.161       0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.04G      0.549      1.005      4.541     0.9397          4        640: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.369      0.105      0.171      0.151      0.369      0.105      0.171      0.149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.35     0.0874      0.172      0.153       0.35     0.0874      0.172       0.15\n",
      "                  card        474        474       0.35     0.0874      0.172      0.153       0.35     0.0874      0.172       0.15\n",
      "Speed: 0.6ms preprocess, 13.3ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▆▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▅▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▆▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▆▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▃▄█▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▃▄█▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄█▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄█▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▁▆▄▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▆▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▂██▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▇▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▅▆▇█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▅▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.17229\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.1723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.15287\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.15048\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.34986\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.34986\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.08742\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.08742\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.978\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.54899\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.54097\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.93974\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.00494\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.4869\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.79732\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.89558\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.8728\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_001011-sfs8h3zu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_001011-sfs8h3zu/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.414      0.116       0.18      0.162      0.414      0.116      0.181      0.158\n",
      "                  card        476        476      0.414      0.116       0.18      0.162      0.414      0.116      0.181      0.158\n",
      "Speed: 1.2ms preprocess, 29.2ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 25 images, 0 backgrounds, 0 corrupt: 100%|██████████| 25/25 [00:00<00:00, 1245.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.08G     0.6693      1.561      4.619      0.963          9        640: 100%|██████████| 2/2 [00:01<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.046     0.0295    0.00677    0.00608     0.0427     0.0274    0.00735     0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.58G     0.6048      1.315      4.573     0.9997         10        640: 100%|██████████| 2/2 [00:01<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0162     0.0527    0.00704    0.00627     0.0182     0.0591    0.00771    0.00647\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.49G     0.5957      1.086      4.214     0.9035         17        640: 100%|██████████| 2/2 [00:01<00:00,  1.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00601      0.101    0.00698    0.00616    0.00727      0.122    0.00753    0.00652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.48G     0.5444      1.471      4.259     0.9894         17        640: 100%|██████████| 2/2 [00:01<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00506       0.53     0.0193     0.0171    0.00547      0.572     0.0211      0.018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.27G     0.6096       1.06      4.171     0.9769         15        640: 100%|██████████| 2/2 [00:01<00:00,  1.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474        0.2     0.0501       0.11     0.0984        0.2     0.0501      0.112     0.0978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.219     0.0591       0.11     0.0981      0.219     0.0591      0.112     0.0976\n",
      "                  card        474        474      0.219     0.0591       0.11     0.0981      0.219     0.0591      0.112     0.0976\n",
      "Speed: 0.9ms preprocess, 13.2ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▂▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▂▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▁▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▁▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄▄▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▇▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅█▁▇▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▅▁▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▆▇█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ███▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▆▇█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▆▇█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.10968\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.11177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.09806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.09763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.21891\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.21891\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.05907\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.05907\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.6096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.17081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.9769\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.47842\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.96074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.89307\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.79395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_001257-ks8gv24c\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_001257-ks8gv24c/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.344     0.0483      0.129      0.118      0.344     0.0483      0.131      0.117\n",
      "                  card        476        476      0.344     0.0483      0.129      0.118      0.344     0.0483      0.131      0.117\n",
      "Speed: 1.0ms preprocess, 29.8ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_11/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 860.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_11/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.96G     0.6703     0.7011      3.732     0.8133          6        640: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.186     0.0359      0.108     0.0952      0.207     0.0414      0.109     0.0941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G     0.9936      1.194        5.2      1.028          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.23     0.0612      0.102     0.0898       0.23     0.0612      0.103     0.0893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.16G     0.6788     0.8684      3.808     0.9256          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.22     0.0928     0.0964     0.0854       0.22     0.0928     0.0981      0.085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.06G     0.5021     0.7338      5.449     0.7685          2        640: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.21      0.116     0.0934     0.0831       0.21      0.116     0.0953     0.0827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.05G     0.6124       1.16      4.095      1.053          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.22       0.12     0.0947     0.0841       0.22       0.12     0.0959     0.0837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.179     0.0338      0.107     0.0943      0.179     0.0338      0.108     0.0936\n",
      "                  card        474        474      0.179     0.0338      0.107     0.0943      0.179     0.0338      0.108     0.0936\n",
      "Speed: 0.9ms preprocess, 13.0ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▅▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▅▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▅▂▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▅▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▂█▇▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▅█▇▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▂▃▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▃█▄▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▇▁█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂▇▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁█▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ██▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▇▇█▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▄▆█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▄▆█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.10691\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.108\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.09428\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.09363\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.17853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.17853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.03376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.03376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.938\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.6124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 4.09457\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.05339\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.16025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.48449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.89748\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.89337\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.85672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_001753-qtg2xnli\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_001753-qtg2xnli/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476        0.3     0.0659      0.119      0.107        0.3     0.0659       0.12      0.105\n",
      "                  card        476        476        0.3     0.0659      0.119      0.107        0.3     0.0659       0.12      0.105\n",
      "Speed: 1.4ms preprocess, 29.1ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 28 images, 0 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<00:00, 1199.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       8.4G     0.5641      1.351       4.72     0.9599         14        640: 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0439     0.0274    0.00707    0.00632      0.042     0.0316     0.0076    0.00664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.59G     0.5725      1.663      4.398      1.018         16        640: 100%|██████████| 2/2 [00:01<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0231     0.0506    0.00705     0.0063      0.025     0.0549    0.00765    0.00657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.48G     0.4882      1.281      4.262     0.8987         23        640: 100%|██████████| 2/2 [00:01<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00299       0.15    0.00694    0.00611    0.00387      0.194    0.00761    0.00652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.19G     0.6025      1.284      4.518     0.9794         20        640: 100%|██████████| 2/2 [00:01<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00638      0.764     0.0201     0.0178    0.00656      0.785     0.0222     0.0188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.28G     0.5192      1.077      3.721     0.9244         23        640: 100%|██████████| 2/2 [00:01<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.296     0.0701      0.147      0.131      0.296     0.0701      0.148       0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.298     0.0696      0.147      0.131      0.298     0.0696      0.148      0.129\n",
      "                  card        474        474      0.298     0.0696      0.147      0.131      0.298     0.0696      0.148      0.129\n",
      "Speed: 0.7ms preprocess, 13.2ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▂▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▂▂▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▁▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▁▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▆▆▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▅▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅█▁▆▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄█▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▇▇█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ███▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▆▇█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▆▇█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.14678\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.14808\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.13072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.12947\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.29829\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.29829\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.06962\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.06962\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.163\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.51918\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.72094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.92442\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.07661\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.47813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.86906\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.89339\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.79838\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_002041-ynjkzmzu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_002041-ynjkzmzu/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.397     0.0609      0.172      0.157      0.397     0.0609      0.174      0.155\n",
      "                  card        476        476      0.397     0.0609      0.172      0.157      0.397     0.0609      0.174      0.155\n",
      "Speed: 1.1ms preprocess, 29.8ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.0885956703481299\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_12/train/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<00:00, 415.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_12/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 3 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.06G     0.5581      1.159      3.301     0.8967          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.33     0.0864      0.149      0.132       0.33     0.0864       0.15      0.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.16G     0.5891      1.611      4.447      1.049          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.344     0.0865      0.149      0.131      0.344     0.0865      0.149       0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.04G     0.6512      2.372      3.363     0.8713          4        640: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.328     0.0886      0.141      0.125      0.328     0.0886      0.142      0.123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.05G      0.501       1.67      4.278     0.9816          3        640: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.31     0.0886      0.133      0.117       0.31     0.0886      0.134      0.116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.04G     0.9509      1.259      3.375     0.9719          5        640: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.29     0.0869      0.124      0.109       0.29     0.0869      0.126      0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.326     0.0844      0.149      0.131      0.326     0.0844       0.15      0.131\n",
      "                  card        474        474      0.326     0.0844      0.149      0.131      0.326     0.0844       0.15      0.131\n",
      "Speed: 0.7ms preprocess, 13.0ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ██▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ██▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ██▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ██▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▅█▅▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▅█▅▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▄▅██▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▄▅██▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▂▂▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▁▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂█▁▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▄█▄▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▁▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.14861\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.14956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.13146\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.13058\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.32616\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.32616\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.08439\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.08439\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.892\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.95092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.37538\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.97187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.25861\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.49753\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.81697\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.89621\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.87589\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_002536-uju9iido\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_002536-uju9iido/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.362     0.0987      0.157      0.141      0.362     0.0987      0.158      0.139\n",
      "                  card        476        476      0.362     0.0987      0.157      0.141      0.362     0.0987      0.158      0.139\n",
      "Speed: 1.2ms preprocess, 29.2ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 31 images, 0 backgrounds, 0 corrupt: 100%|██████████| 31/31 [00:00<00:00, 1057.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.31G     0.6175      1.274      4.686      1.003         17        640: 100%|██████████| 2/2 [00:01<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0487     0.0274      0.007    0.00618     0.0426     0.0274    0.00754    0.00649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.49G      0.649      1.153       4.56     0.9703         21        640: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0231     0.0506    0.00712    0.00632     0.0251     0.0549    0.00772    0.00662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.17G     0.5399       1.49      4.252     0.9525         23        640: 100%|██████████| 2/2 [00:01<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0091     0.0886    0.00692    0.00604    0.00722      0.122    0.00767    0.00652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.18G     0.5417      1.114      4.227     0.9388         21        640: 100%|██████████| 2/2 [00:01<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0703      0.253     0.0389     0.0347      0.072      0.259     0.0411     0.0353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.17G       0.61      1.062      3.686     0.9598         38        640: 100%|██████████| 2/2 [00:01<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.418     0.0653      0.231      0.206      0.418     0.0653      0.232      0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:14<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.418     0.0651      0.232      0.206      0.418     0.0651      0.232      0.203\n",
      "                  card        474        474      0.418     0.0651      0.232      0.206      0.418     0.0651      0.232      0.203\n",
      "Speed: 0.8ms preprocess, 13.3ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▂▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▂▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▃█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▄█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▆█▁▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▇▅▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▄▂▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄▂█▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▇▇█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ███▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▆▇█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▆▇█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.23166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.23208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.20621\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.20284\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.41796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.41796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.06515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.06515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.61002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.68586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.95984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.06216\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.47415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.71061\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.89224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.79483\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_002820-9puw9rc1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_002820-9puw9rc1/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.526      0.103      0.246      0.223      0.526      0.103      0.248       0.22\n",
      "                  card        476        476      0.526      0.103      0.246      0.223      0.526      0.103      0.248       0.22\n",
      "Speed: 0.8ms preprocess, 30.1ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.6064552928863145\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_13/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 1231.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_13/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       6.2G     0.4885      1.657       3.34     0.8989          9        640: 100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474        0.4      0.122      0.212      0.188        0.4      0.122      0.212      0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G     0.6853      2.038      3.583     0.9713          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.407      0.122      0.209      0.184      0.407      0.122      0.209      0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.04G      0.462      1.527      4.427     0.9629          5        640: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.403      0.127      0.208      0.184      0.403      0.127      0.209      0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G     0.7042      1.638      3.998       1.01          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.395      0.124      0.201      0.178      0.395      0.124      0.202      0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.03G     0.4496     0.9508      3.393     0.9593          9        640: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.38      0.114       0.19      0.169       0.38      0.114      0.192      0.166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.404      0.123      0.212      0.187      0.404      0.123      0.211      0.184\n",
      "                  card        474        474      0.404      0.123      0.212      0.187      0.404      0.123      0.211      0.184\n",
      "Speed: 1.0ms preprocess, 13.1ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▆▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▅▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▆▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▅▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▄█▆▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▄█▆▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▂▁█▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▂▁█▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▂▇▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▃█▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▆▅█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▆█▅▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▅▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▄▃▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▂▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.2121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.2115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.18715\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.18447\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.40409\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.40409\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.12303\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.12303\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.909\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.44964\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 3.39287\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.9593\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.95083\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.48908\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 3.67017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.89516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.87289\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_003318-ftwou1ee\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_003318-ftwou1ee/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.496      0.159      0.224      0.201      0.496      0.159      0.224      0.197\n",
      "                  card        476        476      0.496      0.159      0.224      0.201      0.496      0.159      0.224      0.197\n",
      "Speed: 0.9ms preprocess, 29.2ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 36 images, 0 backgrounds, 0 corrupt: 100%|██████████| 36/36 [00:00<00:00, 1085.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.31G     0.4435      1.176      4.588     0.9516          5        640: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0233     0.0485    0.00679    0.00601     0.0233     0.0485    0.00724    0.00627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.18G     0.5636      1.171      4.514     0.9443          5        640: 100%|██████████| 3/3 [00:01<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0599     0.0401     0.0095    0.00838     0.0534     0.0401     0.0107    0.00892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.31G     0.4884       1.22      3.993     0.9687          8        640: 100%|██████████| 3/3 [00:01<00:00,  1.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.333     0.0862      0.157      0.141      0.333     0.0862      0.158       0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.46G     0.4872     0.7561      3.066     0.9023          6        640: 100%|██████████| 3/3 [00:01<00:00,  2.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.864      0.817      0.899       0.81      0.858      0.814      0.896      0.791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.46G     0.4928      1.077      2.291     0.9717          5        640: 100%|██████████| 3/3 [00:01<00:00,  2.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.914      0.892      0.954      0.864      0.904      0.888      0.949       0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:14<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.916      0.892      0.954      0.864      0.911      0.888      0.949       0.84\n",
      "                  card        474        474      0.916      0.892      0.954      0.864      0.911      0.888      0.949       0.84\n",
      "Speed: 0.8ms preprocess, 13.5ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▂██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▂██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▂██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▂██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▁▃██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▃██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▁▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▁▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▄▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ██▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▆▅█▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▇▇█▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ██▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▆▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ██▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ██▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.08629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.95403\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.94915\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.86369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.83992\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.91557\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.91124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.89229\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.88807\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.49283\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.29104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.97167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.07657\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.43469\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.49832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.87431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.74393\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_003604-nowyauf7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_003604-nowyauf7/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476       0.93      0.894      0.967      0.877       0.93      0.894      0.964      0.855\n",
      "                  card        476        476       0.93      0.894      0.967      0.877       0.93      0.894      0.964      0.855\n",
      "Speed: 1.0ms preprocess, 29.9ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 7.744871037765154\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_14/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 499.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_14/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.98G     0.3726     0.6358      2.115     0.9063          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.892      0.858      0.941      0.843      0.897      0.848      0.931      0.819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.13G     0.6395     0.9574      2.834     0.9879          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.888      0.854      0.938      0.842      0.883       0.85      0.931      0.819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.04G     0.3942     0.8837      2.222       0.86          5        640: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.887      0.859      0.937      0.842      0.883      0.854      0.931      0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G     0.3819      1.013      1.893     0.9284          5        640: 100%|██████████| 1/1 [00:00<00:00,  3.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.888      0.857      0.936      0.841      0.884      0.853       0.93      0.817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G     0.5322      0.981      1.885     0.8629          9        640: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.891      0.854      0.935      0.839      0.887       0.85      0.929      0.816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.891      0.859      0.941      0.843      0.888       0.85      0.931      0.819\n",
      "                  card        474        474      0.891      0.859      0.941      0.843      0.888       0.85      0.931      0.819\n",
      "Speed: 0.8ms preprocess, 13.1ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▄▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▆█▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▃▅▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) █▆▄▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▂▁▃▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▁▁▂▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▇▁█▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄█▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▂▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▃█▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▄█▁▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▇▆█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▃▁▅█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▃▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.94058\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.9309\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.84258\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.81871\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.89056\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.88759\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.85865\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.85021\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.53219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.88523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.86286\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.98095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.44784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.57077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.88108\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.80851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_004114-m77qkvww\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_004114-m77qkvww/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.869      0.894      0.942       0.85      0.867      0.891       0.94       0.83\n",
      "                  card        476        476      0.869      0.894      0.942       0.85      0.867      0.891       0.94       0.83\n",
      "Speed: 0.9ms preprocess, 29.4ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 41 images, 0 backgrounds, 0 corrupt: 100%|██████████| 41/41 [00:00<00:00, 1070.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.32G     0.6581      1.551      4.443      1.029         18        640: 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0124     0.0633    0.00672    0.00596       0.01     0.0907    0.00716    0.00625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.15G     0.5491       1.52      4.207     0.9267         20        640: 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00312      0.327    0.00651    0.00566    0.00361      0.378    0.00716    0.00612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.38G     0.5876      1.402      4.236       0.95         20        640: 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.36     0.0527      0.227      0.203       0.36     0.0527      0.227        0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.52G     0.5402      1.171      3.108     0.9477         14        640: 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.831      0.664      0.808      0.723       0.82      0.655      0.801      0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.17G     0.5156     0.9249      2.216     0.9003         18        640: 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.887      0.896      0.949      0.859      0.881       0.89      0.943      0.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:14<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.888      0.899      0.949      0.858      0.881      0.893      0.943      0.833\n",
      "                  card        474        474      0.888      0.899      0.949      0.858      0.881      0.893      0.943      0.833\n",
      "Speed: 0.7ms preprocess, 13.5ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▁▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▃▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▇▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▂▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ██▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ██▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▇█▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▇█▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.08629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.94924\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.94304\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.85807\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.83268\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.88758\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.88133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.89944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.89311\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.51559\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.21604\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.90031\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.92491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.44133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.55308\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.87807\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.74796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_004401-iukinzz4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_004401-iukinzz4/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.913      0.891      0.957      0.867      0.913      0.891      0.954      0.845\n",
      "                  card        476        476      0.913      0.891      0.957      0.867      0.913      0.891      0.954      0.845\n",
      "Speed: 0.9ms preprocess, 29.9ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 6.805377478335679\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_15/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 553.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_15/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.93G     0.5978      1.139      2.946     0.9821          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.884       0.87      0.937       0.84      0.876      0.862      0.929      0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.15G     0.7555      1.671      3.153      1.054          4        640: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.871      0.884      0.938      0.841      0.862      0.876       0.93      0.819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.03G     0.7031      1.331      2.263     0.8779          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.89      0.868      0.937       0.84      0.881       0.86      0.929      0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G     0.4512     0.6618      1.502     0.8375          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.885      0.863      0.936      0.838      0.876      0.854      0.928      0.816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.03G     0.6547       1.31      1.534     0.9342         10        640: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.885      0.865      0.934      0.836      0.875      0.858      0.926      0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.867      0.884      0.938       0.84      0.858      0.876      0.929      0.818\n",
      "                  card        474        474      0.867      0.884      0.938       0.84      0.858      0.876      0.929      0.818\n",
      "Speed: 1.0ms preprocess, 13.1ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▆█▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▆█▇▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▇█▇▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▇██▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▆▂█▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▆▂█▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▃█▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▃█▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▄█▇▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▇█▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▆█▂▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄█▆▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▃█▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▃▆█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.93757\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.92945\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.84037\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.81847\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.86651\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.85775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.88397\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.87553\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.018\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.6547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.53394\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.93424\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.30976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.45278\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.59478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.88279\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.79296\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_004905-bs67tfxb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_004905-bs67tfxb/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476       0.86       0.87      0.934      0.844      0.861      0.871      0.933      0.822\n",
      "                  card        476        476       0.86       0.87      0.934      0.844      0.861      0.871      0.933      0.822\n",
      "Speed: 1.0ms preprocess, 29.2ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 46 images, 0 backgrounds, 0 corrupt: 100%|██████████| 46/46 [00:00<00:00, 1545.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.93G     0.5308      1.513      4.247     0.9501         32        640: 100%|██████████| 3/3 [00:02<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.024     0.0506    0.00673    0.00597      0.025     0.0527    0.00722     0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.16G     0.6122      1.416      4.513     0.9966         21        640: 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00245      0.181    0.00638    0.00552    0.00307      0.228    0.00704    0.00612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.16G      0.572       1.08      4.235     0.9222         31        640: 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.228      0.162     0.0958     0.0852      0.228      0.162      0.097     0.0852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.54G     0.5243      1.008      3.235      0.925         24        640: 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.85      0.715      0.844      0.755      0.839      0.706      0.833      0.739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.15G     0.4882     0.9286      2.054     0.8952         26        640: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.89      0.886      0.948      0.856      0.882       0.88      0.938      0.832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:14<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.885      0.888      0.948      0.856      0.879      0.882      0.938      0.831\n",
      "                  card        474        474      0.885      0.888      0.948      0.856      0.879      0.882      0.938      0.831\n",
      "Speed: 0.8ms preprocess, 13.4ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▂▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▂▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▂▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▂▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▁▃██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▃██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▂▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▂▂▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▃█▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▇█▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅█▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▇▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ██▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▇█▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▇█▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.08629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.94774\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.93768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.85554\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.83131\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.88523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.87892\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.88819\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.88186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.48822\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 2.05392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.8952\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.92861\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.43305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.53371\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.87248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.74365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_005151-7lobwgx1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_005151-7lobwgx1/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.918      0.878      0.958      0.867      0.916      0.876      0.954      0.844\n",
      "                  card        476        476      0.918      0.878      0.958      0.867      0.916      0.876      0.954      0.844\n",
      "Speed: 0.8ms preprocess, 29.7ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 5.95851933446483\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_16/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 421.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_16/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.94G     0.3214      0.785      1.739     0.7358          8        640: 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.875       0.86      0.928      0.831      0.856      0.859       0.92      0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G     0.4252      1.198      1.675     0.8843          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.871      0.859      0.929      0.833      0.862      0.855      0.922       0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.04G     0.4142     0.5901      2.064     0.9042          4        640: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.865      0.861      0.929      0.831      0.859      0.857      0.921       0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.03G      0.395     0.8666      1.727     0.8289          5        640: 100%|██████████| 1/1 [00:00<00:00,  3.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.871      0.857      0.929      0.831      0.862       0.85       0.92       0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.03G     0.3254     0.4664      1.593      0.817          7        640: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.867      0.859      0.927      0.831      0.858       0.85      0.919      0.809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.871      0.859      0.929      0.834      0.862      0.857      0.922      0.811\n",
      "                  card        474        474      0.871      0.859      0.929      0.834      0.862      0.857      0.922      0.811\n",
      "Speed: 0.7ms preprocess, 13.1ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▇▇▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁█▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▃▆▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▇█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▅▁▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▇▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▇▄█▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▅▆▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▇▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▃▂█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▇█▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄█▂▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▅▁▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▂▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▁▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▅▁▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.92923\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.92171\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.83372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.8106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.87063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.86211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.85865\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.85739\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.146\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.32545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.59333\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.81701\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.46644\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.44774\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.58447\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.88046\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.8096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_005656-u4ys2emk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_005656-u4ys2emk/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.888      0.835       0.93      0.839      0.887      0.836      0.927      0.814\n",
      "                  card        476        476      0.888      0.835       0.93      0.839      0.887      0.836      0.927      0.814\n",
      "Speed: 0.7ms preprocess, 29.4ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 51 images, 0 backgrounds, 0 corrupt: 100%|██████████| 51/51 [00:00<00:00, 981.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       8.3G     0.5464      1.249      4.586     0.9729          3        640: 100%|██████████| 4/4 [00:03<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00281      0.139    0.00652    0.00574    0.00371      0.184    0.00716     0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.51G     0.6065      1.101      4.425     0.9679          5        640: 100%|██████████| 4/4 [00:02<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.126      0.154     0.0418     0.0375      0.117      0.175     0.0432     0.0378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.53G     0.5504        1.2      3.288     0.9405          4        640: 100%|██████████| 4/4 [00:02<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.88      0.878      0.935      0.842      0.872      0.873       0.93      0.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.46G     0.4928     0.9271      1.569     0.8792          4        640: 100%|██████████| 4/4 [00:02<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.947      0.934       0.98      0.895      0.942       0.93      0.974      0.872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.48G     0.4125     0.7127      1.273     0.8705          5        640: 100%|██████████| 4/4 [00:01<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.945      0.937      0.981      0.897       0.94      0.932      0.975      0.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.946      0.939      0.981      0.897      0.942      0.935      0.975      0.873\n",
      "                  card        474        474      0.946      0.939      0.981      0.897      0.942      0.935      0.975      0.873\n",
      "Speed: 0.7ms preprocess, 13.3ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▁▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▁▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▆█▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ██▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ██▆▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▇▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ██▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.98117\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.97462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.89723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.8733\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.94582\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.94157\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.93882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.9346\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.149\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.41251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.27257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.87049\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.71266\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.38972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.14323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.85232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.66311\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_005944-7tx6cdyq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_005944-7tx6cdyq/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.947      0.931      0.982        0.9      0.947      0.931      0.981      0.874\n",
      "                  card        476        476      0.947      0.931      0.982        0.9      0.947      0.931      0.981      0.874\n",
      "Speed: 1.0ms preprocess, 29.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 5.43646298432894\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_17/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 530.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_17/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       6.3G     0.2956     0.6427      1.086     0.7955         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.912      0.924      0.969      0.883      0.908      0.919      0.963       0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.15G     0.5851      0.909      1.335      0.916          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.91      0.919       0.97      0.882      0.906      0.915      0.964       0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.13G      0.373     0.5519      1.275     0.9507          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.932      0.902       0.97      0.883      0.928      0.898      0.964      0.861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G     0.5393     0.8995      1.488     0.9995          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.932      0.899       0.97      0.883      0.928      0.895      0.964       0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G     0.3796      0.773      1.153     0.8896          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.903       0.93       0.97      0.883      0.899      0.926      0.964      0.859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.932      0.901       0.97      0.883      0.928      0.897      0.963       0.86\n",
      "                  card        474        474      0.932      0.901       0.97      0.883      0.928      0.897      0.963       0.86\n",
      "Speed: 0.7ms preprocess, 13.1ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▇██▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▅██▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▆▁▅█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▃▁█▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▂▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▂▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▇▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▇▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▃▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▅▄█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▅▆█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▃█▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▆▆▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▂▁▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▄▃▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.96976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.96324\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.88303\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.86005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.93232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.92795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.90085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.89663\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.37964\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.15265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.88964\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.77297\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.39913\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.24288\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.85574\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.70078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_010451-cfqbtkfk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_010451-cfqbtkfk/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.946      0.883      0.967      0.882      0.946      0.883      0.965      0.856\n",
      "                  card        476        476      0.946      0.883      0.967      0.882      0.946      0.883      0.965      0.856\n",
      "Speed: 0.9ms preprocess, 29.1ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 56 images, 0 backgrounds, 0 corrupt: 100%|██████████| 56/56 [00:00<00:00, 867.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.25G     0.5896      1.949      4.377     0.9435          7        640: 100%|██████████| 4/4 [00:03<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0116     0.0612    0.00661    0.00586     0.0136     0.0717    0.00729     0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.49G     0.5513      1.291       4.31     0.9485          9        640: 100%|██████████| 4/4 [00:02<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0074      0.357     0.0172     0.0153    0.00818      0.395     0.0185     0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.58G     0.5402      1.093       3.44     0.9084         12        640: 100%|██████████| 4/4 [00:02<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.875      0.799      0.907      0.812      0.863      0.797      0.897      0.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.51G      0.481     0.9641      1.713     0.8749         15        640: 100%|██████████| 4/4 [00:02<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.917      0.932      0.974       0.88      0.911      0.926      0.966      0.859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.52G     0.3773     0.6375      1.371      0.843         10        640: 100%|██████████| 4/4 [00:02<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.945      0.914      0.975      0.885      0.939      0.907      0.969      0.861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.945      0.914      0.975      0.885      0.939      0.908      0.969      0.861\n",
      "                  card        474        474      0.945      0.914      0.975      0.885      0.939      0.908      0.969      0.861\n",
      "Speed: 0.8ms preprocess, 13.3ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▁▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▇▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ██▆▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ██▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▄▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ██▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ██▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.97482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.96887\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.88466\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.86101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.94544\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.9389\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.91388\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.9077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.37732\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.37054\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.84297\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.63753\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.40552\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.30496\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.85845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.69577\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_010741-h1803vho\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_010741-h1803vho/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.942       0.92      0.978      0.892       0.94      0.918      0.976      0.869\n",
      "                  card        476        476      0.942       0.92      0.978      0.892       0.94      0.918      0.976      0.869\n",
      "Speed: 1.0ms preprocess, 29.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 4.519764521832581\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_18/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 291.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_18/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.19G     0.6154     0.8644      1.245     0.8568          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.903      0.901      0.959      0.867      0.897      0.895      0.952      0.843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G     0.6673     0.9072      1.311     0.9536          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.918      0.892       0.96      0.866      0.907       0.89      0.952      0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.03G     0.5695      0.879      1.063     0.9392          8        640: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.926      0.892       0.96      0.866       0.91      0.886      0.952      0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.01G     0.6715     0.8039       1.56     0.9705          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.921       0.89       0.96      0.866      0.915      0.885      0.951      0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.03G     0.4208     0.8506      1.339     0.8753          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.916      0.892       0.96      0.865      0.909      0.886      0.952      0.843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.924       0.89       0.96      0.866      0.909      0.886      0.952      0.844\n",
      "                  card        474        474      0.924       0.89       0.96      0.866      0.909      0.886      0.952      0.844\n",
      "Speed: 0.6ms preprocess, 13.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▇▇█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ███▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▄▃▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▂▁▇▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▅▆█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▅▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▆█▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▄▄▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▇▆█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅█▆▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▂▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▇█▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▄▁▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▅▁▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.95984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.95223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.86613\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.84365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.92412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.90906\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.8903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.88608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.918\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.42079\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.33856\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.87528\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.85055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.41884\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.40573\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.86541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.75502\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_011253-twkfw3xj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_011253-twkfw3xj/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476       0.91      0.895      0.962      0.871      0.908      0.893      0.958       0.85\n",
      "                  card        476        476       0.91      0.895      0.962      0.871      0.908      0.893      0.958       0.85\n",
      "Speed: 0.8ms preprocess, 29.3ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 61 images, 0 backgrounds, 0 corrupt: 100%|██████████| 61/61 [00:00<00:00, 1015.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.96G     0.5445      1.467      4.374     0.9615         16        640: 100%|██████████| 4/4 [00:03<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00362      0.108    0.00665    0.00589    0.00483      0.143    0.00721    0.00625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.49G     0.5901      1.309      4.237     0.9793         18        640: 100%|██████████| 4/4 [00:02<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00598      0.713     0.0126     0.0113    0.00615      0.734     0.0139     0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.46G     0.5289      1.174      3.567     0.9232         16        640: 100%|██████████| 4/4 [00:02<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.868      0.857      0.923      0.833      0.862       0.85      0.913      0.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.16G     0.4903     0.9454      1.799       0.91         25        640: 100%|██████████| 4/4 [00:02<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.914      0.938      0.975      0.888      0.907      0.931      0.968      0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.52G     0.4702     0.8241       1.55       0.84         19        640: 100%|██████████| 4/4 [00:02<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.941      0.905      0.976      0.892      0.934      0.899      0.969      0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:14<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.941      0.905      0.976      0.891      0.935      0.899      0.969      0.866\n",
      "                  card        474        474      0.941      0.905      0.976      0.891      0.935      0.899      0.969      0.866\n",
      "Speed: 1.1ms preprocess, 13.5ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▁▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▅█▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ██▆▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▇█▅▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ██▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.97636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.96882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.8912\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.86628\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.94114\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.93455\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.90506\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.89873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.47019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.54958\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.83998\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.82411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.39405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.28521\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.85122\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.68066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_011541-uf1imxa1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_011541-uf1imxa1/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [01:03<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.937      0.939      0.981      0.897      0.937      0.939       0.98       0.87\n",
      "                  card        476        476      0.937      0.939      0.981      0.897      0.937      0.939       0.98       0.87\n",
      "Speed: 1.1ms preprocess, 29.3ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 3.67055038262495\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_19/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 495.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_19/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.49G     0.4599     0.3798      1.499     0.9023          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.922      0.897      0.965      0.872      0.915       0.89      0.957      0.847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.15G     0.3117     0.5086      1.253     0.9085          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.922      0.897      0.965      0.873      0.915       0.89      0.956      0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.14G      0.313     0.3389     0.9378     0.8561          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.922      0.896      0.964      0.871      0.915      0.889      0.956      0.847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.03G      0.325     0.4831      1.128     0.8402          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.914      0.902      0.964      0.871      0.908      0.896      0.956      0.846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.03G     0.5257     0.9153      1.214     0.9637          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.947      0.869      0.965      0.872       0.94      0.863      0.957      0.846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.921      0.897      0.965      0.872      0.915       0.89      0.956      0.847\n",
      "                  card        474        474      0.921      0.897      0.965      0.872      0.915       0.89      0.956      0.847\n",
      "Speed: 0.6ms preprocess, 13.1ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▇█▄▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▅▅▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▅█▁▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▅█▆▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ███▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ███▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▂▂▁█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▂▂▁█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▆▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▅▁▃▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅▅▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▃▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▃▄█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▇█▆█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▄▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▇▆▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.96478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.95616\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.87152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.84715\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.92127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.91477\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.89662\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.8903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.013\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.52572\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.21382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.9637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.91535\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.40833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.3761\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.85624\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.72555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_012058-sy7trgno\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_012058-sy7trgno/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.902      0.916      0.968      0.877      0.902      0.916      0.968      0.855\n",
      "                  card        476        476      0.902      0.916      0.968      0.877      0.902      0.916      0.968      0.855\n",
      "Speed: 0.9ms preprocess, 29.4ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 66 images, 0 backgrounds, 0 corrupt: 100%|██████████| 66/66 [00:00<00:00, 1039.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.38G     0.5224      1.253      4.943     0.9179          1        640: 100%|██████████| 5/5 [00:04<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.016     0.0527    0.00695    0.00614     0.0179     0.0591    0.00752    0.00643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.31G     0.5144      1.177      3.663     0.9243          5        640: 100%|██████████| 5/5 [00:02<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.847      0.701      0.833      0.746      0.839      0.694      0.826      0.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.31G     0.4492     0.9628      1.723     0.8747          2        640: 100%|██████████| 5/5 [00:02<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.923       0.92      0.972       0.89      0.914      0.919      0.969      0.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.31G     0.3654     0.5294       1.03     0.7994          3        640: 100%|██████████| 5/5 [00:02<00:00,  1.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.956      0.909      0.979      0.895      0.952      0.905      0.975      0.871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.32G     0.3316     0.5645      1.033     0.8311          2        640: 100%|██████████| 5/5 [00:02<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.943      0.946      0.983        0.9      0.939      0.942      0.979      0.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:14<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.943      0.946      0.983      0.898      0.939      0.942      0.979      0.874\n",
      "                  card        474        474      0.943      0.946      0.983      0.898      0.939      0.942      0.979      0.874\n",
      "Speed: 0.9ms preprocess, 13.5ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▆███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▆███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ██▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ██▅▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▇▅▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.98311\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.97863\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.8984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.87391\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.94321\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.93901\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.94614\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.94192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.114\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.33156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.0331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.83113\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.56451\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.36939\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.93955\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83752\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.60884\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_012347-24ulbu0c\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_012347-24ulbu0c/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:22<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.972       0.95      0.988      0.908      0.972       0.95      0.988      0.877\n",
      "                  card        476        476      0.972       0.95      0.988      0.908      0.972       0.95      0.988      0.877\n",
      "Speed: 1.2ms preprocess, 29.7ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 2.945194764167719\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_20/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 441.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_20/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.25G     0.2472     0.4535     0.8201     0.8145          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.939       0.94      0.977      0.892      0.935      0.936      0.974      0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.15G     0.4133      1.056      1.215      0.795          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.946      0.928      0.978      0.892      0.942      0.923      0.974      0.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.03G     0.3084     0.5112      1.101     0.8264          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.942      0.935      0.978      0.892      0.937       0.93      0.974      0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G     0.4178     0.7204     0.8337     0.9639          9        640: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.943       0.93      0.978      0.891      0.937      0.926      0.973      0.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.02G     0.3268     0.6332      1.051     0.7868          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.942      0.929      0.977      0.892      0.938      0.927      0.973      0.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.943      0.934      0.978      0.892      0.938       0.93      0.974      0.865\n",
      "                  card        474        474      0.943      0.934      0.978      0.892      0.938       0.93      0.974      0.865\n",
      "Speed: 0.6ms preprocess, 13.1ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▇█▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▅█▅▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▂▅█▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▅█▆▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁█▄▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁█▄▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▁▅▃▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▁▅▃▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▄█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▆▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▂▁▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁█▂▄▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▆▂▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▅▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.97763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.97387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.89187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.86535\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.9425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.93826\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.93371\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.92973\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.842\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.32682\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.05066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.78682\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.6332\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.37516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.98412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83961\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.63025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_012904-js5a4dx5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_012904-js5a4dx5/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.963      0.926      0.981      0.898      0.963      0.926      0.981      0.873\n",
      "                  card        476        476      0.963      0.926      0.981      0.898      0.963      0.926      0.981      0.873\n",
      "Speed: 0.8ms preprocess, 29.2ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 71 images, 0 backgrounds, 0 corrupt: 100%|██████████| 71/71 [00:00<00:00, 908.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         8G     0.5565      1.522      4.415     0.9472          7        640: 100%|██████████| 5/5 [00:04<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00253      0.186     0.0068    0.00608    0.00314       0.23    0.00733    0.00635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.58G     0.5321      1.245      4.169     0.9173         16        640: 100%|██████████| 5/5 [00:02<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.698      0.209      0.442      0.394      0.698      0.209      0.439      0.387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.56G     0.4926      1.013      2.356     0.8887          7        640: 100%|██████████| 5/5 [00:02<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.952       0.93      0.981      0.894      0.947      0.926      0.977      0.868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.26G     0.4088     0.6746      1.175     0.8755         11        640: 100%|██████████| 5/5 [00:02<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.952      0.955      0.986        0.9      0.945      0.949      0.981      0.872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.27G     0.4616     0.7446      1.294      0.887          8        640: 100%|██████████| 5/5 [00:02<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.975      0.956      0.989      0.904      0.968      0.949      0.985      0.879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:14<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.974      0.956      0.989      0.905      0.968      0.949      0.985       0.88\n",
      "                  card        474        474      0.974      0.956      0.989      0.905      0.968      0.949      0.985       0.88\n",
      "Speed: 1.2ms preprocess, 13.7ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▄███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▄███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▆███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▇▅▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▇▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▄▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▇▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.98935\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.98546\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.90455\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.87979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.97426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.96762\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.9557\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.94937\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.46165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.29406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.88699\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.74457\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.37004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.94503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.84204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.64343\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_013155-ei7romuw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_013155-ei7romuw/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.959      0.964      0.989      0.908      0.959      0.964      0.989      0.881\n",
      "                  card        476        476      0.959      0.964      0.989      0.908      0.959      0.964      0.989      0.881\n",
      "Speed: 1.0ms preprocess, 29.6ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 2.283957707277513\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_21/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 548.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_21/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.25G     0.3958     0.3297     0.7468     0.8372          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.963      0.937      0.985      0.896      0.963       0.93      0.982      0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.13G     0.3863     0.6362      1.173     0.7683          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.967      0.938      0.984      0.896      0.963      0.934      0.982      0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.02G     0.1715     0.2463     0.8696     0.7893          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.97      0.941      0.986      0.898      0.965      0.937      0.982      0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G     0.2102     0.1702     0.8789     0.7554          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.971      0.941      0.986      0.898      0.967      0.937      0.982      0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.15G     0.3164     0.4905      1.158      0.855          5        640: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.974      0.939      0.985      0.898      0.969      0.935      0.981      0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.971      0.941      0.986      0.897      0.966      0.937      0.981      0.875\n",
      "                  card        474        474      0.971      0.941      0.986      0.897      0.966      0.937      0.981      0.875\n",
      "Speed: 0.7ms preprocess, 13.1ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▃▁██▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▂█▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▂██▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂██▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▅▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▂▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ██▁▂▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▃▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▇▂▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▃█▂▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▇█▇▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁███▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▇█▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.98552\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.98147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.89685\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.8751\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.97075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.9664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.94093\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.93671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.911\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.31637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.15848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.85504\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.49046\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.38127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.98486\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.84642\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.67131\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_013711-8o0wmlgc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_013711-8o0wmlgc/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.959      0.945      0.985      0.901      0.959      0.947      0.985      0.876\n",
      "                  card        476        476      0.959      0.945      0.985      0.901      0.959      0.947      0.985      0.876\n",
      "Speed: 0.9ms preprocess, 29.6ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 76 images, 0 backgrounds, 0 corrupt: 100%|██████████| 76/76 [00:00<00:00, 1159.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.34G     0.5306      1.238      4.354     0.9508         20        640: 100%|██████████| 5/5 [00:04<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00573     0.0949    0.00669    0.00595    0.00751      0.124    0.00742    0.00631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.24G     0.5108      1.107      3.853     0.9073         26        640: 100%|██████████| 5/5 [00:03<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.828       0.55      0.711      0.633      0.822      0.546      0.705       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.59G     0.4541     0.8238      1.964     0.8953         14        640: 100%|██████████| 5/5 [00:03<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.935      0.958      0.984      0.899      0.929       0.96      0.977      0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       8.6G     0.4414     0.7017      1.129     0.8719         25        640: 100%|██████████| 5/5 [00:03<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.958      0.957      0.986      0.906      0.954      0.952      0.984      0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.22G     0.4025     0.5919       1.06     0.8609         22        640: 100%|██████████| 5/5 [00:02<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.958      0.968       0.99      0.909      0.954      0.964      0.987      0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.025 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.958      0.968       0.99      0.909      0.953      0.964      0.987      0.887\n",
      "                  card        474        474      0.958      0.968       0.99      0.909      0.953      0.964      0.987      0.887\n",
      "Speed: 0.9ms preprocess, 13.5ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▆███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▆███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▆███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▆███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▇▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▇▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▇▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.98965\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.98698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.90921\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.88664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.95766\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.95349\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.96835\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.96414\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.40249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.0601\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.8609\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.59189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.36133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.90101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.8398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.61641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_014004-mstq3tpl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_014004-mstq3tpl/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.963      0.974      0.989       0.91      0.963      0.974      0.989      0.882\n",
      "                  card        476        476      0.963      0.974      0.989       0.91      0.963      0.974      0.989      0.882\n",
      "Speed: 1.0ms preprocess, 29.4ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 1.5292663756500822\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_22/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 998.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_22/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.95G     0.3233     0.6451     0.8725     0.8734         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.961      0.944      0.984      0.902      0.957       0.94      0.982      0.879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G     0.5638      0.687      1.175     0.9492          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.961      0.946      0.984      0.904      0.957      0.942      0.982      0.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.03G     0.4053     0.6908      1.379     0.9631          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.957      0.947      0.985      0.904      0.953      0.943      0.983       0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G      0.266      0.538      1.605     0.7508          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.956      0.943      0.985      0.904      0.952      0.939      0.983      0.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.14G     0.2542     0.4396      1.104     0.8359          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.949      0.949      0.985      0.905      0.945      0.945      0.983      0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.95      0.949      0.985      0.904      0.946      0.945      0.983      0.881\n",
      "                  card        474        474       0.95      0.949      0.985      0.904      0.946      0.945      0.983      0.881\n",
      "Speed: 0.7ms preprocess, 13.2ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▄▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▆▇▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▆▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ██▅▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ██▅▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▂▄▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▂▄▆▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▃█▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▄▆█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅██▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▇██▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▃█▆▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▂▅█▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁█▇▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.98502\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.98314\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.90446\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.88103\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.95004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.94582\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.94937\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.94515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.98\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.25425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.10375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.83586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.43956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.36768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.94457\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.84006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.64101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_014517-wlv0v26l\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_014517-wlv0v26l/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476       0.95      0.954      0.987      0.906       0.95      0.954      0.987      0.877\n",
      "                  card        476        476       0.95      0.954      0.987      0.906       0.95      0.954      0.987      0.877\n",
      "Speed: 0.8ms preprocess, 29.5ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 81 images, 0 backgrounds, 0 corrupt: 100%|██████████| 81/81 [00:00<00:00, 1168.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       8.5G     0.6178      1.457      4.219     0.9989          2        640: 100%|██████████| 6/6 [00:04<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00543      0.643    0.00749    0.00654    0.00573      0.679    0.00837    0.00714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       8.8G     0.7892      2.449      4.063      1.084          1        640: 100%|██████████| 6/6 [00:03<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.877      0.844      0.924      0.832      0.867      0.838      0.914      0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       8.3G     0.3926     0.7061      2.694     0.7407          0        640: 100%|██████████| 6/6 [00:03<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.941      0.949      0.982      0.898      0.934      0.943      0.977      0.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.28G     0.4258     0.8358      1.156     0.9301          1        640: 100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.93      0.962       0.98        0.9      0.926      0.958      0.977      0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.59G     0.3871      0.537      0.918     0.8405          2        640: 100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.931      0.979      0.989      0.908      0.925      0.973      0.984      0.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.025 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.946      0.961      0.989      0.908       0.94      0.955      0.984      0.884\n",
      "                  card        474        474      0.946      0.961      0.989      0.908       0.94      0.955      0.984      0.884\n",
      "Speed: 0.7ms preprocess, 13.2ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▅█▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ██▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▆█▁▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄█▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.98874\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.98447\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.90847\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.88353\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.946\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.93977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.96097\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.95464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.013\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.38709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.91797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.8405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.53704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.36473\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.85095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.8388\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.6454\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_014810-4n5acuej\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_014810-4n5acuej/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.966      0.962       0.99      0.913      0.966      0.962       0.99      0.881\n",
      "                  card        476        476      0.966      0.962       0.99      0.913      0.966      0.962       0.99      0.881\n",
      "Speed: 1.0ms preprocess, 29.5ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.7951112022425275\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_23/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 527.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_23/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.13G     0.4212      0.709      1.631     0.8263          7        640: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.939      0.943      0.983      0.898      0.933      0.937      0.977      0.877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.16G     0.3597     0.6579     0.7506     0.8825          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.941       0.94      0.984      0.899      0.935      0.935      0.978      0.878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.14G     0.6536      1.361      1.254      0.954          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.949      0.943      0.984        0.9      0.931      0.945      0.979      0.877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.03G     0.6641      1.267      1.276     0.9115          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.947      0.949      0.984      0.899      0.941      0.942      0.979      0.878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.03G      0.668      2.204      1.474     0.9043          7        640: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.951      0.951      0.985      0.901      0.944      0.945       0.98      0.878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.95      0.951      0.985      0.902      0.944      0.945      0.979      0.879\n",
      "                  card        474        474       0.95      0.951      0.985      0.902      0.944      0.945      0.979      0.879\n",
      "Speed: 0.7ms preprocess, 13.2ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▄▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▄▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▆▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▇▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▂▃▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▃▁▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▂▁█▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▂▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▁▅▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▄█▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▁▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▁▄▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.98457\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.97944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.90158\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.8786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.9505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.94417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.95148\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.94515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.911\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.66797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.47391\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.90433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 2.20415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.37082\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.89276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.84085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.67745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_015323-d1txsrs2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_015323-d1txsrs2/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.956      0.941      0.986      0.904      0.956      0.941      0.986      0.876\n",
      "                  card        476        476      0.956      0.941      0.986      0.904      0.956      0.941      0.986      0.876\n",
      "Speed: 0.8ms preprocess, 29.4ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 86 images, 0 backgrounds, 0 corrupt: 100%|██████████| 86/86 [00:00<00:00, 885.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.93G     0.5702      1.326      4.315     0.9422         10        640: 100%|██████████| 6/6 [00:04<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00637      0.755     0.0196     0.0175    0.00653      0.774     0.0208      0.018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.27G     0.5158      1.195      3.185     0.8959          9        640: 100%|██████████| 6/6 [00:03<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.88      0.886      0.948      0.856      0.876      0.882      0.944      0.837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.18G     0.4499     0.7951        1.4     0.8825         11        640: 100%|██████████| 6/6 [00:03<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.951      0.975      0.987       0.91      0.947      0.972      0.985      0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.21G     0.3794     0.6374      1.173     0.8432          6        640: 100%|██████████| 6/6 [00:03<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.951      0.962       0.99      0.912      0.947      0.958      0.989      0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.23G     0.3928      0.547     0.8972     0.8563         12        640: 100%|██████████| 6/6 [00:03<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.969      0.954      0.991      0.913      0.965      0.949       0.99      0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.026 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.969      0.954      0.991      0.913      0.965      0.949       0.99      0.888\n",
      "                  card        474        474      0.969      0.954      0.991      0.913      0.965      0.949       0.99      0.888\n",
      "Speed: 0.8ms preprocess, 13.4ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅██▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅██▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▆▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▄▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▇▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▃▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91342\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.88768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.96914\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.96485\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.95359\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.94937\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.39278\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.89722\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.8563\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.3584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.8324\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83436\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.60247\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_015613-kvgo603s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_015613-kvgo603s/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.971      0.971      0.992      0.912      0.971      0.971      0.992      0.883\n",
      "                  card        476        476      0.971      0.971      0.992      0.912      0.971      0.971      0.992      0.883\n",
      "Speed: 1.4ms preprocess, 29.7ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.1524478272052181\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_24/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 564.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_24/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.69G     0.4052      1.022      1.014     0.7304          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.948      0.955      0.987      0.908      0.944      0.951      0.985      0.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.15G      0.454     0.8874      1.147     0.8944          5        640: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.963      0.942      0.987      0.907      0.959      0.938      0.985      0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.03G     0.2236     0.3334     0.6948     0.8279          9        640: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.951      0.952      0.987      0.907      0.947      0.948      0.984      0.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.03G     0.3271     0.3913      1.126     0.8789          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.955      0.949      0.987      0.908      0.951      0.945      0.984      0.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.05G     0.1941     0.3033     0.7103     0.7853          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.962      0.951      0.987      0.909      0.957      0.947      0.984      0.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.962      0.951      0.987      0.908      0.957      0.947      0.984      0.883\n",
      "                  card        474        474      0.962      0.951      0.987      0.908      0.957      0.947      0.984      0.883\n",
      "Speed: 0.9ms preprocess, 13.2ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▅▁▂▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▅▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▇▃▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▃▁▇█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁█▃▄▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁█▃▄▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▁▆▅▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▁▆▅▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▇█▂▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▆█▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁█▅▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▇▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▅▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁█▄▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▁▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▂▆█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.98734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.98421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.90799\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.88256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.9616\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.95734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.95099\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.94677\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.878\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.19408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.71025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.78531\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.3033\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.36597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.8844\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.62291\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_020130-5kz6ua19\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_020130-5kz6ua19/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.966      0.955      0.987      0.905      0.966      0.955      0.987      0.878\n",
      "                  card        476        476      0.966      0.955      0.987      0.905      0.966      0.955      0.987      0.878\n",
      "Speed: 0.9ms preprocess, 29.4ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 91 images, 0 backgrounds, 0 corrupt: 100%|██████████| 91/91 [00:00<00:00, 1086.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.37G     0.5527      1.247      4.321     0.9739         28        640: 100%|██████████| 6/6 [00:04<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00618      0.734     0.0161     0.0145    0.00632      0.751     0.0172      0.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.69G     0.4926       1.02      3.475     0.9182         21        640: 100%|██████████| 6/6 [00:03<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.886       0.89      0.952      0.859       0.88      0.883      0.944      0.835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.26G     0.4551     0.8198      1.397     0.8713         26        640: 100%|██████████| 6/6 [00:03<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.941      0.945      0.983      0.906      0.933      0.941      0.977      0.872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.25G     0.3846      0.638      1.127     0.8374         15        640: 100%|██████████| 6/6 [00:03<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.956      0.958      0.988      0.911      0.952      0.954      0.984      0.879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       8.3G     0.3722     0.5827     0.8822     0.8472         20        640: 100%|██████████| 6/6 [00:03<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.962      0.985      0.992      0.917      0.958      0.981      0.991      0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.026 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.963      0.985      0.992      0.917      0.959      0.981      0.991      0.889\n",
      "                  card        474        474      0.963      0.985      0.992      0.917      0.959      0.981      0.991      0.889\n",
      "Speed: 0.8ms preprocess, 13.4ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▆▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99083\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.88858\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.96288\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.95876\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.98089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.076\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.37219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.88219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.84717\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.58265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.35818\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.79009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.8334\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.63109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_020422-q2a2hql4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_020422-q2a2hql4/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476       0.97      0.967       0.99      0.911       0.97      0.967       0.99      0.882\n",
      "                  card        476        476       0.97      0.967       0.99      0.911       0.97      0.967       0.99      0.882\n",
      "Speed: 1.0ms preprocess, 29.6ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.11753400719286933\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_25/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 500.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_25/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.72G     0.4272     0.6388     0.7581     0.8394          8        640: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.963      0.979       0.99      0.907      0.958      0.974      0.988      0.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.14G     0.6959      1.322      1.567     0.8004          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.958      0.985       0.99      0.909      0.954      0.981      0.988      0.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.03G     0.5495      0.729       1.04     0.8147          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.957      0.981       0.99      0.909      0.953      0.977      0.988      0.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.02G      0.398     0.5029      0.793     0.8381          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.957      0.981       0.99      0.909      0.953      0.977      0.988      0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.14G      0.549     0.8959     0.8691     0.8972          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.962      0.974       0.99      0.909      0.958       0.97      0.988      0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.958      0.981       0.99      0.909      0.954      0.977      0.988      0.883\n",
      "                  card        474        474      0.958      0.981       0.99      0.909      0.954      0.977      0.988      0.883\n",
      "Speed: 0.9ms preprocess, 13.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▅█▇▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁█▇█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▇█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▃▁▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▃▁▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁█▄▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁█▄▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▂█▅▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▃▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▄▁▂▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▂█▃▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▃▃▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▇█▇▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▁▂▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99034\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.98805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.90866\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.88281\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.95787\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.95358\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.97679\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.896\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.54901\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.86915\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.89723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.89586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.36668\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.82427\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83312\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.64853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_020938-q5vn1w1r\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_020938-q5vn1w1r/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.963      0.952      0.988      0.903      0.963      0.952      0.988      0.878\n",
      "                  card        476        476      0.963      0.952      0.988      0.903      0.963      0.952      0.988      0.878\n",
      "Speed: 0.8ms preprocess, 29.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 96 images, 0 backgrounds, 0 corrupt: 100%|██████████| 96/96 [00:00<00:00, 1254.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       8.4G     0.6001      1.374      4.459     0.9725         24        640: 100%|██████████| 6/6 [00:05<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00309      0.323    0.00649    0.00564    0.00353      0.369    0.00705     0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.29G      0.546      1.126      3.062     0.9212         22        640: 100%|██████████| 6/6 [00:03<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.915      0.937      0.973      0.885      0.909       0.93      0.967      0.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.29G     0.3907     0.7212      1.048     0.8548         26        640: 100%|██████████| 6/6 [00:03<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.947      0.947      0.981      0.896       0.94      0.941      0.974      0.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.27G     0.3857     0.5975     0.9273     0.8709         33        640: 100%|██████████| 6/6 [00:03<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.95      0.962      0.984      0.902      0.942      0.954      0.979      0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.28G     0.3616     0.5665     0.8283     0.8592         23        640: 100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.97      0.945      0.988      0.908      0.947       0.96      0.984      0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.026 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.95      0.964      0.987      0.908      0.946       0.96      0.984      0.885\n",
      "                  card        474        474       0.95      0.964      0.987      0.908      0.946       0.96      0.984      0.885\n",
      "Speed: 0.9ms preprocess, 13.6ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▆▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▅▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▃▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.98671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.98428\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.9078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.88542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.95043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.94627\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.96414\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.95992\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.36158\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.82831\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.85924\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.56651\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.36602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.81492\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.60845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_021228-zjoykis7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_021228-zjoykis7/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.978       0.96      0.991      0.913      0.978       0.96      0.991      0.887\n",
      "                  card        476        476      0.978       0.96      0.991      0.913      0.978       0.96      0.991      0.887\n",
      "Speed: 1.2ms preprocess, 29.7ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.1265750803518565\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_26/train/labels... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<00:00, 649.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_26/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.19G     0.4474     0.6272     0.9134     0.8679         11        640: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.951      0.937      0.978      0.898      0.946      0.932      0.976      0.877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      3.15G     0.4525     0.7942      3.434     0.8761          3        640: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.953      0.937      0.979      0.898      0.949      0.933      0.976      0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      3.14G     0.3057     0.4548     0.6182     0.8946          8        640: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.952      0.937      0.979        0.9      0.948      0.932      0.975      0.877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      3.14G     0.4023     0.6848      1.303     0.8165          6        640: 100%|██████████| 1/1 [00:00<00:00,  3.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.959      0.931       0.98      0.899      0.952      0.925      0.975      0.877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      3.13G      0.652      1.097      0.995     0.9743          6        640: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.96      0.932       0.98      0.899      0.953      0.926      0.975      0.878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.96      0.932       0.98      0.899      0.953      0.926      0.976      0.878\n",
      "                  card        474        474       0.96      0.932       0.98      0.899      0.953      0.926      0.976      0.878\n",
      "Speed: 0.9ms preprocess, 13.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▄▄█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▆▄▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▂▁█▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▄▁▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▂▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▃▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▇█▇▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▇█▇▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▄▄▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▂█▁▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▃▄▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▃▅▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ██▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▇█▂▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▇▆▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.98015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.97554\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.89941\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.87794\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.95953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.95302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.93249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.92616\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.869\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.65201\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.99503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.97433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 1.09714\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.3705\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.8701\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.8387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.63546\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_021748-mdufan3p\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_021748-mdufan3p/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.951      0.943      0.983      0.902      0.951      0.943      0.983      0.878\n",
      "                  card        476        476      0.951      0.943      0.983      0.902      0.951      0.943      0.983      0.878\n",
      "Speed: 0.7ms preprocess, 29.5ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 101 images, 0 backgrounds, 0 corrupt: 100%|██████████| 101/101 [00:00<00:00, 943.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       8.4G     0.6064      1.431      4.395     0.9973          7        640: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474    0.00335      0.241    0.00844    0.00739    0.00404      0.369    0.00948     0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.43G     0.5371       1.08      2.608     0.9189         13        640: 100%|██████████| 7/7 [00:04<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.939      0.939      0.983        0.9      0.924      0.951      0.978      0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.28G     0.3987     0.6792       1.19     0.8659          8        640: 100%|██████████| 7/7 [00:03<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.954      0.979      0.989      0.912       0.95      0.975      0.988       0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.29G     0.4012     0.5677     0.8541     0.8453          8        640: 100%|██████████| 7/7 [00:04<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.978      0.968      0.993      0.912      0.972      0.964      0.992      0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.28G     0.4079     0.6115      0.794     0.8714         10        640: 100%|██████████| 7/7 [00:03<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.989       0.96      0.992      0.914      0.984      0.956      0.992      0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.026 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:14<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.989       0.96      0.992      0.914      0.985      0.956      0.992      0.895\n",
      "                  card        474        474      0.989       0.96      0.992      0.914      0.985      0.956      0.992      0.895\n",
      "Speed: 1.1ms preprocess, 13.4ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▆▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▄▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▃▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▃▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▃▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.89523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.98925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.98491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.95992\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.9557\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.40792\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.79404\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.87135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.61146\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.3598\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.65187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.57905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_022039-gy3opfqg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_022039-gy3opfqg/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:22<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.988      0.979      0.994      0.916      0.988      0.979      0.994       0.89\n",
      "                  card        476        476      0.988      0.979      0.994      0.916      0.988      0.979      0.994       0.89\n",
      "Speed: 1.4ms preprocess, 29.8ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.11158666027554054\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_27/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 389.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_27/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.25G     0.3114     0.4183     0.6054     0.8444         17        640: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.962      0.971      0.991      0.911       0.96      0.969       0.99      0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.04G     0.2707     0.3101     0.9608     0.8057         11        640: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.966       0.97      0.991       0.91      0.962      0.968      0.991      0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.92G     0.3475     0.5607     0.6328     0.7865         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.964       0.97      0.991      0.912      0.961      0.968      0.991      0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.92G     0.3671     0.4139     0.8811     0.8342         11        640: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.964      0.969      0.991      0.912       0.96      0.968      0.991      0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.92G     0.2578     0.3932     0.6734      0.786         15        640: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.974      0.957      0.991      0.911      0.949      0.981      0.991      0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.964       0.97      0.991      0.913      0.962      0.968      0.991      0.889\n",
      "                  card        474        474      0.964       0.97      0.991      0.913      0.962      0.968      0.991      0.889\n",
      "Speed: 0.7ms preprocess, 13.1ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▄█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▃▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▃▁▅▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁█▅▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▃█▄▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▆▆▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▄▂▇█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▂▆▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▃▁▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄▁█▄▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▇▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▇▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99073\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.88927\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.96433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.9618\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.96968\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.96835\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.25776\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.67345\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.39323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.36548\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.67245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83742\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.5917\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_022600-c1lkdo14\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_022600-c1lkdo14/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.981      0.974      0.992      0.914      0.981      0.974      0.992      0.886\n",
      "                  card        476        476      0.981      0.974      0.992      0.914      0.981      0.974      0.992      0.886\n",
      "Speed: 0.8ms preprocess, 29.2ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 111 images, 0 backgrounds, 0 corrupt: 100%|██████████| 111/111 [00:00<00:00, 859.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.37G     0.5608      1.363      4.296     0.9562         27        640: 100%|██████████| 7/7 [00:06<00:00,  1.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474     0.0297      0.262     0.0278     0.0248     0.0317      0.278     0.0297     0.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.39G     0.4974      1.021      2.485     0.9041         30        640: 100%|██████████| 7/7 [00:04<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.916      0.948      0.975       0.89       0.91      0.942       0.97      0.868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.29G     0.3923     0.6828       1.14     0.8783         27        640: 100%|██████████| 7/7 [00:04<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.95      0.956      0.984      0.907      0.948      0.954      0.983      0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.32G     0.3848     0.5894     0.7972     0.8431         24        640: 100%|██████████| 7/7 [00:04<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.967       0.97      0.991      0.911      0.963      0.966       0.99      0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.37G     0.3902     0.5802     0.6954     0.8479         21        640: 100%|██████████| 7/7 [00:04<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.98      0.964      0.992      0.914      0.975       0.96      0.992      0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.027 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.981      0.965      0.992      0.914      0.976      0.961      0.992      0.891\n",
      "                  card        474        474      0.981      0.965      0.992      0.914      0.976      0.961      0.992      0.891\n",
      "Speed: 1.0ms preprocess, 13.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▅▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▅▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▃▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▃▁▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.89111\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.98071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.97642\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.96516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.96094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.39018\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.69539\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.84789\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.58023\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.36331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.64676\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.64937\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_022853-v5usepad\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_022853-v5usepad/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:22<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.961      0.989      0.992      0.913      0.961      0.989      0.992      0.889\n",
      "                  card        476        476      0.961      0.989      0.992      0.913      0.961      0.989      0.992      0.889\n",
      "Speed: 1.3ms preprocess, 29.8ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.08931309022928446\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_28/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 404.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_28/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.27G     0.3619     0.5163     0.5799     0.7995         16        640: 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.976      0.958      0.988      0.902      0.974      0.956      0.987      0.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.04G     0.4278     0.6198     0.7644     0.8353         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.978      0.955      0.989      0.903      0.976      0.953      0.988      0.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      5.03G     0.3473     0.4865      0.641     0.7913         20        640: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.978      0.955      0.989      0.904      0.976      0.953      0.988      0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.92G     0.2587     0.3924     0.6222     0.8359         15        640: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.98      0.954      0.989      0.904      0.978      0.952      0.988      0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.92G     0.2556     0.5076     0.8371     0.9232         15        640: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.985      0.953       0.99      0.904      0.983      0.951      0.989      0.885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.985      0.953       0.99      0.903      0.983      0.951      0.989      0.885\n",
      "                  card        474        474      0.985      0.953       0.99      0.903      0.983      0.951      0.989      0.885\n",
      "Speed: 0.8ms preprocess, 13.1ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▃▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▅▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▄█▇▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▃▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▄▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▄▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▅█▅▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▆▃▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▃▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅█▄▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▇▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▇▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.98986\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.98891\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.90342\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.8852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.98474\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.98256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.95291\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.9508\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.857\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.25563\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.83708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.92317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.50765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.37476\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.66629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.84476\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.68922\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_023417-3um3j54u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_023417-3um3j54u/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.963      0.974      0.989      0.909      0.963      0.974      0.989      0.885\n",
      "                  card        476        476      0.963      0.974      0.989      0.909      0.963      0.974      0.989      0.885\n",
      "Speed: 0.8ms preprocess, 29.3ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 121 images, 0 backgrounds, 0 corrupt: 100%|██████████| 121/121 [00:00<00:00, 932.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.33G     0.5103      1.316       4.26     0.9409         15        640: 100%|██████████| 8/8 [00:06<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.68       0.15      0.346       0.31       0.68       0.15      0.345      0.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.66G     0.4496      0.801      1.835     0.8685         14        640: 100%|██████████| 8/8 [00:05<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.955      0.946      0.986      0.909      0.951      0.941      0.983      0.877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.32G     0.4093     0.6384     0.9549      0.859         16        640: 100%|██████████| 8/8 [00:04<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.981       0.96      0.991      0.911      0.977      0.956      0.988      0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.28G     0.3848       0.59     0.7469     0.8609         16        640: 100%|██████████| 8/8 [00:04<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.991      0.974      0.994      0.914      0.989       0.97      0.994      0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.32G      0.332     0.5258     0.6256     0.8353         13        640: 100%|██████████| 8/8 [00:04<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.983      0.985      0.994      0.918      0.981      0.983      0.994      0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.027 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.983      0.985      0.994      0.917      0.981      0.983      0.994      0.895\n",
      "                  card        474        474      0.983      0.985      0.994      0.917      0.981      0.983      0.994      0.895\n",
      "Speed: 0.9ms preprocess, 13.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▃▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99409\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99407\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91742\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.8951\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.98306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.98096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.98312\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.33203\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.62564\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.83527\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.52575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.35326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.56629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.8309\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.60491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_023709-hvg959n1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_023709-hvg959n1/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:22<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.985      0.981      0.994      0.913      0.985      0.981      0.994      0.893\n",
      "                  card        476        476      0.985      0.981      0.994      0.913      0.985      0.981      0.994      0.893\n",
      "Speed: 1.3ms preprocess, 29.6ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.10577274784714785\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_29/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 415.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_29/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.71G     0.4541     0.8173     0.5349     0.8439         17        640: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.969      0.988      0.993      0.912      0.967      0.986      0.993      0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.06G      0.493     0.9297     0.6822     0.8573         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.966      0.992      0.993      0.912      0.964      0.989      0.993      0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.92G     0.4896     0.9282     0.5054     0.8701         21        640: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.966      0.992      0.993      0.912      0.964      0.989      0.993      0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.93G     0.4077     0.6382     0.6285     0.8929         12        640: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.967      0.989      0.993      0.913      0.965      0.987      0.993      0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.92G     0.4209     0.7327     0.5554     0.9084         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.967      0.989      0.993      0.912      0.965      0.987      0.993      0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.967      0.989      0.993      0.912      0.965      0.987      0.993      0.893\n",
      "                  card        474        474      0.967      0.989      0.993      0.912      0.965      0.987      0.993      0.893\n",
      "Speed: 0.7ms preprocess, 13.2ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▆▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▄▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▃▁▂█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄██▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▁▂▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▁▂▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁██▃▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁██▃▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▅██▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▂█▁▆▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▂▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅██▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▃▁▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▅▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▆▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99307\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.89307\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.96685\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.96478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98945\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.98734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.921\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.42094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.55544\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.90842\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.73274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.35801\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.58717\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.61494\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_024233-znsctb4h\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_024233-znsctb4h/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.967      0.985      0.993      0.911      0.967      0.985      0.993       0.89\n",
      "                  card        476        476      0.967      0.985      0.993      0.911      0.967      0.985      0.993       0.89\n",
      "Speed: 0.9ms preprocess, 29.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 131 images, 0 backgrounds, 0 corrupt: 100%|██████████| 131/131 [00:00<00:00, 1113.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.46G     0.5416      1.251      4.202     0.9276          6        640: 100%|██████████| 9/9 [00:06<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.79      0.437      0.656      0.587      0.783      0.433      0.651      0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.69G     0.4061     0.8199      1.601     0.8487          3        640: 100%|██████████| 9/9 [00:05<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.933      0.967      0.985      0.905      0.929      0.963      0.982      0.877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       8.3G     0.3799      0.591     0.8201     0.8406          7        640: 100%|██████████| 9/9 [00:05<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.978       0.96      0.991      0.908      0.978       0.96      0.991      0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       8.6G     0.4027     0.5916     0.7192     0.8632          4        640: 100%|██████████| 9/9 [00:05<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.98      0.979      0.993      0.921       0.98      0.979      0.993      0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.27G     0.3561       0.52     0.6081      0.833          4        640: 100%|██████████| 9/9 [00:05<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.991      0.983      0.994      0.918      0.991      0.983      0.994      0.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.028 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:15<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.99      0.981      0.994      0.919       0.99      0.981      0.994        0.9\n",
      "                  card        474        474       0.99      0.981      0.994      0.919       0.99      0.981      0.994        0.9\n",
      "Speed: 0.8ms preprocess, 13.4ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▆███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▃▂▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▃▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▂▂▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▄▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▂▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.05692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.90004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.99001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.99001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.98101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.35612\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.60807\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.83299\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.52001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.35402\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.48292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.58773\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_024525-19vklz6a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_024525-19vklz6a/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476       0.98      0.983      0.994      0.916       0.98      0.983      0.994      0.888\n",
      "                  card        476        476       0.98      0.983      0.994      0.916       0.98      0.983      0.994      0.888\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.03551424756903243\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_30/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 413.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_30/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.05G      0.566     0.9722     0.6787     0.8958         17        640: 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.985      0.973      0.993      0.917      0.985      0.973      0.993      0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.05G     0.5296     0.8764      0.838     0.9309          9        640: 100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.975      0.975      0.993      0.917      0.975      0.975      0.993      0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.91G     0.5345     0.7638     0.6464     0.8424         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.975      0.976      0.993      0.916      0.975      0.976      0.993      0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.93G     0.5479     0.9019     0.7325     0.9314         12        640: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.975      0.979      0.993      0.916      0.975      0.979      0.993      0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.93G     0.6071     0.7384     0.6443     0.9665         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.975      0.979      0.993      0.916      0.975      0.979      0.993      0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.975      0.975      0.993      0.916      0.975      0.975      0.993      0.898\n",
      "                  card        474        474      0.975      0.975      0.993      0.916      0.975      0.975      0.993      0.898\n",
      "Speed: 0.7ms preprocess, 13.0ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▇▃▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▇▃▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▅█▁▅▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▃▁▃█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▃▅█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▃▅█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▄▁▁▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▂█▁▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▄▆▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▅▂▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▂▃▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▇▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99269\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99269\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91609\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.89831\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.97477\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.97477\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.97468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.97468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.6071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.64426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.96646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.73837\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.35769\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.51087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.59443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_025054-19f1a16l\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_025054-19f1a16l/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.975      0.987      0.993      0.911      0.975      0.987      0.993       0.89\n",
      "                  card        476        476      0.975      0.987      0.993      0.911      0.975      0.987      0.993       0.89\n",
      "Speed: 1.0ms preprocess, 29.2ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 141 images, 0 backgrounds, 0 corrupt: 100%|██████████| 141/141 [00:00<00:00, 957.21it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.23G     0.5654      1.355      4.163     0.9471         26        640: 100%|██████████| 9/9 [00:06<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.81      0.532      0.689      0.617      0.806       0.53      0.686      0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       8.6G     0.4383     0.9108       1.51     0.8775         18        640: 100%|██████████| 9/9 [00:05<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.94      0.947      0.983      0.899      0.936      0.943      0.979      0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.28G     0.3923     0.6222      0.902      0.865         31        640: 100%|██████████| 9/9 [00:05<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.966      0.971      0.991      0.915      0.966      0.971      0.991      0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.63G     0.3976     0.6366     0.7232     0.8571         20        640: 100%|██████████| 9/9 [00:05<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.981      0.979      0.993      0.911      0.981      0.979      0.993      0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.28G     0.3797     0.5362     0.5885     0.8438         30        640: 100%|██████████| 9/9 [00:05<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.98      0.985      0.994      0.914       0.98      0.985      0.994      0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.027 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.98      0.985      0.994      0.915       0.98      0.985      0.994      0.897\n",
      "                  card        474        474       0.98      0.985      0.994      0.915       0.98      0.985      0.994      0.897\n",
      "Speed: 0.6ms preprocess, 13.4ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▃▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▄▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.05692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91509\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.8967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.98013\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.98013\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.98523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.37967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.58848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.84382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.53622\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.36348\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.54288\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83538\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.6211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_025342-fyw27fb1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_025342-fyw27fb1/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.991      0.987      0.995      0.915      0.991      0.987      0.995       0.89\n",
      "                  card        476        476      0.991      0.987      0.995      0.915      0.991      0.987      0.995       0.89\n",
      "Speed: 0.9ms preprocess, 29.8ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.04243781753098819\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_31/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 417.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_31/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      4.77G     0.4691     0.6476     0.4652     0.8651         18        640: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.989      0.981      0.994      0.912      0.987      0.978      0.994      0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.04G      1.037      1.536      1.383      1.011         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.988      0.979      0.994      0.911      0.986      0.977      0.994      0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.92G     0.6257     0.7889     0.6131     0.8577         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.987      0.981      0.994      0.912      0.983      0.977      0.993      0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.91G     0.5465     0.4514     0.6396     0.8598         11        640: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.987      0.979      0.994      0.912      0.985      0.977      0.994      0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.91G     0.5994     0.6399     0.6494     0.9594         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.989       0.98      0.994      0.913      0.987      0.978      0.994      0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.989      0.981      0.994      0.912      0.987      0.978      0.994      0.896\n",
      "                  card        474        474      0.989      0.981      0.994      0.912      0.987      0.978      0.994      0.896\n",
      "Speed: 0.7ms preprocess, 13.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▃▂▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▄▅▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▃▁▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▃▄▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▃▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) █▅▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▁█▂▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▅▁▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁█▃▂▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▂▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁█▁▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▂█▃▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▇█▇▆▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▇▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.9941\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99363\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91242\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.89622\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.98936\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.98723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98052\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.97841\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.861\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.59939\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.64936\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.95943\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.63989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.36834\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.55862\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83824\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.63882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_025906-lfrku0qc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_025906-lfrku0qc/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.985      0.993      0.994      0.916      0.985      0.993      0.994      0.891\n",
      "                  card        476        476      0.985      0.993      0.994      0.916      0.985      0.993      0.994      0.891\n",
      "Speed: 0.9ms preprocess, 29.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|██████████| 151/151 [00:00<00:00, 1092.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.41G     0.5406      1.183      4.117     0.9296          8        640: 100%|██████████| 10/10 [00:07<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.846      0.709      0.837      0.751      0.838      0.708       0.83      0.738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.32G     0.4742     0.9331      1.508     0.8858          8        640: 100%|██████████| 10/10 [00:06<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.985      0.924      0.986      0.908       0.98       0.92       0.98      0.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.46G     0.4405     0.7073     0.8865     0.8662         11        640: 100%|██████████| 10/10 [00:05<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.983      0.951      0.989      0.905       0.98      0.949      0.987      0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.43G     0.4163     0.6311     0.7347     0.8807          8        640: 100%|██████████| 10/10 [00:05<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.992      0.964      0.992      0.913       0.99      0.962      0.992      0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.28G     0.3894     0.5072     0.5428     0.8621          8        640: 100%|██████████| 10/10 [00:05<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.991      0.977      0.994      0.918      0.989      0.973      0.994      0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.029 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.991      0.977      0.994      0.919      0.989      0.973      0.994      0.899\n",
      "                  card        474        474      0.991      0.977      0.994      0.919      0.989      0.973      0.994      0.899\n",
      "Speed: 0.8ms preprocess, 13.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁█▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▃▁▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▂▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▂▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.05202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99401\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99399\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91888\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.89855\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.99143\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.98928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.97662\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.97309\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.193\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.38936\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.54279\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.86212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.50721\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.36291\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.45832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.8365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.60624\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_030155-t6t2zsg6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_030155-t6t2zsg6/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.983      0.994      0.992      0.914      0.983      0.994      0.992      0.893\n",
      "                  card        476        476      0.983      0.994      0.992      0.914      0.983      0.994      0.992      0.893\n",
      "Speed: 0.9ms preprocess, 29.6ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.062135517620917846\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_32/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 439.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_32/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.52G     0.5669     0.9019     0.5183     0.7811         13        640: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.987      0.958      0.993      0.913       0.99      0.954      0.993      0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.03G     0.5148      1.116     0.5947      0.842         13        640: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.983      0.967      0.993      0.913      0.991      0.954      0.992      0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.93G     0.6958      1.186     0.5837     0.8743         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.979       0.97      0.993      0.913      0.983      0.956      0.993      0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.93G     0.4011     0.5183     0.6817      0.899         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.977      0.966      0.993      0.912      0.983      0.966      0.993      0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.93G     0.3993     0.6266     0.6358     0.9118         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.967      0.981      0.993      0.912      0.977      0.969      0.993      0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.966      0.981      0.993      0.912      0.977      0.968      0.993      0.895\n",
      "                  card        474        474      0.966      0.981      0.993      0.912      0.977      0.968      0.993      0.895\n",
      "Speed: 0.7ms preprocess, 13.2ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▅▄▅▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▄▁▂▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▆█▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▅█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▆▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ██▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄▅▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▁▂▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▅▄█▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▄▄█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▄▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅▇█▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▁▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▂▁▄▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99303\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99297\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.89541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.96629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.9766\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.96846\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.857\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.39931\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.63575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.91177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.62658\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.37061\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.49446\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.84075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.60175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_030726-omsa7iiw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_030726-omsa7iiw/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.977      0.985      0.989      0.911      0.977      0.985      0.989      0.887\n",
      "                  card        476        476      0.977      0.985      0.989      0.911      0.977      0.985      0.989      0.887\n",
      "Speed: 0.7ms preprocess, 29.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 161 images, 0 backgrounds, 0 corrupt: 100%|██████████| 161/161 [00:00<00:00, 1067.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.96G     0.5537      1.445      3.845     0.9063          3        640: 100%|██████████| 11/11 [00:07<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.838      0.823       0.91      0.815      0.831      0.817      0.902      0.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.29G     0.4285     0.8211      2.004     0.8016          0        640: 100%|██████████| 11/11 [00:06<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.949      0.944      0.983      0.902      0.949      0.944      0.983      0.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.33G     0.4332     0.7112     0.7364     0.8553          3        640: 100%|██████████| 11/11 [00:06<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.981      0.958      0.992        0.9      0.981      0.958      0.992      0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.64G     0.4305     0.6058      0.585     0.8747          1        640: 100%|██████████| 11/11 [00:06<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.977      0.979      0.994      0.903      0.977      0.979      0.994      0.885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.21G     0.4081     0.5454     0.5585     0.8908          1        640: 100%|██████████| 11/11 [00:06<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.991      0.976      0.994      0.916      0.991      0.976      0.994      0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.030 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:14<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.991      0.977      0.994      0.915      0.991      0.977      0.994      0.891\n",
      "                  card        474        474      0.991      0.977      0.994      0.915      0.991      0.977      0.994      0.891\n",
      "Speed: 1.0ms preprocess, 13.4ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▆█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▄▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▁▅▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▁▃▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▁▄▇▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▂▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.04712\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.9149\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.89116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.99143\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.99143\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.97659\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.97659\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.40814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.55848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.89084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.54541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.38415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.4471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.85802\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.60262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_031017-6v3yuhkz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_031017-6v3yuhkz/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.983      0.994      0.994      0.908      0.983      0.994      0.994      0.888\n",
      "                  card        476        476      0.983      0.994      0.994      0.908      0.983      0.994      0.994      0.888\n",
      "Speed: 0.9ms preprocess, 29.6ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.005133461090874425\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_33/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 420.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_33/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.27G     0.3195     0.4824     0.4628     0.7437         13        640: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.983       0.97      0.993       0.91      0.983       0.97      0.993      0.885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.05G      0.264     0.3985     0.4616     0.8253         12        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.983      0.972      0.993       0.91      0.983      0.972      0.993      0.885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.94G     0.3695     0.5249     0.4264     0.8536         20        640: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.983      0.973      0.994      0.913      0.983      0.973      0.994      0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.91G     0.4201     0.6162     0.7086     0.9935         12        640: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.986      0.975      0.994      0.913      0.986      0.975      0.994      0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.92G     0.2755     0.4067     0.4185      0.837         15        640: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.985      0.976      0.994       0.91      0.985      0.976      0.994      0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.986      0.975      0.994      0.913      0.986      0.975      0.994      0.888\n",
      "                  card        474        474      0.986      0.975      0.994      0.913      0.986      0.975      0.994      0.888\n",
      "Speed: 0.7ms preprocess, 13.2ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▂▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▂▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▂▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▁▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▄▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▄▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▃▁▆█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▂▂▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▃▄█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▄▁▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ██▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▇▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.9132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.88838\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.98584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.98584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.97468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.97468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.834\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.27547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.41848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.83703\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.40673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.38788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.48137\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.85813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.6135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_031551-ntxbm100\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_031551-ntxbm100/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.971      0.995      0.994      0.909      0.971      0.995      0.994      0.887\n",
      "                  card        476        476      0.971      0.995      0.994      0.909      0.971      0.995      0.994      0.887\n",
      "Speed: 0.8ms preprocess, 29.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 171 images, 0 backgrounds, 0 corrupt: 100%|██████████| 171/171 [00:00<00:00, 1058.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.03G      0.572      1.228       3.88     0.9107         26        640: 100%|██████████| 11/11 [00:08<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.88      0.913      0.951      0.861      0.876      0.909      0.945       0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.37G     0.4446     0.7573      1.254     0.8724         16        640: 100%|██████████| 11/11 [00:06<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.956      0.983      0.991       0.91      0.951      0.981       0.99      0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.32G     0.4181     0.7025     0.8957      0.857         15        640: 100%|██████████| 11/11 [00:06<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.974      0.979      0.993       0.91       0.97      0.975      0.992      0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.26G     0.3903     0.5836      0.635     0.8476         20        640: 100%|██████████| 11/11 [00:06<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.987      0.983      0.994      0.914      0.983      0.979      0.993      0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       8.3G     0.4194     0.5907     0.5017     0.8404         19        640: 100%|██████████| 11/11 [00:06<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.983      0.987      0.994      0.918      0.989      0.975      0.992      0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.030 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:14<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.983      0.987      0.994      0.918      0.989      0.975      0.992      0.893\n",
      "                  card        474        474      0.983      0.987      0.994      0.918      0.989      0.975      0.992      0.893\n",
      "Speed: 1.1ms preprocess, 13.2ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁█▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁█▇█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▃▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▁▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▁▂▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.04712\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99434\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.9181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.893\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.98319\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.98921\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98688\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.97468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.286\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.41944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.50172\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.84042\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.59069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.36639\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.40848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83982\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.59201\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_031840-x3z63ylx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_031840-x3z63ylx/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.989      0.981      0.994      0.915      0.989      0.981      0.994       0.89\n",
      "                  card        476        476      0.989      0.981      0.994      0.915      0.989      0.981      0.994       0.89\n",
      "Speed: 0.9ms preprocess, 29.6ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.021601352998911638\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_34/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 430.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_34/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      5.52G     0.2658     0.3595     0.4067     0.8518         17        640: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.983      0.983      0.994      0.916      0.987      0.975      0.993      0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.03G     0.4085     0.8037     0.7924     0.8094         11        640: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.985      0.981      0.994      0.917      0.988      0.975      0.994      0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.93G     0.4957     0.7308     0.4691     0.8408         21        640: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.989       0.98      0.994      0.918      0.991      0.977      0.994      0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.91G      0.615      0.932     0.6707     0.8588         15        640: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.991      0.979      0.994      0.917      0.991      0.977      0.994      0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.92G      0.373     0.4631     0.4679     0.8589         14        640: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.985      0.986      0.994      0.917      0.989      0.976      0.994      0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.985      0.985      0.994      0.919      0.989      0.977      0.994      0.896\n",
      "                  card        474        474      0.985      0.985      0.994      0.919      0.989      0.977      0.994      0.896\n",
      "Speed: 0.8ms preprocess, 13.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▃▆▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▂▅▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▃▇█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃█▇▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▆▃▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▄▆█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁█▂▆▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▇▁▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▆▆█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99377\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91864\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.89569\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.98523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.98931\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.97679\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.847\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.37302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.46791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.8589\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.46307\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.3694\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.43178\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.84096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.60504\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_032415-iry9hx01\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_032415-iry9hx01/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.982      0.983      0.994      0.915      0.982      0.983      0.994       0.89\n",
      "                  card        476        476      0.982      0.983      0.994      0.915      0.982      0.983      0.994       0.89\n",
      "Speed: 0.8ms preprocess, 29.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 181 images, 0 backgrounds, 0 corrupt: 100%|██████████| 181/181 [00:00<00:00, 950.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       7.9G     0.5769      1.356      3.678     0.9232          7        640: 100%|██████████| 12/12 [00:08<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.926      0.929      0.975      0.883       0.92      0.923      0.967      0.863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.27G     0.4248     0.7303       1.01      0.846          7        640: 100%|██████████| 12/12 [00:07<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.977      0.982      0.993      0.915      0.973      0.978      0.992      0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.51G     0.3954     0.5678     0.7148     0.8531          7        640: 100%|██████████| 12/12 [00:06<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.979      0.977      0.994      0.922      0.985      0.972      0.994      0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.19G      0.392     0.5603     0.5681     0.8702          8        640: 100%|██████████| 12/12 [00:06<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.984      0.979      0.994      0.918      0.981      0.977      0.993      0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.47G     0.4001      0.586     0.4704     0.8419          9        640: 100%|██████████| 12/12 [00:06<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.989      0.981      0.994       0.92      0.987      0.979      0.994        0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.030 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.989      0.981      0.994      0.919      0.987      0.978      0.994      0.901\n",
      "                  card        474        474      0.989      0.981      0.994      0.919      0.987      0.978      0.994      0.901\n",
      "Speed: 0.8ms preprocess, 13.4ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▇█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▆█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁█▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁█▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▁▂▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▁▂▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▁▁▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▁▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.04223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91887\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.9009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.98936\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.98723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.97848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.324\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.40012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.47041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.84194\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.58595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.36645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.3444\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.58902\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_032704-5kmg4nxh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_032704-5kmg4nxh/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.981      0.985      0.994      0.917      0.981      0.985      0.994      0.897\n",
      "                  card        476        476      0.981      0.985      0.994      0.917      0.981      0.985      0.994      0.897\n",
      "Speed: 0.9ms preprocess, 29.4ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.0757332050008348\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_35/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 406.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_35/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.16G     0.4165      1.561     0.5944     0.8923         17        640: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.983      0.977      0.994      0.913      0.979      0.973      0.993      0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.03G     0.4689     0.8684     0.6569      1.033         17        640: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.985      0.979      0.994      0.914      0.981      0.974      0.993      0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.93G     0.4443     0.6735      0.723      0.991         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.985      0.978      0.994      0.914      0.981      0.973      0.993      0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       4.9G     0.5545      1.075     0.8663      1.078         13        640: 100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.987      0.979      0.994      0.915      0.983      0.975      0.993      0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.91G     0.4547     0.8249     0.6368     0.9125         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.985      0.979      0.994      0.915      0.981      0.975      0.992      0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.985      0.979      0.994      0.914      0.981      0.974      0.993        0.9\n",
      "                  card        474        474      0.985      0.979      0.994      0.914      0.981      0.974      0.993        0.9\n",
      "Speed: 1.1ms preprocess, 13.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▃▄▁▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ██▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▆▄█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▅▆▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▄▄█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▄█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁█▄█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁█▄█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▁▄▂█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▁▃▄█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▁▆▅█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▃▁▄▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▄▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99304\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.8999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.98513\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.98089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.97856\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.97434\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.889\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.45468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.63682\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.91246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.8249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.37297\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.36691\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83794\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.5919\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_033240-9vy8ba43\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_033240-9vy8ba43/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.981       0.98      0.993      0.913      0.981       0.98      0.993      0.894\n",
      "                  card        476        476      0.981       0.98      0.993      0.913      0.981       0.98      0.993      0.894\n",
      "Speed: 1.0ms preprocess, 29.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 191 images, 0 backgrounds, 0 corrupt: 100%|██████████| 191/191 [00:00<00:00, 870.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.22G     0.5565      1.197      3.836     0.9121         22        640: 100%|██████████| 12/12 [00:09<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.906      0.922      0.965      0.873        0.9      0.916      0.958       0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.25G     0.4071      0.696       1.08     0.8577         25        640: 100%|██████████| 12/12 [00:07<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.967      0.979      0.992      0.911      0.957      0.973       0.99      0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5       8.2G     0.4054     0.6373     0.7029     0.8623         26        640: 100%|██████████| 12/12 [00:07<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.982       0.97      0.993      0.918       0.98      0.968      0.993       0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.17G     0.4037     0.5629     0.5828     0.8707         27        640: 100%|██████████| 12/12 [00:07<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.996      0.992      0.995      0.916      0.996      0.992      0.995       0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.21G     0.4163     0.5989     0.4779     0.8403         28        640: 100%|██████████| 12/12 [00:07<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474          1      0.989      0.995      0.919          1      0.989      0.995      0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.030 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:14<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474          1      0.989      0.995      0.918          1      0.989      0.995      0.892\n",
      "                  card        474        474          1      0.989      0.995      0.918          1      0.989      0.995      0.892\n",
      "Speed: 0.8ms preprocess, 13.4ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▅▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▇▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▆▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▁▁▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▃▃▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▁▁▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▁▂▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.04223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99496\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99496\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.89238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98878\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.98878\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.271\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.41629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.47787\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.84034\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.59888\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.36632\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.33381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.60604\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_033528-ybsh0yjq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_033528-ybsh0yjq/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.988      0.989      0.995      0.914      0.988      0.989      0.995      0.891\n",
      "                  card        476        476      0.988      0.989      0.995      0.914      0.988      0.989      0.995      0.891\n",
      "Speed: 0.9ms preprocess, 29.7ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.004070776023988865\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_36/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 400.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_36/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       6.3G     0.6856      1.102     0.5252     0.8729         18        640: 100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.994       0.98      0.995      0.915      0.994       0.98      0.995      0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      5.04G     0.5083     0.7596     0.4724     0.8619         16        640: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.994       0.98      0.995      0.916      0.994       0.98      0.995      0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      4.91G     0.6512      1.446     0.6211     0.8504         13        640: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.993      0.983      0.995      0.916      0.993      0.983      0.995      0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      4.91G     0.3995     0.7051     0.6477      0.912         10        640: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.995      0.983      0.994      0.916      0.995      0.983      0.994      0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      4.91G      0.496     0.6338     0.3583     0.8181         18        640: 100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.994      0.983      0.994      0.917      0.994      0.983      0.994      0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.994      0.983      0.994      0.917      0.994      0.983      0.994      0.893\n",
      "                  card        474        474      0.994      0.983      0.994      0.917      0.994      0.983      0.994      0.893\n",
      "Speed: 1.1ms preprocess, 13.2ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▆█▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) █▆█▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▆▆▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▃▂▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▃▂▁█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▁███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄▇▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▅▄▇█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▅▄▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▅▂█▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▇▅▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▅▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▇▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▃▃▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.09608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 8e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99446\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99446\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91669\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.89308\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.99423\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.99423\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98312\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.98312\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.49604\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.35834\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.81814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.63382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.36693\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.35331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83655\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.61208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_034105-t7esdoc0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_034105-t7esdoc0/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.985      0.994      0.995      0.916      0.985      0.994      0.995      0.896\n",
      "                  card        476        476      0.985      0.994      0.995      0.916      0.985      0.994      0.995      0.896\n",
      "Speed: 1.0ms preprocess, 29.2ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 201 images, 0 backgrounds, 0 corrupt: 100%|██████████| 201/201 [00:00<00:00, 859.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.42G     0.5348      1.168       3.43     0.9173         12        640: 100%|██████████| 13/13 [00:09<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.934      0.941       0.98      0.898      0.928      0.935      0.974       0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.68G      0.448     0.7472      1.047     0.8747         14        640: 100%|██████████| 13/13 [00:07<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.976      0.973      0.993      0.913      0.976      0.973      0.993      0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.38G       0.43     0.6513     0.6641     0.8535         17        640: 100%|██████████| 13/13 [00:07<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.985      0.977      0.994      0.911      0.985      0.977      0.994      0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.68G     0.4126     0.6058     0.5233      0.871         20        640: 100%|██████████| 13/13 [00:07<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.989      0.977      0.994      0.912      0.989      0.977      0.994      0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.32G     0.4105     0.5557     0.4641     0.8613         15        640: 100%|██████████| 13/13 [00:07<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.986      0.983      0.994      0.913      0.986      0.983      0.994      0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.031 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:14<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.989      0.977      0.994      0.912      0.989      0.977      0.994      0.892\n",
      "                  card        474        474      0.989      0.977      0.994      0.912      0.989      0.977      0.994      0.892\n",
      "Speed: 1.1ms preprocess, 13.4ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁█▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▅███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▃▁▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▂▂█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▆▁▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.03733\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99409\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99409\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.89241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.98931\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.98931\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.97664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.97664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.41052\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.4641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.86127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.55566\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.38513\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.35217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.84142\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.59723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_034356-ksrlmphg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_034356-ksrlmphg/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.983      0.987      0.994      0.912      0.983      0.987      0.994      0.892\n",
      "                  card        476        476      0.983      0.987      0.994      0.912      0.983      0.987      0.994      0.892\n",
      "Speed: 0.9ms preprocess, 29.4ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.008295431065871495\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_37/train/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<00:00, 397.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_37/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.73G     0.5081     0.5497     0.5298     0.8726          2        640: 100%|██████████| 4/4 [00:03<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.983      0.984      0.994      0.917      0.983      0.984      0.994      0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      7.77G      0.482     0.6412      0.486     0.8789          3        640: 100%|██████████| 4/4 [00:02<00:00,  1.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.983      0.985      0.994      0.912      0.983      0.985      0.994      0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.12G     0.4315      0.532     0.4864     0.8499          2        640: 100%|██████████| 4/4 [00:02<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.981      0.985      0.991       0.91      0.981      0.985      0.991       0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       7.8G     0.6463     0.9454     0.5563     0.9236          2        640: 100%|██████████| 4/4 [00:02<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.986      0.981      0.994      0.912      0.986      0.981      0.994       0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.06G     0.4989      0.541     0.3962     0.8295          5        640: 100%|██████████| 4/4 [00:01<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.985      0.981      0.994      0.913      0.985      0.981      0.994      0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.984      0.981      0.994      0.913      0.984      0.981      0.994      0.892\n",
      "                  card        474        474      0.984      0.981      0.994      0.913      0.984      0.981      0.994      0.892\n",
      "Speed: 0.8ms preprocess, 13.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▇█▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▇█▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) █▄▁▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁█▆▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▄▄▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▄▄▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▆▇█▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▆▇█▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▃▃▁█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▇▅▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▄▅▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▁▃▁█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▅▃█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▃▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▆█▆▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▆▃▁█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99432\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99432\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91272\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.89195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.98433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.98433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.98101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.031\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.49892\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.39617\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.8295\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.54095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.3852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.31098\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83695\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_034934-jos2e0ii\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_034934-jos2e0ii/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.986      0.983      0.994      0.913      0.986      0.983      0.994      0.894\n",
      "                  card        476        476      0.986      0.983      0.994      0.913      0.986      0.983      0.994      0.894\n",
      "Speed: 0.8ms preprocess, 29.4ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 251 images, 0 backgrounds, 0 corrupt: 100%|██████████| 251/251 [00:00<00:00, 1030.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.23G     0.5331      1.126      2.983     0.9184         19        640: 100%|██████████| 16/16 [00:11<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.959      0.935      0.983      0.903      0.955      0.931       0.98      0.877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       8.8G     0.4413     0.6977     0.8652     0.8621         20        640: 100%|██████████| 16/16 [00:09<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.979      0.974      0.993       0.91      0.975       0.97      0.992      0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.52G     0.4582     0.6286     0.6209       0.86         13        640: 100%|██████████| 16/16 [00:09<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.973      0.977      0.989      0.897      0.973      0.977      0.989      0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.54G     0.4287     0.5757     0.4716     0.8584         21        640: 100%|██████████| 16/16 [00:09<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.989      0.981      0.994      0.889      0.985      0.975      0.992      0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5       8.5G     0.4438     0.5456     0.4203     0.8667         15        640: 100%|██████████| 16/16 [00:09<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.998      0.984      0.995      0.917      0.998      0.984      0.995      0.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.033 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.998      0.984      0.995      0.916      0.998      0.984      0.995      0.904\n",
      "                  card        474        474      0.998      0.984      0.995      0.916      0.998      0.984      0.995      0.904\n",
      "Speed: 1.2ms preprocess, 13.3ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▇▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▇▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▄▆▃▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▅▃▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▅▃▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▄▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▂▃▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▁▁▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▂▅█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▁▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▃▁█▇▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.02264\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00164\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00164\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99477\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99477\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91643\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.90395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.99786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.99786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.98372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.44382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.42026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.86674\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.54561\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.39622\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.3791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.84047\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.60645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_035232-pzxrqdxk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_035232-pzxrqdxk/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.989      0.985      0.995      0.914      0.989      0.985      0.995      0.898\n",
      "                  card        476        476      0.989      0.985      0.995      0.914      0.989      0.985      0.995      0.898\n",
      "Speed: 0.9ms preprocess, 29.5ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.06788134644034449\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_38/train/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<00:00, 321.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_38/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.73G     0.5959     0.8601     0.4703     0.8857          5        640: 100%|██████████| 4/4 [00:03<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.991      0.985      0.995      0.914       0.99      0.983      0.995      0.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      7.82G     0.4408     0.7035     0.4171      0.875          2        640: 100%|██████████| 4/4 [00:02<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.991      0.987      0.995      0.916      0.996      0.981      0.995      0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.89G       0.49     0.6451     0.4634     0.8676          2        640: 100%|██████████| 4/4 [00:02<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.994      0.981      0.995      0.915      0.994      0.981      0.995      0.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.08G     0.2864     0.3782     0.9377     0.6447          0        640: 100%|██████████| 4/4 [00:02<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.989      0.985      0.995      0.916      0.995      0.977      0.994      0.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.06G     0.3672     0.4534     0.3581     0.7947          3        640: 100%|██████████| 4/4 [00:01<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.987      0.987      0.995      0.917      0.991      0.979      0.994      0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.987      0.987      0.995      0.917      0.992      0.979      0.994      0.905\n",
      "                  card        474        474      0.987      0.987      0.995      0.917      0.992      0.979      0.994      0.905\n",
      "Speed: 0.9ms preprocess, 13.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▃▄█▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▆▆█▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▅▅▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁█▆▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▄▅█▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁█▆█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▆█▁▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▆▆▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄▆▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▂▂▂█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ██▇▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▅▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▆▁▅▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▅▁▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▃▁▂██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99446\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.90543\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.98733\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.99176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98678\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.9789\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.36722\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.35808\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.79465\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.45344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.38942\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.29982\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.84324\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.62042\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_035816-m89bgpqu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_035816-m89bgpqu/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.989      0.987      0.995      0.917      0.989      0.987      0.995      0.896\n",
      "                  card        476        476      0.989      0.987      0.995      0.917      0.989      0.987      0.995      0.896\n",
      "Speed: 0.6ms preprocess, 29.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 301 images, 0 backgrounds, 0 corrupt: 100%|██████████| 301/301 [00:00<00:00, 924.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.52G     0.5368      1.083      2.821     0.8989         28        640: 100%|██████████| 19/19 [00:13<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.961      0.966       0.99      0.908      0.957      0.962      0.987      0.885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5       8.8G     0.4312     0.6904     0.7957     0.8652         10        640: 100%|██████████| 19/19 [00:11<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.968      0.983      0.993       0.91      0.969      0.978      0.993       0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.36G     0.4473     0.6223      0.604     0.8561         21        640: 100%|██████████| 19/19 [00:11<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.977      0.973      0.992      0.905      0.977      0.973      0.992      0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.36G     0.4527     0.6047     0.4474     0.8581         28        640: 100%|██████████| 19/19 [00:11<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.984      0.985      0.994      0.914      0.984      0.985      0.994      0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.39G     0.4527     0.6065     0.3661     0.8697         25        640: 100%|██████████| 19/19 [00:11<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.997      0.981      0.995      0.914      0.997      0.981      0.995      0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.035 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.997      0.981      0.995      0.914      0.997      0.981      0.995      0.899\n",
      "                  card        474        474      0.997      0.981      0.995      0.914      0.997      0.981      0.995      0.899\n",
      "Speed: 1.0ms preprocess, 13.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▆▄██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▇▅██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▃▅▁█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▁▄▁▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▂▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▇▃█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▆▄█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▁▂▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▂▁▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁███▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁█▅▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▇█▃▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.89891\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.99682\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.99682\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.98101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.45274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.36607\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.86966\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.60652\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.38016\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.26481\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.84053\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.59344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_040115-fbfj96oa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_040115-fbfj96oa/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.991      0.992      0.995      0.915      0.989      0.987      0.995      0.892\n",
      "                  card        476        476      0.991      0.992      0.995      0.915      0.989      0.987      0.995      0.892\n",
      "Speed: 1.1ms preprocess, 29.2ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.0037010873331250194\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_39/train/labels... 100 images, 0 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:00<00:00, 436.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_39/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.01G     0.5102     0.6907     0.4564     0.8939          5        640: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.994      0.983      0.994      0.914      0.994      0.983      0.994      0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.22G     0.4758     0.7051     0.3752     0.8526          7        640: 100%|██████████| 7/7 [00:04<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.998      0.989      0.995      0.919      0.998      0.989      0.995      0.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.76G     0.4497     0.6342      0.347     0.8616          9        640: 100%|██████████| 7/7 [00:03<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.987      0.992      0.995      0.921      0.987      0.992      0.995      0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      8.07G     0.4517     0.6288      0.371     0.8823         10        640: 100%|██████████| 7/7 [00:03<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474       0.99      0.992      0.995      0.923       0.99      0.992      0.995        0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.08G     0.4483     0.6449     0.3378     0.8657          7        640: 100%|██████████| 7/7 [00:03<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.994      0.989      0.995      0.925      0.994      0.989      0.995      0.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.994      0.989      0.995      0.923      0.994      0.989      0.995      0.904\n",
      "                  card        474        474      0.994      0.989      0.995      0.923      0.994      0.989      0.995      0.904\n",
      "Speed: 1.2ms preprocess, 13.2ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▆██▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▆██▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▅▆██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▄█▁▃▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▅█▁▃▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▅█▁▃▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅█▇▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅█▇▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▄▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▃▂▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▁▃▆▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss ▇█▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▄▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▃▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss █▁▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99479\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99479\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.92305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.90369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.99364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.99364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.98932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 12.984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.44834\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.33784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.86574\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.64487\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.36058\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.22376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.55988\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_040707-34zi0l7o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_040707-34zi0l7o/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.986      0.994      0.994      0.924      0.986      0.994      0.994      0.901\n",
      "                  card        476        476      0.986      0.994      0.994      0.924      0.986      0.994      0.994      0.901\n",
      "Speed: 0.8ms preprocess, 29.4ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = 0.09482318735246631\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=./runs/segment/train/weights/last.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/temp_0_40/train/labels... 100 images, 0 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:00<00:00, 452.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/temp_0_40/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      7.94G     0.4456     0.6419     0.3257     0.8852          8        640: 100%|██████████| 7/7 [00:05<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.994      0.984      0.995      0.923      0.994      0.984      0.995      0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.22G     0.4292     0.5949     0.3347     0.8547         10        640: 100%|██████████| 7/7 [00:04<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.993      0.987      0.995      0.927      0.993      0.987      0.995       0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.08G     0.4075     0.5099     0.3444     0.8406          6        640: 100%|██████████| 7/7 [00:03<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.995      0.987      0.995      0.923      0.995      0.987      0.995      0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      7.76G     0.4016     0.5107     0.3184     0.8475         10        640: 100%|██████████| 7/7 [00:03<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.993      0.989      0.995      0.923      0.993      0.989      0.995      0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      7.78G     0.3949     0.4908      0.306     0.8565          6        640: 100%|██████████| 7/7 [00:03<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.992      0.994      0.995       0.92      0.992      0.994      0.995      0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 55.0MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.993      0.987      0.995      0.927      0.993      0.987      0.995       0.91\n",
      "                  card        474        474      0.993      0.987      0.995      0.927      0.993      0.987      0.995       0.91\n",
      "Speed: 1.0ms preprocess, 13.4ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▁▁█▇▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▂█▁▂█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▃█▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▄▁█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▄▁█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▅▅█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) ▁▅▅█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▆▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ▅▆█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▃▁▂▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▆▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▃▅█▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▆█▆▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▄█▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▃▄█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.06671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99477\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99477\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.92678\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.91022\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.99254\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.99254\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.98734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.014\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.39491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.30597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.85648\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.49083\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.35583\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.21428\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.83383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.56102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_041115-owxkq1tv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_041115-owxkq1tv/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:20<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.985      0.988      0.995      0.921      0.985      0.988      0.995      0.901\n",
      "                  card        476        476      0.985      0.988      0.995      0.921      0.985      0.988      0.995      0.901\n",
      "Speed: 0.8ms preprocess, 29.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.0.220 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/kaggle/working/yolov8m-seg.pt, data=/kaggle/working/feet-14/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/feet-14/retrain/train/labels... 501 images, 0 backgrounds, 0 corrupt: 100%|██████████| 501/501 [00:00<00:00, 983.92it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/feet-14/retrain/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/valid_0/labels.cache... 474 images, 0 backgrounds, 0 corrupt: 100%|██████████| 474/474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      8.04G     0.5005      0.893      1.938     0.8917          5        640: 100%|██████████| 32/32 [00:21<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.967      0.994      0.994      0.909      0.967      0.994      0.994      0.885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      8.36G     0.4584     0.6219     0.6823     0.8675         11        640: 100%|██████████| 32/32 [00:19<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.993      0.985      0.994      0.903      0.993      0.985      0.994      0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      8.38G     0.4797     0.6125     0.5116     0.8666          8        640: 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.977      0.979      0.992      0.892      0.977      0.979      0.992      0.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5       8.3G     0.4831      0.605     0.4469     0.8768          8        640: 100%|██████████| 32/32 [00:19<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.992      0.985      0.994      0.903      0.992      0.985      0.994      0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      8.34G     0.4961     0.6193     0.4048     0.8684          8        640: 100%|██████████| 32/32 [00:19<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.968      0.964      0.984      0.894      0.968      0.964      0.984      0.879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.045 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 55.0MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 55.0MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:13<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        474        474      0.967      0.994      0.994      0.913      0.967      0.994      0.994      0.888\n",
      "                  card        474        474      0.967      0.994      0.994      0.913      0.967      0.994      0.994      0.888\n",
      "Speed: 0.9ms preprocess, 13.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 █▅▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▁▆█▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▇█▁▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) ▇█▁▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▇▅▁▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) ▄▅▁█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁█▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) ▁█▄█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▄▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) █▄▁▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▁▅▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▁▁▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss █▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▆▇█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▃▆▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▆█▅▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss ▄▃█▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(M) 0.99387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.91281\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(M) 0.88834\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.96673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(M) 0.96673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.99367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(M) 0.99367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 110.395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 27240806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.49609\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.40476\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.86839\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/seg_loss 0.61929\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.42817\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.35562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.85563\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/seg_loss 0.62093\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/feet-14/wandb/offline-run-20231129_041421-526xk611\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20231129_041421-526xk611/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.219 🚀 Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/feet-14/test_0/labels.cache... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:21<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        476        476      0.979      0.977      0.994       0.91      0.979      0.977      0.994      0.885\n",
      "                  card        476        476      0.979      0.977      0.994       0.91      0.979      0.977      0.994      0.885\n",
      "Speed: 1.3ms preprocess, 29.6ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "Progress for 10 last iterations with 0.001 threshold = -0.0860474428432535\n",
      "Итоговый результат (инкрементальное обучение) для класса 0: \n",
      " defaultdict(<class 'list'>, {0: [0.015815162877214805, 0.01818747528131884, 0.01734335677234252], 1: [0.01564110294934346, 0.017984665188100622, 0.016922032079608337], 2: [0.012465429358120181, 0.01409140282837472, 0.013741589979808505], 3: [0.013895680687916393, 0.015977440493523787, 0.015171221516016919], 4: [0.012646140483052248, 0.014263466515736274, 0.013983099254839185], 5: [0.01201253142841285, 0.013503631186345975, 0.013267409687531508], 6: [0.012239343566699347, 0.013779769249156972, 0.0134916109426336], 7: [0.06790869600984545, 0.07728722727557216, 0.07508432170640249], 8: [0.1800284511591605, 0.2029191484256206, 0.20067311496513274], 9: [0.11666968102002193, 0.13087965358054834, 0.12967963640165714], 10: [0.1547917889887917, 0.17355555117209215, 0.17223817853291762], 11: [0.22047541385376784, 0.2479734238362083, 0.24471843525879036], 12: [0.8548004194320942, 0.9635161055084538, 0.9590088767313897], 13: [0.8450845624965441, 0.9541906100272417, 0.9513773193236803], 14: [0.8435176362903221, 0.9536549740639683, 0.9486772291647333], 15: [0.8743991508574599, 0.9809989314789512, 0.9807992047642001], 16: [0.8689679665507288, 0.9763623994849528, 0.9709563673929477], 17: [0.8697194149283687, 0.9804770911707404, 0.9788222971120802], 18: [0.8773649249744979, 0.9875071423280588, 0.9873117633223032], 19: [0.880974866667011, 0.9887338590883471, 0.9887338590883471], 20: [0.8819362520689669, 0.988868512507519, 0.9888673380032953], 21: [0.8812351810362289, 0.9900791634935769, 0.9880869667517523], 22: [0.883044820250744, 0.9916972047538002, 0.9911664456524277], 23: [0.8823778783313742, 0.9902841717310955, 0.9902841717310955], 24: [0.8870113172307559, 0.9910309691056267, 0.9910309691056267], 25: [0.8898618433171677, 0.9935017809263076, 0.9935017809263076], 26: [0.8891807555585128, 0.9916332626270483, 0.9915350144837103], 27: [0.8928480002210776, 0.9941552474347204, 0.9941552474347204], 28: [0.8881350087225369, 0.99431316676385, 0.99431316676385], 29: [0.8899043740935364, 0.9945106992926571, 0.9945106992926571], 30: [0.8927670948451819, 0.992417175732515, 0.992417175732515], 31: [0.8881499734697991, 0.9942352626417075, 0.9938771053821417], 32: [0.8904882419039598, 0.9943577154742818, 0.9941914353799635], 33: [0.8966457692694737, 0.9935241705063165, 0.9933290862284093], 34: [0.8909063154655991, 0.9946842071512997, 0.9946842071512997], 35: [0.8917182807932716, 0.9941825628990516, 0.9941438065598937], 36: [0.8978625160783293, 0.9945429396786964, 0.9945429396786964], 37: [0.892312666219589, 0.9946809015654325, 0.9946809015654325], 38: [0.9013713428213743, 0.994213475975633, 0.994213475975633], 39: [0.8846079132116861, 0.9937955163033334, 0.9937752323276743]})\n",
      "Количество данных (train) для класса 0: [2, 4, 6, 8, 10, 13, 16, 19, 22, 25, 28, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 201, 251, 301, 401, 501, 1001, 1501, 2001, 2501, 3001, 3501, 3798]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWXklEQVR4nO3deVwU9f8H8Nfs7MGNIAgoKB55pYInoWYXRenX1FIpLY0007RDyvLIq76plZUdlh0e9S3T6pd2aGp5VB5pHmRZaZqBpoAnyL3H5/fHsAMDuyiK7OHr+XjsA3bmM7PvnQU+bz7XSEIIASIiIiIvoXN1AERERES1ickNEREReRUmN0RERORVmNwQERGRV2FyQ0RERF6FyQ0RERF5FSY3RERE5FX0rg6grtlsNhw7dgyBgYGQJMnV4RAREdEFEELg3LlzaNiwIXS66ttmrrjk5tixY4iJiXF1GERERHQRjhw5gujo6GrLXHHJTWBgIADl4gQFBbk4GiIiIroQeXl5iImJUevx6lxxyY29KyooKIjJDRERkYe5kCElHFBMREREXoXJDREREXkVJjdERETkVZjcEBERkVdhckNERERehckNEREReRUmN0RERORVmNwQERGRV3FpcvPDDz+gb9++aNiwISRJwsqVK897zKZNm9CpUyeYTCa0aNECS5YsuexxEhERkedwaXJTUFCAuLg4zJ8//4LKHz58GH369MENN9yA9PR0PPbYYxg5ciTWrl17mSMld3DgADBnDvD008CHHwJFRTU/h9kMfPIJMGAA0KsXMHIksH27tkxxMbBkCZCUBMTFAXfcAaxZAwhRXubcOeD114HOnYGYGODaa4EPPgBKS6u+5unTSuxnzzqO6ZdfgMcfB4YMUb7u3avdb7MB69YBd90F9OgBDBwIfPklYLVqyxUVAcuWAS+8ACxeXPX1iouBt95S3lNwMNC0KTBjBpCToy23YwfwwAPAddcp7/2zz5Tr5q6EAL77DujfH4iOBpo3ByZMAP75x9WRVW/rViAlBQgLA+rXBwYNAjZvdnVU3qfUWoqlvy5Fn6V9cM1712DYimH4IeMHiIq/0FQrTpwAXnpJ+bv62GPADz9o/27WKeEmAIgVK1ZUW+bJJ58UV199tWZbSkqKSE5OvuDXyc3NFQBEbm7uxYRJteD334V47DEhbrlFiDvvFOLjj4U4ckSIJUuEmD9fiE2bhMjIEGL6dGX/3XcL0bOnEIAQsiyEwaB8HxwsRMUfmdOnhXjxRSE6dhQiNlaI3r2F+PJLIaxWZX9OjhDt2yvH6nTKV71e+Tp6tFIuK0uItm0dl7nzTiFKS4U4dkyIFi2EkCTlUbFsz55C5Ocrr7dnjxB9+pSXkWUhBg4U4s8/lf1msxCpqeWvodOVv1ZqqrK/uFiIvn21cciy8rVXLyHOnVPOtWSJEEFB5fslSQiTSYhnnxXCZlPKJSRoY7aXjYgQ4sAB5f2PGeP4teLilOvnbmw2IcaP18Zsj9vXV4iNG10doWOvv141Zvv38+a5OjrvkZOfI9q92U5gBoRupk5gBoT+Gb3ADIj7Vt4nLFaLq0P0GgsXKn+b7X/H7D/PPXsKcepU7bxGTepvSQj3SF8lScKKFSvQv39/p2V69eqFTp06Yd68eeq2xYsX47HHHkNubq7DY0pKSlBSUqI+t994Kzc3l/eWqiGbDdi4ETh4EKhXD2jTRmnhWLECKCkBOnYEWrZUsvUDB4DAQODuu5VtW7cqLQunTgEbNgB6PWCxAJKkzewrPtfpyr939FMqScpj40YgKkppacjOVuIEAFlWWjdSUoCPPlJaYn78sWqLh93LLwNffaXE76iMJAFTpgBbtijnsViqltHpgAcfBO69F7jxRqXFo+K5ZBnw81PO8dFHSiuLs/f21FNKa8trr5W/p4pkWbm+t98ODB7s+D0BwKxZwNGjwNtvO35fej1w9dXAsGFKy5Ejer3SOrVhg/PXcYXly5UWLUd0OsDfHzhyRGmpchd79gCdOlVfZudOpVWQLs2N79+IHzN+hEVU/WWVIGHWTbMwsedEF0TmXdasAW67zfE+WQZ69lT+Tl/ALaGqlZeXh+Dg4Auqvz0quWnZsiVSU1MxadIkddvq1avRp08fFBYWwtfXt8oxM2bMwMyZM6tsZ3JTM999pzQ1ZmRot+t0jiveymRZKVfbP22yrFS6WVnAX385T0rGjVO6kaoTFgacPOlojwAk5WtAIJBfIJRfUkkoD0gQpTLKCsFkUrpHDh92npR07qx0PxUXO4/Hx0e5XhVy8yp0OqBRI6UCd8bXVzlPcTEAnQ06owWSwQoICcImQVh1gE1CSLAOp09K6vtwJD1d6da6FEKI8qTV/lzdBwgIzc9J5W0Vj0lKAnbvBoQNZZ+FlqQDZs8GRowof21NLJq4KsWJKhsu+tiK+ydMAP7v/xwnx4CSSA4YoCTbgFIJA9qKQar0TeUyFT9B+00GJfW59piKhSsf7+xYZ3E5PH9Nz3upNWCZvdl7Ebeg+h/WML8wHEs7BoNsqJXXvFL17Als21Z9XfDTT0BCwqW9DpObCthy45jNBhw6pPyBbdZMqZCd2bpVaRWx2S4skaltkt4KQ3gejA2UhxxYDFuxAbZiI6xFBtiKjGUPA6xFRtiKDRAWGbJ/CeSAYsj+JfANLYHNVAydfwlk/2LIASWQfUvLEhSoFWN50gIAAtIFjkoTVgnWQqMai/17a5ERtkIjbCV6SHordCYLdCYLJKPyVWc0QzLZv7cAOgFJEoBOSZwkCeXf6wQAAWHVQVhkCIsOwipDmMu+Wsq2WyVIBit0RquSyBgt5V8N5/8AhVVJemCr9OYlAaMRMBq1CYf6B6SaJARwYd87eTRniZF2m/15eWGrzQKzreJgsco/gMpzP4Mf5LJf9MpJV8UnDl+/BrGh2mSv4sudP1GtfB5teefJ8IW8P0flqovPagX27SvbKcoLluYE4tTqeABKwp6WBjz/PC5JTZIb/aW9VN2KjIxEdna2Zlt2djaCgoIcJjYAYDKZYKqu5r7CCAG8+abSHZKZqWwLDgbGjAGmT1daC+z27gW++UYZhFptYiMrlXblStlmlmEr0QNWWSknCRjC8+ATfRqm6DMwRZ0FAFiLDWXJipKU6IwW6Exllb6PGfqgogtOMlxFkgX0gSVAYDXNLLXGCuDSRvgKa9kfKNlBa4csyrZX/cAtACwOBk17iyqtEFX2S073Vz3W8clKS+yjbJy/viSVJZFlFbCmJcv+tWyjtyePFZNlzQbHpSt8r4MO5//bX2wWUH6n6GIZG1TdZrOU/9GWJKCwsA4DgoclN4mJiVi9erVm27fffovExEQXReR50tKACkOWAAC5uUqys22bMisnP18Zx/Dtt1W7neTAIgR1OQx9SAHkwGLoA4sh+1df2wmLDrZiAySDBTpT1T8iepx/2pM134TSnCCU5gTBctZXaenwLYXO1wy9Xyl0vqWQfMyQfUuh8zFDkgWsRQZY802wFvjAeq7sa74J1vyyr0VGwCYp3TMC8DFJStdN2X8fyjB3qeyhfG8yAcXF5c+FUH5xlVhKIfuVwhhYCmEse+5bCp1fKXQmC4RZhq3EAFuJHqJUD1uJHrayr6JED5tZD9jKWk3Kuox0kgSbtXwbBCDJNkh6GyS9VfkqWyEZKn61wWaWldcoVb6aZD0Kzpa9bqm+QquMkpBKsg2+fgLFZpvSQqSzlSc+FeqL99+XcG3P8ufKuCdJ8x+eBEn7X6ek/W9PguNjIOG8ZSr/p5p0k4Rt28q6I0XZi1Uaw/XWW8CoURW31U63x8V64gnld9DZ2C+9XulGfeXFS38tNQGq9FFWToy0ZaomVJWfVy5zIeeFk/NryzpO2ASqFnZWxv78pyM/YfBnKdo3Yf85LPvqa/DF9pE74G/wr1EiqS1X3XGV4q+4rZp9jp5fzHVzFJ/Dz7zCAdXFXvljEAKwWIGBdwIFhdrgbSXl6YXFArRrhzrl0m6p/Px8HDx4EADQsWNHvPzyy7jhhhsQGhqKxo0bY9KkSfj333/xwQcfAFCmgrdr1w5jx47F/fffjw0bNuCRRx7BqlWrkJycfEGvWZNmLW+zcyfQtavz/ZIEzJ+vTCPevbvyH1+BgPhMhFz/J3Qmx4MFhA1qMiAEHHaB2Er0KPk3BMVHQ1Dyb4jSUuNjhuxjVpISvbWs0jeolb75rB9sBT5VXxDK+JXevZWBwBVjhU5oulUiIpTBpRkZjisVWQYeflgZKPzLL84HC48bB/z5pzKwtroBxUuWVD9VPSwMaNVK6Yd2Fk/37krcK1Y4Hwjcs6cy/Xz7dufjjSIilMr92Wcd/9Mry8BNNykDxN94w3k8sbHKQHGdG7Wiffkl0K+f4306nTLwPTNT+ezdxd9/K9fabK76eUiS8rn+/jvQooVr4vMWQghc/ebVOHDqAKyi6g+1LMkY120c5t06r+6D8zITJwJz5zr/G+Trq4yLDAy8tNepUf1dOxO0Ls7GjRuVQQSVHsOHDxdCCDF8+HBx3XXXVTkmPj5eGI1G0axZM7F48eIaveaVPBX8gQcqTZcNLBSG8Fz1OVA+zbriQx96TkQM2SqaPPW1aPLU1yLyns0iIP4f4dssSxganBU63xIB2KocB8kmdKZSIQcVCEN4rjCE5QlIDspd5EOWhWjSRIjjx4Vo3bp82nLlhyQJMWeOEL/8IkRIiLacfWp0YqIyhfvvv4Vo1Kh8ajdQ/v211wpRUCBEdnb5dPGK07wBIZKShCgqEmLGjOpjf/11If76S4iwMO1nAijPw8KU/SdOKO+tYjz2mBo3FiIzU4hdu5Rpz5Xfv06nPL74QplWPmRI+fkrvq+4OCFOnlTe/zXXOJ4uHhKiXD93NHOm9n3Z31tQkBA//eTq6Bz76itlqn7Fz0yWhTAalc+LasfvOb+LsBfChDxTFpgBgRkQ0gxJSDMk0f297iK/JN/VIXqFvDzl70jlv1OyrGz79NPaeZ2a1N8uTW5c4UpObq69tkKlrreIRg99K5o89bUIvflXAdlStRKWLSI48YBo/Phq0eSpr0XM+G9EYKe/azVBudBH5V8ak0mI++9X1qURQlmnJSpKW85ecaSkCGEpW87iyBEhJkwQIjJSSQiuvlpJNIqKyq/TqVNCzJ4tRKtWSpLRrZsQixYJUVJSXqawUIj33lOuacuWypo9n36qJBFCKGvGTJhQnmBUXP/hv/9V1mexxzNunBD+/kqs/v7K8yNHyl8rL0+IuXOV1wkIEKJpU+UcFdeO2L1biBtu0F6jjh2FWLeuvIzNJsT69cq6Qd26KWvwfPyx9n0VFQnx2mtK8ubjo1ynCROUJMqd7dghxH33KZ9n587K9bH/bLiro0eFmDZNWQekRw8hpk7Vfu5UO46fOy6eXv+0aPxKYxE4K1DEvRUn3vr5LVFsLnZ1aF4lL0+Ip58Won798n/8brtNiB9/rL3X8Mh1burKldwt1a8f8PXXyhga/6uPIuw/v6j7SrODcOKLTrCcUdrvfZtlIyTpdxhClFFgRX+H49TadrDm+Tk9v32NGvs4ncpr2FTk7690p/j6Au3bK109p06V72/bVhn7k5kJGAzK1NgJE4DwcGV14MaNgcof35kzwKJFyvoxZ88qTf8PPgj85z+u60o5ehT4+GNl/Z3oaGUV4gaOBt/ZlAF3fn6XFmtGhjItPDxc6fYiIqpLVqvyt9jPT3nUJo+cCl5XruTkZulSYOhQ5fvIe7bA1OgsCvZHwifmNGS/UthKZJz5vjV8m56A31XKmvyWcyac2dgGhX80ROW5I5GRypiPzExlfEm3bsqU8U2bgD/+AEJClPVcfvkFWLVK+aFv3lwZ2/LQQ0rSYmc2K8v+FxQArVsryQugjGuR5aozUYiI6MrC5KYa3pTcCKEMSF28WPlvPSKifGVcR8lASYmyMurhs7locO9mCKuEo2/eBEknENZ3D3wany4/t1VC3s6myN16FURp+ah3SQJSU5VF0RISlMTjQthsSqJiNF7quyYioisRk5tqeEtyY7EA992ndMHYb2Vgv93ArbcCn3+udPlUlpUF3PDkXhQ1PILCP6Nw4ouydeAlG4J7/oXghEMoPlIfp79rC8sp7dB2WVZWp/3xx9pvbiQiIqpOTepvN5rUSTUxbZrSzQSUT0m2T8Nbu1ZpWcnJqTrmxa+eGWhyDABwe9sm5V1DQofcH1sh85Vk5CxPqJLY+PkpXUmbNjGxISIi98bkxgPl5ys3U3TW5iaEMog1IgJo2hR49VUl0fn1V2DJxn9RZLbiqgYBePe5UIwbV2kAq7W8n0mWlfEvu3YpA2Jfe+3S1ykgIiK63JjceKBt25SBt3bGyLOISv0B9a7dD8mgXVkuIwN47DEl0enQQWDO/2UAALo3aAJJkvDcc8qNJwFtkqPTKcesWqWM0wkIuMxvioiIqJYwufFApZXuduDbIgfGBucQ3P0gGj6wCf5tjwJVbhIHmGJOwxiWD5tZxuwHG2HdOmVczrp1yqDkrl2VKcStWwPPPafcW6pZs7p5T0RERLXFo+4tRYr4eO0aMpKu/DYH+sAShPX9BYGdMnD2x1bqLQ4AILCj0mpTsK8hLEUGpKYq07iNRmVw8n331e37ICIiuhyY3HigRo2UBfm++qpsELFOyXLydsbCmm9CcPeDMDU6i4i7tkPYJJhPBqA0Kxh+LbMAAOf2NIEQwLFjSqvNbbe58M0QERHVMnZLeagFC5QbGep0yl2iAUCYZeRtb4Fj716Pc7/EwJJvgqQTMDY4h4AORyHJAiXH6sGcEwxAObbsvqVERERegy03HioiAvj5Z+D114H39igtN8KmrNxnzffB6TUdAAjIASUwRp6FKSoX+nqFyPu5qXoOmw0IDnZF9ERERJcPkxsPFhKirHdT9LnAxzuAQH8d8uWKt52XYM33QdHBSBQdjKxyvNGo3HeJiIjIm7BbygtYrEq31AMjJDRpomwzGKq/NYIkAY8/DoSG1kGAREREdYgtN17AYlO6paIidDhwQLnz93ffKS04BQXA8uXK9HG9vrxVZ/x44L//dWHQRERElwmTGy9gT25knQRZVmZS9etXvv/VV4FPPlEW9AsLA1JSgIYNXRQsERHRZcbkxgvYu6UMsoNbgQOoVw8YNaoOAyIiInIhjrnxAmar0nKjl/lxEhERsTb0Ahab0nIj6xy33BAREV1JmNx4AWvZmBtn3VJERERXEiY3XsBcNuZGr+PHSURExNrQC1isbLkhIiKyY3LjBczqVHB+nERERKwNvYC1bECxni03RERETG68gdotxZYbIiIiJjfeQB1QzJYbIiIiJjfewH77BT3XuSEiImJy4w0sXKGYiIhIxdrQC9hXKGbLDREREZMbr1DecsPkhoiIiMmNFygfc8OPk4iIiLWhF7CUzZbiCsVERERMbryCfYViDigmIiJicuMVLFYOKCYiIrJjcuPhbDaBsoYbJjdERERgcuPx7IOJAXZLERERAUxuPJ59jRuAA4qJiIgAJjcez2wtb7mR2S1FRETE5MbTWSt0S/Gu4ERERExuPJ59ppROAnRsuSEiImJy4+nMXJ2YiIhIgzWih7PyvlJEREQaTG48nJl3BCciItJgcuPh7HcEN3CNGyIiIgBMbjyeuWxAMaeBExERKZjceDj7VHC23BARESlYI3o4+wrFHFBMRESkYHLj4ewrFHNAMRERkYLJjYezWLnODRERUUWsET0cu6WIiIi0mNx4OLXlhgOKiYiIADC58XgWLuJHRESkweTGw1lsHFBMRERUEZMbD8cViomIiLRYI3o4+wrFHFBMRESkYHLj4dgtRUREpMXkxsOVJzf8KImIiAAmNx7Pwm4pIiIiDZcnN/Pnz0dsbCx8fHyQkJCAHTt2VFt+3rx5aNWqFXx9fRETE4Px48ejuLi4jqJ1PxxQTEREpOXSGnH58uVIS0vD9OnTsXv3bsTFxSE5ORk5OTkOyy9duhQTJ07E9OnT8ccff2DhwoVYvnw5Jk+eXMeRuw9z2To3MsfcEBERAXBxcvPyyy/jgQceQGpqKtq2bYsFCxbAz88PixYtclh+69at6NGjB4YMGYLY2FjccsstuPvuu8/b2uPNrGrLDZMbIiIiwIXJTWlpKXbt2oWkpKTyYHQ6JCUlYdu2bQ6P6d69O3bt2qUmM3///TdWr16N3r17O32dkpIS5OXlaR7exMwBxURERBp6V73wyZMnYbVaERERodkeERGBP//80+ExQ4YMwcmTJ9GzZ08IIWCxWDB69Ohqu6Vmz56NmTNn1mrs7sQ+oJjdUkRERAqP+nd/06ZNmDVrFt58803s3r0bn3/+OVatWoVnn33W6TGTJk1Cbm6u+jhy5EgdRnz5WW3sliIiIqrIZS03YWFhkGUZ2dnZmu3Z2dmIjIx0eMzUqVNx7733YuTIkQCA9u3bo6CgAKNGjcKUKVOgc9A1YzKZYDKZav8NuAkz7wpORESk4bIa0Wg0onPnzli/fr26zWazYf369UhMTHR4TGFhYZUERpZlAIAQ4vIF68bsdwU3sFuKiIgIgAtbbgAgLS0Nw4cPR5cuXdCtWzfMmzcPBQUFSE1NBQAMGzYMjRo1wuzZswEAffv2xcsvv4yOHTsiISEBBw8exNSpU9G3b181ybnS2FtuZA4oJiIiAuDi5CYlJQUnTpzAtGnTkJWVhfj4eKxZs0YdZJyZmalpqXn66achSRKefvpp/PvvvwgPD0ffvn3x3HPPueotuJzVxhWKiYiIKpLEFdafk5eXh+DgYOTm5iIoKMjV4VyytOXp+HzPv5jcuzVG9Wru6nCIiIgui5rU3+zL8HBc54aIiEiLNaKH440ziYiItJjceDgLW26IiIg0WCN6OLbcEBERaTG58XDlLTdMboiIiAAmNx7PwhWKiYiINFgjejiuUExERKTF5MbD8d5SREREWqwRPZy95YZjboiIiBRMbjxc+ZgbJjdEREQAkxuPx3VuiIiItFgjejj7OjcGttwQEREBYHLj8ewDimWOuSEiIgLA5MbjWcu6pQycLUVERASAyY3HU2dLsVuKiIgIAJMbj6euc8MBxURERACY3Hg8K+8tRUREpMHkxsOZeVdwIiIiDSY3Hs7CAcVEREQarBE9mBBC7ZbiVHAiIiIFkxsPZm+1AQADBxQTEREBYHLj0ez3lQI45oaIiMiOyY0HM5etcQMwuSEiIrJjcuPBNC037JYiIiICwOTGo9lXJ5YkDigmIiKyY3LjwewtNxxMTEREVI61ogezJzccb0NERFSOyY0Hs3dLsUuKiIioHJMbD8bViYmIiKpirejB1PtKseWGiIhIxeTGg6ljbpjcEBERqZjceDB7t5Se3VJEREQq1ooezGLvluJsKSIiIhWTGw+mDijmOjdEREQq1ooezD6gmFPBiYiIyjG58WBWdSo4kxsiIiI7JjcezGzlgGIiIqLKWCt6MPsKxZwKTkREVI7JjQez2nhvKSIiosqY3HgwtVuKs6WIiIhUrBU9mH2dGw4oJiIiKsfkxoOZy7qlOBWciIioHJMbD2ZVVyjmx0hERGTHWtGDla9QzJYbIiIiOyY3Hozr3BAREVXFWtGDqTfOZMsNERGRismNB7NwnRsiIqIqmNx4sPIVivkxEhER2bFW9GAWK2+cSUREVBmTGw9mUde54cdIRERkx1rRg3GFYiIioqqY3Hgw+wrFHHNDRERUjrWiB1OngrPlhoiISMXkxoOpU8G5zg0REZGKyY0Hs3CFYiIioipYK3ow+zo3HFBMRERUjsmNB7PfW0pmtxQREZHK5cnN/PnzERsbCx8fHyQkJGDHjh3Vlj979izGjh2LqKgomEwmtGzZEqtXr66jaN2LVb0ruMs/RiIiIrehd+WLL1++HGlpaViwYAESEhIwb948JCcnY//+/WjQoEGV8qWlpbj55pvRoEEDfPbZZ2jUqBEyMjJQr169ug/eDZg5W4qIiKgKlyY3L7/8Mh544AGkpqYCABYsWIBVq1Zh0aJFmDhxYpXyixYtwunTp7F161YYDAYAQGxsbF2G7FY4oJiIiKgql9WKpaWl2LVrF5KSksqD0emQlJSEbdu2OTzmyy+/RGJiIsaOHYuIiAi0a9cOs2bNgtVqdfo6JSUlyMvL0zy8hZVTwYmIiKpwWXJz8uRJWK1WREREaLZHREQgKyvL4TF///03PvvsM1itVqxevRpTp07FSy+9hP/+979OX2f27NkIDg5WHzExMbX6PlzJrN4VnMkNERGRnUf1Z9hsNjRo0ADvvPMOOnfujJSUFEyZMgULFixwesykSZOQm5urPo4cOVKHEV9e5XcF96iPkYiI6LJy2ZibsLAwyLKM7Oxszfbs7GxERkY6PCYqKgoGgwGyLKvb2rRpg6ysLJSWlsJoNFY5xmQywWQy1W7wbsI+oJhTwYmIiMq57F9+o9GIzp07Y/369eo2m82G9evXIzEx0eExPXr0wMGDB2Er644BgAMHDiAqKsphYuPt1DE3nC1FRESkcml/RlpaGt599128//77+OOPPzBmzBgUFBSos6eGDRuGSZMmqeXHjBmD06dP49FHH8WBAwewatUqzJo1C2PHjnXVW3Ap+72l2C1FRERUzqVTwVNSUnDixAlMmzYNWVlZiI+Px5o1a9RBxpmZmdBVWKAuJiYGa9euxfjx49GhQwc0atQIjz76KJ566ilXvQWXUte5YbcUERGRShJCCFcHUZfy8vIQHByM3NxcBAUFuTqcS3LNrPXIyivGV+N6on10sKvDISIiumxqUn+zP8ODWTjmhoiIqAomNx6MdwUnIiKqismNB1Nvv8AbZxIREalYK3owrnNDRERUFZMbD2blVHAiIqIqWCt6KCEEBxQTERE5cEnr3Bw7dgxvv/02Dh48iKioKIwcORKtW7eurdioGvbEBuA6N0RERBXVqOXGz88PJ06cAAD8/vvvaNu2LZYuXQqz2YxVq1ahc+fO2Lt372UJlLSsFZMbdksRERGpalQrFhcXw77m3+TJk9GrVy/88ccf+OSTT7Bv3z7cfvvtmDJlymUJlLTsg4kBttwQERFVdNHdUrt378ZHH30EvV45hU6nw5NPPok+ffrUWnDknH0aOMABxURERBXVqFaUJAmSpLQS6HQ6BAdrl/yvV68ezpw5U3vRkVPmCndGZ8MNERFRuRolN0IItGzZEqGhoTh27FiV8TUHDx5EZGRkrQZIjpVPAy9POImIiKiG3VKLFy/WPG/RooXm+U8//YQBAwZcelR0XlydmIiIyLEaJTfDhw+vdv/UqVMvKRi6cPYBxVzjhoiISIv/9nsodQE/DrghIiLSqFFyExgYiBEjRmDr1q2XKx66QGq3FGdKERERadSoZiwoKMD27dvRs2dPtGnTBi+99JK6qB/VLUvZbCkDW26IiIg0avxv/4YNG7Bnzx4kJSVh1qxZiI6Oxp133olvvvlGXeCPLj8zW26IiIgcuqiaMS4uDq+//jqOHTuGJUuWIDc3F//5z3/QuHFjTJs2rbZjJAesHHNDRETkUI0X8avIZDLh7rvvxnfffYdDhw7hvvvuw5IlS2ozPnLCwtlSREREDtV4ET9nYmNj8eyzzyIjI+OSg6LzM9u4zg0REZEjNaoZp0+fjoCAgGrLcLXcusGWGyIiIsdqtIjf9OnTL1ccVENc54aIiMixGrXc2Gw2PP/88+jRowe6du2KiRMnoqio6HLFRtXgOjdERESO1ahmfO655zB58mQEBASgUaNGePXVVzF27NjLFRtVQ13nht1SREREGjVKbj744AO8+eabWLt2LVauXImvvvoKH330EWxlFS3VHfs6NzIHFBMREWnUqGbMzMxE79691edJSUmQJAnHjh2r9cCoelauUExERORQjZIbi8UCHx8fzTaDwQCz2VyrQdH5la9QzOSGiIioohrNlhJC4L777oPJZFK3FRcXY/To0fD391e3ff7557UXITlUPhWc3VJEREQV1Si5GT58eJVt99xzT60FQxeOU8GJiIgcq1Fys3jx4ssVB9WQhSsUExEROVRrNaMQAt988w0GDhxYW6ekati7pTgVnIiISOuSk5vDhw9j6tSpaNy4MQYMGIDi4uLaiIvOo3wqOJMbIiKiimrULWVXUlKCzz77DAsXLsTmzZthtVoxd+5cjBgxAkFBQbUdIzlgLeuWMnBAMRERkUaNasZdu3bhoYceQmRkJObNm4f+/fvjyJEj0Ol0SE5OZmJTh8xl69xwQDEREZFWjVpuEhIS8PDDD+Onn35Cq1atLldMdAF4bykiIiLHapTc3HTTTVi4cCFycnJw7733Ijk5GZLElgNXUNe5YcsNERGRRo3+7V+7di327duHVq1aYcyYMYiKisKjjz4KAExy6pg6FZyzpYiIiDRq3KcRExODadOm4fDhw/jf//6HEydOQK/Xo1+/fpg8eTJ27dp1OeKkSuzdUhxQTEREpHVJNePNN9+MpUuX4tixY3jkkUfwzTffoFu3brUVG1WDA4qJiIgcu6ip4IByT6m9e/ciJycHNpsNjRs3xsyZM3Ho0KHajI+csE8F5zo3REREWheV3KxZswbDhg3DyZMnq+yTJAnjx4+/5MCoeuyWIiIicuyiasaHH34YgwYNwvHjx2Gz2TQPq9Va2zGSA2b1ruBsuSEiIqroopKb7OxspKWlISIiorbjoQvEu4ITERE5dlHJzcCBA7Fp06ZaDoVqgncFJyIicuyixty88cYbGDRoEH788Ue0b98eBoNBs/+RRx6pleDIOQu7pYiIiBy6qOTm448/xrp16+Dj44NNmzZpFvCTJInJTR3ggGIiIiLHLiq5mTJlCmbOnImJEydCx24Rl7Cvc8Op4ERERFoXlZmUlpYiJSWFiY0L2de5MbBbioiISOOispPhw4dj+fLltR0L1YDZygHFREREjlxUt5TVasULL7yAtWvXokOHDlUGFL/88su1Ehw5xwHFREREjl1UcvPrr7+iY8eOAIDffvtNs493B68bVk4FJyIicuiikpuNGzfWdhxUQ+qNM9lyQ0REpMF/+z2UOhWcLTdEREQarBk9lH1AMaeCExERaTG58VDWsm4pTgUnIiLSYnLjoezdUnquUExERKTBmtFDqQOK2S1FRESk4RbJzfz58xEbGwsfHx8kJCRgx44dF3TcsmXLIEkS+vfvf3kDdEPlLTdMboiIiCpyeXKzfPlypKWlYfr06di9ezfi4uKQnJyMnJycao/7559/8MQTT+Daa6+to0jdhxACFq5zQ0RE5JDLa8aXX34ZDzzwAFJTU9G2bVssWLAAfn5+WLRokdNjrFYrhg4dipkzZ6JZs2Z1GK17sC/gB3BAMRERUWUuTW5KS0uxa9cuJCUlqdt0Oh2SkpKwbds2p8c988wzaNCgAUaMGHHe1ygpKUFeXp7m4eksFZIbDigmIiLScmnNePLkSVitVkRERGi2R0REICsry+ExmzdvxsKFC/Huu+9e0GvMnj0bwcHB6iMmJuaS43Y1TXLDAcVEREQaHvVv/7lz53Dvvffi3XffRVhY2AUdM2nSJOTm5qqPI0eOXOYoLz/7TTMBJjdERESVXdS9pWpLWFgYZFlGdna2Znt2djYiIyOrlD906BD++ecf9O3bV91ms0+J1uuxf/9+NG/eXHOMyWSCyWS6DNG7jn11YoArFBMREVXm0pYbo9GIzp07Y/369eo2m82G9evXIzExsUr51q1b49dff0V6err6uP3223HDDTcgPT3dK7qcLoSlwho3vAs7ERGRlktbbgAgLS0Nw4cPR5cuXdCtWzfMmzcPBQUFSE1NBQAMGzYMjRo1wuzZs+Hj44N27dppjq9Xrx4AVNnuzbjGDRERkXMuT25SUlJw4sQJTJs2DVlZWYiPj8eaNWvUQcaZmZnQcS0XDfuAYt4RnIiIqCpJCCHOX8x75OXlITg4GLm5uQgKCnJ1OBflr+xzuPmVHxDiZ8Ceabe4OhwiIqLLrib1N//190D2AcUyW26IiIiqYO3ogewrFHN1YiIioqqY3Hgg9Y7gTG6IiIiqYHLjgeyzpTigmIiIqCrWjh7Ivs4NF/AjIiKqismNBypf54YfHxERUWWsHT2QveWGA4qJiIiqYnLjgcqngjO5ISIiqozJjQeycoViIiIip1g7eiCzlVPBiYiInGFy44E4oJiIiMg51o4eyD6gWM8xN0RERFUwufFA9ruCM7khIiKqismNB1JXKGa3FBERURWsHT0QBxQTERE5x+TGA9mngnOdGyIioqqY3HggC9e5ISIicoq1owditxQREZFzTG48EAcUExEROcfa0QNZOOaGiIjIKSY3HsjCbikiIiKnmNx4IA4oJiIico61oweyDyhmtxQREVFVTG48kH2dGwO7pYiIiKpgcuOBzLwrOBERkVOsHT0Q7wpORETkHJMbD8S7ghMRETnH5MYDlU8F58dHRERUGWtHD1S+QjFbboiIiCpjcuOBzGq3FD8+IiKiylg7eiCrjSsUExEROcPkxgOpU8HZckNERFQFa0cPxHtLEREROcfkxgNxKjgREZFzTG48kIUrFBMRETnF2tED2VcoNrDlhoiIqAomNx6ILTdERETOsXb0QPYxNzJbboiIiKpgcuOB7LOluEIxERFRVUxuPBBXKCYiInKOtaOHsVqBklKl5QaCLTdERESVMbnxEDYb8NJLQOPGwNlcpeXmhuskPPccYLG4ODgiIiI3wuTGAwgBpKYCEyYAx44B0CnJzemTOkydCgwapLToEBEREZMbj/Dtt8AHHyhJDgBIstItJWwShABWrgQ+/9x18REREbkTJjceYMECQK+3PxOQZCXLETZlzI0sK2WIiIiIyY1H+OOPCuNqyrqkAABW5eOzWoH9++s+LiIiInfE5MYDhIQAUtnEKNm/BAAgrBJsxQa1TFCQKyIjIiJyP0xuPMDdd5d/LwcWAwCs+T4AlIxHpwPuuccFgREREbkhJjceYPhwIDpaGXejL0tuLOd8ACjjbcLCgAcecGWERERE7oPJjQcICgI2bQJaty5vubHlK8lN06bKvvBw18VHRETkTpjceIhmzYC9e4G7RxQBADq38cHatcpA4jZtXBwcERGRG9Gfvwi5C0kCDEFKy83APr64paeLAyIiInJDbLnxMFm5SnITFezj4kiIiIjcE5MbD3O8LLmJZHJDRETkEJMbD2KzCWTnseWGiIioOkxu3IwQwKlTQG5u1X0nC0pgsQnoJCA8wFT3wREREXkAJjduwmIBXnlFmdodFgbUqwd07Qp89ll5Gft4mwaBPtDL/OiIiIgccYsacv78+YiNjYWPjw8SEhKwY8cOp2XfffddXHvttQgJCUFISAiSkpKqLe8JrFZg0CDg8ceBjIzy7bt3K9tnzVKec7wNERHR+bk8uVm+fDnS0tIwffp07N69G3FxcUhOTkZOTo7D8ps2bcLdd9+NjRs3Ytu2bYiJicEtt9yCf//9t44jrz0ffgisXKl0SVVksylfp0wBfv+dM6WIiIguhMuTm5dffhkPPPAAUlNT0bZtWyxYsAB+fn5YtGiRw/IfffQRHnroIcTHx6N169Z47733YLPZsH79+jqOvPa8/rpyfyg7fXAhdL6l5c/1wNtvs+WGiIjoQrg0uSktLcWuXbuQlJSkbtPpdEhKSsK2bdsu6ByFhYUwm80IDQ11uL+kpAR5eXmah7v5/ffyVhqdTykajvweEUPK37/FoqxOnJWrrE7MlhsiIiLnXJrcnDx5ElarFREREZrtERERyMrKuqBzPPXUU2jYsKEmQapo9uzZCA4OVh8xMTGXHHdt8/Ut/14fXARJb4MxLB+QrQCUVp2AgIotN76OTkNERERwg26pSzFnzhwsW7YMK1asgI+P49aMSZMmITc3V30cOXKkjqM8v0GDlK4nAND5mNXt9juA22zAHXcAWVzjhoiI6LxcmtyEhYVBlmVkZ2drtmdnZyMyMrLaY+fOnYs5c+Zg3bp16NChg9NyJpMJQUFBmoe7GT9eSW50OkBnKk9u5MBiyDLQpAkweLAob7kJYnJDRETkjEuTG6PRiM6dO2sGA9sHBycmJjo97oUXXsCzzz6LNWvWoEuXLnUR6mXVqhWwahUQGFi55aYITZsCGzYAJTCj1KIMzIlgckNEROSUy7ul0tLS8O677+L999/HH3/8gTFjxqCgoACpqakAgGHDhmHSpElq+eeffx5Tp07FokWLEBsbi6ysLGRlZSE/P99Vb6FW3Hgj8O+/QMq9FnVb6rhi/PknEBUFfPK1Mpi4nskEAxfwIyIicsrltWRKSgrmzp2LadOmIT4+Hunp6VizZo06yDgzMxPHjx9Xy7/11lsoLS3FwIEDERUVpT7mzp3rqrdQa/z9gTYdyltugqOK8corSnKTNkXpksrOMCEuDvj5Z1dFSURE5N4kISovHefd8vLyEBwcjNzcXLccfzP9i9/w/jZlmeIYXQQ2z1a63QLiM1A/+TcU/hWBUyu7wGQCtm0D4uJcGS0REVHdqEn97fKWG9LKKy7vljp0vEj93j5zynrOBzYbUFoKPP10nYdHRETk9pjcuJncIu1sqcrfW84pg4mtVmUQ8smTdRsfERGRu2Ny42byKiY3fqXqQn764EIAgDWvfKaUEICTW3ARERFdsZjcuJm8YrPmudIdJWBooNw2ovRkoLpPkoAGDeoyOiIiIvend3UApJVXZNE8lwOLIaw6yD4WCKsEc1lyI8vAbbcBYWGuiJKIiMh9seXGzdhbbmJClftH6YOKYIxQWm3MpwIAmw6yDBiNwHPPuSxMIiIit8Xkxo2YrTYUlipjbFpFKC00fVOKEdi4rEsqW5n61q4d8MMPQDV3nSAiIrpiMblxI+cqTAO/qiy5ad6+CLcPU5KblFuDsGsXkJ4OeMFdJ4iIiC4LjrlxI/aZUgEmPaJDlG6prNxiHMhWbi0x9LYgdGrhsvCIiIg8Altu3Ih9jZsgHz0aBivJzYHsfGSeVqaBt4lyvxWViYiI3A2TGzdiH0wc5GtAVD1lPRt7YhMV7IMQf6PLYiMiIvIUTG7ciH0aeJCPAVFBvpp9bdlqQ0REdEGY3LiRii03O7boobPJ6j7rqSCUlLgqMiIiIs/B5MaN2AcUp/+sxy23SCg5W36rhU/fDULXrryXFBER0fkwuXEj9pabw38aAACWvPKuqdLsIPz+OzBkiEtCIyIi8hhMbtzImXxlzI21RElurGV3ALeVyLCc9YPVCnz7LbBvn8tCJCIicntMbtzIP8eVlhtbsbL8kKXsDuClJ4IASAAAnQ5Yv94l4REREXkEJjdupKC0LLkpa7kpyawPYZVQ9FeEppzVWuehEREReQyuUOxODPaWGyW5Kc4Mw5F5yRCW8llTNhvQvbtLoiMiIvIITG7cSIFZGXMjmQ3qtoqJjSwrN8vs1q3OQyMiIvIY7JZyI/ap4G1b6CFJgCSV79PpgAYNgE8/1W4nIiIiLSY3bsQ+FXzZ/wx46y0gPh4ICQGaNwdmzAD27lW+JyIiIufYLeUmSixWFJttAICwYAMefBB48EEXB0VEROSB2HLjJs4Vl423kYBAE3NOIiKii8Xkxk3klo23CTDpodNxUA0REdHFYnLjJuyDiYN8DOcpSURERNVhcuMm8sq6pYJ8mdwQERFdCiY3bsLechPsy/E2REREl4LJjZuwTwNntxQREdGlYXLjJvKK2C1FRERUG5jcuImTuUrLTSBbboiIiC4JkxsX++Yb4NprgXlvKsnNO2/o8d//AsXFLg6MiIjIQzG5caEFC4DevYFt2wCdj5LcnDtlwPTpQHIyUFLi4gCJiIg8EJMbF/n3X2DcOOV7qxXQmZQxN7YSA2w2YPNm4PXXXRggERGRh2Jy4yILF2qf21tubMXKmBubDXjjjbqOioiIyPMxuXGRffsAIcqf60xlyU1J+To3GRnsmiIiIqopJjcu4u8P6NSrLyAHFQEArOd81DJ6PWDg5CkiIqIaYXLjIgMGABZlmA10/iXQGWwQArDk+QJQEpt+/SomQERERHQhWHW6SO/eQLt2ShKjD67QamPTQSq7KfhTT7kwQCIiIg/F5MZFZBlYtw5o3x7QBxcCAKy5fpAkwNcX+PRToGtXFwdJRETkgZjcuFBUFLBzJzBqvNJy07SBH954Azh+HOjf37WxEREReSregtrFdDrAFFoIHAIG9/HFQ0mujoiIiMizseXGDRw5o3RLxYT4uTgSIiIiz8fkxg0cOa10S8WEMrkhIiK6VExuXMxqEzh2VkluokN8XRwNERGR52Ny42LHc4tgsQkYZAkRQT7nP4CIiIiqxeTGxexdUo3q+ULWSS6OhoiIyPMxuXExdTAxx9sQERHVCiY3Lnb0tJLcRHOmFBERUa1gcuNiR87YZ0pxMDEREVFt4CJ+teTvM39jb/ZelOb7o4muBxo18EN09PmPO3Kaa9wQERHVJiY3lygzNxMjvxyJb3f9BXw3G/ijD2AzAABatRKIi5MQFgY0aAD06QN06AAYjeXHHz3DNW6IiIhqE5ObS5Cdn43EhYnIyvQD3vkZKA4GhEHdv3+/hP37y8vPmKHcbkGvVx42yYoGY4shScAHb/qiURoQHl7374OIiMibcMzNJZi7dS6y87NhW/t8lcTGGZsNKC0FCgsBi7EIkgTYSmW89qIRnTsDR4/WQeBERERejMnNRRJC4L0978F6rj6wvx90flbUu+F3BCUcgn/7I9D5lZz3HPp6SpeUJdcPVquE48eBBx+83JETERF5N3ZLXSSzzYyzxWeBMwmAkKEPzkNwt8PqfluxHnk/N4McVAR9YDFKs4JQeiII1nwTrIUmQEgwNTwDALDkKjOlLBbgm2+Af/4BYmPr/j0RERF5AyY3F8mgMyDQGIhzPmcBALZCI3K3N4PsVwpjZC6M4edQ79oDannfZiecnstytnwwsRBAejqTGyIioovF5OYiSZKE1PhUvFE6H7bwfbCcaIOzm9qU7RQIiMuE31XZMJ8MgPmsH0xRudDXK4DsXwLZvxQAICw62IoNKPi9kebcJlNdvxsiIiLvIQkhhKuDmD9/Pl588UVkZWUhLi4Or7/+Orp16+a0/KeffoqpU6fin3/+wVVXXYXnn38evXv3vqDXysvLQ3BwMHJzcxEUFHRJcR/NO4qOb3fE6d29YFv2fwAEgEu7P5SfH5CdDQQEXNJpiIiIvEpN6m+XDyhevnw50tLSMH36dOzevRtxcXFITk5GTk6Ow/Jbt27F3XffjREjRmDPnj3o378/+vfvj99++62OIweig6Kx5f4t6HbTMaBfKiBZoCQ4F0eSgIcfZmJDRER0KVzecpOQkICuXbvijTfeAADYbDbExMTg4YcfxsSJE6uUT0lJQUFBAb7++mt12zXXXIP4+HgsWLCgSvmSkhKUlJTPXMrLy0NMTEyttNxUtDd7Lzbv34dXH03CgfRwSJIyfuZCyDJgtQJDhwJLlihr4BAREVG5mrTcuLQaLS0txa5duzBp0iR1m06nQ1JSErZt2+bwmG3btiEtLU2zLTk5GStXrnRYfvbs2Zg5c2atxexMh4gO6BDRAQ/tAX7/HfjwQyAnB6hfXxkcfOwYkJWlfD11SklmfHyAoCCgSRMgNRXo2vWyh0lEROT1XJrcnDx5ElarFREREZrtERER+PPPPx0ek5WV5bB8VlaWw/KTJk3SJEP2lpvLqW1bYNasy/oSRERE5ITXd4CYTCaYOP2IiIjoiuHSAcVhYWGQZRnZ2dma7dnZ2YiMjHR4TGRkZI3KExER0ZXFpcmN0WhE586dsX79enWbzWbD+vXrkZiY6PCYxMRETXkA+Pbbb52WJyIioiuLy7ul0tLSMHz4cHTp0gXdunXDvHnzUFBQgNTUVADAsGHD0KhRI8yePRsA8Oijj+K6667DSy+9hD59+mDZsmXYuXMn3nnnHVe+DSIiInITLk9uUlJScOLECUybNg1ZWVmIj4/HmjVr1EHDmZmZ0OnKG5i6d++OpUuX4umnn8bkyZNx1VVXYeXKlWjXrp2r3gIRERG5EZevc1PXanOFYiIiIqobHrVCMREREVFtYnJDREREXoXJDREREXkVJjdERETkVVw+W6qu2cdP5+XluTgSIiIiulD2evtC5kFdccnNuXPnAOCy31+KiIiIat+5c+cQHBxcbZkrbiq4zWbDsWPHEBgYCEmSavXc9pty/v7772jbti0AqN/bvx45cgQANOUqbnP2vbOy9ulw9te2b6v83JvLOPscvK2Mu8bkThgzOcPrXHcu17UWQuDcuXNo2LChZv07R664lhudTofo6OjL+hqBgYFVvrd/rfhBO9rm7HtnZSv/4FTediWVqcxby7hrTO6EMZMzvM5153Jc6/O12NhxQDERERF5FSY3RERE5FWuuG6py8lkMmH69OkICgrClClTACjNcvZt06dPh8lkAgCn25x9X13Ziq9t31b5uTeXcfY5eFsZd43JnTBmcobXue64w7W+4gYUExERkXdjtxQRERF5FSY3RERE5FWY3BAREZFXYXJDREREXoXJzSWaPXs2unbtisDAQDRo0AA9e/ZE9+7dYTAYIEmS5uHn5wdJktTVFSvvr+5xvvIffPAB5syZA0mSEBMTA39/f5hMJodlg4ODnZ4/NDQUvr6+aN68OTp06AC9Xl+jOO0P+zlGjhyJ2NhY9fxGoxFNmzaFj48PJEmCj48PunfvjsmTJ6vXR5IkyLKsriKdnp4OIQT69+8PWZbVMk2aNEFmZqb6WQwZMgQBAQGaOFauXKnuN5vNSE5Ohq+vr6bMokWLNJ/pjTfeWOXavfDCC5oyzz33HNq1a6eJZ8SIEZoynTp1qnJdOnbsWOU8LVq00JRp0aKF5n05u8YvvviiWmbatGkIDQ3V7B89erTmtXr37q35uQwPD8fatWs1ZebPn49GjRqpZW6//XZkZ2dryjzyyCPo3LkzTCYT4uPjnfxm1J7Kv2P9+/fH/v37NWWuv/76Kten8vuvy7jfeustdOjQQV3ELDExEd988426v7i4GGPHjkX9+vUREBCAO++80+XX2RvY/wY+9thj6jZe69oxY8aMKr9jrVu3Vve723VmcnOJvv/+e4wdOxY//fQTvv32WxQWFmLbtm3qjb0aNGiAvn37AgAsFgsA4MSJE4iNjQUAxMbGwmAwQKfTQa9XZub7+PjAaDSiWbNmCAkJgU6nQ/369QEA7dq1Q9euXdGgQQPExcWpS1APHz4cL730EnQ6HRo3boyFCxciPDwcPj4+8PX1xeTJkwEAH3/8MYqKihAREYFNmzbh4YcfRu/evdUVkD/99FN8+OGHOH78ODIyMtC3b1988sknGDRoEAYMGICJEycCUP54A4C/vz/GjBmD0aNHo127dup12b59O+6//34sXLgQx44dwxtvvIHvvvsON954IzIzM9Upgp988gm6dOmC2bNnQwiBMWPGAACio6PV6wUATz31FL744gu0aNECaWlpAIDc3FzNZ1FUVIRWrVqhadOmDj+rwsJC/PPPP0hISEBCQoK6fdasWZpy9erVQ1JSEuLi4uDj4wNA+cU+ceKEWqa0tBTdu3dH8+bNnd7Gw2azITo6Gh07dlTP8/jjj2vKZGVl4ejRo4iKilLLDB48WP0eAGbOnImUlBR0795dc+ydd96pfr9q1SpYLBa0adNGPfbdd9/Fl19+CUBZtnzjxo0IDg7GXXfdBUCZrtmnTx/k5OSo51m6dCkKCgowcuRINb477rijynu7//77kZKS4vB917bKv2Nmsxm33HILCgoKNOUeeOABHD9+XH1UTkjrMu7o6GjMmTMHu3btws6dO3HjjTeiX79+2LdvHwBg/Pjx+Oqrr/Dpp5/i+++/x7Fjx1x+nT3dzz//jLfffhsdOnTQbOe1rj1XX3215nds8+bN6j63u86CatWDDz4oAIg2bdoIAOI///mPEEIIACIhIUEAEMOHD1e3ffjhh0Kn06n7AIhXXnlFABDff/+9yMrKEgBEdHS0MBgMQpZl4e/vLz744AMhhBCBgYECgNDpdCIyMlI0btxYjBkzRlx11VXi22+/FU2aNBFhYWFi48aNAoDo0qWLuPbaa0VcXJwa81NPPSXat28vAIgzZ86IhIQE0b17d9GzZ88q7+/w4cMCgBgyZIgICAgQQ4cOVffFxsYKPz8/zXn8/f1F8+bN1TKFhYVCkiT1/e7Zs0fceeedAoAYPHiwel1WrFgh2rVrJwCI3bt3Cx8fH9GpUyf1PACEXq8XH3/8cZUYX3zxRfVarlixwuHnZL8e9kdGRkaVMosXLxbBwcFqme+++06z/+jRoyIkJEQEBAQIAOL+++/X7B8+fLjo16+f5jyV40lJSRH33HNPtWUcxdy+fXvNvquvvlo888wzmvM0a9ZMTJkyRQghxP79+wUA8dtvv6nnsW+bMGGCEEKIs2fPCoPBID799FO1zPbt2wUAsW3btirxTJ8+XfNzVFdycnLU3w+76667Tjz66KMXdLyr4g4JCRHvvfee5jrb/fHHH253nT3JuXPn1L95FX8WeK1rT3XXxh2vM1tuatnSpUsBKF0gALBx40a8++67AJSbaAJAXFycWt7eRVJUVKRumz9/PgAgNDRUvYv52bNnYTabYbVaASgtCfPnz0dxcTEApesiKysLRqMRixcvxtGjR/Hss8+iuLgYZ8+excCBAwEAO3fuhE6nw6+//gpZluHr64s33nhDvd9W8+bNsX37dvz22284dOiQ2orUsmVL9X0ASktBaWkpWrVqheTkZISHhyMzMxM2mw2A0jq1fft2mM1mZGRkoH79+rjuuuuwZMkSCCHQqVMnAErrxpo1awAAq1evRoMGDQAoLT/2FogjR46guLgYCQkJSE5OVstERkZi27Ztl/R52dWrV8/hdlHWAufn56f53Gw2G+69917ceuutkGXZ6Xk3bdqERx55RP0c7V/t51i1ahVatmyJuXPnIi8vD4Dy3s8nKSlJ87x79+748ssvcebMGTXmY8eO4ZZbbgEAlJSUAICmRSg/Px8A1C6eXbt2wWw2a87dsmVLNG7cuNauc22wt9iFhoZqtn/00UcICwtDu3btMGnSJBQWFroivCqsViuWLVuGgoICJCYmOrzOrVu3drvr7EnGjh2LPn36VPm94LWuXX/99RcaNmyIZs2aYejQoWr3uTteZyY3tWjp0qU4d+4cJElSk4mCggKMGjUKAJCYmAhAe+OvH374AVarFXv37oUsywgNDVX7Kbds2YKWLVsCULpUgoKCcMcdd8BiseDvv//GuHHj1CRq+vTpAIC///4bsixjw4YN6NSpE7Kzs9GjRw88//zzmtdMTU3F0qVLceutt6KgoEAdD/Df//4XgHJX15ycHAwZMgSDBg3C33//jYcffhj/93//B0CppEtLSzFnzhzceuutmDBhAoQQarLVpk0bAMqNSm+++WacOXMGmzdvxkMPPYSoqCjs3r0bgJIE2bsXSkpK8OGHHwKA2qQPAIcPHwYALFmyBLfeeivWrVsHADh69Ch+/fXXS/vQAFx77bVVbu729ddfY/To0WrCMWPGDISFhan7n3/+eej1etx8881Oz3vrrbfigw8+wIQJE9Sk4plnnlET1JycHOTn52POnDlo3749/P391ff+/fffVxvzNddco3n++uuvo23btkhLS1NjHjVqFHr16gWg/A/NpEmT1ATL3j1l/8zsyXHlRC8iIgJZWVnVxlNXbDYbHnvsMfTo0UPTDTpkyBB8+OGH2LhxIyZNmoT//e9/uOeee1wYKfDrr78iICAAJpMJo0ePxooVK9C2bVuPuM6eZNmyZdi9ezdmz55dZR+vde1JSEjAkiVLsGbNGrz11ls4fPgwrr32Wpw7d84trzOTm1py5MgRdZxCp06d1P/yO3bsiLvvvhuAklRU1qpVKwBKEjBw4EAUFxerlc3o0aNhMBgQHx8Pg8GAoqIiTJo0CYMGDVLH7NjNmTNH/b5fv3645ppr8Morr8Df3x8FBQVo3ry5ut9oNCIxMREpKSlYsWIFAKjjRpo1a6Y+9/X1xaJFi/DRRx+hbdu2aNeuHT766CMAQNeuXdXXGj9+PNavX4/4+HgYjUYAwBtvvAFA+a91+/btWLp0KdLT0xEdHY1Tp06p41d69+4NAGjYsCH0ej2Sk5MBKC0lDRs2BAC1NSg5ORnjx49XB6KFhITg4MGD5/9wHKg4nqfywFMAuOGGGzBz5kw14XjxxRfVsSm7du3Cq6++iiVLljgdbwMoycPtt9+OmJgYGAwGAMDBgwexadMmzfvq168fkpOT1RagLl26YMGCBdXGb7/Odq+//jp++uknPProowgICAAAvPPOO/juu+8AAAaDAZ9//jkOHDiA22+/HYDyM3v99der47Y8wdixY/Hbb79h2bJlmu2jRo1CcnIy2rdvj6FDh+KDDz7AihUrcOjQIRdFqvxup6enY/v27RgzZgyGDx+utt5S7Thy5AgeffRRfPTRR5pWSap9t912GwYNGoQOHTogOTkZq1evxtmzZ/HJJ5+4OjSHPOevmpt78MEH1a6l3bt3qwnNnj171D/E9v/yKw6E/eKLLwAAHTp0QFhYGEpLS/Hoo4+iQ4cOMBgM2LlzJw4ePIjw8HD07NkTL730Ej788MMqP1D2JnibzYalS5dCkiTo9XoUFBRg586duOmmm9SyDRs21CQFfn5+6mDmyMhIdZu98gWUlhidTocjR44AAAYOHAi9Xo+2bdsiIyMD3333HTIzM9G+fXsA5a1Uer0eer0ed911F9q3b4/u3btrRth//fXX0Ov1CA0NxQ033KB2lSQnJ6stOvYBwvZkx06n02mSlAtlNpsxc+ZMzfuvzN/fHxEREep1kWUZCxcuBAD8+OOPyMnJQePGjTFixAj181y8eHGVpLOywMBA9dqHhYWp17CimJgYzWwpu7179zo8Z1FRESZPnoyXX34Z8fHxapLUo0cPzJ07Vy3XuXNnpKeno0+fPgCAn376CYWFhWpCGxkZidLSUpw9e1Zz/uzsbPXnwpXGjRuHr7/+Ghs3blS7UZ2xDxi/2OS3NhiNRrRo0QKdO3fG7NmzERcXh1dffdXtr7Mn2bVrF3JyctCpUyf1b83333+P1157DXq9HhEREbzWl0m9evXQsmVLHDx40C1/ppncXCIhBMaNG4c9e/bg66+/xm233YaOHTuqXU/XXXcdhg4dCgBq18fevXvVcRE7duwAoPwQrFixApGRkfj+++9x4MAB3HjjjRg2bBjy8/PVcTj2JObAgQMAyiv+Ll26wGQyISwsDP/5z3/w+eefIz09Hb6+vrj66qvx3nvvAVCaCY8fP46oqCj1PRgMBjVJaNy4MRo2bAiTyaQZS2J/PXtlf/3116Nr167Yv38/Fi9ejAYNGkAIgTNnzmjOYzab1fdqP09ISIiaOEVFRaFjx47Yv38/+vXrp7aUZGRkqIlOkyZNYDAY8NNPP2mu/enTp53OjHLGbDZj8ODBOHr0aI2OE0Ko41buvfde7N27F+np6Zg5c6baUtK/f/8qU6srO3funHrtjUajeg0r+vfff9GkSZMqx65evdrpezKbzVVaYGRZ1iSo9p9V+5gei8WCnTt3ol+/fgCU5MdgMGD9+vXqMX/99RcyMzPVZNUV7HGvWLECGzZsuKDPPD09HQA0P+euZrPZUFJS4vA679+/3+XX2RPddNNN+PXXX5Genq4+unTpgqFDh6rf81pfHvn5+Th06BCioqLc82f6sg5XvgKMGTNGBAcHi02bNonjx4+Lzz//XMiyLFq2bCkAiPDwcCHLsgAgfHx8BABhMBjU2UlRUVHCYDAIAKJVq1bqfgAiNDRUyLIs2rVrJ7p06SIAiIcffliEh4cLg8EgQkJChCRJ6gyaAQMGCFmWRe/evcVff/0lnn76aQFAJCYmitmzZwsAIiYmRj3Pxo0bxeDBgzWzhpYuXSr69OmjzsBKS0sTDz30kNDr9cJoNKqzs5YtWyZeeuklodfrRWhoqLjnnnvU2U0AxPLly0W/fv3U9/3OO++IcePGCb1eL/z8/ESPHj0EADF58mTRsGFDdbbUO++8o54jMjJSfS17TIMHDxavvfaaWmbBggXqTKdffvlFLFmyRNx2223q/nvvvVd8+eWXIiMjQ5SWlork5GQRHh4uRo0apZYZPXq0+Pbbb0VGRobIz88XY8eOFW+//bYYOnSoMJlMAoCQZVl8+OGH6mtlZGSILVu2iNGjRwtfX18BQFx//fViy5YtIiMjQ5w7d06MGjVKvP3222LIkCHCaDQKAKJevXpi48aN6nnefvttIcuy6NWrl/rzIUmSePPNN9Uyx48fF2vXrhV6vV6N+fHHHxebNm1Sy1xzzTWiadOmom/fvup5ZFkWTzzxhFrmuuuuE76+vmLkyJHqz2aPHj3E0aNH1Z/nYcOGicjISPH4448LAOLqq68WHTp0EKdOnVLL/PXXX2LPnj3iwQcfFC1bthR79uwRe/bsESUlJXXyO2Z/FBYWCiGEOHjwoHjmmWfEzp07xeHDh8UXX3whmjVrJnr16qU5T13GPXHiRPH999+Lw4cPi71794qJEycKSZLEunXrhBBCjB49WjRu3Fhs2LBB7Ny5UyQmJorExESXxetNKs+c47WuHfa/OYcPHxZbtmwRSUlJIiwsTOTk5Agh3O86M7m5RBUTg7p8VExqKj7CwsJEQECA8PPzE4mJiWpF5+x4e+JV+dGpUydRv359IUmSkCRJ1K9f32G5a665Rk2EHO2/6qqrhL+/v3qeevXqOSzXvHnz877n6Ohoh9vtU+vtCZOzMvZp7NWVKSoqEo0bN662jBDKNO/qyhQWFqpJ26WcRwhl2uT5ylROUh2VcbZ/xIgR6s/zlClTHJZZvHixWua6665zWObw4cN1+jtmjykzM1P06tVLhIaGCpPJJFq0aCEmTJggcnNzNeepy7jvv/9+0aRJE2E0GkV4eLi46aab1MRGCCGKiorEQw89JEJCQoSfn58YMGCAOH78uMvi9SaVkxte69qRkpIioqKihNFoFI0aNRIpKSni4MGD6n53u86SEBX6DIiIiIg8HMfcEBERkVdhckNERERehckNEREReRUmN0RERORVmNwQERGRV2FyQ0RERF6FyQ0RERF5FSY3RERE5FWY3BCRWxBCYNSoUQgNDYUkSUhPT8f111+Pxx57TC0TGxuLefPmXdY41q9fjzZt2sBqtV6W8993333o37//BZcvLS1FbGwsdu7ceVniIfJGTG6IrkD33XcfJEnCnDlzNNtXrlwJSZJcEtOaNWuwZMkSfP311zh+/DjatWuHzz//HM8++2ydxvHkk0/i6aefVm8cO2PGDMTHx9fa+V999VUsWbLkgssbjUY88cQTeOqpp2otBiJvx+SG6Arl4+OD559/Xr2Tu6vZ7zDcvXt3REZGQq/XIzQ0FIGBgXUWw+bNm3Ho0CHceeedNT7WbDZfULng4GDUq1evRuceOnQoNm/ejH379tU4LqIrEZMboitUUlISIiMjMXv2bKdlHLVazJs3D7GxsepzezfLrFmzEBERgXr16uGZZ56BxWLBhAkTEBoaiujoaCxevNjp69x33314+OGHkZmZCUmS1PNX7paq7OzZsxg5ciTCw8MRFBSEG2+8Eb/88ou6/5dffsENN9yAwMBABAUFoXPnztV27yxbtgw333wzfHx8AABLlizBzJkz8csvv0CSJEiSpLa6SJKEt956C7fffjv8/f3x3HPPwWq1YsSIEWjatCl8fX3RqlUrvPrqq1Xea8Vuqeuvvx6PPPIInnzySYSGhiIyMhIzZszQHBMSEoIePXpg2bJlTmMnonJ6VwdARK4hyzJmzZqFIUOG4JFHHkF0dPRFn2vDhg2Ijo7GDz/8gC1btmDEiBHYunUrevXqhe3bt2P58uV48MEHcfPNNzt8nVdffRXNmzfHO++8g59//lntEjqfQYMGwdfXF9988w2Cg4Px9ttv46abbsKBAwcQGhqKoUOHomPHjnjrrbcgyzLS09NhMBicnu/HH3/EkCFD1OcpKSn47bffsGbNGnz33XcAlJYXuxkzZmDOnDmYN28e9Ho9bDYboqOj8emnn6J+/frYunUrRo0ahaioKAwePNjp677//vtIS0vD9u3bsW3bNtx3333o0aMHbr75ZrVMt27d8OOPP17QdSG60jG5IbqCDRgwAPHx8Zg+fToWLlx40ecJDQ3Fa6+9Bp1Oh1atWuGFF15AYWEhJk+eDACYNGkS5syZg82bN+Ouu+6qcnxwcDACAwMhyzIiIyMv6DU3b96MHTt2ICcnByaTCQAwd+5crFy5Ep999hlGjRqFzMxMTJgwAa1btwYAXHXVVdWeMyMjAw0bNlSf+/r6IiAgAHq93mFcQ4YMQWpqqmbbzJkz1e+bNm2Kbdu24ZNPPqk2uenQoQOmT5+uxvjGG29g/fr1muSmYcOGyMjIqDZ+IlKwW4roCvf888/j/fffxx9//HHR57j66quh05X/OYmIiED79u3V57Iso379+sjJybmkWCv65ZdfkJ+fj/r16yMgIEB9HD58GIcOHQIApKWlYeTIkUhKSsKcOXPU7c4UFRWpXVIXokuXLlW2zZ8/H507d0Z4eDgCAgLwzjvvIDMzs9rzdOjQQfM8KiqqyrXy9fVFYWHhBcdGdCVjckN0hevVqxeSk5MxadKkKvt0Oh2EEJptjgbOVu7qkSTJ4TabzVYLESvy8/MRFRWF9PR0zWP//v2YMGECAKXbaN++fejTpw82bNiAtm3bYsWKFU7PGRYWVqMB1v7+/prny5YtwxNPPIERI0Zg3bp1SE9PR2pqKkpLS6s9z4Vcq9OnTyM8PPyCYyO6krFbiogwZ84cxMfHo1WrVprt4eHhyMrKghBCnSKenp7uggir6tSpE7KysqDX6zUDnCtr2bIlWrZsifHjx+Puu+/G4sWLMWDAAIdlO3bsiN9//12zzWg0XvCaN1u2bEH37t3x0EMPqdvO11p0oX777Td07NixVs5F5O3YckNEaN++PYYOHYrXXntNs/3666/HiRMn8MILL+DQoUOYP38+vvnmGxdFqZWUlITExET0798f69atwz///IOtW7diypQp2LlzJ4qKijBu3Dhs2rQJGRkZ2LJlC37++We0adPG6TmTk5OxefNmzbbY2FgcPnwY6enpOHnyJEpKSpwef9VVV2Hnzp1Yu3YtDhw4gKlTp+Lnn3+ulff7448/4pZbbqmVcxF5OyY3RAQAeOaZZ6p0hbRp0wZvvvkm5s+fj7i4OOzYsQNPPPGEiyLUkiQJq1evRq9evZCamoqWLVvirrvuQkZGBiIiIiDLMk6dOoVhw4ahZcuWGDx4MG677TbNgN/Khg4din379mH//v3qtjvvvBO33norbrjhBoSHh+Pjjz92evyDDz6IO+64AykpKUhISMCpU6c0rTgXa9u2bcjNzcXAgQMv+VxEVwJJVO5QJyK6gk2YMAF5eXl4++23XR2KKiUlBXFxcersMyKqHltuiIgqmDJlCpo0aVKrg58vRWlpKdq3b4/x48e7OhQij8GWGyIiIvIqbLkhIiIir8LkhoiIiLwKkxsiIiLyKkxuiIiIyKswuSEiIiKvwuSGiIiIvAqTGyIiIvIqTG6IiIjIqzC5ISIiIq/y/9BxasVUJZwnAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/feet-14/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "FIB_FLAG = True\n",
    "PREV_NUM = 10\n",
    "THRESHOLD = 0.001\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "# exp_inc.train_test_val_split(KEEP_PERC)\n",
    "# cls_tl_dict, cls_fif_dict = exp_inc.take_piece(PIECE_PERC, FIB_FLAG)\n",
    "exp_inc.increm_learning(KEEP_PERC, ITERS, PIECE_PERC, FIB_FLAG, PREV_NUM, THRESHOLD)\n",
    "exp_inc.plot_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fbf2a7",
   "metadata": {
    "papermill": {
     "duration": 4.367353,
     "end_time": "2023-11-29T04:21:02.614339",
     "exception": false,
     "start_time": "2023-11-29T04:20:58.246986",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Сравнение базового и инкрементального обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea25bb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.850572Z",
     "iopub.status.idle": "2023-11-08T18:23:06.850969Z",
     "shell.execute_reply": "2023-11-08T18:23:06.850802Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.850768Z"
    },
    "papermill": {
     "duration": 4.364885,
     "end_time": "2023-11-29T04:21:11.428394",
     "exception": false,
     "start_time": "2023-11-29T04:21:07.063509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "PATH_TO_MODEL = \"/kaggle/working/yolov8m-seg.pt\"\n",
    "PATH_TO_YAML = \"/kaggle/working/feet-14/data.yaml\"\n",
    "TRAIN_PERC = 0.8\n",
    "TEST_PERC = 0.1\n",
    "VAL_PERC = 0.1\n",
    "KEEP_PERC = 1.0\n",
    "PIECE_PERC = 0.05\n",
    "ITERS = 5\n",
    "\n",
    "result_dict_base = dict()\n",
    "result_dict_inc = dict()\n",
    "color_dict_inc = dict()\n",
    "\n",
    "exp_base = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC)\n",
    "result_dict_base = exp_base.base_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_base.plot_ram_usage()\n",
    "del(exp_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7593a118",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.852484Z",
     "iopub.status.idle": "2023-11-08T18:23:06.852881Z",
     "shell.execute_reply": "2023-11-08T18:23:06.852713Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.852691Z"
    },
    "papermill": {
     "duration": 4.357829,
     "end_time": "2023-11-29T04:21:19.955508",
     "exception": false,
     "start_time": "2023-11-29T04:21:15.597679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "exp_inc = YoloModel(PATH_TO_MODEL, PATH_TO_YAML, TRAIN_PERC, TEST_PERC, VAL_PERC, 1, 1)\n",
    "result_dict_inc, color_dict_inc = exp_inc.increm_learning(KEEP_PERC, PIECE_PERC, ITERS)\n",
    "exp_inc.plot_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c138edba",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.854063Z",
     "iopub.status.idle": "2023-11-08T18:23:06.854396Z",
     "shell.execute_reply": "2023-11-08T18:23:06.854260Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.854245Z"
    },
    "papermill": {
     "duration": 4.369885,
     "end_time": "2023-11-29T04:21:28.685707",
     "exception": false,
     "start_time": "2023-11-29T04:21:24.315822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import math \n",
    "\n",
    "map_base_list = [j[0] for j in result_dict_base.values()]\n",
    "map_inc_list = [j[0] for j in result_dict_inc.values()]\n",
    "mse = 0\n",
    "for map_base, map_inc in zip(map_base_list, map_inc_list):\n",
    "    dev = (map_base - map_inc)\n",
    "    mse += dev**2\n",
    "print(f\"MSE = {mse}\\nRMSE = {math.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eba491",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.856319Z",
     "iopub.status.idle": "2023-11-08T18:23:06.856674Z",
     "shell.execute_reply": "2023-11-08T18:23:06.856526Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.856509Z"
    },
    "papermill": {
     "duration": 4.641721,
     "end_time": "2023-11-29T04:21:37.487996",
     "exception": false,
     "start_time": "2023-11-29T04:21:32.846275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "metrics_names = (\"mAP\",\"mAP50\", \"mAP75\")\n",
    "for i, metric in enumerate(metrics_names):\n",
    "    plt.plot(list(result_dict_base.keys()),\n",
    "             [j[i] for j in result_dict_base.values()],\n",
    "             marker='o',\n",
    "             color=\"green\",\n",
    "             linestyle='-',\n",
    "             zorder=0,\n",
    "             label = \"Базовое обучение\")\n",
    "    \n",
    "    plt.scatter(list(result_dict_inc.keys()),\n",
    "                [j[i] for j in result_dict_inc.values()],\n",
    "                color=list(color_dict_inc.values()),\n",
    "                zorder=1)\n",
    "    plt.plot(list(result_dict_inc.keys()),\n",
    "             [j[i] for j in result_dict_inc.values()],\n",
    "             linestyle='-',\n",
    "             label = \"Инкрементальное обучение\")\n",
    "    \n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"Keep percent (%)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278f69c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-08T18:23:06.858132Z",
     "iopub.status.idle": "2023-11-08T18:23:06.858483Z",
     "shell.execute_reply": "2023-11-08T18:23:06.858342Z",
     "shell.execute_reply.started": "2023-11-08T18:23:06.858326Z"
    },
    "papermill": {
     "duration": 4.470066,
     "end_time": "2023-11-29T04:21:46.499507",
     "exception": false,
     "start_time": "2023-11-29T04:21:42.029441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "num_folders = 1 / PIECE_PERC\n",
    "for folder in range(int(num_folders)):\n",
    "    dir_path = f\"temp_{folder+1}/train/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/train/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/labels\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))\n",
    "    dir_path = f\"temp_{folder+1}/valid/images\"\n",
    "    print(dir_path, len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]), '\\n')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39170.893971,
   "end_time": "2023-11-29T04:21:58.606107",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-28T17:29:07.712136",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
